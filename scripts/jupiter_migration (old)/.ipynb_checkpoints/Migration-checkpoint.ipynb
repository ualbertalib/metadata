{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  MAIN CONTROLLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from config import sparqlTerms, mig_ns, sparql_mig_test, sparql_mig_simple, sparql_mig_dev, vocabs, types\n",
    "from SPARQLWrapper import JSON, SPARQLWrapper\n",
    "from utilities import removeNS, PrintException, cleanOutputs\n",
    "import re, os, concurrent.futures, json, requests, time, datetime\n",
    "from rdflib import URIRef, Literal, Namespace, Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(datetime.datetime.fromtimestamp(time.time()).strftime('%H:%M:%S'))\n",
    "    sparqlData=sparql_mig_simple\n",
    "    #  Iterate over every type of object that needs to be migrated. \n",
    "    #  This is the first splitting of the data for migration.\n",
    "    cleanOutputs(types)\n",
    "    for objectType in types:\n",
    "        # a queryObject knows where it came from.\n",
    "        # a queryObject has been split into multiple groups\n",
    "        # only one group exists for community, and one for collection objects\n",
    "        # approximately a thousand queries each are minted for thesis and for generic objects\n",
    "        # these queries are based on the first folder in the fedora pair tree\n",
    "        queryObject = QueryFactory.getMigrationQuery(objectType, sparqlData)\n",
    "        queryObject.generateQueries()\n",
    "        print('%s queries generated' % (objectType))\n",
    "        print('%i queries of %s objects to be transformed' % (len(queryObject.queries), objectType))\n",
    "        i = 0\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "            \n",
    "            future_to_result = {executor.submit(parellelTransform, queryObject, group): group for group in queryObject.queries.keys()}\n",
    "            for future in concurrent.futures.as_completed(future_to_result):\n",
    "                result = future_to_result[future]\n",
    "                try:\n",
    "                    i = i + 1\n",
    "                    future.result()\n",
    "                    print(\"%i of %i %s queries transformed\" % (i, len(queryObject.queries), objectType) )\n",
    "                except Exception:\n",
    "                    PrintException()\n",
    "        #queryObject.postResults()\n",
    "        print(\"%s objects transformation completed\" % (objectType) )\n",
    "        del queryObject\n",
    "    print(datetime.datetime.fromtimestamp(time.time()).strftime('%H:%M:%S'))\n",
    "\n",
    "def parellelTransform(queryObject, group):\n",
    "    DTO = Data(queryObject.queries[group], group, queryObject.sparqlData, sparqlTerms, queryObject) # query, group, object\n",
    "    DTO.transformData()\n",
    "    DTO.resultsToTriplestore()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  TRANSFORMATIONS\n",
    "#### functions for handling data passed over by the data object. Takes a triple, detects what kind of action needs to be taken based on the predicate, sends it to the appropriate function for transformations, then returns it back to the data handler to be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Transformation():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.output = []\n",
    "       \n",
    "    ############################################################################\n",
    "    ######################## transformation on dcterms:language ################\n",
    "    ############################################################################\n",
    "\n",
    "    def language(self, triple, objectType):\n",
    "        # normalize values and convert to URI (consult the \"vocabs\" variable from the config file (this folder))\n",
    "        for vocab in vocabs[\"language\"]:\n",
    "            # mint a new triple with the mapped type\n",
    "            if triple['object']['value'] in  vocab[\"mapping\"]:\n",
    "                self.output.append(\n",
    "                    {\n",
    "                            'subject': {\n",
    "                                'value': triple['subject']['value'], # the subject of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'predicate': {\n",
    "                                'value': triple['predicate']['value'], # the predicate of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'object': {\n",
    "                                'value': vocab[\"uri\"], # mapped uri\n",
    "                                'type': 'uri'\n",
    "                            }\n",
    "                        } \n",
    "                    ) \n",
    "        return self.output\n",
    "\n",
    "\n",
    "    ############################################################################\n",
    "    ######################## transformation on dc:rights #######################\n",
    "    ############################################################################\n",
    "    \n",
    "    \n",
    "    def rights(self, triple, objectType):\n",
    "        #### \n",
    "        # several different license values need to be coerced into one common value, this needs to be confirmed with leah before it is written\n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "\n",
    "    ############################################################################\n",
    "    ######################## transformation on dc:license ######################\n",
    "    ############################################################################\n",
    "    \n",
    "    \n",
    "    def license(self, triple, objectType):\n",
    "        #### \n",
    "        \n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "    \n",
    "    ############################################################################\n",
    "    ######################## transformation on acl:visibilityAfterEmbargo ######################\n",
    "    ############################################################################\n",
    "    \n",
    "    \n",
    "    def aclvisibilityAfterEmbargo(self, triple, objectType):\n",
    "        if (\"open\" in triple['object']['value']) or (\"open access\" in triple['object']['value']):\n",
    "            triple['object']['value'] = \"http://terms.library.ualberta.ca/public\"\n",
    "            triple['object']['type'] = 'uri'\n",
    "            self.output.append(triple)\n",
    "            return self.output            \n",
    "        elif \"university_of_alberta\" in triple['object']['value']:\n",
    "            triple['object']['value'] = \"http://terms.library.ualberta.ca/authenticated\"\n",
    "            triple['object']['type'] = 'uri'\n",
    "            self.output.append(triple)\n",
    "            return self.output\n",
    "    \n",
    "    ############################################################################\n",
    "    ######################## transformation on ual:institution #################\n",
    "    ############################################################################\n",
    "\n",
    "    def institution(self, triple, objectType):\n",
    "        self.output.append(\n",
    "            {\n",
    "            'subject': {\n",
    "                'value': triple['subject']['value'], \n",
    "                'type': 'uri'\n",
    "            }, \n",
    "            'predicate': {\n",
    "                'value': triple['predicate']['value'], \n",
    "                'type': 'uri'\n",
    "            }, \n",
    "            'object': {\n",
    "                'value': 'http://id.loc.gov/authorities/names/n79058482', \n",
    "                'type': 'uri'\n",
    "            }\n",
    "        }\n",
    "        )\n",
    "        return self.output\n",
    " \n",
    "\n",
    "    ############################################################################\n",
    "    ######################## transformation on dcterms:license #################\n",
    "    ############################################################################\n",
    "\n",
    "    \n",
    "    def license(self, triple, objectType):\n",
    "        #### \n",
    "        # convert licenses from text to URI (use vocabs variable, some coersion will be necessary)\n",
    "        if \"I am required to use/link to a publisher's license\" in triple['object']['value']:\n",
    "            return None\n",
    "        else:\n",
    "            for vocab in vocabs[\"license\"]:\n",
    "                if triple['object']['value'] in vocab[\"mapping\"]:\n",
    "                    self.output.append(\n",
    "                        {\n",
    "                            'subject': {\n",
    "                                'value': triple['subject']['value'], # the subject of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'predicate': {\n",
    "                                'value': triple['predicate']['value'], # the predicate of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'object': {\n",
    "                                'value': vocab[\"uri\"], # mapped uri\n",
    "                                'type': 'uri'\n",
    "                            }\n",
    "                        }\n",
    "                    )\n",
    "            if len(self.output)>0:\n",
    "                return self.output\n",
    "            else:\n",
    "                self.output.append(\n",
    "                    {\n",
    "                        'subject': {\n",
    "                            'value': triple['subject']['value'], # the subject of the triple\n",
    "                            'type': 'uri'\n",
    "                        }, \n",
    "                        'predicate': {\n",
    "                            'value': \"http://purl.org/dc/elements/1.1/rights\", # the predicate of the triple\n",
    "                            'type': 'uri'\n",
    "                        }, \n",
    "                        'object': {\n",
    "                            'value': triple['object']['value'], # mapped uri\n",
    "                            'type': 'literal'\n",
    "                        }\n",
    "                    }\n",
    "                )\n",
    "                return self.output\n",
    "    \n",
    "    ############################################################################\n",
    "    ######################## transformation on dcterms:type ####################\n",
    "    ############################################################################\n",
    "    \n",
    "    def type(self, triple, objectType):\n",
    "        if objectType == 'generic':\n",
    "            for vocab in vocabs[\"type\"]:\n",
    "                # mint a new triple with the mapped type\n",
    "                if triple['object']['value'] in vocab[\"mapping\"]:\n",
    "                    self.output.append(\n",
    "                        {\n",
    "                            'subject': {\n",
    "                                'value': triple['subject']['value'], # the subject of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'predicate': {\n",
    "                                'value': triple['predicate']['value'], # the predicate of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'object': {\n",
    "                                'value': vocab[\"uri\"], # mapped uri\n",
    "                                'type': 'uri'\n",
    "                            }\n",
    "                        }\n",
    "                    )\n",
    "     \n",
    "            else:\n",
    "                pass\n",
    "        elif (objectType == 'community') or (objectType == 'collection'):\n",
    "            self.output.append(triple)\n",
    "        \n",
    "        return self.output\n",
    "        \n",
    "    def modelsmemberOf(self, triple, objectType):\n",
    "        if \"http\" not in triple['object']['value']:\n",
    "            value = triple['object']['value']\n",
    "            triple['object']['value'] = \"http://gillingham.library.ualberta.ca:8080/fedora/rest/prod/%s/%s/%s/%s/%s\" % (value[0:2], value[2:4], value[4:6], value[6:8], value)\n",
    "            triple['object']['type'] = 'uri'\n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "\n",
    "    def modelshasMember(self, triple, objectType):\n",
    "        if \"http\" not in triple['object']['value']:\n",
    "            value = triple['object']['value']\n",
    "            triple['object']['value'] = \"http://gillingham.library.ualberta.ca:8080/fedora/rest/prod/%s/%s/%s/%s/%s\" % (value[0:2], value[2:4], value[4:6], value[6:8], value)\n",
    "            triple['object']['type'] = 'uri'\n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "    \n",
    "    def accessRights(self, triple, objectType):\n",
    "        if \"http://projecthydra.org/ns/auth/group#public\" in triple['object']['value']:\n",
    "            triple['object']['value'] = \"http://terms.library.ualberta.ca/public\"\n",
    "            triple['object']['type'] = 'uri'\n",
    "            self.output.append(triple)\n",
    "            return self.output            \n",
    "        elif (\"http://projecthydra.org/ns/auth/group#university_of_alberta\" in triple['object']['value']) or (\"http://projecthydra.org/ns/auth/group#registered\" in triple['object']['value']):\n",
    "            triple['object']['value'] = \"http://terms.library.ualberta.ca/authenticated\"\n",
    "            triple['object']['type'] = 'uri'\n",
    "            self.output.append(triple)\n",
    "            return self.output \n",
    "        else:\n",
    "            triple['object']['value'] = \"http://terms.library.ualberta.ca/private\"\n",
    "            triple['object']['type'] = 'uri'\n",
    "            self.output.append(triple)\n",
    "            return self.output\n",
    "    \n",
    "    def available(self, triple, objectType):\n",
    "        self.output.append(triple)\n",
    "        self.output.append(\n",
    "                        {\n",
    "                            'subject': {\n",
    "                                'value': triple['subject']['value'], # the subject of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'predicate': {\n",
    "                                'value': \"http://purl.org/dc/terms/accessRights\", # the predicate of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'object': {\n",
    "                                'value':\"http://terms.library.ualberta.ca/public\", # mapped uri\n",
    "                                'type': 'uri'\n",
    "                            }\n",
    "                        }        \n",
    "        )\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  QUERY BUILDER\n",
    "##### Pulls current mappings from triplestore, dynamically builds queries in managable sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Query(object):\n",
    "    \"\"\" Query objects are dynamically generated, and contain SPARQL CONSTRUCT queries with input from the jupiter application profile \"\"\"\n",
    "    def __init__(self, objectType, sparqlData, sparqlTerms=sparqlTerms):\n",
    "        self.mapping = []\n",
    "        self.sparqlTerms = SPARQLWrapper(sparqlTerms)  # doesn't need to change (the terms store doesn't change)\n",
    "        self.sparqlData = SPARQLWrapper(sparqlData)  # sets the triple store from which to get data (simple, test, or dev)\n",
    "        self.sparqlResults = SPARQLWrapper(\"http://206.167.181.123:9999/blazegraph/namespace/results/sparql\")\n",
    "        self.sparqlTerms.setMethod(\"POST\")\n",
    "        self.sparqlData.setMethod(\"POST\")\n",
    "        self.sparqlResults.setMethod(\"POST\")\n",
    "        self.queries = {}\n",
    "        self.splitBy = {}\n",
    "        self.prefixes = \"\"\n",
    "        self.filename = \"\"\n",
    "        for ns in mig_ns:\n",
    "            self.prefixes = self.prefixes + \" PREFIX %s: <%s> \" % (ns['prefix'], ns['uri'])\n",
    "        self.getMappings()\n",
    "        \n",
    "\n",
    "    \n",
    "    def postResults(self):\n",
    "        directory = 'results/%s' % (self.objectType)\n",
    "        for (dirpath, dirnames, filenames) in os.walk(directory):\n",
    "            for filename in filenames:\n",
    "                with open(os.path.join(dirpath, filename), 'rb') as f:\n",
    "                    query = \"INSERT DATA {%s}\" % (f.read())\n",
    "                    self.sparqlResults.setReturnFormat(JSON)\n",
    "                    self.sparqlResults.setQuery(query)\n",
    "                    self.sparqlResults.query()                        \n",
    "                \n",
    "    \n",
    "    def getMappings(self):\n",
    "        if (self.objectType == 'collection') or (self.objectType == 'community') or (self.objectType == 'generic') or (self.objectType ==  'thesis'):\n",
    "            query = \"prefix ual: <http://terms.library.ualberta.ca/>SELECT * WHERE {GRAPH ual:%s {?newProperty ual:backwardCompatibleWith ?oldProperty} }\" % (self.objectType)\n",
    "            self.sparqlTerms.setReturnFormat(JSON)\n",
    "            self.sparqlTerms.setQuery(query)\n",
    "            results = self.sparqlTerms.query().convert()\n",
    "            for result in results['results']['bindings']:\n",
    "                self.mapping.append((result['newProperty']['value'], result['oldProperty']['value']))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def getSplitBy(self):\n",
    "        # base query only needs 3 prefixes appended to the \"select\" statement defined by the object\n",
    "        query = \"prefix dcterm: <http://purl.org/dc/terms/> prefix info: <info:fedora/fedora-system:def/model#> prefix ual: <http://terms.library.ualberta.ca/> %s\" % (self.select)\n",
    "        self.sparqlData.setReturnFormat(JSON)\n",
    "        self.sparqlData.setQuery(query)\n",
    "        results =  self.sparqlData.query().convert()\n",
    "        # iterate over query results\n",
    "        for result in results['results']['bindings']:\n",
    "            # the group is the two folders at the base of the pair tree, concatenated by an underscore\n",
    "            group = result['resource']['value'].split('/')[6]\n",
    "            # assign that parameter by which you want to search to that group\n",
    "            self.splitBy[group] = \"/\".join( result['resource']['value'].split('/')[:7] )# the stem of the resource [0] and the group number by which to save [1] (this is the first digit in the pair tree)\n",
    "            \n",
    "\n",
    "    def generateQueries(self):\n",
    "        pass\n",
    "    \n",
    "    def writeQueries(self):\n",
    "        filename = \"cache/%s.json\" % (self.objectType)\n",
    "        with open(filename, 'w+') as f:\n",
    "            json.dump([self.queries], f, sort_keys=True, indent=4, separators=(',', ': '))\n",
    "               \n",
    "class Collection(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.objectType = 'collection'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; rdf:type pcdm:Collection\"\n",
    "        self.where = [\"WHERE { ?resource info:hasModel 'Collection'^^xsd:string . OPTIONAL { ?resource ualids:is_community 'false'^^xsd:boolean } . OPTIONAL { ?resource ualid:is_community 'false'^^xsd:boolean } . OPTIONAL { ?resource ual:is_community 'false'^^xsd:boolean }\"]\n",
    "        self.select = None\n",
    "        super().__init__(self.objectType, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        for where in self.where:\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (str(?%s)!='') }\" % (where, pair[1], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')), re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "            self.queries['collection'] = \"%s %s } %s }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries\n",
    "\n",
    "class Community(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.objectType = 'community'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; rdf:type pcdm:Object; rdf:type ual:Community\"\n",
    "        self.where = [\"WHERE { ?resource info:hasModel 'Collection'^^xsd:string ; OPTIONAL { ?resource ualids:is_community 'true'^^xsd:boolean } . OPTIONAL { ?resource ualid:is_community 'true'^^xsd:boolean } . OPTIONAL { ?resource ual:is_community 'true'^^xsd:boolean }\"]\n",
    "        self.select = None\n",
    "        super().__init__(self.objectType, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        for where in self.where:\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (str(?%s)!='') }\" % (where, pair[1], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')), re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "            self.queries['community'] = \"%s %s } %s }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries()\n",
    "\n",
    "class Generic(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.objectType = 'generic'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; dcterm:available ?available ; dcterm:accessRights ?visibility; rdf:type works:Work; rdf:type pcdm:Object ; bibo:owner ?owner ; acl:embargoHistory ?history ; acl:visibilityAfterEmbargo ?visAfter\"\n",
    "        self.where = []\n",
    "        self.select = \"SELECT distinct ?resource WHERE { ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type ?type . filter(str(?type) != 'Thesis'^^xsd:string) }\"\n",
    "        super().__init__(self.objectType, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()\n",
    "        query = \"%s %s\" % (self.prefixes, self.select)\n",
    "        for group in self.splitBy.keys():\n",
    "            where = \"WHERE {  ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type ?type . filter(str(?type) != 'Thesis'^^xsd:string) . FILTER (contains(str(?resource), '%s'))\" % (self.splitBy[group])\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (str(?%s)!='') }\" % (where, pair[1], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')), re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "            self.queries[group] =  \"%s %s } %s . OPTIONAL {?permission webacl:accessTo ?resource ; webacl:mode webacl:Read ; webacl:agent ?visibility } . OPTIONAL {?permission webacl:accessTo ?resource ; webacl:mode webacl:Write ; webacl:agent ?owner } . OPTIONAL {?resource acl:hasEmbargo ?embargo . OPTIONAL {?embargo acl:embargoReleaseDate ?available } . OPTIONAL {?embargo acl:embargoHistory ?history } . OPTIONAL {?embargo acl:visibilityAfterEmbargo ?visAfter } } }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries()\n",
    "\n",
    "\n",
    "class Thesis(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.objectType = 'thesis'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; dcterm:available ?available ; dcterm:accessRights ?visibility; rdf:type works:Work ; rdf:type pcdm:Object ; rdf:type bibo:Thesis; bibo:owner ?owner ; acl:embargoHistory ?history ; acl:visibilityAfterEmbargo ?visAfter\"\n",
    "        self.where = []\n",
    "        self.select = \"SELECT distinct ?resource WHERE { ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type 'Thesis'^^xsd:string }\"\n",
    "        super().__init__(self.objectType, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()        \n",
    "        query = \"%s %s\" % (self.prefixes, self.select)\n",
    "        for group in self.splitBy.keys():\n",
    "            where = \"WHERE { ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type 'Thesis'^^xsd:string . FILTER (contains(str(?resource), '%s'))\" % (self.splitBy[group])\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (str(?%s)!='') } \" % (where, pair[1], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')), re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "            self.queries[group] =  \"%s %s } %s . OPTIONAL {?permission webacl:accessTo ?resource ; webacl:mode webacl:Read ; webacl:agent ?visibility } . OPTIONAL {?permission webacl:accessTo ?resource ; webacl:mode webacl:Write ; webacl:agent ?owner } . OPTIONAL {?resource acl:hasEmbargo ?embargo . OPTIONAL {?embargo acl:embargoReleaseDate ?available } . OPTIONAL {?embargo acl:embargoHistory ?history } . OPTIONAL {?embargo acl:visibilityAfterEmbargo ?visAfter } } }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries()\n",
    "\n",
    "\n",
    "class File(Query):\n",
    "    def __init__(self, sparqlData, objectType, filterType):\n",
    "        self.rdfType = \"<http://www.w3.org/ns/ldp#NonRDFSource>\"\n",
    "        self.pcdmType = \"pcdm:File\"\n",
    "        self.construct = \"CONSTRUCT {?file rdf:type %s; rdf:type %s; pcdm:fileOf ?fileset ; iana:describedby ?fixty ; iana:describedby ?fcr ; fedora:hasParent ?fileset ; ?predicate ?object }\" % (self.rdfType, self.pcdmType)\n",
    "        self.where = \"WHERE { ?resource rdf:type %s . FILTER ( strEnds(str(?resource), '%s') && \" % (self.rdfType, self.filterType)\n",
    "        self.select = \"SELECT distinct ?resource WHERE  {?resource rdf:type %s . FILTER ( strEnds(str(?resource), '%s') ) }\" % (self.rdfType, self.filterType)\n",
    "        super().__init__(self.objectType, self.sparqlData)\n",
    "        \n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()\n",
    "        for group in self.splitBy.keys():\n",
    "            self.queries[group] = \"%s %s %s strStarts(str(?resource), '%s') ) . ?resource ?predicate ?object . FILTER ( !contains(str(?predicate), 'http://www.iana.org/assignments/relation/') && !contains(str(?predicate), 'http://fedora.info/definitions/v4/repository#hasFixityService')  && !contains(str(?predicate), 'http://fedora.info/definitions/v4/repository#hasParent') && str(?object)!='' )  . BIND(URI(CONCAT(str(?resource), '/file')) AS ?file)  . BIND(URI(CONCAT(str(?resource), '/fileset')) AS ?fileset) . BIND(URI(CONCAT(str(?resource), '/file/fcr:fixity')) AS ?fixity)  . BIND(URI(CONCAT(str(?resource), '/file/fcr:metadata')) AS ?fcr)}\" % (self.prefixes, self.construct, self.where, self.splitBy[group])\n",
    "        self.writeQueries()    \n",
    "\n",
    "\n",
    "class Fileset(Query):\n",
    "    def __init__(self, sparqlData, objectType, filterType):\n",
    "        self.pcdmType = \"works:Fileset\"\n",
    "        self.rdfType = \"<http://fedora.info/definitions/v4/repository#NonRdfSourceDescription>\"\n",
    "        self.construct = \"CONSTRUCT { ?parent pcdm:hasRelatedObject ?relatedObject . ?fileset rdf:type fedora:Container ; rdf:type fedora:Resource ; rdf:type pcdm:Object ; rdf:type works:FileSet; rdf:type <http://www.w3.org/ns/ldp#Container> ; rdf:type <http://www.w3.org/ns/ldp#RDFSource> ; pcdm:hasFile ?file ; pcdm:isMemberOf ?relatedObject ; fedora:hasParent ?relatedObject . ?relatedObject pcdm:relatedObjectOf ?parent ; rdf:type ual:%s ; rdf:type fedora:Container ; rdf:type fedora:Resource ; rdf:type pcdm:Object ; rdf:type works:Work ; rdf:type <http://www.w3.org/ns/ldp#Container> ; rdf:type <http://www.w3.org/ns/ldp#RDFSource> ; pcdm:hasMember ?fileset ; fedora:hasParent ?parent ; ?predicate ?object } \" % (self.filterType)\n",
    "        self.where = \"WHERE { ?resource rdf:type %s . FILTER ( strEnds(str(?resource), '%s/fcr:metadata') && \" % (self.rdfType, self.filterType)\n",
    "        self.select = \"SELECT distinct ?resource WHERE {?resource rdf:type %s . FILTER ( strEnds(str(?resource), '%s/fcr:metadata') ) }\" % (self.rdfType, self.filterType)\n",
    "        super().__init__(self.objectType, self.sparqlData)\n",
    "        \n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()\n",
    "        for group in self.splitBy.keys():\n",
    "            self.queries[group] = \"%s %s %s strStarts(str(?resource), '%s')) . ?resource ?predicate ?object FILTER ( !contains(str(?predicate), 'http://www.iana.org/assignments/relation/') && !contains(str(?predicate), 'http://fedora.info/definitions/v4/repository#hasFixityService') && !contains(str(?predicate), 'http://fedora.info/definitions/v4/repository#hasParent') && !contains(str(?predicate), 'http://fedora.info/definitions/v4/repository#hasVersions') && str(?object)!='' )  . BIND(URI(REPLACE(STR(?resource), '/%s/fcr:metadata', '/fileset')) AS ?fileset) . BIND(URI(REPLACE(STR(?resource), '/%s/fcr:metadata', '/file')) AS ?file)  . BIND(URI(REPLACE(STR(?resource), '/%s/fcr:metadata', '')) AS ?parent) . BIND(URI(REPLACE(STR(?resource), '/fcr:metadata', '/relatedObject')) AS ?relatedObject) }\" % (self.prefixes, self.construct, self.where, self.splitBy[group], self.filterType, self.filterType, self.filterType)\n",
    "        self.writeQueries()     \n",
    "\n",
    "\n",
    "class era1statsFile(File):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'era1statsFile'        \n",
    "        self.filterType = \"era1stats\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "\n",
    "        \n",
    "class era1statsFileset(Fileset):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'era1statsFileset'        \n",
    "        self.filterType = \"era1stats\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)  \n",
    "        \n",
    "\n",
    "class fedora3foxmlFile(File):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'fedora3foxmlFile'        \n",
    "        self.filterType = \"fedora3foxml\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "        \n",
    "\n",
    "class fedora3foxmlFileset(Fileset):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'fedora3foxmlFileset'        \n",
    "        self.filterType = \"fedora3foxml\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "        \n",
    "\n",
    "class contentFile(File):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'contentFile'\n",
    "        self.filterType = \"content\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "        self.construct = \"CONSTRUCT { ?file rdf:type ldp:NonRDFSource ; rdf:type fedora:Binary ; rdf:type fedora:Resource ; rdf:type pcdm:File; pcdm:fileOf ?fileset; iana:describedby ?fcr ; ?predicate ?object }\"\n",
    "\n",
    "        \n",
    "class contentFileset(Fileset):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'contentFileset'\n",
    "        self.filterType = \"content\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "        self.construct = \"CONSTRUCT { ?fileset rdf:type fedora:Container ; rdf:type fedora:Resource ; rdf:type pcdm:Object ; rdf:type works:FileSet; rdf:type ldp:Container ; rdf:type ldp:RDFSource ; pcdm:hasFile ?file ; pcdm:memberOf ?parent ; ?predicate ?object }\"\n",
    "        \n",
    "        \n",
    "class characterizationFile(File):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'characterizationFile'\n",
    "        self.filterType = \"characterization\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "        self.construct = \"CONSTRUCT { ?file rdf:type ldp:NonRDFSource ; rdf:type fedora:Binary ; rdf:type fedora:Resource ; rdf:type pcdm:File; pcdm:fileOf ?fileset; iana:describedby ?fcr ; ?predicate ?object }\"\n",
    "\n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()\n",
    "        for group in self.splitBy.keys():\n",
    "            self.queries[group] = \"%s %s %s strStarts(str(?resource), '%s') ) . ?resource ?predicate ?object . FILTER ( !contains(str(?predicate), 'http://www.iana.org/assignments/relation/') && !contains(str(?predicate), 'http://fedora.info/definitions/v4/repository#hasFixityService')  && !contains(str(?predicate), 'http://fedora.info/definitions/v4/repository#hasParent') && str(?object)!='' )  . BIND(URI(CONCAT(str(?resource), '/file')) AS ?file)  . BIND(URI(REPLACE(str(?resource), '/characterization', '/fileset')) AS ?fileset) . BIND(URI(CONCAT(str(?resource), '/file/fcr:fixity')) AS ?fixity)  . BIND(URI(CONCAT(str(?resource), '/file/fcr:metadata')) AS ?fcr)}\" % (self.prefixes, self.construct, self.where, self.splitBy[group])\n",
    "        self.writeQueries() \n",
    "    \n",
    "class characterizationFileset(Fileset):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'characterizationFileset'\n",
    "        self.filterType = \"characterization\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "        self.construct = \"CONSTRUCT { ?fileset rdf:type %s; rdf:type %s; rdf:type ual:fits ; pcdm:hasFile ?file ; pcdm:memberOf ?parent ; iana:describes ?file ; ?predicate ?object }\" % (self.rdfType, self.pcdmType)      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  DATA TRANSPORT OBJECTS\n",
    "##### Runs a query, sends data to get transformed, saves data to appropriate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    def __init__(self, query, group, sparqlData, sparqlTerms, queryObject):\n",
    "        self.q = query\n",
    "        self.prefixes = queryObject.prefixes\n",
    "        self.group = group\n",
    "        self.sparqlData = sparqlData\n",
    "        self.sparqlTerms = sparqlTerms\n",
    "        self.output = []\n",
    "        self.graph = Graph()\n",
    "        self.objectType = queryObject.objectType\n",
    "        self.directory = \"results/%s/\" % (self.objectType)\n",
    "        self.filename = \"results/%s/%s.nt\" % (self.objectType, group)\n",
    "        if not os.path.exists(self.directory):\n",
    "            os.makedirs(self.directory)\n",
    "        \n",
    "\n",
    "    def transformData(self):\n",
    "        self.sparqlData.setReturnFormat(JSON)\n",
    "        self.sparqlData.setQuery(self.q)\n",
    "        # queries a batch of resources from this particular \"group\"\n",
    "        results = self.sparqlData.query().convert()['results']['bindings']\n",
    "        # iterates over each resource and performs transformations\n",
    "        for result in results:\n",
    "            result = TransformationFactory().getTransformation(result, self.objectType)\n",
    "            if isinstance(result, list):\n",
    "                for triple in result:\n",
    "                    s = URIRef(triple['subject']['value'])\n",
    "                    p = URIRef(triple['predicate']['value'])\n",
    "                    if triple['object']['type'] == 'uri':\n",
    "                        o = URIRef(triple['object']['value'])\n",
    "                    else:\n",
    "                        o = Literal(triple['object']['value'])\n",
    "                    self.graph.add((s, p, o))\n",
    "        self.graph.serialize(destination=self.filename, format='nt')\n",
    "        \n",
    "    def resultsToTriplestore(self):\n",
    "        print('hello')\n",
    "        url = 'http://206.167.181.123:9999/blazegraph/namespace/results/sparql'\n",
    "        files = {'file': ('result.nt', self.graph.serialize(format='nt'), 'text/turtle') }\n",
    "        r = requests.post(url, files=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QueryFactory():\n",
    "    @staticmethod\n",
    "    def getMigrationQuery(objectType, sparqlData):\n",
    "        \"\"\" returns a specified query object depending on the type passed in\"\"\"\n",
    "        if objectType == \"collection\": return Collection(sparqlData)\n",
    "        elif objectType == \"community\": return Community(sparqlData) \n",
    "        elif objectType == \"thesis\": return Thesis(sparqlData)\n",
    "        elif objectType == \"generic\": return Generic(sparqlData)\n",
    "        elif objectType == \"era1statsFile\": return era1statsFile(sparqlData)\n",
    "        elif objectType == \"era1statsFileset\": return era1statsFileset(sparqlData) \n",
    "        elif objectType == \"fedora3foxmlFile\": return fedora3foxmlFile(sparqlData)\n",
    "        elif objectType == \"fedora3foxmlFileset\": return fedora3foxmlFileset(sparqlData) \n",
    "        elif objectType == \"contentFile\": return contentFile(sparqlData)\n",
    "        elif objectType == \"contentFileset\": return contentFileset(sparqlData) \n",
    "        elif objectType == \"characterizationFile\": return characterizationFile(sparqlData)\n",
    "        elif objectType == \"characterizationFileset\": return characterizationFileset(sparqlData)\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TransformationFactory():\n",
    "    @staticmethod\n",
    "    def getTransformation(triple, objectType):\n",
    "        function = re.sub(r'[0-9]+', '', triple['predicate']['value'].split('/')[-1].replace('#', '').replace('-', ''))      \n",
    "        if function ==  \"accessRights\": return Transformation().accessRights(triple, objectType)\n",
    "        elif function ==  \"modelsmemberOf\": return Transformation().modelsmemberOf(triple, objectType)\n",
    "        elif function ==  \"modelshasMember\": return Transformation().modelshasMember(triple, objectType)\n",
    "        elif function == \"language\": return Transformation().language(triple, objectType)\n",
    "        elif function == \"type\": return Transformation().type(triple, objectType)\n",
    "        elif function ==  \"rights\": return Transformation().rights(triple, objectType)\n",
    "        elif function == \"license\": return Transformation().license(triple, objectType)\n",
    "        elif function == \"ontologyinstitution\": return Transformation().institution(triple, objectType)\n",
    "        elif function == \"available\": return Transformation().available(triple, objectType)\n",
    "        elif function == \"aclvisibilityAfterEmbargo\": return Transformation().aclvisibilityAfterEmbargo(triple, objectType)\n",
    "        else:\n",
    "            return [triple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:34:11\n",
      "collection queries generated\n",
      "1 queries of collection objects to be transformed\n",
      "1 of 1 collection queries transformed\n",
      "collection objects transformation completed\n",
      "community queries generated\n",
      "1 queries of community objects to be transformed\n",
      "1 of 1 community queries transformed\n",
      "community objects transformation completed\n",
      "generic queries generated\n",
      "1 queries of generic objects to be transformed\n",
      "1 of 1 generic queries transformed\n",
      "generic objects transformation completed\n",
      "thesis queries generated\n",
      "2 queries of thesis objects to be transformed\n",
      "1 of 2 thesis queries transformed\n",
      "2 of 2 thesis queries transformed\n",
      "thesis objects transformation completed\n",
      "era1statsFile queries generated\n",
      "1 queries of era1statsFile objects to be transformed\n",
      "1 of 1 era1statsFile queries transformed\n",
      "era1statsFile objects transformation completed\n",
      "era1statsFileset queries generated\n",
      "1 queries of era1statsFileset objects to be transformed\n",
      "1 of 1 era1statsFileset queries transformed\n",
      "era1statsFileset objects transformation completed\n",
      "fedora3foxmlFile queries generated\n",
      "1 queries of fedora3foxmlFile objects to be transformed\n",
      "1 of 1 fedora3foxmlFile queries transformed\n",
      "fedora3foxmlFile objects transformation completed\n",
      "fedora3foxmlFileset queries generated\n",
      "1 queries of fedora3foxmlFileset objects to be transformed\n",
      "1 of 1 fedora3foxmlFileset queries transformed\n",
      "fedora3foxmlFileset objects transformation completed\n",
      "contentFile queries generated\n",
      "1 queries of contentFile objects to be transformed\n",
      "1 of 1 contentFile queries transformed\n",
      "contentFile objects transformation completed\n",
      "contentFileset queries generated\n",
      "1 queries of contentFileset objects to be transformed\n",
      "1 of 1 contentFileset queries transformed\n",
      "contentFileset objects transformation completed\n",
      "characterizationFile queries generated\n",
      "1 queries of characterizationFile objects to be transformed\n",
      "1 of 1 characterizationFile queries transformed\n",
      "characterizationFile objects transformation completed\n",
      "13:34:19\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
