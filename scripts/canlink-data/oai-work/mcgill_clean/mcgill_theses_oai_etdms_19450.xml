<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/assets/blacklight_oai_provider/oai2-b0e501cadd287c203b27cfd4f4e2d266048ec6ca2151d595f4c1495108e36b88.xsl"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd"><responseDate>2020-07-25T01:16:47Z</responseDate><request resumptionToken="oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):19450" verb="ListRecords">https://escholarship.mcgill.ca/catalog/oai</request><ListRecords><record><header><identifier>oai:escholarship.mcgill.ca:th83m347q</identifier><datestamp>2020-03-21T21:17:32Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Actuellement, l'expérience utilisateur des réseaux sociaux en ligne (Online Social Networks) est difficile lorsqu'un utilisateur a à valider des identités d'autres pour se connecter. Compte tenu des attaques rampantes de vol d'identité sur OSN, il est parfois difficile de distinguer si la personne à connecter sur OSN est celle qui l'utilisateur connaît-il dans la vie réelle. Pour cette raison, la construction d'un système de validation d'identité est nécessaire pour protéger l'intérêt des utilisateurs ainsi que pour améliorer de l'expérience utilisateur.Dans cette thèse, nous présentons un système de validation d'identité - CredFinder pour OSN développé en plate-forme des dispositifs mobiles. Trois protocoles de validation sont conçus pour faire face à différents scénarios que d'utilisateurs peuvent-ils rencontrer. Concernant ​​Facebook, nous proposons une implémentation basée sur Android prototype composée par trois sous-systèmes: application de dispositif mobile, serveur de validation et serveur d'application OSN. Les résultats et les analyses de l'implémentation démontrent que CredFinder est à la fois efficace et efficiente pour accomplir la validation d'identité. Au meilleur de nos connaissances, CredFinder est le premier système réel basé sur appareil mobile contre les attaques de vol l'identité sur OSN. La stratégie de validation dans notre système donne aux utilisateurs ordinaires le pouvoir de connecter sur leurs réseaux sociaux en ligne et hors ligne.</description><description>Currently, online social networks (OSNs) do not provide validation mechanisms to verify the identity of a user who is seeking linkage with another user. This shortfall is exploited by attackers to infiltrate other people's social circles to gain access to personal data. Therefore, building an identity validation system is necessary for protecting the user interest as well as enhancing the user experience.In this thesis I present an identity validation system---CredFinder for OSNs using commodity mobile devices. Three validation protocols are designed under different scenarios people may encounter. Targeted on Facebook, we propose an Android based prototypical implementation including three subsystems, the mobile device application, the validation server and the OSN application server. The implementation results demonstrate that CredFinder is capable of performing identity validation. To the best of our knowledge, CredFinder is the first mobile device based practical system against social network identity theft attacks. The validation strategy in our system gives users the power to connect their online and offline social networks together.</description><creator>Shi, Yiwei</creator><contributor>Muthucumaru Maheswaran (Internal/Supervisor)</contributor><date>2012</date><subject>Applied Sciences - Computer Science</subject><title>A mobile device based identity validation system for online social networks</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/z603r252r.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/th83m347q</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:pg15bk01z</identifier><datestamp>2020-03-21T21:17:33Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Dans un premier temps, ce mémoire propose une analyse de la poétique du personnage du prêtre dans un choix de fabliaux érotiques écrits entre les XIIe et XIVe siècles (Gombert et les deus clers, Le Prestre taint, Le Vilain de Bailluel et Le Prestre ki abevete). Tout en permettant de nuancer « l'anticléricalisme » des fabliaux par la différenciation des types du clerc et du prêtre, cette analyse s'attarde à la figure du prêtre trompé et du prêtre trompeur. Par l'étude de ce personnage rusé, elle concourt à démontrer que le prêtre trompeur constitue bien souvent une mise en abyme des figures de l'auteur et du jongleur en représentation dont se sert le fabliau pour réhabiliter la fiction et interroger la puissance de la parole et du langage, ce qui contribue à dévoiler la « mécanique » du genre et des motifs de la littérature médiévale. La seconde partie de ce mémoire, dite d'écriture littéraire, propose un texte narratif qui utilise certaines caractéristiques du genre dramatique pour créer un effet de distanciation devant le spectacle de ce village, où règne un certain désintérêt religieux, mais qui se voit heurté par l'annonce et l'arrivée d'un jeune prêtre, Adagio. Ce nouvel arrivant deviendra le sujet de toutes les discussions et de toutes les rumeurs, au point de n'exister qu'à travers la parole d'autrui.</description><description>The first part of this thesis is an analysis of the priest in a selection of erotic fabliaux written between the 12th and 14th centuries (Gombert et les deus clers, Le Prestre taint, Le Vilain de Bailluel and Le Prestre ki abevete). While the "anticlericalism" of the fabliaux is toned down by the differences between the types of the cleric and the priest, this analysis dwells on the figures of the deceived priest and the deceitful one. Through the study of the deceitful priest, it demonstrates that the duper offers a mise en abyme of the author and the jongleur in action, used by the fabliau to rehabilitate the fiction and to examine the power of speech and language, which helps unveil the "mecanic" of the genre and the types of medieval literature.The second part of this thesis is a narrative text that uses some traits of the drama genre to create a distance between the reader and the characters, who live in a small village where a certain lack of interest for religion rules. These inhabitants will be thrilled by the announce and arrival of a young priest, Adagio. Soon, this newcomer will become the object of all discussions and all rumors, so much so that he will exist only through others' words.</description><creator>Deschênes, Sarah</creator><contributor>Michel Biron (Internal/Cosupervisor2)</contributor><contributor>Isabelle Arseneau (Internal/Supervisor)</contributor><date>2012</date><subject>Literature - Medieval</subject><title>Le Prêtre mis à nu: étude de la poétique du personnage dans les fabliaux érotiques (XIIe- XIVe siècles) suivi de: Adagio malgré lui</title><language>fre</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/nc580r63v.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/pg15bk01z</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of French Language and Literature</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:8k71nn129</identifier><datestamp>2020-03-21T21:17:34Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Multiple sclerosis (MS) is an inflammatory neurodegenerative disease, and although the cause of MS remains unknown, it is widely accepted that both genetic and environmental factors play a role. The purpose of this thesis was to investigate the role of active and passive cigarette smoke exposure, both of which have been recently implicated as possible risk factors for MS. A systematic review was performed to consolidate the existing literature on smoking and MS. This review resulted in 20 published articles, 17 of which reported on active smoke exposure, and 3 that reported on passive smoke exposure as a risk factor for MS. Of the studies reported in these 20 articles, one study was judged to be of excellent quality, 5 studies were of good quality, 9 studies of acceptable quality, and the remaining 5 studies of poor quality. The second part of this thesis investigated active cigarette smoke exposure and passive cigarette smoke exposure (among never-smokers) in the etiology of MS using data from the Norwegian component of the International Case-Control Study on Environmental risk factors in Multiple Sclerosis (EnvIMS). Cases (N=807) were frequency matched to controls (N=1716) on sex and age at the time of study. Using a self-administered questionnaire, participants were asked about several environmental exposures, including their active smoke exposure in five year intervals between the ages 11 and 30, and household passive smoke exposure from birth to age 30. Consistent with the literature on active smoking, individuals with MS had a 2.19 (95% CI 1.82-2.63) greater odds of having smoked than controls. The relationship of passive smoke exposure and MS among never-smokers was not statistically significant, OR=1.20 (95% CI 0.83-1.76); however, the magnitude of the effect was consistent with previous literature. The research presented here confirms that active smoke exposure is a risk factor for MS, and although this study was not adequately powered to find a statistically significant effect, the results suggest that passive smoke exposure may also be a risk factor for MS.</description><description>La sclérose en plaques (SP) est une maladie inflammatoire neurodégénérative. Bien que sa cause demeure inconnue, il est largement accepté que des facteurs à la fois génétiques et environnementaux jouent un rôle dans cette maladie. Cette thèse avait pour but d'examiner le rôle de l'exposition active et passive à la fumée de cigarette; ces deux types d'exposition ayant récemment été identifiés comme étant des facteurs de risque potentiels de la SP. Une revue systématique a été faite afin de regrouper la documentation existante sur l'usage du tabac et la SP. Cette revue a permis d'identifier vingt articles publiés, dont dix-sept traitaient de l'exposition active à la fumée de cigarette et trois traitaient de l'exposition passive à la fumée de cigarette comme facteur de risque de la SP. La qualité de ces vingt articles a été jugée comme suit : une étude était d'excellente qualité, cinq études étaient de bonne qualité, neuf études étaient de qualité acceptable et les cinq études restantes étaient de mauvaise qualité. La deuxième partie de cette thèse a examiné le rôle de l'exposition active à la fumée de cigarette, ainsi que l'exposition active à la fumée de cigarette chez les individus qui n'ont jamais fumé, dans l'étiologie de la SP en utilisant les données de la cohorte norvégienne de l'International Case-Control Study on Environmental risk factors in Multiple Sclerosis (EnvIMS). Les cas (N = 807) ont été appariés pour la fréquence à des contrôles (N = 1716) en fonction du sexe et de l'âge au moment de l'étude. À l'aide d'un questionnaire auto-administré, les participants devaient répondre à des questions sur l'exposition à différents risques environnementaux, dont l'exposition active à la fumée de cigarette en intervalles de cinq ans entre 11 et 30 ans, ainsi que l'exposition passive à la fumée de cigarette dans le ménage de la naissance à l'âge de 30 ans. Conformément à la littérature sur l'usage actif du tabac, la probabilité d'avoir fumé était supérieure de 2,19 (95 % IC 1,82-2,63) chez les individus atteints de SP par rapport aux contrôles. La relation entre l'exposition passive à la fumée de cigarette et la SP chez les individus qui n'ont jamais fumé n'était pas significative d'un point de vue statistique, rapport de cote = 1,20 (95 % IC 0,83-1,76); toutefois, l'ampleur de l'effet correspondait aux études déjà publiées. La présente recherche confirme que l'exposition active à la fumée de cigarette représente un facteur de risque de la SP. Bien que cette étude ne soit pas suffisamment puissante pour détecter un effet significatif d'un point de vue statistique, les résultats suggèrent également que l'exposition passive à la fumée de cigarette pourrait être un facteur de risque de la SP.</description><creator>Styles, Amy</creator><contributor>Christina Wolfson (Internal/Supervisor)</contributor><contributor>Maura Pugliatti (Internal/Cosupervisor2)</contributor><date>2012</date><subject>Health Sciences - Epidemiology</subject><title>Environmental risk factors in multiple sclerosis: the role of active and passive cigarette smoke exposure</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/h702qb352.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/8k71nn129</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Epidemiology and Biostatistics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:1544bt37p</identifier><datestamp>2020-03-21T21:17:34Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Introduction: Low income, less educated and immigrant populations are notorious for having low response rates in research studies. Therefore, it is not surprising that when attempting to estimate food allergy prevalence in Canada, the SCAAALAR study (Surveying Canadians to Assess the Prevalence of Common food Allergies and Attitudes towards food LAbeling and Risk), which attained a response rate of only 34.6% , underrepresented several vulnerable populations (those of low socioeconomic status, non post-secondary graduates, new Canadians, residents of the territories and Aboriginals).Objective: The objective of this thesis is two fold: 1) to determine an effective methodology for obtaining high response rates in the vulnerable populations not adequately represented in SCAAALAR and 2) to attain food allergy prevalence estimates for these vulnerable populations.Methods: To increase response rates and adequately sample the desired populations, a pilot study was conducted to evaluate the effect of unconditional incentives in vulnerable populations for a telephone survey. Households in low income/high immigrant postal codes were randomly selected and randomly assigned to receive either an unconditional incentive or no incentive. The difference in response rate and 95% confidence interval was calculated using a normal approximation to the difference of two binomial distributions. The pilot study informed the methodology employed in the SPAACE study (Surveying the8Prevalence of Food Allergy in All Canadian Environments), which subsequently addressed the second objective of this Thesis. SPAACE then estimated the prevalence of food allergy for those of low socioeconomic status, non post-secondary graduates, new Canadians, residents of the territories and Aboriginals. Prevalence estimates among vulnerable populations were compared to their comparator populations (i.e., those of high socioeconomic status, post-secondary graduates, individuals born in Canada, residents of the provinces and non-Aboriginals); between population differences and 95% confidence intervals were calculated using normal approximations to the difference of two binomial distributions.Results: The response rates were 38.4% and 31.4% for the incentive and non-incentive groups respectively, with a between group difference of 0.070 (-0.013, 0.15). The cooperation rates, which exclude non-contacts from the calculation, were 47.3% and 40.0% for the incentive and non-incentive group respectively, with a between group difference of 0.073 (-0.023, 0.17). Prevalence estimates for those of low socioeconomic status, new Canadians and Aboriginals were lower than their comparator population's prevalence (between population differences respectively: -2.44% (95% CI: -3.52%, -1.35%); -2.66% (95% CI: -3.5%, -1.82%); -2.17% (95% CI: -3.18%, -1.16%)) .Discussion: Although wide confidence intervals preclude definitive conclusions, our results suggest that unconditional incentives are an effective means of9increasing response rates in vulnerable populations for telephone surveys. Additionally, the results of SPAACE demonstrate that socioeconomic status, birthplace and ethnicity are associated with the prevalence of food allergy. These findings are indicative of potential lifestyle, cultural, and genetic factors that may influence the development of food allergy.</description><description>Introduction : Les populations immigrantes, moins nanties and moins éduquées sont reconnues comme ayant des taux de réponses peu élevés lors d'études. Il est alors peu surprenant de constater que l'étude SCAAALAR (Surveying Canadians to Assess the Prevalence of Common food Allergies and Attitudes towards food LAbeling and Risk), qui a atteint un taux de réponse de seulement de 34.6%, ait sous-représenté plusieurs groupes de la population (ceux de statut socioéconomique moins élevé, de non-gradués postsecondaire, de nouveaux arrivants au Canada, de résidents des territoires et des amérindiens). Objectif : L'objectif de cette thèse est en deux parties : 1) déterminer une méthodologie efficace pour obtenir un haut taux de réponse au sein des populations vulnérables mal-représentées avec SCAAALAR et 2) obtenir des estimés de prévalences d'allergies alimentaires pour ces populations vulnérables. Méthodologie : Pour améliorer les taux de réponse et de sonder adéquatement les populations désirées, une étude pilote a été réalisée pour évaluer les effets des incitatifs inconditionnels sur les populations vulnérables lors d'un sondage téléphonique. Les ménages situés dans les codes postaux à faibles revenus et à haute présence d'immigrants ont été sélectionnés et assignés de manière aléatoire à recevoir un incitatif inconditionnel ou à ne pas en recevoir. La différence du taux de réponse et de l'intervalle de confiance à 95% a été calculé en utilisant une approximation normale jusqu'à 2 distribution binômes. L'étude pilote a informé la11méthodologie employée dans l'étude SPAACE (Surveying the Prevalence of Food Allergy in All Canadian Environments), qui a par la suite adressé le deuxième objectif de cette thèse. SPAACE a ensuite estimé la prévalence d'allergies alimentaires pour les populations non graduées d'études postsecondaire, les immigrants, les résidents des territoires et des amérindiens. Les estimés de prévalences au sein des populations vulnérables ont été comparés à leurs populations comparatives (i.e., celles de statut socioéconomique plus élevé, les gradués postsecondaire, les canadiens nés au pays, les résidents des provinces et des non-Amérindiens); les différences entre populations et les intervalles à 95% de confiance ont été calculés en utilisant des estimés normaux de différences entre 2 distributions binômes.Résultats : Les taux de réponse ont atteint 38.4% et 31.4% pour les groupes avec et sans incitatifs, respectivement, avec une différence entre groupes de 0.070 (-0.013, 0.15). Les taux de coopération, ce qui exclu les non-contacts des calculs, ont été de 47.3% et 40.0% pour les groupes avec et sans incitatifs, respectivement, avec une différence entre groupes de 0.073 (-0.023, 0.17). Les estimés de prévalences pour les populations de statut socioéconomique moins élevé, les immigrants, et les amérindiens étaient moins élevés que les prévalences de leurs populations comparatives (différences entre populations, respectivement : -2.44% (95% CI : -3.52%, -1.35%); -2.66% (95% CI : -3.5%, -1.82%); -2.17% (95% CI : -3.18%, -1.16%)).12 Discussion : Bien que de larges intervalles de confiance excluent des conclusions définitives, nos résultats suggèrent que des incitatifs inconditionnels sont une manière efficace d'augmenter le taux de réponse lors de sondages téléphoniques auprès des populations vulnérables. De plus, les résultats de SPAACE démontrent que le statut socioéconomique, le lieu de naissance et l'ethnie sont associés à la prévalence des allergies alimentaires. Ces découvertes indiquent que des facteurs culturels, génétiques et des habitudes de vie peuvent influencer le développement des allergies alimentaires.</description><creator>Knoll, Megan</creator><contributor>Ann Clarke (Supervisor)</contributor><date>2012</date><subject>Health Sciences - Epidemiology</subject><title>Survey methodology and prevalence estimates from the SPAACE (surveying the prevalence of food allergy in all Canadian environments) study</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/sb397d320.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/1544bt37p</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Epidemiology and Biostatistics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:sx61dr133</identifier><datestamp>2020-03-21T21:17:35Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Following the lone detection of the Galactic supernova remnant Cas A by gamma-ray detectors aboard CGRO and hard X-ray detectors aboard INTEGRAL in the nuclear lines of the 44Ti decay chain, The et al, 2006, argued that these surveys should have detected several sources, given models for the yield of 44Ti and an estimate of the Galactic supernova rate. In this thesis, this result is revisited by exploring the effect of various newer yield models of Type II supernovae, which include yields that differ by approximately an order of magnitude. We also consider several estimates of the Galactic supernova rate, which also differ by an order of magnitude, and various models for the Galactic distribution of massive stars. We find that the lone detection of Cas A is in fact consistent with a large number of reasonable models. We find that in order to detect a significant number of previously unknown remnants in a survey for 44Ti and thus constrain supernova models, a sensitivity to fluxes of less than 1E-7 photon per square cm per second within an absolute Galactic latitude of less than 5 degrees is required.</description><description>Suivant la seule détection dans les lignes de désintégration nucléaires du 44Ti de Cassiopeia A avec les détecteurs à bord de CGRO et d'INTEGRAL, The et al, 2006 ont présenté une analyse de la distribution de jeunes restants de supernova dans la Galaxie dont la conclusion est que ces missions auraient dû detecter plusieurs sources. Ce mémoire vise a reproduire et raffiner ce résultat en prenant compte de différents modèles pour la production du 44Ti (qui sont incertains par approximativement un ordre de grandeur), de différents modèles de la répartition des étoiles massives dans la Galaxie et de différents taux de supernovae dans la Galaxie (également incertain par un ordre de grandeur). Nous concluons que la detection de Cassiopeia A est consistante avec une large gamme de modèles raisonnables. Finalement, nous extrapolons qu'il serait nécessaire qu'un futur relevé ait une limite de détection de moins de 1E-7 photon par cm carré par seconde dans le plan Galactique (ie. a une latitude Galactique absolue de moins de 5 degrés) afin de déctecter une quantité non-nulle de jeunes restants de supernova jusqu'ici inconnus dans le but de contraindre les modèles de supernova.</description><creator>Dufour, François</creator><contributor>Victoria Kaspi (Internal/Supervisor)</contributor><date>2012</date><subject>Physics - Astronomy and Astrophysics</subject><title>Modeling of the galactic distribution of 44Ti emitting young supernova remnants</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/p8418s28m.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/sx61dr133</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Physics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:kh04dt473</identifier><datestamp>2020-03-21T21:17:36Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Colibacillosis (diarrhea in piglets caused by Escherichia coli) is the leading killer to piglets. Pathogenic E.coli responsible for this onset is referred as diarrheagenic E.coli.  In six defined groups of diarrheagenic E.coli, enterotoxigenic E. coli (ETEC) is an important cause of post weaning diarrhea (PWD) in pigs. ETEC was first recognized by their ability to secrete two defined groups of enterotoxins: heat-stable toxin (STs) and heat-labile enterotoxin (LTs). F4 and F18 fimbriae, the most prevalent adhesins are commonly expressed on porcine ETEC to facilitate bacterial colonization. In addition to enterotoxins and fimbrial adhesins, functions of many other colonization factors are constantly identified. In 2009, EtpA, an exoprotein, was identified in human ETEC and confirmed to interact with a conserved region of flagella. This interaction appears critical for ETEC adherence to human intestinal epithelia. Our current study demonstrated that EtpA gene was also present in some wildtype porcine ETECs. However, a subsequent correlation analysis showed ETEC adherence ability cannot be solely attributed to a single pathogenic feature, such as the expression of enterotoxins, fimbrial adhesins or EtpA protein. It appears that pathogenesis of ETEC is more complicated than previously thought. To study the pathogenesis of ETEC adherence, this project firstly focused on the recognition between cellular glycoconjugates and bacterial adhesins that accounts for the initiation of bacterial adherence. The removal of cellular sialic acid from porcine intestinal epithelia confers a favoured environment for ETEC to enhance binding. Monosaccharides were subsequently utilized as competitive inhibitors in order to determine the recognition sites on ETEC adhesin. Our result suggests that subterminal N-acetylgalactosamine (GalNAc) seems responsible for the recognition of F4ac fimbriae. Also, in all ETECs responsive to monosaccharide treatments, 100% of Neu5Ac saturated ETECs, as well as 80% of Mannose saturated ETECs showed enhanced binding ability to desialylated IPEC-J2 cell monolayers. An earlier proposed model of conformation change in bacterial adhesin was adopted to explain this phenomenon. It is suggested that there is an allosteric effect on ETEC adhesin after first binding where an essential recognition of free Neu5Ac initiates bacterial adherence, and certain sugar, such as fucose or mannose can possibly synergistically function with Neu5Ac on adhesin and contribute to better binding.</description><description>La colibacillose (diarrhée causée par Escherichia coli chez le porcelet) constitue la principale cause de décès chez le porcelet. La souche pathogène d'E.coli responsable de ce phénomène est connue sous le nom d'E.coli diarrheagénique.  Parmi les six différents groupes identifiés d'E.coli diarrheagéniques, la variété E. coli entérotoxigénique (ETEC) est la cause majeure des diarrhées survenant après le sevrage chez le porc. ETEC a intialement été identifiée pour sa capacité à sécréter 2 groupes distincts d'entérotoxines : l'entérotoxine ST (heat-stable) et l'entérotoxine LT (heat-labile). Il a été démontré que les formes F4 et F18 des fimbriae, adhésines les plus communes, sont communément exprimées dans les ETEC de porcs facilitant ainsi la colonisation bactérienne. En plus des entérotoxines et des adhésines, de nombreux autres facteurs de colonisation sont constamment identifiés. En 2009, EtpA, une exoprotéine, a été identifiée dans des ETECs chez l'humain et son interaction avec la région conservée des flagelles a été confirmée. Cette interaction est primordiale pour l'adhérence des ETECs sur l'épithélium intestinal humain. Notre étude a montré que le gène EtpA est aussi présent dans les ETECs « wildtype » chez le porc. Une analyse de corrélation a révélé que la capacité d'adhérence des ETECs ne peut pas être uniquement attribuée à un seul trait pathogénique tel que l'expression d'entérotoxines, d'adhésines ou d'EptA. Il semble que la pathogénécité des ETECs est très complexe. Dans le but d'étudier les mécanismes d'adhérence des ETECs, ce projet s'est d'abord concentré sur la reconnaissance entre les glycoprotéines des cellules et les adhésines des bactéries, étape cruciale pour l'adhérence bactérienne. Dépriver les cellules de l'épithélium intestinal porcin d'acide sialique a ainsi permis d'augmenter la liaison des ETECs. Différents monosaccharides ont ensuite été utilisés en tant qu'inhibiteurs compétitifs dans le but de déterminer les sites que reconnaissent les adhésines des ETECs. Nos résultats suggèrent que le résidu subterminal N-acétylgalactosamine (GalNAc) semble être reponsable de la reconnaissance de la forme F4ac des fimbriae. De plus, chez toutes les ETECs répondant aux traitements avec les monosaccharides, 100% des ETECs saturées en Neu5Ac ainsi que 80% des ETECs saturés en Mannose ont montré une augmentation de la capacité de liaison sur les monocouches cellulaires IPEC-J2 dépourvues d'acide sialique. Un modèle de changement de conformation des adhésines bactériennes a déjà été proposé et a été accepté pour expliquer ce phénomène. Il a été suggéré qu'un effet allostérique se produirait : après la liaison sur les adhésines des ETECs, où la reconnaissance des sites Neu5Ac libres est essentielle pour initier l'adhérence bactérienne, certains sucres, comme le fucose ou le mannose pourraient agir avec Neu5Ac sur les adhésines et contribuer ainsi à une meilleure liaison.</description><creator>Lin, Tsung-Jung</creator><contributor>Xin Zhao (Supervisor)</contributor><date>2012</date><subject>Biology - Microbiology</subject><title>The binding mechanism of enterotoxigenic escherichia coli (ETEC) to swine intestinal epithelia</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/ww72bg67p.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/kh04dt473</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Animal Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:rn301550s</identifier><datestamp>2020-03-21T21:17:37Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Partant d'une analyse des pratiques contemporaines de cours de formation en ligne a enseigné dans les environnements virtuels, je cherche à récupérer une notion d'identité sociale dans la vision de Hannah Arendt sur une scène politique, l'identité sociale comme un masque que les acteurs portent quand il agit politiquement. J'évite le langage de la médiation, au lieu de voir le "Mask" plus que jamais présent. J'offre ce mode d'inscription comme étant cruciales pour notre compréhension de la spécificité moyenne, et il s'applique en particulier à mon analyse de l'utilisation de Second Life (SL) dans des environnements d'apprentissage en ligne. Je prends l'utilisation de SL dans les cours universitaires comme un exemple de penser à ce qui arrive quand l'éducation-ce que je comprends comme étant essentiels à la citoyenneté, une pratique qui dépend apparaître en public-se déplace vers un espace de publicité virtuelle. J'examine l'histoire de l'université moderne et le rôle que les technologies ont joué dans la réorganisation des entreprises de croissance de l'université. Je défends l'université, idéalement, un site retiré par d'autres institutions, un site à partir de laquelle, dans les mots de Nietzsche, le «prématurée» peut émerger. Je me tourne vers la pensée politique de Hannah Arendt, comme un motif théorique pour comprendre et avatars communauté virtuelle, après Norma Claire Moruzzi en lisant le masque de l'identité sociale comme un site d'engagement politique. J'explore l'apposition de l'articulation de Hannah Arendt de public, personae politique ou des masques dans Essai sur la révolution, ainsi que sa critique de bifurcation métaphysique de Platon de l'Etre et l'apparence, et sa compréhension de (juif) identité en tant que non-territoriales-et donc virtuelle aux débats actuels concernant cybersociality et de la communauté en ligne. Je lui ai lu contre la réception commune pour faire valoir que la conception des acteurs politiques animant ses textes est la meilleure lumineux lorsqu'il est lu à travers les discours contemporains heuristique de la technologie. Ce faisant je développe un point de vue d'Arendt de la politique et l'identité sociale qui est susceptible d'être et s'investit dans des modes de résistance possibles par cybersociality. Du point de vue de la pédagogie critique, je vise à réfléchir aux moyens d'utiliser les technologies comme potentiellement repolitiser, et je identifier les propriétés d'apprentissage en ligne doivent démontrer de manière à créer de nouveaux sites de résistance.</description><description>Proceeding from an analysis of contemporary practices of online education courses taught in virtual environments, I seek to recuperate a notion of social identity in Hannah Arendt's vision of a political stage; social identity as a mask that actors wear when acting politically.  I avoid the language of mediation, instead seeing the 'Mask' as ever present.  I offer this mode of inscription as being central to our understanding of medium specificity, and apply it in particular to my analysis of the use of Second Life (SL) in online learning environments.  I take the use of SL in university courses as an example to think through what happens when education- which I understand as being essential to citizenship, a practice that depends on appearing in public- shifts to a space of virtual publicity. I examine the history of the modern university and the role that technologies have played in the growing corporate reorganization of the university.  I defend the university as, ideally, an autonomous site from which, in Nietzsche's words, the "untimely" can emerge.  I look to the political thought of Hannah Arendt as a theoretical ground for understanding avatars and virtual community, following Norma Claire Moruzzi in reading the mask of social identity as a site of political engagement.  I explore the appositeness of Hannah Arendt's articulation of public, political personae or masks in On Revolution, as well as her critique of Plato's metaphysical bifurcation of Being and appearance, and her understanding of (Jewish) identity as non-territorial- and therefore virtual- to contemporary debates concerning cybersociality and online community.  I read her against common reception to argue that the conception of political actors animating her texts is best illuminated when read heuristically through contemporary discourses of technology. In so doing I develop an Arendtian view of politics and social identity that is amenable to and invests itself in modes of resistance enabled by cybersociality.  From the perspective of critical pedagogy, I aim to think through ways of utilizing technologies as potentially repoliticizing, and I identify the properties online learning must demonstrate in order to create new sites of resistance.</description><creator>Sannicandro, Joseph</creator><contributor>Darin Barney (Internal/Supervisor)</contributor><date>2012</date><subject>Communications And The Arts - Mass Communications</subject><title>Nothing behind the mask: an Arenditian approach to virtual worlds and the politics of online education</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/9306t325z.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/rn301550s</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of Art History and Communication Studies</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:dn39x528n</identifier><datestamp>2020-03-21T21:17:38Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les interfaces sérielles à haute vitesse voient leur vitesse continuellement augmentée afin de satisfaire à des exigences de bande passante sans cesse croissantes. Ces interfaces sérielles doivent donc rencontrer des contraintes temporelles toujours plus serrées. Ceci a pour conséquence l'apparition de problèmes de vacillement et d'erreur sur les bits. Ce mémoire explore des techniques permettant l'accélération des tests de vacillement et de taux d'erreur sur les bits pour les interfaces sérielles à haute vitesse. Nous proposons une méthode de test de transmetteur basée sur le sur échantillonnage qui accélère le test du vacillement et du diagramme de l'oeil par l'utilisation d'un circuit de test de taux d'erreur sur les bits (BERT) multiphase. La méthode proposée fait usage de plusieurs éléments de test en parallèle travaillant ensemble et permet de numériser le comportement du vacillement du signal d'entrée de façon multiphase. Plus le nombre de phases utilisé est élevé, plus rapide est le test. La méthode proposée va au delà de nos résultats obtenus avec les interfaces de disque SATA [2], soit un temps de test passant de quelques secondes à 100 ms. Elle permet en effet d'extraire de façon précise le vacillement dans le domaine temporel et de compléter la totalité du test du transmetteur en quelques dizaines de millisecondes.</description><description>High speed serial interfaces (HSSI) are continually pushed toward operating at higher speed to meet the demand for higher bandwidth.  As a result, the timing constraints for HSSI devices get tighter.  Consequently, HSSI devices experience issues such as timing jitter and bit-errors. This thesis investigates techniques to speed up bit-error rate (BER) and jitter testing of HSSI devices. This work proposes an oversampling-based transmitter test scheme that accelerates transmitter jitter as well as eye diagram testing through the deployment of a multi-phase bit-error rate test circuit (BERT). The proposed scheme creates parallel BERT elements working in conjunction that are able to digitize the input signal jitter behavior in a multi-phase manner. The more phases we deploy the faster the test is completed. We aim to accurately extract the transmitter jitter in time domain and finish the whole transmitter test within tens of milliseconds. This exceeds the performance of [2], which by itself was an improvement from seconds to 100 ms.</description><creator>Najafi Nejad Nasser, Rozita</creator><contributor>Zeljko Zilic (Internal/Supervisor)</contributor><date>2012</date><subject>Engineering - Electronics and Electrical</subject><title>Oversampled multi-phase time domain bit-error rate processing for transmitter testing</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/rn3015512.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/dn39x528n</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:2801pm262</identifier><datestamp>2020-03-21T21:17:38Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Cette thèse est un rapport sur la conception, la construction et l'analyse des données du calorimètre hadronique digital (CALHD). Le CALHD a été construit dans le cadre des efforts menés par la collaboration CALICE pour la conception du détecteur SiD destiné au future Collisionneur Linéaire International (CLI). Le SiD est un des deux détecteurs proposés pour le CLI. Le CALHD lui-même n'est qu'un des sous-systèmes devant constituer le détecteur complet. La collaboration CALICE est impliquée dans le développement des calorimètres pour le CLI. Le CALHD utilise la technologie des chambers à plaques résistives pour détecter les événements physiques et est le premier calorimètre par images digitales au monde. La construction du prototype a été realisée au Laboratoire National Argonne et ses performances étudiées dans un montage de tests avec des rayons cosmiques. De plus, le CALHD a été placé à plusieurs reprises dans une ligne de fasiceau de particules au Laboratoire National d'Accélérateur Fermi. Ce travail sera complété par l'analyse des données du CALHD avec des muons. La calibration à l'aide de muons sera discutée, ainsi que la viabilité globale de cette technologie pour un détecteur à grande échelle.</description><description>This thesis is a report on the design, construction and data analysis of the Digital Hadron Calorimeter (DHCAL). The DHCAL was constructed as part of the CALICE collaboration efforts in the SiD detector design for the proposed International Linear Collider (ILC). The SiD detector design is one of two detector designs for the ILC. The DHCAL is but one of the detector sub-systems that are to make up the entire detector. The CALICE collaboration is involved in the development of calorimeters for the ILC. The DHCAL utilizes Resistive Plate Chamber technology to detect the physics events and is the world's first digital imaging calorimeter. The prototype construction was performed at Argonne National Laboratory and the detector studied locally in a cosmic ray test stand. In addition, the DHCAL was also put into multiple test beam runs at Fermi National Accelerator Laboratory. This work will be completed with the analysis of the DHCAL data with muons. The calibration with muons will be discussed, as well as its purpose to the overall viability of this technology in a full scale detector.</description><creator>Trojand, Daniel</creator><contributor>Francois Corriveau (Internal/Supervisor)</contributor><date>2012</date><subject>Physics - Elementary Particles and High Energy</subject><title>A novel digital hadron calorimeter: analysis and calibration with muons</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/t148fn16g.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/2801pm262</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Physics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:9k41zj58k</identifier><datestamp>2020-03-21T21:17:39Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Selon la théorie de la complexité des algorithmes, une réduction est une approche pour résoudre unproblème en le transformant en un autre problème de référence qui a déjà été résolu. Ceci permet de trouver une solution à ce problème initial d'une manière efficace, comparemment à essayer de le résoudre directement, ce qui pourrait être coûteux ou même infaisable. Le concept de réduction n'est pas seulement constrainte à la théorie, en pratique,les humains utilisent leurs expériences pour résoudre de nouveaux problèmes en se basant surleurs raisonnements analogiques et en les conformant aux problémes qui se trouvent dans leurs références ou leurs souvenirs. Cependant, parce que les informations conservées dans les références ne sont pas toujours exactes etparfois manquent des détails, la conformation doit en quelque sorte être suffisamment robuste pour tolérer ces incertitudes. Dans cette thèse, nous construisons un systéme de résolution de problèmes basé sur la méthode de réduction, et nous le présentons dans le domaine de la robotique dans lequel les contextes des problèmes peuvent être représentés dans une espace geométrique. Nous définissons la conformation spatiale par le processus de correspondence entre un probléme d'origine et un autre probléme de référence. Tout d'abord, nous développons une approche générale pour résoudre une série de problèmes devant être traités par réduction. Par la suite, nous mettons l'accent sur une catégorie de problèmes de satisfaction de constraintesformulé dans le système de conformation spatiale. Une implémentation de chaque partie dans les applications de la robotique a été démontrée pour servir d'évaluation empirique.</description><description>In computational complexity theory, a reduction is an approach to solving one problemby transforming it into another reference problem in which a solution already exists,thus providing the solution to the original problem in an efficient manner especiallywhen compared with solving the problem directly, which can be costly or even infeasible.The concept of reduction is not only limited to theory; in practice, humansuse past experience to solve problems by \emph{conforming} them, based on analogical reasoning, to known ones that are contained in references or memories.However, because the information retained in references is not always accurate and sometimes filled with redundancies or missing details, the conformation must somehow be robust enough to tolerate these uncertainties.In this thesis, we construct a framework for problem solving by reduction, and we present it in the robotics domain where contexts of problems can be represented using graphical spaces. The process has to match an input problem space to another one in a reference in order to retrieve a solution; we call this process spatial conformation. The content of this thesis can be divided into two parts.First, we develop a general approach and mathematical framework for a range of problem solving challenges to be addressed by reduction. Then we shift our attention to a class of constraint satisfaction problems formulated within the spatial conformation framework. An implementation for each part in robotics applications has been demonstrated to serve as empirical evaluation.</description><creator>Viriyasuthee, Chatavut</creator><contributor>Gregory L Dudek (Internal/Supervisor)</contributor><date>2012</date><subject>Applied Sciences - Computer Science</subject><title>Problem solving by spatial conformation</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/5999n7273.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9k41zj58k</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:9w0327009</identifier><datestamp>2020-03-21T21:17:40Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les algorithmes de routage géographique utilisent conventionnellement des techniques avides de renvois à un bond comme leur technique primaire de routage mais ces techniques peuvent aboutir à une impasse. Les techniques secondaires de routage utilisées pour contourner les impasses ne sont malheureusement pas efficaces en termes de débits ou de consommation d'énergie. De plus, l'énergie résiduelle des nœuds et la qualité des liens ne sont pas considérés durant le procédé de routage. Ce mémoire présente une technique de routage géographique écoénergétique (TIEGeR) à deux bonds et basée sur de l'information pour obtenir un équilibre d'énergie efficace à travers le réseau tout en évitant les impasses en empêchant de manière proactive les nœuds maximaux relatifs. La distance pour atteindre la destination, la connexité des nœuds, la qualité des liens, et l'énergie résiduelle des nœuds sont utilisés pour formuler la mesure de routage pour TIEGeR. Par ailleurs, les techniques secondaires de routage traitant les impasses sont complémentées par le mode de progrès inverse. L'algorithme TIEGeR proposé est implémenté et évalué dans un environnement IEEE 802.15.4 en utilisant des simulations basées sur le NS-2 and en utilisant un banc d'essai basé sur les nœuds TI CC2530ZDK. Les simulations sont utilisées pour examiner la performance de TIEGeR dans une topologie de réseaux à grande échelle. Avec le banc d'essais, nous examinons et nous démontrons le fonctionnement et la performance réalisable de la technique TIEGeR quand elle est implémentée dans la couche réseau d'un réseau de capteurs sans-fil qui utilise la couche physique et la couche de contrôle d'accès au support (MAC) du IEEE 802.15.4. Les résultats des simulations et du banc d'essai vérifient les avantages du TIEGeR contre les techniques conventionnelles de routage géographique.</description><description>Geographic routing algorithms conventionally use one-hop greedy forwarding as their primary routing technique, which might lead to routing voids. Secondary routing schemes used to circumnavigate such routing voids are unfortunately not efficient in terms of throughput and energy consumption. Moreover, node residual energy and link quality are not considered during the routing process. This thesis presents a Two-hop Information based Energy-efficient Geographic Routing (TIEGeR) scheme to achieve effective energy balancing throughout the network, while preventing routing voids by proactively avoiding "local maxima" nodes. Distance to reach destination, node connectivity, link quality, and node residual energy are employed to formulate the routing metric for the TIEGeR. Besides, secondary routing scheme dealing with routing voids is supplemented by the reverse progress mode. The proposed TIEGeR algorithm is implemented and evaluated in an IEEE 802.15.4 environment using both simulation based on NS-2 and experimental testbed based on TI CC2530ZDK nodes. Simulations are used to investigate the performance of TIEGeR in large-scale network topologies. By experiment, we further evaluate and demonstrate the real-life operation and performance advantages of the TIEGeR scheme implemented in the network layer of a WSN using IEEE 802.15.4 MAC/PHY layers. Simulation and experimental results verify the advantages of TIEGeR against conventional geographic routing schemes.</description><creator>Singh, Ishaan Bir</creator><contributor>Tho Le-Ngoc (Internal/Supervisor)</contributor><date>2012</date><subject>Engineering - Electronics and Electrical</subject><title>TIEGeR: An energy-efficient multi-parameter geographic routing algorithm</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/np193d923.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9w0327009</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:41687n266</identifier><datestamp>2020-03-21T21:17:41Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Matrix completion problem deals with the reconstruction of a data matrix from a small subset of its entries. It has been recently shown that, under certain conditions, the missing entries can be recovered, when the data matrix has a low rank. However, we cannot provide an accurate reconstruction of the unknown entries even for a low rank matrix under, but not limited to, the following two conditions: First, the number of available entries falls below a certain limit; and second, some of the rows and columns of the matrix are unsampled, i.e., completely unknown. In this thesis, we propose two ways to improve the reconstruction performance. Firstly, when the number of known entries is insufficient for an accurate reconstruction, we propose to use extra information in the form of additional convex constraints, such as the sample mean and non-negativity of the unknown entries. Secondly, when there are unsampled rows and columns in the matrix, we propose the method of multi-stage matrix completion, which reconstructs the unknown entries by borrowing information from neighbouring known entries.We demonstrate the application of the proposed methods in the reconstruction of images with missing pixels. Additionally, these methods find their applicability in the simulation/modeling of natural phenomena encountered in the geo-sciences and geo-engineering, such as characteristics of petroleum reservoirs (e.g., porosity, permeability, fluid saturation); attributes of mineral deposits (e.g., metal content, rock properties, deleterious elements); and spatial and spatiotemporal pollutants in the air, water and soil. These phenomena can be modelled as two-dimensional spatial random processes. An important problem is the reconstruction of the process from a set of spatially distributed samples. However, due to the high cost associated with data acquisition, the number of available data samples is very small and is typically insufficient for performing accurate reconstructions. For this reason, reference models are frequently used to improve the quality of the reconstruction. In this thesis, we cast the spatial simulation/reconstruction problem as a matrix completion problem and we show that matrix completion with added constraints can be used to increase the quality of data sets. More specifically, we propose an improved version of the pre-existing High Order Stochastic Simulation (HOSIM) algorithm, termed HOSIM+, that adds a matrix completion-based pre-processing stage to HOSIM. Furthermore, we show that multi-stage matrix completion can effectively build training images (analogues) that can be used as reference models for spatial simulations and, importantly, are consistent with the data and their high-order spatial statistics, unlike the commonly used training images.</description><description>Le problème de complétion de matrices concerne la reconstruction d'une matrice de données à partir d'un petit sous-ensemble de ses entrées. Il a été montré récemment, que sous certaines conditions, les entrées manquantes peuvent être récupérées lorsque le rang de la matrice de données est petit.  Cependant, une reconstruction précise, même pour une matrice dont le rang est petit, est impossible dans certain cas incluant, sans toutefois s'y limiter, les deux cas suivant: Primo, le nombre d'entrées spécifiées est sous une certaine limite; et secundo quelques colonnes et linges de la matrice n'ont pas été échantillonnées, c'est-à-dire, elles demeurent entièrement inconnues. Dans cette thèse, nous proposons deux façons d'améliorer la performance de la reconstruction. Premièrement, si le nombre d'entrées est insuffisant, nous proposons d'incorporer de l'information additionnelle sous forme de contraintes convexes, telles que la moyenne de l'échantillon et la non-négativité des entrées inconnues. Deuxièmement, si quelques colonnes et linges de la matrice n'ont pas été échantillonnées, nous proposons la méthode de completion multi-étapes, qui complète les entrées manquantes en utilisant de l'information provenant des entrées connues avoisinantes. Nous démontrons l'application des méthodes proposées dans le cadre de la reconstitution d'images avec des pixels manquant.  De plus, ces méthodes peuvent êtres utilisées dans la simulation/modélisation de phénomènes naturels propres aux géosciences et à la géo-ingénierie, tels que la caractérisation des réservoirs pétroliers (ex. porosité, perméabilité, saturation des fluides); les attributs des depots minéraux (ex. teneur en métaux, propriétés de la pierre, elements délétères); ainsi que les polluants spatiaux et spatiaux-temporels dans l'air, dans l'eau et dans le sol.  Ces phénomènes peuvent êtres modélisés par des processus aléatoires spatiaux deux-dimensionnels. Un problème important est celui de la reconstruction d'un processus à partir d'un ensemble d'échantillons distribués spatialement.  Or, à cause des coûts élevés liés à l'acquisition de données, le nombre de données demeure très petit et est généralement insuffisant pourobtenir une reconstruction adéquate.  Ainsi, des modèles de reference sont fréquemment utilisés afin d'améliorer la qualité de la reconstruction.Dans cette thèse, nous interprétons le problème de la simulation/reconstruction spatiale comme un problème de complétion de matrices.  Nous montrons que cette approche, avec l'inclusion de contraintes additionnelles, peut améliorer la qualité de données. Plus précisément, nous proposons une version améliorée de l'algorithme de simulation stochastique d'ordre élevé (HOSIM) que nous appelons HOSIM+, en ajoutant une étape de prétraitement basée sur la completion de matrices.  De plus, nous montrons que la méthode de completion multi-étapes peut créer des images d'entrainement pouvant être utilise comme des modèles de référence pour des simulations spatiales et, contrairement aux images d'entrainement communément utilisé, ells sont compatibles avec les données et avec leurs statistiques spatiales d'ordre élevé.</description><creator>Yahya, Wadood</creator><contributor>Ioannis Psaromiligkos (Internal/Supervisor)</contributor><contributor>Roussos G Dimitrakopoulos (Internal/Cosupervisor2)</contributor><date>2012</date><subject>Engineering - Electronics and Electrical</subject><title>Image reconstruction from a limited number of samples: a matrix-completion-based approach</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/4x51hp48j.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/41687n266</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:9019s652m</identifier><datestamp>2020-03-21T21:17:42Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Marine stratocumulus clouds play a critical role in Earth's radiative balance primarily due to the role of their high albedo reflecting incoming solar radiation, causing a cooling effect, while weakly reflecting outgoing infrared radiation. Characterization of the 3-Dimensional (3D) structure of these cloud systems over scales of 20-40 km is required to accurately account for the role of cloud inhomogeneity and structure on their shortwave forcing and lifetime, which has important applications for Global Climate Models. For first time, such 3D measurements in clouds were made available from a scanning cloud radar during the U.S. Department of Energy (DOE) Atmospheric Radiation Measurement (ARM) program's Clouds, Aerosol, and Precipitation in the Marine Boundary Layer (CAP-MBL) field campaign in the Azores Islands.  The scanning radar observations were complimented by a suite of zenith-pointing active and passive remote sensors that were deployed to provide a detailed description of marine stratus over a long-term observation period in the ideal marine environment commonly found at the Azores.  The scanning cloud radar observations present a shift from a multi-instrument, vertically pointing 'soda-straw' observation technique to a radar-only, 'radar-centric' observation technique.  The scanning radar observations were gridded using a nearest-neighbor type scheme devised to take the natural variability of the observed field into account.  The ability of the scheme to capture primary cloud properties (cloud fraction, cloud boundaries, drizzle detection) was assessed using measurements from the vertically pointing sensors.  Despite the great sensitivity of the scanning cloud radar (-42.5 dBZ at 1 km range), the drop in sensitivity with range resulted in an artificial thinning of clouds with range from the radar.  Drizzle-free cloud structures were undetectable beyond 5 km from the radar.  Cloud fields containing drizzle were generally detectable to ranges exceeding 10 km from the radar.  Well-defined streaking patterns in the drizzle field (reflectivity greater than -15 dBZ) at cloud base were concluded to be  concomitant with the formation of boundary layer rolls.  Sounding data for these well-defined (unbroken) rolls revealed a mean sub-cloud layer wind exceeding 3.9 ms-1, sub-cloud layer shear exceeding 7.5 x 10-3 s-1, and a majority of streaks oriented within 20${\circ}$ of the mean sub-cloud layer wind, satisfying many boundary layer roll criteria proposed in past studies. Attempts to reconstruct the 3D cloud liquid water content and 2D column liquid water path across the scanning radar domain using Z (Reflectivity) vs. LWC (Liquid Water Content) regressions trained using the zenith measurements were proved ineffective due to the overall extent of drizzle at Graciosa, and errors associated with sensitivity loss at range.  Despite some difficulties, the SWACR satisfied ARM metrics for success by proving effective at detecting weak clouds for extended time periods across a 10 km plane, and drizzle across a 20 km range, at high spatial resolutions.  Difficulties in resolving accurate vertical velocity patterns also suggest the need for an adaptive sampling strategy to most effectively remove horizontal wind components.</description><description>Les nuages stratocumulus marins jouent un rôle essentiel dans l'équilibre radiatif de la Terre en raison, principalement, de leur albédo élevé réfléchissant le rayonnement solaire, provoquant un effet de refroidissement, tout en ayant peu d'effet thermique. La caractérisation de la structure tridimensionnelle (3D) de ces systèmes nuageux sur des échelles de 20-40 km est requise pour tenir compte, avec exactitude, du rôle de l'hétérogénéité et de la structure des nuages sur leur forçage dans les ondes courtes et leur cycle de vie, ce qui a des applications importantes pour les modèles climatiques globaux. Pour la première fois, de telles mesures 3D dans les nuages ont été rendues disponibles grâce à un radar de nuages à balayage (le SWACR) pendant la campagne de terrain dans les Açores « Clouds, Aerosol, and Precipitation in the Marine Boundary Layer » (CAP-MBL) du programme « Atmospheric Radiation Measurement » (ARM) du « Department of Energy » (DOE) américain. Les observations du radar à balayage ont été complémentées par une suite d'instruments de télédétection actifs et passifs pointant vers le zénith ayant été déployée pour fournir une description détaillée des stratus marins au cours d'une longue période d'observation dans l'environnement marin idéal couramment trouvé dans les Açores.  Les observations du radar de nuages à balayage présentent le passage d'une technique d'observation « paille », utilisant plusieurs instruments pointant verticalement, à une technique d'observation « radar-centrique », utilisant uniquement un radar. Les observations du radar à balayage ont été quadrillées en utilisant une technique du plus proche voisin conçue pour prendre en compte la variabilité naturelle du champ observé. La capacité du régime à capturer les propriétés primaires des nuages (fraction nuageuse, limites des nuages, détection de bruine) a été évaluée en utilisant les mesures des détecteurs pointant verticalement. Malgré la grande sensibilité du radar de nuages à balayage (-42,5 dBZ à une distance de 1 km), la diminution de la sensibilité avec la distance a entraîné un amincissement artificiel des nuages avec la distance du radar. Les structures nuageuses sans bruine étaient indétectables au delà de 5 km du radar. Les domaines de nuages contenant de la bruine étaient généralement détectables à des distances excédant 10 km du radar. Des stries bien définies dans le domaine de bruine (réflectivité Z supérieure à -15 dBZ) à la base des nuages ont été associées avec la formation de rouleaux dans la couche limite. Des données de sondage pour ces rouleaux bien définis (ininterrompus) ont révélé un vent moyen dans la sous-couche nuageuse dépassant 3,9 ms-1, un cisaillement dans la sous-couche nuageuse supérieur à 7,5 x 10-3 s-1 et une majorité des stries orientées dans les 20° du vent moyen de la sous-couche nuageuse, satisfaisant de nombreux critères des rouleaux de couche limite proposés dans des études antérieures. Les tentatives visant à reconstruire la teneur 3D en eau liquide (LWC) et la colonne 2D d'eau liquide des nuages dans le domaine du radar à balayage utilisant des régressions de Z vs LWC formées à partir des mesures en zénith se sont avérées inefficaces en raison de l'étendue générale de la bruine sur Graciosa et les erreurs associées à la perte de sensibilité avec la distance.  Malgré quelques difficultés, le SWACR satisfait les métriques de réussite de ARM en s'avérant efficace pour détecter les nuages faibles pendant de longues périodes à travers un plan de 10 km et la bruine sur une distance de 20 km, à haute résolution spatiale. Des difficultés à résoudre les structures précises de vitesse verticale suggèrent également la nécessité d'une stratégie d'échantillonnage adaptatif pour éliminer plus efficacement les composantes du vent horizontal.</description><creator>Bowley, Kevin</creator><contributor>Pavlos Kollias (Internal/Supervisor)</contributor><date>2012</date><subject>Earth Sciences - Atmospheric Sciences</subject><title>An evaluation of the observational capabilities of a scanning 95-GHz radar in studying the 3D structures of marine stratocumulus clouds</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/9593v037z.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9019s652m</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Atmospheric and Oceanic Sciences</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:1544bt38z</identifier><datestamp>2020-03-21T21:17:43Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Dans le contexte d'Internet, les identifiants des usagers jouent un rôle critique. L'un des avantages des identifiants traditionnels, soient les pseudonymes, est de fournir une protection de la vie privée des usagers. Les usagers peuvent créer autant d'identifiants anonymes qu'ils le désirent simplement en utilisant une adresse courriel. Par contre, l'anonymité même peut devenir un facteur limitant dû à la déresponsabilisation des usagers. L'importance des réseaux sociaux en ligne nous inspire à créer un système de pseudonymes sociaux à travers lequel il sera possible de déterminer la proximité entre pseudonymes tout en conservant la confidentialité. Le système se base sur l'idée d'associer un réseau social à un espace géométrique et d'assigner des coordonnées à chaque usager qui dépendent de la relation entre l'usager et son voisinage. Les coordonnées elles-même ne fournissent aucune information confidentielle à propos d'un usager. Cependant, en calculant la distance entre différentes coordonnées, la proximité entre usagers peut être estimée avec une certaine probabilité. J'ai évalué le système avec des données provenant de réseaux sociaux réels. Les résultats indiquent que le système proposé, en imposant certaines conditions, est prometteur.</description><description>Online identities play critical roles in the current Internet world. One of the virtues of traditional online identities, in forms of pseudonyms,  is the privacy protection of online users. Users can create as many anonymous identities as they want with only an email account. However, the anonymity itself could be a limitation because of the lack of accountability.The prevalence of online social networks inspires us to create a social pseudonym framework through which it is possible to determine proximity between pseudonyms while retaining privacy. The basic idea of this work is mapping the online social network into a geometric space and assigning each user a coordinate according to the relationship with his/her neighborhood. The coordinate itself will not disclose any information of a user, but by computing the coordinates distance, proximity between users could be estimated with a certain probability. I evaluated the framework with several real online social network datasets. The results indicate that the proposed framework is promising under certain conditions.</description><creator>Tang, Fugui</creator><contributor>Muthucumaru Maheswaran (Internal/Supervisor)</contributor><date>2012</date><subject>Applied Sciences - Computer Science</subject><title>A proximity determinable social pseudonym framework in online identity management system</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/w0892g074.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/1544bt38z</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:05741w77s</identifier><datestamp>2020-03-21T21:17:44Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les réseaux électriques ne cessent d'augmenter en capacité pour répondre à la demande énergétique en constante augmentation. Leur fiabilité et les normes de qualité sont aussi devenues de plus en plus contraignantes. Le déploiement des ressources distribuées, incluant la production et le stockage d'énergie, se répand dans les réseaux conventionnels, et remplace une partie de la production centralisée. Malgré les nombreux avantages pour les utilités à intégrer les ressources distribuées, des problèmes d'intégration doivent être gérés, tel que la nécessité d'îlotage des générateurs lorsqu'une section du réseau de distribution est séparée du réseau principal. Maintenir cette section alimentée les génératrices distribuées peut, potentiellement, créer des effets secondaires non-intentionnels tel qu'une augmentation des probabilités de choc électrique pour lepersonnel de chargé du service et la possibilité d'endommager les infrastructures duréseau de distribution, incluant les génératrices décentralisés. Cette thèse compare les caractéristiques et la performance d'un relais intelligent de détection d'îlotage, nouvellement développé, aux performances des relais de détection présentement utilisés en industrie. Le relais intelligent emploie des méthodes d'analyse à plusieurs variables et d'analyse de données afin d'arriver à des arbres de décision qui contiennent les réglages et les propriétés du relais de protection. La méthodologie d'essai est développée sur un simulateur en temps réel pour évaluer la performance du relais intelligent sur un modèle réduit d'une artère dedistribution existante. La méthodologie expose les applications potentielles du relais intelligent et un grand nombre de tests a été effectué pour représenter une multitude de conditions d'opération du réseau. Les tests indiquent que le relais intelligent estgénéralement plus performant que les relais conventionnels, basés sur la fréquence, latension ou le taux de variation de la fréquence, présentement utilisés pour la détection d'îlotage, tout en respectant les contraintes sur les temps de détection imposées par les normes d'interconnexions de la production distribuée.</description><description>As electric power systems continue to grow to meet ever-increasing energydemand, their security, reliability, and sustainability requirements also become morestringent. The deployment of distributed energy resources (DER), including generationand storage, in conventional passive distribution feeders, gives rise to integrationproblems involving protection and unintentional islanding. Distributed generators need tobe islanded for safety reasons when disconnected or isolated from the main feeder asdistributed generator islanding may create hazards to utility and third-party personnel, andpossibly damage the distribution system infrastructure, including the distributedgenerators.This thesis compares several key performance indicators of a newly developedintelligent islanding detection relay, against islanding detection devices currently used bythe industry. The intelligent relay employs multivariable analysis and data miningmethods to arrive at decision trees that contain both the protection handles and thesettings.A test methodology is developed to assess the performance of these intelligentrelays on a real time simulation environment using a generic model based on a real-lifedistribution feeder. The methodology demonstrates the applicability and potentialadvantages of the intelligent relay, by running a large number of tests, reflecting amultitude of system operating conditions. The testing indicates that the intelligent relayoften outperforms frequency, voltage and rate of change of frequency relays currentlyused for islanding detection, while respecting the islanding detection time constraintsimposed by standing distributed generator interconnection guidelines.</description><creator>Zhuang, Davy</creator><contributor>Geza Joos (Internal/Supervisor)</contributor><date>2012</date><subject>Engineering - Electronics and Electrical</subject><title>Real time testing of intelligent relays for synchronous distributed generation islanding detection</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/h415pf59d.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/05741w77s</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:sx61dr14c</identifier><datestamp>2020-03-21T21:17:44Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Endotherms are capable of using internal heat to precisely regulate body temperature at an elevated level, yet there is considerable variation in the range of body temperatures (heterothermy) expressed by an endotherm.  In this thesis, I exploit two different approaches to address the causes and consequences of heterothermy in mammals, reflective of an underlying trade-off between the functional benefits and energetic costs of endothermy.  I first conduct an inter-specific, empirical analysis of mammalian body temperatures reported in the literature, treating heterothermy as a continuous variable spanning all endotherms, to examine factors that predict the degree of body temperature fluctuation observed in different species.  Across mammals, body temperature variation decreased with body mass and increased with proximity to the poles, and food hoarders were less heterothermic than non-hoarders.  Further, with these allometric, latitudinal, and behavioural effects included, phylogeny still had a strong influence on the degree of body temperature variation in a given species.  In my second chapter, I examine potential behavioural consequences of torpor, a special case of heterothermy involving a pronounced reduction in body temperature and metabolism.  This research was conducted in captivity on eastern chipmunks (Tamias striatus), which exhibit deep torpor and show extreme individual variation in heterothermy that spans most of the heterothermic continuum expressed by mammals in general.  To test the hypothesis that torpor impairs exploration and spatial memory, individual performance was assessed in an open field and a radial arm maze prior to and during hibernation.  Results showed that habituation in the open field was negatively impacted by torpor, particularly prolonged torpor, however performance in the radial maze, tested later in the arousal period, was less affected.  Thus, torpor expression clearly affects behaviour, but these effects are very transient and therefore unlikely to have long-term fitness consequences.  Mammals overall are characterized by extensive variability, both among and within species, in the degree of body temperature variation, with species occupying cold climates and relying on ephemeral food being characterized by the most heterothermy.  As to why more individuals and species do not exploit the energetic savings of high-amplitude heterothermy, captive research suggests the immediate costs of reduced body temperature on endotherm function may be more important than its long-term effects.</description><description>Les animaux endothermiques sont capables d'utiliser leur chaleur interne afin de réguler précisément leur température corporelle à un niveau élevé, pourtant il y une gamme considérable dans le degré de variation en température corporelle (hétérothermie) chez les endothermes.  Dans cette thèse, j'utilise deux méthodes différentes pour adresser les causes et conséquences de l'hétérothermie chez les mammifères, reflétant un compromis entre les avantages fonctionnels et les désavantages énergétiques de l'endothermie.  Je mène premièrement une analyse empirique inter-espèce de l'hétérothermie chez les mammifères rapportée dans la littérature.  L'hétérothermie est considérée comme trait continu pour examiner les facteurs qui prédisent le gradient hétérothermique chez 545 espèces.  L'hétérothermie diminue avec la masse corporelle et augmente vers les pôles, et les amasseurs de nourriture sont moins hétérothermiques que les non-ammasseurs.  Une fois que ces effets allométriques, latitudinaux, et comportementaux sont inclus, la phylogénie avait encore une influence forte sur le degré d' hétérothermie.  Dans mon deuxième chapitre, j'examine les désavantages comportementaux de la torpeur, un cas spécial d'hétérothermie dans lequel les individus montrent une réduction marquée de leur température corporelle et de leur métabolisme.  Cette recherche a été menée en captivité sur les tamias rayés (Tamias striatus), reconnus pour manifester des degrés de torpeur traversant la plupart de la gamme d'hétérothermie exprimée par les mammifères en générale.  Pour examiner les désavantages comportementaux de la torpeur comme une explication potentielle de cette variation, la performance individuelle a été évaluée avant et durant l'hibernation à l'aide d'un test de l'arène et d'un test de labyrinthe radial.  Les résultats ont montré que l'habituation dans le test de l'arène était affectée négativement par la torpeur, particulièrement la torpeur profonde, mais la performance dans le labyrinthe radiale, testée plus tard dans la période d'éveil, était moins affectée.  Ainsi, l'expression de la torpeur affecte clairement le comportement, mais ces effets sont très transitoires et ont alors probablement peu de conséquences à long terme sur l'aptitude de l'individu.  Les mammifères en générale sont caractérisés par une vaste variation, inter- et intra-espèce, dans le degré d'hétérothermie et les espèces occupants les climats froids et se nourrissants de ressources éphémères sont caractérisées par le plus d'hétérothermie.  En expliquant pourquoi il n'y a pas plus d'individus et d'espèces qui exploitent les avantages énergétiques de l'hétérothermie de haute amplitude, la recherche en captivité suggère que les désavantages immédiats de la torpeur sur la fonction des endothermes peuvent être plus importants que ses effets à long terme.</description><creator>Thompson, Amy</creator><contributor>Murray Mitchell Humphries (Internal/Supervisor)</contributor><date>2012</date><subject>Health And Environmental Sciences - Environmental Sciences</subject><title>Correlates and consequences of heterothermy in mammals</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/v405sf641.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/sx61dr14c</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Natural Resource Sciences</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:s1784q495</identifier><datestamp>2020-03-21T21:17:45Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les menaces sont un aspect important des relations internationales mais peu d'études leur sont entièrement dédiées. Dans ce mémoire, nous présentons une explication de la perception des menaces qui repose sur deux facteurs principaux. Le premier est le niveau de compatibilité entre les préférences actuelles de deux États. Plus les préférences de deux pays sont incompatibles, plus ils se sentiront mutuellement menacés. Les prédispositions historiques qu'un État a vis-à-vis d'un autre constituent le deuxième facteur. Des prédispositions négatives tendent à exacerber les effets des incompatibilités de préférences alors que des prédispositions positives tendent à les minimiser. De plus, nous considérons que les préférences étatiques sont façonnées par l'évaluation que fait le gouvernement de la situation matérielle du pays et par sa vision de l'identité nationale. Nous écartons donc l'explication de la formation des préférences étatiques basée sur l'influence des groupes d'intérêts avancée par certains théoriciens. En ce qui concerne les prédispositions historiques, nous croyons qu'elles sont influencées par les premières interactions entre deux États suite à un changement de régime chez au moins l'un d'entre eux. Ces premières interactions sont elles-mêmes façonnées par le niveau de compatibilité entre les préférences étatiques qui existait à ce moment crucial. Nous testons cette explication ainsi qu'un certain nombre d'explications rivales découlant de différentes théories des relations internationales en comparant les perceptions américaines et britanniques de la Chine depuis 1949 et, plus particulièrement, entre 2006 et 2010. Cela nous permet de conclure que notre explication de la perception des menaces est confirmée par les faits alors que les explications rivales semblent pour leur part infirmées.</description><description>Threats are key elements in international relations but very few studies are exclusively devoted to them. In this thesis, we present an explanation of threat perception which rests on two main factors. The first one is the level of compatibility between the current preferences of two states. The more two countries have incompatible preferences, the more they will see each other as threatening.  The second factor is the historical predispositions that two states hold towards each other. Negative historical predispositions tend to exacerbate the effects of conflicting preferences whereas positive ones tend to minimize their effects. In addition, we claim that state preferences are shaped by the government's evaluation of the country's material situation and by its view of the national identity and not by the influence of domestic interest groups as some theorists claim. Concerning historical predispositions, we believe that they are influenced by the first interactions between two states following a regime change in one or both of them. Those first interactions are themselves shaped by the level of compatibility between state preferences that existed at that crucial time. We test this explanation along with rival ones derived from different International Relations theories by comparing American and British perceptions of China since 1949 and more particularly between 2006 and 2010. In the end, we are able to conclude that our explanation of threat perception is confirmed by the evidence gathered while rival ones tend to be disproved.</description><creator>Courvoisier Daoust, Thomas</creator><contributor>T V Paul (Internal/Supervisor)</contributor><date>2012</date><subject>Political Science - International Law and Relations</subject><title>Threat perceptions: American and British assessments of China</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/c821gp986.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/s1784q495</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of Political Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:b5644w73f</identifier><datestamp>2020-03-21T21:17:46Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The purpose of this thesis is to examine the causes of Islamist ideological moderation. It focuses on the role of discursive structures and social practices in bringing about this ideational change. Through an in-depth case study of the Muslim Brotherhood in Jordan, a discourse and practice analysis is conducted to provide a theory that traces this group's moderation as a process. The thesis presents the argument that the group's increasing moderation was a result of practicing politics in a structural environment that challenged them strategically and ideologically. Under these environmental conditions, significant contestation arose within the movement. Resolving these debates internally by providing ideological justifications for controversial political practices, and doing so through deliberative democratic processes, provided the legitimacy needed to alter, and moderate, the movement's ideology.</description><description>L'objectif du présent mémoire est d'examiner les causes qui sous-tendent la modération du discours idéologique des groupes Islamistes. À cet égard, ce mémoire se concentre sur le rôle des structures discursives et des pratiques sociales qui constituent la condition de possibilité de ce changement idéationnel. Grâce à une étude de cas approfondie des Frères Musulmans en Jordanie, ce mémoire  mène une analyse du discours et des pratiques sociales pour formuler une théorie qui trace le processus de modération idéologique du dit groupe. Ainsi, ce mémoire présente la thèse que la croissante modération idéologique des Frères Musulmans en Jordanie est le résultat d'une façon de pratiquer la politique dans un environnement structurel qui les défit stratégiquement et idéologiquement. Sous ces conditions structurelles, un important courant de contestation est né au sein du groupe. Le fait de résoudre cette contestation à l'interne en ayant recours à des explications idéologiques pour justifier des pratiques politiques controversées, en plus de le faire en ayant recours à des processus démocratiques délibératifs, a fourni la légitimité nécessaire pour altérer et modérer l'idéologie du groupe.</description><creator>Abdo, Ragheb</creator><contributor>Vincent Pouliot (Internal/Supervisor)</contributor><date>2012</date><subject>Political Science - General</subject><title>Islamist moderation in practice: democratic practices and their shifting meanings</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/xk81jq625.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/b5644w73f</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of Political Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:6h440x75v</identifier><datestamp>2020-03-21T21:17:47Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>To protect Digital Subscriber Line (DSL) systems against impulse noise (IN), interleaving combined with Reed-Solomon (RS) coding is typically deployed in the conventional DSL standards. However, interleaving introduces a long delay. To reduce such delay in conventional DSL systems that are corrupted by IN, retransmission can be used instead of interleaving. For an effective retransmission, reliable detection of corruption due to IN is required. In this thesis, we consider three detection approaches.  The first one is based on the RS decoding status since the decoder either detects the number of corrected errors or reports the failure of decoding when the errors exceed its correction capability. Retransmission is required when the transmitted codeword cannot be decoded. The second one uses the square distance method in which erasures are marked for unreliably received samples and retransmission is issued when the number of erased samples exceeds a certain threshold. Finally, the third one takes advantage of the unused tones in DSL systems in order to detect whether IN is present. For all the above approaches, we analyze the average retransmission delay and bit error rate (BER) and provide simulation results to validate the analysis. It is found that the "Decoding Status" approach can reliably indicate received signals corrupted by IN. We consider it a trustful way to correct the symbols and detect the errors since the probability of wrong decoding for the received symbol is very low. In the frequency selective fading channel and with the presence of Repetitive Electrical Impulse Noise (REIN), numerical results using different parameters such as various channel responses and IN powers show that retransmission offers a short delay while effectively avoiding transmission errors. Specifically, with the "Decoding Status" approach, the error caused by REIN can be completely avoided with the average retransmission delay of around 0.029ms and the maximum round-trip delay of 0.75ms.</description><description>Pour protéger les systèmes de ligne d'abonné numérique (DSL) contre le bruit impulsif (IN), les normes conventionnelles de DSL sont typiquement déployées avec de l'entrelacement combiné au codage Reed-Solomon (RS). Cependant, l'entrelacement introduit un long retard. Afin de réduire ce retard dans les systèmes conventionnels de DSL qui sont corrompus par l'IN, une retransmission peut être utilisée au lieu de l'entrelacement. Pour une retransmission efficace, une détection fiable de l'altération causée par l'IN est nécessaire. Dans cette thèse, nous considérons trois approches de détection. La première est basée sur le statut du décodage RS puisque le décodeur détecte le nombre d'erreurs corrigées ou bien signale qu'il a échoué quand le nombre d'erreurs dépassent sa capacité de correction. Une retransmission est nécessaire quand le mot codé transmis ne peut pas être décodé. La deuxième méthode emploie la méthode des distances carrées dans laquelle les suppressions sont marquées pour les échantillons reçus non fiables et une retransmission est émise quand le nombre d'échantillons supprimés dépasse un certain seuil. Enfin, la troisième méthode est de profiter des tonalités inutilisées dans les systèmes de DSL afin de détecter si l'IN est présent. Pour toutes les approches ci-dessus, nous analysons le retard moyen et le taux d'erreur sur les bits (BER) et nous fournissons des résultats de simulation pour valider l'analyse. Il est constaté que l'approche du statut de décodage peut indiquer de manière fiable les signaux reçus corrompus par IN et nous le considérons comme une manière efficace pour corriger les symboles et pour détecter les erreurs puisque la probabilité de mauvais décodage pour le symbole reçu est très basse. Dans la voie sujette à évanouissement progressif de fréquences avec la présence de bruit électrique impulsif répétitif (REIN), les résultats numériques utilisant des paramètres différents tels que de diverses réponses de voies de transmission et de diverses puissances du IN prouvent que la retransmission offre un court retard tout en évitant efficacement les erreurs de transmission. Spécifiquement, avec l'approche du statut de décodage, l'erreur provoquée par le REIN peut complètement être évitée avec un délai de retransmission moyennant 0.029ms et un retard aller-retour maximale est de 0.75ms.</description><creator>Zhang, Dan</creator><contributor>Tho Le-Ngoc (Internal/Supervisor)</contributor><date>2012</date><subject>Engineering - Electronics and Electrical</subject><title>Impulse noise detection techniques for retransmission to reduce delay in DSL systems</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/m039k924j.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/6h440x75v</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:kd17cz294</identifier><datestamp>2020-03-21T21:17:48Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Implantation is a complex process that involves precisely orchestrated and reciprocal protein signalling between the uterine endometrium and the implanting blastocyst. The free-floating blastocyst is able to secrete factors that activate certain protein signalling pathways in the luminal epithelial cells of the uterus, specifically at future sites of implantation. The activation of the Wnt protein signalling pathway has been shown to be a critical component of this embryo-uterine cross-talk that is required for successful implantation to occur. Canonical Wnt signalling can be visualized in a special strain of TCF/Lef transgenic mice. Previous microarray studies on these reporter mice have revealed that the genes encoding Ptgis, a prostaglandin I2 synthase, and Cyp26b1, a member of the cytochrome P450 superfamily of enzymes, are up-regulated in the luminal epithelial cells of mouse uteri at the time implantation occurs. β-galactosidase stainings of uterine tissues isolated from reporter mice allowed for the characterization of Wnt/β-catenin signalling within the uterus at different time points of pregnancy and pseudopregnancy. The observed expression pattern of canonical Wnt signalling was then compared to that of Ptgis and Cyp26b1 in vivo using immunofluorescently labelled slides of the uterine tissues under investigation. Ptgis and Cyp26b1 were shown to follow the same expression pattern as Wnt/β-catenin signalling in all tissue sections. Uterine exposure to Wnt7a around the time that implantation would usually occur stimulates canonical Wnt activity in the absence of a blastocyst in the pseudopregnant mouse uterus. This activation of Wnt/β-catenin protein signalling resulted in the increase in Ptgis and Cyp26b1 protein levels suggesting that these two molecules are indeed downstream targets of canonical Wnt signalling. Ptgis and Cyp26b1 expression patterns were shown to be restricted to the luminal epithelial cells of the mouse uterus at the time implantation occurs. Implantation was severely compromised when a Ptgis inhibitor was injected into the mouse uterus at post-coital day 3.0. These results suggest that both Ptgis and Cyp26b1 are components of the Wnt/β-catenin signalling pathway playing essential roles in embryo-uterine cross-talk. Further research needs to be done in order to elucidate the precise mechanisms by which these proteins contribute towards successful implantation and how they are linked to Wnt/β-catenin signalling cascades.</description><description>L'implantation est un processus extrêmement complexe qui dépend sur un dialogue moléculaire précis et synchronisé entre l'endomètre maternel et le blastocyste implantatoire. L'embryon est capable de sécréter des molécules qui stimulent des voies de signalisation protéiques particulières dans les régions de l'endomètre maternel où le processus implantatoire aura lieu. La stimulation de la voie Wnt est une signalisation biochimique essentielle au dialogue moléculaire materno-fœtal qui fait partie du processus implantatoire. La voie Wnt canonique peut être visualisée en utilisant un modèle murin transgénique TCF/Lef très spécial incluant le gène rapporteur LacZ. Auparavant, une analyse micropuces ADN sur les souris transgéniques TCF/Lef a conduit à l'identification de plusieurs gènes dont l'expression génique est stimulée par l'activité de la voie Wnt dans les cellules de l'épithélium de l'utérus durant le temps d'implantation. Le but de cette étude est d'analyser la régulation de deux de ces gènes Ptgis, une prostaglandine I2 synthase, et Cyp26b1, un membre de la famille enzymatique cytochrome P450, durant le processus implantatoire. Le marquage β-galactoside est une techniques expérimentale qui a été utilisée dans cette étude pour observer la signalisation Wnt/β-caténine dans l'utérus des souris transgéniques durant différents stades de gestation et de pseudo-gestation. Les résultats obtenus ont identifié une signalisation Wnt canonique très particulière et ce modèle d'expression a été comparé à l'expression protéique de Ptgis et Cyp26b1 in vivo en utilisant le marquage par immunofluorescence sur les tissus utérins d'intérêt. Ptgis et Cyp26b1 ont été démontré à suivre le même modèle d'expression que la voie Wnt/β-caténine dans toutes les sections de tissus utérins analysés. L'exposition utérine à Wnt7a durant le temps quand l'implantation aurait lieu, stimule la voie Wnt canonique même avec l'absence d'un blastocyste dans l'utérus des souris en état de pseudo-gestation. Cette hausse de signalisation Wnt/β-caténine stimule l'expression protéique de Ptgis et Cyp26b1 suggérant qu'en effet, ces deux molécules fonts partie de la signalisation canonique induite par les Wnts. L'expression protéique de Ptgis et de Cyp26b1 a été démontré d'être restreinte aux cellules de l'épithélium luminal utérin durant le processus implantatoire. L'implantation de l'embryon dans l'utérus murin a été empêchée par l'injection d'un inhibiteur de Ptgis dans la cavité utérine 3.0 jours après la fertilisation. Ces résultats suggèrent que Ptgis et Cyp26b1, à travers la signalisation Wnt /β-caténine, jouent un rôle qui est essentiel au dialogue moléculaire materno-fœtal. Les futures recherches vont devoir élucider le mécanisme précis par lequel ces deux protéines contribuent au succès du processus implantatoire et découvrir comment ces deux protéines et leurs gènes sont liés à la signalisation canonique induite par les Wnts.</description><creator>Djogo, Tina</creator><contributor>Daniel Dufort (Supervisor)</contributor><date>2012</date><subject>Biology - General</subject><title>The role canonical Wnt protein signalling plays during the process of implantation</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/47429f50r.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/kd17cz294</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Medicine</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:5m60qw817</identifier><datestamp>2020-03-21T21:17:49Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Le multiplexage à répartition  en fréquence orthogonale (MRFO) optique à la détection cohérente avec intervalle à protection réduite (IPR) est un candidat potentiel pour la prochaine génération des systèmes de transport optique au-delà de 100G. Cette méthode démontre un rendement spectral élevé et une grande tolérance aux dégradations du canal optique. En premier lieu, nous présentons un bilan sur les systèmes optiques à la détection cohérente avec l'emphase sur MRFO, les dégradations  du canal optique, et ainsi les techniques générales de traitement numérique du signal pour corriger ces dégradations. Ce travail se concentre sur l'égalisation du canal et l'estimation de phase des systèmes MRFO optique à la détection cohérente avec IPR. Nous commençons par proposer une nouvelle façon d'égalisation basée sur MRFO optique à la détection cohérente avec IPR pour réduire la marge de la préfixe cyclique à zéro. Ensuite, nous présentons que les non-linéarités intra-canal devrait être considérées pendant la conception des  symboles de référence  pour l'estimation du canal. Prochainement, nous proposons et analysons le phénomène du bruit de phase à la dispersion améliorée (BPDA) qui est causée par l'interaction entre le bruit de phase du laser and la dispersion chromatique dans les transmissions MRFO optique à la détection cohérente avec IPR. Le BPDA entraîne une dégradation de performance non-négligeable et limite la tolérances de la largeur spectrale du laser. Cependant, le BPDA peut être compensé par l'estimation de phase groupée à la vraisemblance maximum proposée dans ce travail.</description><description>Reduced-guard-interval (RGI) coherent optical (CO) orthogonal frequency-division multiplexing (OFDM) is a potential candidate for next generation 100G beyond optical transports, attributed to its advantages such as high spectral efficiency and high tolerance to optical channel impairments. First of all, we review the coherent optical systems with an emphasis on CO-OFDM systems as well as the optical channel impairments and the general digital signal processing techniques to combat them. This work focuses on the channel equalization and phase estimation of RGI CO-OFDM systems. We first propose a novel equalization scheme based on the equalization structure of RGI CO-OFDM to reduce the cyclic prefix overhead to zero. Then we show that intra-channel nonlinearities should be considered when designing the training symbols for channel estimation. Afterwards, we propose and analyze the phenomenon of dispersion-enhanced phase noise (DEPN) caused by the interaction between the laser phase noise and the chromatic dispersion in RGI CO-OFDM transmissions. DEPN induces a non-negligible performance degradation and limits the tolerant laser linewidth. However, it can be compensated by the grouped maximum-likelihood phase estimation proposed in this work.</description><creator>Zhuge, Qunbi</creator><contributor>David V Plant (Internal/Supervisor)</contributor><date>2012</date><subject>Engineering - Electronics and Electrical</subject><title>Channel equalization and phase estimation for reduced-guard- interval CO-OFDM systems</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/xg94ht636.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/5m60qw817</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:8910jz48q</identifier><datestamp>2020-03-21T21:17:49Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les individus autistes de haut niveau (HFA) ont des difficultés en face à face l'interaction sociale et de la communication. Développement de la communication par Internet et des services sociaux des médias au cours des deux dernières décennies a évoqué la possibilité pour les individus avec HFA pour construire leur propre contact et des réseaux de soutien. Cependant, la conception initiale et le développement des médias sur Internet sociale ne considèrent pas toujours les besoins des personnes handicapées. Actuellement, les données disponibles sont insuffisantes pour évaluer l'utilisabilité d'Internet basée sur les médias sociaux par les personnes atteintes de la SPT. Aussi, il ya un besoin croissant d'examiner les expériences de ces personnes en utilisant les médias sociaux pour communiquer et accéder à des informations sur une base quotidienne. Dans l'étude actuelle, nous rapportons l'analyse des questions du sondage en ligne visant à explorer la convivialité et les intérêts des individus avec HFA au Canada qui utilisent différents médias sociaux. Nous avons recueilli des informations sur la démographie des participants, leur niveau d'expertise dans l'utilisation de logiciels informatiques, matériel, internet, et leur expérience avec différents médias sociaux en ligne. Notre analyse des réponses de 17 individus avec HFA (M = 28 ans) sur des questions ouvertes et fermées suggèrent qu'il ya un haut niveau d'expertise accessibilité et l'autoévaluation dans l'utilisation de l'ordinateur, Internet et médias sociaux entre les individus avec HFA. Alors que, la plupart des participants ont montré un vif intérêt à utiliser l'Internet et les médias sociaux pour communiquer et l'accès à l'information, il ya une demande générale pour rendre l'utilisation des médias sociaux simples et sécurisés. Ces résultats peuvent contribuer à la compréhension de la nécessité actuelle de personnes utilisant le HFA médias sociaux, qui à son tour peut favoriser de nouvelles avenues afin de faciliter leurs capacités à forger de meilleurs réseaux sociaux et la communication.</description><description>Individuals with High Functioning Autism (HFA) have difficulties in face to face social interaction and communication. Development of internet-based communication and social media services over the last two decades has raised the possibility for the individuals with HFA to build their own contact and support networks. However, the initial design and development of the internet-based social media did not always consider the needs of the individuals with disabilities. Currently, insufficient data is available to evaluate the usability of internet-based social media by the individuals with HFA. Also, there is a growing need to examine the experiences of these individuals using the social media to communicate and access information on a day to day basis. In the current study, we report the analysis of online survey questions designed to explore the usability and the interests of individuals with HFA in Canada who use various social media. We collected information on participants' demography; their level of expertise in using computer software, hardware, internet, and their experience with various online social media. Our analysis of the responses from 17 individuals with HFA (M = 28 years) on both open and close-ended questions suggest that there is a high level of accessibility and self-perceived expertise in using computer, internet, and social media among the individuals with HFA. While, most of the participants showed keen interest to use the internet and social media for both communication and access to information, there is a general demand for making the use of the social media simple and secured. These findings may contribute to the understanding of the existing need of individuals with HFA using the social media, which in turn may promote new avenues to facilitate their abilities to forge better social and communication networks.</description><creator>Hashemy, Syeda</creator><contributor>Tara Flanagan (Internal/Supervisor)</contributor><date>2012</date><subject>Education - Psychology</subject><title>Usability and accessibility of social media among Canadians with high functioning autism</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/1r66j512k.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/8910jz48q</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of Educational and Counselling Psychology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:1v53k212t</identifier><datestamp>2020-03-21T21:17:50Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Despite the popularity of Java, problems may arise from potential data-race conditionsduring execution of a Java program. Data-races are considered errors in concurrent pro-gramming languages and greatly complicate both programming and runtime optimizationefforts. A race-free version of Java is therefore desirable as a way of avoiding this com-plexity and simplifying the programming model.This thesis is part of work trying to build a race-free version of Java. It implements andoptimizes thread-local accesses and comes up with a new semantics for this language. Animportant part of implementing a language without races is to distinguish thread-local datafrom shared data because these two groups of data need to be treated differently. This iscomplex in Java because in the current Java semantics all objects are allocated on a singleheap and implicitly shared by multiple threads. Furthermore, while Java does provide amechanism for thread-local storage, it is awkward to use and inefficient.Many of the new concurrent programming languages, such as OpenMP, UPC, and D,use "sharing directives" to distinguish shared data from thread-local data, and have fea-tures that make heavy use of thread-local data. Our goal here is to apply some of theselanguage ideas to a Java context in order to provide a simpler and less error-prone pro-gramming model. When porting such features as part of a language extension to Java,however, performance can suffer due to the simple, map-based implementation of Java'sbuilt-in ThreadLocal class. We implement an optimized mechanism based on program-mer annotations that can efficiently ensure class and instance variables are only accessed bytheir owner thread. Both class and instance variables inherit values from the parent threadthrough deep copying, allowing all the reachable objects of child threads to have localcopies if syntactically specified. In particular, class variable access involves direct accessto thread-local variables through a localized heap, which is faster and easier than the defaultmap mechanism defined for ThreadLocal objects. Our design improves performance sig-nificantly over the traditional thread-local access method for class variables and providesa simplified and more appealing syntax for doing so. We further evaluate our approach bymodifying non-trivial, existing benchmarks to make better use of thread-local features, il-lustrating feasibility and allowing us to measure the performance in realistic contexts. Thiswork is intended to bring us closer to designs for a complete race-free version of Java, aswell as show how improved support for use of thread-local data could be implemented inother languages.</description><description>Malgré la popularité de JAVA, de potentiels accès concurrents aux données peuvent causer des problèmes à l'exécution d'un programme. Les accès concurrents aux données sont considérés comme des erreur par les langages de programmation et compliquent grandement le processus de programmation et d'optimisation. Une version de JAVA sans accès concurrents serait la bienvenue et simplifierait ce processus. Cette thèse n'est qu'une partie d'une recherche plus importante visant à établir une version de JAVA sans accès concurrents. Elle implémente et optimise les accès en thread local et introduit une nouvelle sémantique pour ce langage. Une part importante de l'implémentation d'un langage sans concurrence est de distinguer les données locales de thread des données partagées car ces 2 types de données doivent être traitées différemment. Ceci est complexe en JAVA, car avec la sémantique actuelle, tous les objets sont alloués en un seul tas (heap) et implicitement partagés entre plusieurs threads. De plus, le mécanisme de stockage en thread local de Java est étrange et inefficace. Plusieurs des nouveaux langages concurrents, comme OpenMP, UPC et D, utilisent des "directives de partage" pour distinguer les données partagées des données locales de thread, et ont des structures faisant un usage avancé des données locales de thread. Notre but ici est d'appliquer certaines idées de ces langages dans un contexte JAVA dans le but de fournir un modéle de programmation plus simple et plus fiable. Cependant, apporter ces fonctionnalités sous forme d'extension a JAVA peut en affecter les performance du fait de la structure de la classe ThreadLocal de JAVA. Nous implémentons donc un mécanisme qui garantit efficacement que seul le processus propriétaire accède aux classes et variables d'instances. Aussi bien les classes que les variables d'instances héritent des valeurs du processus parent par copie, ce qui permet aux objets de processus enfants d'avoir des copies locales si précisé dans la syntaxe. En particulier, l'accès à des variables de classe utilise un accès direct aux variables du processus local via un tas local, ce qui est plus rapide et facile que le mécanisme par défaut de mappage défini pour les objet ThreadLocal. Notre conception améliore le performance de faon significative comparé à la méthode d'accès au processus local traditionnelle pour les variables de classe et fournit une syntaxe simplifiée et plus attrayante. Nous évaluons ensuite notre approche en modifiant des outils de test (benchmarks) complexes existants pour faire un meilleur usage de leurs fonctionnalités en processus local, ceci illustrant la faisabilité et nous permettant de mesurer les performances dans un contexte réaliste. Ce travail a pour but de nous rapprocher de la conception d'une version JAVA sans concurrence aussi bien que de montrer comment un support amélioré des données en thread local pourrait être implémenté dans d'autres langages.</description><creator>Zhang, Yi</creator><contributor>Clark Verbrugge (Internal/Supervisor)</contributor><date>2012</date><subject>Applied Sciences - Computer Science</subject><title>Implementation and optimization of thread-local variables for a race-free Java dialect</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/2z10wv61g.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/1v53k212t</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:p8418s29w</identifier><datestamp>2020-03-21T21:17:51Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Developed countries' growing awareness of greenhouse gas (CO2, CH4, N2O) emissions from agricultural soils has led to an increased interest in the management of soil organic matter (SOM), which now extends to developing countries, including Bangladesh. Bangladeshi agriculture follows a largely rice-based cropping rotation, for which insufficient site-specific information regarding gas emissions exists to identify temporal variability of SOM content. The objective of this study was to evaluate the applicability of the 'Denitrification-Decomposition' model (DNDC, version 9.3) as a tool to better understand SOC trends in tropical agriculture. DNDC was used to simulate gas emissions from 1948 to 1969 and 1981 to 2007, under farm management practices prevalent in the Dinajpur district of Bangladesh. Forty-nine years of historical daily precipitation and temperature data were used for simulation with DNDC, such that both aerobic and anaerobic conditions were experienced in any given year. A "summer rice - monsoon rice - wheat" cropping pattern was used. As the input parameters of annual precipitation and flooding duration would likely affect DNDC-simulated results, model outputs were categorized on the basis of the magnitude of these parameters. In each categorization scheme the output data were sorted either based on (i) mean, (ii) probability of exceedance, or (iii) standard deviation of annual precipitation or flooding duration. An analysis was then conducted of correlations among input and output variables.  Relationships between simulated variables like CO2 emissions, CH4 emissions, and change in SOC content, and input variables such as annual precipitation and flooding duration were generally similar under both of categorization schemes. In high precipitation years changes in SOC content showed a negative correlation (r =  0.90, P ≤ 0.05) with CO2 emissions, and a positive correlation with CH4 emissions (r = 0.85, P ≤ 0.05), highlighting the importance of studying gas emissions as part of the net C balance embedded in DNDC.  When categorized according to annual precipitation, CO2 and CH4 emissions were negatively correlated; however, no significant relationship existed when emissions data were categorized on the basis of flooding duration. This discrepancy might arise from the way in which DNDC computes the soil's net C balance. In physical systems, CH4 emissions from paddy fields have an important effect on SOC; however, DNDC calculates CH4 emissions based on available organic C generated by the decomposition sub-model, but the net change in SOC is only balanced according to the CO2 gas emissions calculated by decomposition sub-model. Thus, the CH4 emission calculated by the fermentation sub-model is not included as a loss of SOC in the C balance. The consequence of this in the output data was a steadily increasing SOC associated with the increase in CH4 emissions from the simulated soil system. In order to more accurately model the soil carbon balance in tropical agricultural systems with flooded soils, DNDC should be modified to take into consideration C lost through CH4 emissions in addition to those lost as CO2. DNDC might then be used in sensitivity analysis for different farm management practices under paddy-based cropping systems. Physical experimental analysis is also important for validation of the modelling work. This study showed that DNDC can serve as a rough tool to represent change in the SOC content under Bangladeshi agricultural practices. Some modifications of DNDC, however, would be desirable to make it better suited for future work of this kind.</description><description>La plus grande prise de conscience des pays développés quant aux émissions de gaz à effet de serre (CO2, CH4, N2O) provenant de sols agricoles a mené à un intérêt accru pour une gestion durable de la matière organique du sol (MOS). Cet intérêt s'étend maintenant à plusieurs pays en voie de développement, dont le Bangladesh. L'objectif de cette étude fut d'évaluer l'applicabilité du modèle informatique 'Dénitrification-Décomposition' (DNDC, version 9.3) comme outil permettant de mieux comprendre les tendances en MOS dans le contexte de l'agriculture des tropiques. Le DNDC servit à simuler les émissions de gaz à effet de serre de 1948 à 1969 et de 1981 à 2007, selon les modes de gestion agricole prévalent dans le district de Dinajpur, au Bangladesh. Une historique de précipitations et températures quotidiennes de 49 ans servit à alimenter les simulations avec DNDC, de façon à ce que des conditions aérobies et anaérobies aient lieu en toute année donnée. Une rotation de cultures "riz d'été - riz mousson - blé" fut employée. Comme les paramètres d'entrée (précipitation annuelle et durée d'inondations) auraient probablement un effet sur les résultats simulés par DNDC, les variables de sortie furent triées selon l'échelle de chacun des paramètres d'entrée. Pour chaque mode de catégorisation les variables de sortie furent triées selon soit (i) la moyenne, (ii) la probabilité de dépassement, or (iii) et l'écart type de la précipitation annuelle ou de la durée annuelle d'inondations. Une analyse fut ensuite conduite des corrélations entre les variables d'entrée et de sortie.  Le type de corrélation existant entre les variables de sortie simulées (émissions de CO2, émissions de CH4, et variation en MOS) et les variables d'entrée (précipitation annuelle, durée d'inondations) fut généralement semblable pour les deux critères de tri. Lors d'années de précipitation élevée la variation en MOS fut inversement corrélée (r =  0.90, P ≤ 0.05) aux émissions de CO2, et directement corrélée aux émissions de CH4 émissions (r = 0.85, P ≤ 0.05), soulignant l'importance qu'il y a d'étudier les émissions de gaz par l'entremise du module de bilan global en C de DNDC.  Lorsque trié selon la précipitation annuelle, les émissions de CO2 and CH4 furent inversement corrélées, tandis que lorsque le tri se fit selon la durée des inondations aucune corrélation significative n'apparut. Cette divergence s'avère peut-être le résultat de la façon par laquelle DNDC calcul le bilan en C du sol. Dans le monde réel, les émissions de CH4 provenant de rizières submergées ont un important effet sur la MOS. Cependant, DNDC calcule les émissions de CH4 selon le carbone organique disponible calculé par le module de décomposition, mais le bilan global en MOS n'est ajusté que pour le CO2 émis par le module de décomposition. Ainsi, les émissions de CH4 calculées par le module de fermentation ne sont pas prises en compte comme une perte en MOS dans le bilan de C. Par conséquence les données de sortie indiquèrent une augmentation progressive en MOS, associée à une augmentation en émissions de CH4 provenant du sol simulé. Afin de modeler plus précisément le bilan en C du sol dans les systèmes agricoles des tropiques à sols inondés, DNDC devrait être modifié afin de prendre en compte les pertes en C sous forme d'émissions de CH4 en plus de celles sous forme de CO2. Le DNDC pourrait alors servir à une analyse de sensibilité qui examinerait différentes pratiques de gestion agricole pour les rizières. Une analyse physique d'expériences sur le terrain s'avèrerait utile à une validation des travaux de modélisation. Cette étude démontra que DNDC peut servir d'outil approximatif pour représenter les variations en MOS advenant des pratiques agricoles courantes au Bangladesh. Cependant, il serait souhaitable que certaines modifications soient faites au modèle DNDC, pour qu'il soit mieux adapté à de futures utilisations de ce genre.</description><creator>Shahid, Syeda Rubyat</creator><contributor>Grant Clark (Internal/Supervisor)</contributor><date>2012</date><subject>Agriculture - Soil Science</subject><title>Simulating changes in soil organic carbon in Bangaladesh with the denitrification-decomposition (DNDC) model</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/v692tb37b.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/p8418s29w</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Bioresource Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:pg15bk027</identifier><datestamp>2020-03-21T21:17:52Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>With the advancement of technologies, earth observation data could be obtained with finer spatial and spectral resolution. However, the increasing volume and complexity of those high resolution data presents new challenges in geographic information system (GIS) and remote sensing (RS) research, such as heterogeneous distributed data handling, efficient parallel data processing algorithms, and easy manageability of the underlying cyberinfrastructure, new collaboration model and lower computation costs. Geospatial cloud computing is leveraged in GIS/RS research to address the challenges of heterogeneous distributed data and its processing. Although the early experience has proven it is a great success to utilize cloud computing in GIS/RS research, the manageability of the cyberinfrastructure cannot be neglected. To be manageable, I argue that cloud computing must handle domain specific problems in GIS/RS, manage privacy of data, ease of use, and be inexpensive. In thesis I propose IHC3—integrated hybrid cloud computing cyberinfrastructure for advanced scalability and easy manageability in GIS/RS cyberinfrastructure research. IHC3 is designed to seamlessly integrate the computing resource of local hardware with public cloud providers, and it can dynamically adjust the boundary of private and public cloud with respect to the variable workload. A set of functionalities to simplify the image data processing, analysis, and visualization in GIS/RS research are also implemented in IHC3. I use MODIS data re-projection experiment with IHC3 to evaluate IHC3's performance, and compare the execution time and computation costs with single desktop, private cloud and Amazon EC2. The experiment proves that IHC3 is an effective platform for GIS/RS research, and it can offload the onerous system administration work from GIS/RS scientists, providing them with a tool for enhancing their research.</description><description>Avec l'avancement des technologies, des données d'observation de la terre pourrait être obtenu avec une résolution spatiale et spectrale plus fine. Toutefois, le volume et la complexité croissantes de ces données à haute résolution présente de nouveaux défis en matière de système d'information géographique (SIG) et télédétection (RS) de recherche, tels que la manipulation des données distribuées hétérogènes, parallèle efficace des algorithmes de traitement de données, la gestion facile des cyberinfrastructure sous-jacente, nouveau modèle de collaboration et de coût de calcul inférieur. Géospatiales cloud computing ont un effet de levier en matière de SIG / RS de recherche pour relever les défis de données hétérogènes distribués et son traitement. Bien que les premières expériences ont prouvé qu'il est un grand succès d'utiliser le cloud computing dans les SIG / RS recherche, la gestion de l'cyberinfrastructure ne peut pas être négligée. Pour être gérable, je soutiens que le cloud computing doit traiter les problèmes domaine spécifique en matière de SIG / RS, de gérer la confidentialité des données, la facilité d'utilisation, et d'être peu coûteux. Ainsi, dans cet article je propose IHC3 intégrée cyberinfrastructure hybrides de cloud computing pour l'évolutivité de pointe et maniabilité facile dans la recherche cyberinfrastructure SIG / RS. IHC3 s'intègre de façon transparente les ressources de calcul du local de matériel avec les fournisseurs de cloud public, et il pourrait ajuster dynamiquement la limite de cloud privé et public à l'égard de la charge de travail variable. Un ensemble de fonctionnalités pour simplifier le traitement des données d'image, l'analyse et la visualisation de SIG / RS de recherche sont également mis en œuvre dans IHC3. Je utilise des données MODIS re-projection expérimenter avec IHC3 pour évaluer la performance IHC3, et de comparer les temps d'exécution et les coûts de calcul avec le bureau unique, nuage privé et Amazon EC2. L'expérience prouve que IHC3 est une plateforme efficace pour la SIG / RS de recherche, et il peut décharger le travail du système onéreux administration de SIG / RS scientifiques, en leur fournissant un outil pour l'amélioration de leurs recherches.</description><creator>Xing, Jin</creator><contributor>Bettina Kemme (Internal/Cosupervisor2)</contributor><contributor>Renee Sieber (Internal/Supervisor)</contributor><date>2012</date><subject>Applied Sciences - Computer Science</subject><title>IHC3: an integrated hybrid cloud computing cyberinfrastructure for GIS/RS research</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/g732df009.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/pg15bk027</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><resumptionToken completeListSize="47894">oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):19475</resumptionToken></ListRecords></OAI-PMH>