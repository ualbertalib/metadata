<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/assets/blacklight_oai_provider/oai2-b0e501cadd287c203b27cfd4f4e2d266048ec6ca2151d595f4c1495108e36b88.xsl"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd"><responseDate>2020-07-24T23:20:49Z</responseDate><request resumptionToken="oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):7950" verb="ListRecords">https://escholarship.mcgill.ca/catalog/oai</request><ListRecords><record><header><identifier>oai:escholarship.mcgill.ca:6d5700307</identifier><datestamp>2020-03-21T14:55:10Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La réutilisation de modèle reste encore un défi majeur dans le MDE, malgréles différents succès dans les langages de programmation, illustré par des exemples tels que les bibliothèques de classe, les services, et les composants. Les modélisateurs créent généralement des modèles à partir de zéro, car les langages de modélisation offrent un support limité pour réutiliser des modèles existants; de plus, les outils de modélisation en général ne sont pas livrés avec une bibliothéque de modèles réutilisables. Mais aussi, la nature transversale des questions sur le développement des logiciels complique l'application des techniques de génie logiciel tels que cacher l'information, la décomposition, les interfaces et l'abstraction dans le contexte de la MDE. Cette thèse atténue les défis mentionnés auparavant, qui réutilisent les faces dans le contexte de la MDE en proposant le CORE, un nouveau paradigme de réutilisation qui étend la MDE avec des meilleures pratiques, des techniques de modularisation de pointe ainsi que la séparation des préoccupations (SoC), le but de la modélisation, et lignes de produits logiciels (SPL). Le CORE préconise l'utilisation d'une interface en trois parties pour décrire une nouvelle unité de réutilisation appelée « concern » qui couvre plusieurs phases de développement. L'interface de variation décrit les choix fournis ainsi que leurs impacts sur les qualités du systéme. L'interface de personnalisation permet d'adapter une variation choisie á un contexte de réutilisation spécifique, tandis que l'interface d'utilisation définit comment une concern personnalisée peut éventuellement être utilisé. La thèse établie les bases du CORE en définissant ses concepts, un processus de réutilisation simple en trois étapes, un méta modèle, et des algorithmes de composition pour générer des modèles de reálisation basésur la sélection des fonctions et des interfaces de personnalisation. L'approche du CORE est validée de multiples façons. Un examen approfondi de la littérature compare la concern comme une unité de réutilisation à d'autres unités de réutilisation, en soulignant ses points forts. L'efficacité et l'utilité du méta modèle proposé (CORE) est validé par l'extension d'un langage de modélisation existant, le (modèles aspect réutilisables) RAM, pour supporter la concern-orientation. La faisabilité des algorithmes de composition présentés est démontrée par leur application au sein de l'outil TouchCORE. L'efficacité du processus de conception et de réutilisation du CORE est affichée au moyen de plusieurs études de cas: l'élaboration d'une concern d'un flux de travail réutilisable ainsi que d'une famille de systèmes de gestion de crise. Nous prévoyons que si CORE est adopté sur une grande échelle, il a le potentiel de transformer la discipline du génie logiciel dans son ensemble. Contrairement aux pratiques actuelles qui nécessitent souvent des ingénieurs logiciels ou des expertises concernant moult préoccupations simultanément dans chaque phase de développement, le CORE permettrait aux ingénieurs logiciels de se spécialiser, par exemple, dans le domaine des préoccupations. Les entreprises pourraient se concentrer sur la création de bibliothèques de concern à long terme, et, si nécessaire, de fournir des services de consultation pour personnaliser les préoccupations au contexte spécifique de l'application. En fin de compte, la réutilisation de la concern, les bibliothèques de concern, les outils basés sur CORE, ainsi que la spécialisation rapprocheront la pratique actuelle du génie logiciel aux pratiques dans les autres branches de l'ingénierie.</description><description>Model reuse remains a major challenge in Model Driven Engineering (MDE), despite the success stories in programming languages as exemplified by class libraries, services, and components. Modellers usually create models from scratch because modelling languages offer limited support to reuse existing models and modelling tools in general are not shipped with a library of reusable models. In addition, the crosscutting nature of software development concerns complicates the application of software engineering techniques such as information hiding, decomposition, interfaces, and abstraction in the context of MDE.This thesis mitigates the aforementioned challenges that reuse faces in the context of MDE by proposing Concern-Oriented Reuse (CORE), a novel reuse paradigm that extends MDE with best practices and techniques from advanced modularization and separation of concerns (SoC), goal modelling, and Software Product Lines (SPL). CORE advocates the use of a three-part interface to describe a new unit of reuse called concern that spans multiple development phases. The variation interface describes provided choices and their impact on system qualities. The customization interface allows adapting a chosen variation to a specific reuse context, while the usage interface defines how a customized concern may eventually be used. The thesis lays the foundation of CORE by defining its concepts, a simple three-step reuse process, a metamodel, and composition algorithms to generate realization models based on feature selections and customization mappings. The CORE approach is validated in multiple ways. An extensive literature review compares the concern as a unit of reuse to other reuse units, highlighting its strengths. The effectiveness and practicality of the proposed CORE metamodel is validated by extending an existing modelling language, Reusable Aspect Models (RAM), to support concern-orientation. The feasibility of the proposed composition algorithms is demonstrated by implementing them within the TouchCORE tool. The effectiveness of the CORE design and reuse process is shown by means of several case studies: the design of a reusable workflow concern as well as a family of Crisis Management Systems. We envision that if CORE is adopted on a large scale, it has the potential to transform the software engineering discipline as a whole. Unlike the current practices that often require software engineers to deal with and be an expert in many concerns simultaneously within each software development phase, CORE would enable software engineers to specialize, i.e., to become concern specialists. Companies could focus on creating long-lived concern libraries, and provide consulting services to customize concerns to specific application context, if necessary. Ultimately, concern reuse, concern libraries, CORE-based tools, and specialization will bring software engineering practices closer to what is done in other engineering disciplines.</description><creator>Alam, Omar</creator><contributor>Jorg Andreas Kienzle (Supervisor)</contributor><date>2016</date><subject>Computer Science</subject><title>Concern oriented reuse: A software reuse paradigm</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/9306t190v.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/6d5700307</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:br86b620z</identifier><datestamp>2020-03-21T14:55:11Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>In the first part, we show that a uniform quadrangulation, its largest 2-connected block, and its largest simple block, upon rescaling the graph distance properly, jointly converge to the same Brownian map in distribution for the Gromov-Hausdorff-Prokhorov topology. We start by deriving a local limit theorem for the asymptotics of maximal block sizes, extending the result by Banderier, Flajolet, Schaeffer &amp; Soria[16]. The resulting diameter bounds for pendant submaps of random quadrangulations straightforwardly lead to Gromov-Hausdorff convergence. To extend the convergence to the Gromov-Hausdorff-Prokhorov topology, we show that exchangeable "uniformly asymptotically negligible" attachments of mass simply yield, in the limit, a deterministic scaling of the mass measure.      In the second part, for each n ∈ ℕ, let Qₙ be a uniform rooted measured quadrangulation of size n conditioned to have r(n) vertices in its root block. We prove that for a suitable function r(n), after rescaling graph distance by $\left(\frac{21}{40\cdot r(n)}\right)^{1/4}$, with an appropriate rescaling of measure, Qₙ converges to a random pointed measured non-compact metric space S, in the local Gromov-Hausdorff-Prokhorov topology; the space S is built by identifying a uniform point of the Brownian map with the distinguished point of the Brownian plane. Our result relies upon both the convergence of uniform quadrangulations towards the Brownian plane by Curien &amp; Le Gall[30], and the convergence of uniform 2-connected quadrangulations to the Brownian map, proved in the first part of the thesis. The main steps of the proof are as follows. First, we show that the sizes of submaps pendant to the root block have an asymptotically stable distribution. Second, we deduce asymptotics for occupancy in a random allocation model with a varying balls-to-boxes ratio. Third, we establish a bound for the number of pendant submaps of the root block, which allows us to apply the occupancy bounds to uniformly control the sizes of pendant submaps. This entails that the pendant submaps act as uniformly asymptotically negligible "decorations" which do not affect the scaling limit.</description><description>Dans la première partie, nous démontrons qu'une quadrangulation uniforme, son plus grand bloc 2-connexe, et son plus grand bloc simple, convergent conjointement, après rescaling, vers la carte brownienne, en distribution pour la topologie de Gromov-Hausdorff-Prokhorov. Nous commençons par obtenir un théorème limite locale pour les asymptotique des tailles de blocs maximales, étendant le résultat par Banderier, Flajolet, Schaeffer &amp; Soria[16]. En résultent des bornes sur le diamètre des sous-cartes pendantes d'une quadrangulation aléatoire, qui permettent de garantir la convergence au sens de Gromov-Hausdorff. Pour obtenir la convergence au sens de la topologie de Gromov-Hausdorff-Prokhorov, nous montrons que des ajouts de masse échangeables et "uniformément et asymptotiquement négligeables" donnent tout simplement à la limite la même mesure de masse, à changement d'échelle déterministe près. Dans la deuxième partie, pour chaque n ∈ ℕ, soit Qₙ une quadrangulation uniforme de taille n, enracinée, mesurée et conditionnée à avoir r(n) sommets dans son bloc racine. Nous prouvons que pour une fonction appropriée r(n), après multiplication de la distance de graphe par $\left(\frac{21}{40 \cdot r(n)}\right)^{1/4}$, la quadrangulation Qₙ converge dans la topologie locale de Gromov-Hausdorff-Prokhorov vers S un espace métrique aléatoire non-compact, pointé et mesuré; l'espace S est construit par identification d'un point uniforme de la carte brownienne avec le point distingué du plan brownien. Notre résultat repose à la fois sur la convergence des quadrangulations uniformes vers le plan brownien par Curien &amp; Le Gall[30], et la convergence des quadrangulations uniformes 2-connexes vers la carte brownienne, récemment prouvée par Addario-Berry &amp; Wen [5]. Les principales étapes de la preuve sont les suivantes. Premièrement, nous démontrons que les tailles des sous-cartes pendantes au bloc racine suivent asymptotiquement une loi stable. Deuxièmement, nous prouvouns des asymptotiques pour les taux d'occupation dans un modèle d'allocation aléatoire avec un ratio "boules-aux-boîtes" variant. Troisièmement, nous établissons une borne pour le nombre de sous-cartes pendantes du bloc racine, ce qui nous permet d'appliquer les résultats du modèle d'allocation pour contrôler uniformément les tailles des sous-cartes pendantes. Cela implique que les sous-cartes pendantes agissent comme des "décorations" uniformément asymptotiquement négligeables, qui n'affectent pas la limite d'échelle.</description><creator>Wen, Yuting</creator><contributor>Dana Louis Addario-Berry (Supervisor)</contributor><date>2016</date><subject>Mathematics and Statistics</subject><title>Critical and subcritical scaling limits of random planar maps with connectivity constraints</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/j098zd95f.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/br86b620z</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Mathematics and Statistics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:bg257h63s</identifier><datestamp>2020-03-21T14:55:12Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Nous avons étudié plusieurs méthodes pour améliorer le rendement quantique externe des diodes électroluminescentes (DEL) GaN. Comme les fuites d'électrons sortantes de la région active du dispositif sont la principale responsable de la dégradation d'efficacité interne de ces dispositifs, nous avons proposé et démontré les diodes électroluminescentes de lumière blanche d'injection de tunnel point-en-fil sur Silicium, dans lesquels les électrons et les trous sont injectés dans la région active des points quantiques à travers deux puits injecteurs InGaN séparés. Le débordement d'électrons est réduit d'une façon importante sans utiliser aucune couche de blocage d'électrons (CBE) contenant de l'Al. Dans la seconde approche, nous avons démontré que le débordement d'électrons dans les DELs à nanofils peut être efficacement empêché en intégrant une CBE AlGaN dopée de type P, conduisant à la réalisation des DELs blanches sans phosphore qui peuvent présenter, pour la première fois dans le monde, pratiquement zéro d'affaissement d'efficacité. De plus, nous rapportons sur la démonstration d'un nouveau type des hétéro-structures DELs nanofils axiales qui utilisent des réseaux nanofils core-shells point-en-fils auto-organisés InGaN / AlGaN. Les couches barrières AlGaN dopées de type P sont plus efficaces, comme les CBEs distribuées, pour réduire le débordement d'électrons par rapport aux CBEs AlGaN classiques.D'autre part, l'extraction des photons générés hors des DELs GaN est difficile. La plupart des photons sont réfléchis à l'interface GaN / air en raison de la réflexion interne totale, et par conséquent sont piégés et absorbé à l'intérieur de la DEL. Nous avons montré que l'efficacité d'extraction de lumière des DELs GaN peut être considérablement améliorée par l'intégration des réseaux de nanotubes. L'extraction de la lumière se fait en deux étapes successives, y compris le couplage de la source lumineuse au tube et l'émission subséquente à partir du tube à l'air. Nous avons encore améliorée l'efficacité d'extraction de lumière des DELs UV profondes en utilisant des réseaux périodiques de nanofils. L'émission des modes guidés a été inhibée et redirigée vers les modes rayonnés en appliquant des structures nanofils. Nous avons montré qu'une efficacité d'extraction de lumière sans précédente de ~ 72% peut être atteinte.</description><description>We have developed several methods to enhance the external quantum efficiency of GaN light emitting diodes (LEDs). As electron leakage out of the device active region is primarily responsible for internal efficiency degradation in such devices, we have demonstrated that electron overflow in nanowire LEDs can be effectively prevented with the incorporation of a p-doped AlGaN electron blocking layer (EBL), leading to the achievement of phosphor-free white LEDs that can exhibit virtually zero efficiency droop. We further report on the demonstration of a new type of axial nanowire LED heterostructures, with the use of self-organized InGaN/AlGaN dot-in-a-wire core-shell nanowire arrays. The p-doped AlGaN barrier layers as distributed EBLs is found to be more effective in reducing electron overflow, compared to the conventional AlGaN EBL. In the second approach, we have proposed and demonstrated InGaN/GaN dot-in-a-wire tunnel injection white light emitting diodes on Si, wherein electrons and holes are injected into the quantum dot active region through two separate InGaN injector wells. Significantly reduced electron overflow is realized without the use of any Al-containing EBL. On the other hand, extracting the generated photons out of the GaN LEDs is difficult. Most of the photons are reflected at the GaN/air interface due to the total internal reflection, and consequently are trapped and absorbed inside the LED. We have shown that the light extraction efficiency of GaN LEDs can be significantly enhanced by integrating with nanotube arrays. The light extraction involves two successive steps, including the coupling from the light source to the tube and the subsequent emission from the tube to the air. We have further enhanced the light extraction efficiency of deep UV LEDs using periodic array of nanowires. The emission of the guided modes could be inhibited and redirected into radiated modes utilizing nanowire structures. We have shown that an unprecedentedly high light extraction efficiency of ~72% can, in principle, be achieved.</description><creator>Djavid, Mehrdad</creator><contributor>Zetian Mi (Supervisor)</contributor><date>2016</date><subject>Electrical and Computer Engineering</subject><title>High efficiency nanowire-based phosphor-free white and deep ultraviolet light sources</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/tb09j8162.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/bg257h63s</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:bk128d78n</identifier><datestamp>2020-03-21T14:55:12Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Résumé Les implants en titane sont facilement contaminés par la salive durant l'intervention chirurgicale ou après la mise en place. Cette contamination risque de modifier les caractéristiques de la surface et d'avoir une incidence sur le processus d'ostéointégration, ce qui peut mener à une péri-implantite et à la perte de l'implant. Même si plusieurs substances chimiques sont souvent utilisées pour la décontamination des implants, leur effet exact reste mal connu. La détermination de leurs effets sur les contaminants du titane et de la bouche est donc cruciale lorsqu'il s'agit de développer des traitements améliorés de décontamination des implants dentaires en titane. L'objectif de la thèse est de décrire les caractéristiques physiques des surfaces de titane contaminées par de la salive et de mieux évaluer les différentes substances qui peuvent favoriser l'ostéointégration. Dans le premier document, nous avons évalué l'efficacité de six solutions couramment utilisées pour la prise en charge de la péri-implantite (Listerine, chlorhexidine 0,2 %, acide citrique 50 %, solution saline 0,9 %, STP et acide phosphorique 35 %) sur des surfaces d'implant contaminées par de la salive. Nous avons utilisé la spectroscopie de photoélectrons XPS pour évaluer la composition en éléments des surfaces et la microscopie par fluorescence pour évaluer la charge bactérienne. L'analyse par XPS a montré que parmi toutes les solutions évaluées, l'acide citrique et la solution saline étaient les agents les plus efficaces pour la décontamination du titane et pour la restauration partielle des caractéristiques chimiques de départ à la surface de l'implant. Cependant, aucune des solutions évaluées n'était en mesure de restaurer complètement les caractéristiques chimiques de départ de la surface. Toutes, sauf la solution saline et Listerine, étaient efficaces en ce qui a trait à la réduction de la charge bactérienne. Ces résultats laissent penser que parmi les solutions mises à l'essai, l'acide citrique et la solution saline sont peut-être la meilleure solution pour l'usage clinique. Dans le deuxième document, nous avons évalué la manière dont la salive interagit avec les surfaces de titane, et ce que cela signifie du point de vue de l'interaction titane-sang. Nous avons utilisé la mesure des angles de contact, la spectroscopie de photoélectrons XPS et la microscopie par fluorescence afin d'observer les caractéristiques d'échantillons de titane avant et après une exposition à de la salive humaine. La recherche portait également sur l'effet de la contamination par la salive sur l'interaction sang-implant. Notre analyse a montré que sur les surfaces de titane, la salive formait une couche organique hydrophobe riche en bactéries qui a une incidence sur l'interaction sang-titane. Après avoir montré la nature hydrophobe des contaminants de surface liés à la salive, nous avons examiné l'utilisation de solvants (acide acétique et acétone) et de détergents (Tween 20) pour la décontamination des surfaces de titane. De fait, notre analyse montre que l'acide acétique et Tween 20 permettent d'obtenir une décontamination en éléments et microbienne importante, ce qui laisse penser que ces deux substances pourraient être utiles lorsqu'il s'agit de décontaminer des implants en titane. Cette partie de l'étude montre donc que la salive interagit avec les implants en titane d'une façon qui a une incidence sur l'interaction sang-titane, mais qu'il est possible de contrecarrer cette contamination par la salive au moyen d'acide acétique et de Tween 20 en tant qu'agents de décontamination du titane. La salive a donc une incidence sur l'interaction sang implant en titane par la mise en place d'une couche hydrophobe riche en bactéries. Il est cependant facile d'enlever cette couche avec des solvants, des détergents ou des chélateurs du calcium.</description><description>Abstract Ti-implants can get easily contaminated with saliva during surgery or after placement. This might alter its surface properties and interfere with the process of ossteointegration, ultimately leading to pre-implantitis and implant loss. Though several chemical agents are routinely used for implant decontamination, their exact effect is not well known and hence identifying their effect on Ti and oral contaminants is critical for developing better treatments for decontamination of Ti dental implants. Thesis objective manuscript-base was to characterize the physical properties of saliva-contaminated titanium surfaces and further assess the different chemicals that could be used for osteointegration. In the first manuscript, we evaluated the efficacy of 6 different solutions that are commonly used to manage peri-implantitis (Listerine, 0.2% Chlorhexidine, 50% citricacid, 0.9% saline, PBS and 35% phosphoric acid) on saliva-contaminated implant surfaces. We used x-ray photoelectron spectroscopy (XPS) to assess the elemental composition of the surfaces and fluorescence microscopy to assess the bacterial load. XPS analysis revealed that amongst all the solutions assessed, citric acid and saline were the most effective in decontaminating Ti and partially restoring the original implant surface chemistry. Although none of the solutions was able to fully recuperate the original surface chemistry. All of them except saline and Listerine were effective in reducing the microbial load. These results indicate that amongst the solutions tested, citric acid and saline could be the best option for clinical application. In second manuscript of this thesis, we assessed how saliva interacts with Ti-surfaces and the subsequent implication on Ti-blood interaction. We used contact angle measurements (CAM), x-ray photoelectron spectroscopy (XPS) and fluorescence microscopy to characterize Ti samples before and after exposure to human saliva. The effect of saliva contamination on blood-implant interaction was further investigated. Our analysis revealed that on the Ti surfaces saliva formed a bacterial-rich hydrophobic organic layer that interfered with Ti-Blood interaction. After revealing the hydrophobic nature of saliva surface contaminants, we explored the use of solvents (acetic acid and acetone) and detergents (tween20) for Ti surface decontamination. Indeed, our analysis demonstrated that acetic acid and tween-20 achieved substantial elemental as well as microbial decontamination, suggesting that they can be potentially useful for Ti-implant decontamination. This part of this study therefore demonstrates that saliva interacts with Ti-implants interfering with blood Ti interaction but this saliva contamination can be managed with the use of acetic acid and tween-20 for Ti decontamination. Therefore saliva interferes with the interaction of Ti-implants with blood by creating a hydrophobic layer that it is rich in bacteria. However this layer can be easily remove with solvents, detergents or calcium chelators.</description><creator>Fayezi Sisi, Azam</creator><contributor>Faleh Tamimi Marino (Internal/Supervisor)</contributor><date>2016</date><subject>Dentistry</subject><title>Surface characterization of ti implants following contamination with biological fluids and effects of various chemical reagents on implant surface contamination</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/4q77fv248.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/bk128d78n</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Faculty of Dentistry</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:fq977x619</identifier><datestamp>2020-03-21T14:55:13Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>This thesis presents a method that can be used to create operational transconductance amplifiers (OTAs), or their many related constructs such as operational amplifiers, with extremely high DC voltage gains − levels previously deemed unachievable due to stability concerns. The principle is based on the cascade of integrators to realize large DC gains and a controller to stabilize its operation in a closed-loop configuration. With K-integrators in cascade, the DC gain approaches levels described by (gmro)^2K V/V with a frequency response involving K co-incident poles having a frequency roll-off of -20K dB/decade. With the addition of the controller, the order N of the OTA is simply one order higher than the number of integrators in cascade, i.e., N=K+1. Collectively, this arrangement of gain stages provides an extremely high DC voltage gain but also a larger 3-dB bandwidth than its predecessors resulting in improved closed-loop negative feedback properties.To demonstrate the design principles and the proposed topology, a programmable OTA was fabricated in the IBM 130 nm CMOS process that could be programmed to realize orders ranging from 2 to 5. Measure data reveals DC gains ranging from 50 dB to 150 dB with a 3-dB bandwidth of 10 kHz and a unity gain frequency of 10 MHz. Operation in a unity-gain configuration demonstrate the accuracy of the synthesis method as defined by its Euclidean distance from its desired transfer function. While this thesis demonstrates the design principles using CMOS integrated circuits, the principles are general and can be applied to any type of circuit technology such as integrated or discrete implementations. Moreover, the methods are easily automated as the principles are based on closed-form formulae as opposed to iterative numerical search techniques.</description><description>Cette thèse présente une méthode pouvant être utilisée pour concevoir des amplificateurs opérationnels de transconductance (OTAs), ou autres designs semblables, tels que les amplificateurs opérationnels dont le gain en tension continue est tellement élevé, que ces designs étaient auparavant considérés comme irréalisables pour des raisons de stabilité. Ce concept de topologie consiste en une cascade d'intégrateurs, pour réaliser l'important gain en tension continue, ainsi qu'en un régulateur, pour stabiliser son fonctionnement en boucle fermée. Avec K intégrateurs en cascade, le gain en tension continue approche le comportement décrit par (gmro)^2K V/V avec une réponse fréquentielle comprenant des pôles coïncidents et une atténuation de -20K dB/decade. Avec l'ajout d'un régulateur, l'ordre N de l'OTA est simplement d'un ordre supérieur au nombre d'intégrateurs en cascade, tel que N=K+1. Cette configuration d'étages amplificateurs permet non seulement un gain en tension continue extrêmement élevé, mais aussi une bande passante à -3 dB plus large que celles de ses prédécesseurs, résultant en une amélioration des propriétés du comportement en boucle fermée à rétroaction négative.Afin de démontrer les principes de ce design ainsi que la topologie proposée, un OTA programmable a été fabriqué selon le procédé de fabrication de CMOS de 130 nm d'IBM. Cet OTA peut être programmé afin de faire varier son ordre de 2 à 5. Les mesures donnent un gain en tension continue variant de 50 à 150 dB avec une bande passante à -3 dB de 10 kHz et une fréquence à gain unitaire de 10 MHz. Le comportement en boucle à gain unitaire atteste de la précision de la méthode de synthèse, définie par la distance euclidienne entre la fonction de transfert voulue et celle obtenue.Bien que cette thèse démontre les principes de ce design avec des circuits intégrés de CMOS, les principes sont généraux et peuvent s'appliquer à tout types de technologies de circuits, telles que les implémentations intégrées ou discrètes. De plus, les méthodes peuvent être facilement automatisées car ces principes sont basés sur des formules analytiques et non sur des techniques de recherche itérative.</description><creator>Yang, Ming</creator><contributor>Gordon W Roberts (Internal/Supervisor)</contributor><date>2016</date><subject>Electrical and Computer Engineering</subject><title>Synthesis of ultra-high gain operational transconductance amplifiers using a generalized controller-based compensation method</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/vx021h91q.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/fq977x619</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:qf85nd881</identifier><datestamp>2020-03-21T14:55:14Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>RÉSUMÉL'analyse de flux de trésorerie actualisé (DCF) est une analyse assez simple selon laquelle l'investissement minier peut s'effectuer si la valeur actuelle nette (NPV) de l'ensemble des flux de trésorerie futurs actualisés selon la valeur présente est positif. Dans la plupart des cas, l'utilisation d'une évaluation DCF statique relativement simple, avec un petit nombre de sensibilités clés tels que les prix, les coûts d'exploitation, le taux d'actualisation, le taux d'intérêt et des scénarios discrets sont suffisants pour guider les décisions d'investissement minier. Quelques-uns des inconvénients majeurs de l'analyse DCF viennent de sa nature statique, car elle ne tient pas compte de la souplesse en matière de gestion. L'analyse DCF ne tient pas compte de la nature cyclique de l'industrie minière, plus particulièrement le marché et la marge d'incertitude, et elle n'examine pas l'impact à long terme du risque souverain. Elle ne tient pas compte de la teneur et de l'incertitude structurelle. Dans certains projets, l'utilisation de méthodes quantitatives pour obtenir des informations supplémentaires sur les risques du projet est encouragée. Ces outils peuvent aider les équipes de projet à hiérarchiser les risques identifiés, évaluer l'effet global des risques identifiés sur les résultats prévus, fixer des objectifs réalistes pour leurs projets, valider les calendriers des projets et les estimations de coûts, et aider à quantifier les niveaux de contingence appropriés pour les projets. L'incertitude et la concurrence au sein du marché affectent le calendrier des investissements pour les entreprises d'exploitation de minerai de fer. Le concept des options réelles a mis en lumière la souplesse en matière de gestion de l'investissement irréversible en cas d'incertitude contrairement aux modèles DCF.L'analyse des options réelles ne remplace pas nécessairement l'analyse DCF, elle vient plutôt en complément. Tel que souligné précédemment, et comme cela sera évident tout au long de cette thèse, l'application de la théorie des options réelles se construit plutôt sur celle de la DCF et ses concepts sous-jacents en les intégrant dans un nouveau paradigme d'évaluation. L'analyse des options réelles tient compte des diverses incertitudes tels que les prix, le taux d'actualisation et la corrélation en lien avec les investissements miniers.Dans le cadre de cette recherche, une étude de cas a été réalisée sur un gisement de minerai de fer. Les principaux apports de cette thèse sont: une modélisation de prix du minerai de fer; une corrélation stochastique utilisant le procédé Jacobi entre les prix et le facteur de réduction des risques; l'intégration de la valorisation d'option réelle (ROV) (souplesse en matière de gestion) dans la planification stratégique de la mine; et la comparaison entre l'évaluation des actifs modernes (MAP) et l'analyse DCF.L'étude de cas révèle que le prix du minerai de fer revient effectivement à son équilibre moyen à long terme et qu'il y a une corrélation entre les prix et le facteur de réduction des risques. On démontre que la souplesse en matière de gestion apporte une valeur ajoutée au développement des ressources et avec l'inclusion des prix ajustés au facteur de risque et le taux de risque actualisé à l'analyse DCF, on ajoute de la valeur au projet. Cela définit simplement MAP comme un complément à la DCF.Mots-clés: Flux de Trésorerie Actualisés (DCF), Valorisation D'options Réelles (ROV), Mouvement Brownien Géométrique (GBM), Rendement Moyen, Corrélation, Évaluation des Actifs Financier Modernes (MAP).</description><description>ABSTRACTDiscounted Cash Flow (DCF) analysis is simply straightforward analysis with the assumption that mining investment can proceed if the Net Present Value (NPV) of all its future cash flows discounted to the present is positive. In most circumstances the use of a relatively simple static DCF valuation, along with a small number of key sensitivities such as prices, operating cost, discount rate, interest rate, and discrete scenarios, is sufficient to guide mining investment decisions. Some of the major drawbacks of DCF analysis lie with its static nature as it does not consider managerial flexibility. DCF analysis does not consider the cyclical nature of the mining industry especially market and margin uncertainty, nor does it consider the long-term impact of sovereign risk. It does not consider grade and structural uncertainty.In some projects, the use of quantitative methods to obtain additional insight into project risks is encouraged. These tools can assist project teams to prioritise identified risks, evaluate the overall effect of identified risks on predicted project outcomes, set realistic project targets, validate project schedules and cost estimates, and help quantify appropriate levels of project contingency. Uncertainty and competition within the market affects timing of investment for iron ore mining companies. The concept of real options has shed light on managerial flexibility of irreversible investment under uncertainty in contrast to the DCF models. Real option analysis does not necessarily replace DCF analysis but rather complements it. As pointed out before, and as will be evident throughout this thesis, the application of real option theory builds on DCF and the underlying concepts integrating them into a new valuation paradigm. Real option analysis considers various uncertainties such as prices, discount rate, and correlation associated with mining investments. In this research, a case study is carried out on an iron ore deposit. The main contributions to this thesis are: iron ore price modelling; stochastic correlation using Jacobi process between prices and risk discount factor; incorporating Real Option Valuation (ROV) (managerial flexibility) into strategic mine planning; and comparison between Modern Asset Price (MAP) and DCF analysis.The case study reveals that iron ore price does revert to the long term mean equilibrium and that prices and risk discount factor do correlate. It is shown that managerial flexibility adds value to resource development, and, with the inclusion of risk adjusted prices and risk discount factor to DCF analysis, it does add value to the project. That simply defines MAP as a complement to DCF. Keywords: Discounted Cash Flow (DCF), Real Option Valuation (ROV), Geometric Brownian Motion (GBM), Mean Reversion, Correlation, Modern Asset Pricing (MAP)</description><creator>Gardner, Nick</creator><contributor>Mustafa Kumral (Internal/Cosupervisor2)</contributor><contributor>Hani Mitri (Internal/Supervisor)</contributor><date>2016</date><subject>Mining and Materials</subject><title>Traditional DCF and ROV approach of iron ore mining company</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/z316q4244.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/qf85nd881</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Mining and Materials</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:c534fr567</identifier><datestamp>2020-03-21T14:55:15Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Ce mémoire se penche sur l'œuvre romanesque de Ying Chen, écrivaine sino-canadienne très prolifique au Québec depuis la publication de son premier roman La Mémoire de l'eau en 1992. Nombre de ses écrits ont été analysés par des commentateurs en regard de la littérature dite « migrante », alors que la deuxième vague d'écrivains migrants venait diversifier le paysage littéraire au Québec au tournant des années 1990. Les études récentes portant sur les œuvres fictives de Chen s'intéressent moins à la question des origines de l'auteure qu'à la question proprement identitaire, surtout depuis que l'écrivaine a procédé à l'effacement des repères spatio-temporels et des données culturelles dans Immobile, Le Champ dans la mer et Querelle d'un squelette avec son double. Par ailleurs, les temps et les lieux indéterminés de ces trois romans alimentent l'identité hybride d'une narratrice fuyante. Cette deuxième partie de son œuvre romanesque permet à Ying Chen de dépasser l'étiquette d'« écrivaine migrante » qu'on lui accolait dès lors qu'elle traitait des thèmes de l'exil et de la pérégrination dans ses premiers écrits.  Le corpus de notre recherche est formé des six premiers romans de Ying Chen, publiés entre 1992 et 2003. Nous nous intéressons à la littérarité de ces textes, en étudiant les œuvres dans l'optique du récit fictif et en nous éloignant du lien supposé entre la production d'un auteur et son origine ethnique. Nous nous attachons à analyser de quelle façon l'hybridité identitaire s'actualise dans La Mémoire de l'eau, Les Lettres chinoises, L'Ingratitude, Immobile, Le Champ dans la mer et Querelle d'un squelette avec son double. À la lumière d'une hybridité corporelle, redoublée d'un enchevêtrement des lieux, des temps et des marqueurs spatiotemporels indéterminés, nous voyons comment l'identité trouble et double est un thème central qui affecte à différents degrés les personnages et narrateurs de Ying Chen.</description><description>Since the publication of her first novel La Mémoire de l'eau, in 1992, Ying Chen is known to be a prolific Sino-Canadian writer in Quebec. Many of her novels were analyzed by commentators who were interested in the literary movement called "littérature migrante", while the second wave of migrant writers came to diversify the literary landscape in Quebec in the turning point of the 1990s. Recent studies concerning Ying Chen's novelistic work deal less with the question of the cultural origins of the author than the broader questions relating to identity especially since the writer proceeded to erase the time-space marks and the cultural data in Immobile, Le Champ dans la mer and Querelle d'un squelette avec son double allowing the works of Chen to go beyond the label of "migrant writer" since she had written on the themes of exile and peregrination in her first novels.  This thesis focuses on the first six novels of Ying Chen, published between 1992 and 2003. Our analysis addresses the "literarity" of her fictions, by studying her works in the optics of the fictitious narrative and by overstepping the supposed link between the production of an author and his ethnicity. Therefore, the goal of this thesis is to show how the hybrid identity appears in La Mémoire de l'eau, Les Lettres chinoises, L'Ingratitude, Immobile, Le Champ dans la mer, and Querelle d'un squelette avec son double. In order to illustrate how tormented identities divide Ying Chen's characters, we redefine and analyze the various components of hybridity that cross over our corpus in the light of several entanglements of time, space, and time-space markers that become increasingly unfixed in one novel after another. Finally, this thesis aims to explain how the shady and double identity is a central theme in Ying Chen's novels in regard to the concept of hybridity in the literary field.</description><creator>Nadeau, Liang Li</creator><contributor>Diane Desrosiers (Internal/Supervisor)</contributor><date>2016</date><subject>French Language and Literature</subject><title>Les flottements identitaires dans l'oeuvre romanesque de Ying Chen</title><language>fre</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/sf268798x.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/c534fr567</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of French Language and Literature</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:xp68kk01r</identifier><datestamp>2020-03-21T14:55:16Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>In this manuscript, we present a thorough theoretical description of two novel schemes for enhancing the intrinsic nonlinear interaction in optomechanical cavities. We show that properly tuning a strong classical drive of the cavity can make the weak nonlinearity resonant, therefore resulting in a great amplification of its effects. We use a self-consistent Keldysh approach to treat in perturbation the resonant polariton interaction and investigate how it modifies the response function of the cavity as well as the non-equilibrium signatures. In particular, we focus on the generation of non-zero effective polariton temperatures from vacuum fluctuations coming from the cavity drive and mechanical dissipation.The second scheme is based on using a large amplitude, strongly detuned parametric drive on the mechanics to amplify mechanical zero-point fluctuations and hence enhance the radiation pressure interaction. It leads to an exponential enhancement of the single-photon coupling constant using only additional linear resources. Allowing to reach the single-photon strong coupling regime even if the single-photon coupling constant is much smaller than the mechanical frequency and cavity damping rates. It has the further benefit of allowing time-dependent control, enabling pulsed protocols. Applied to an undriven two-cavity optomechanical setup, we show that our scheme generates photon blockade for experimentally accessible parameters, and even makes the production of photonic states with negative Wigner functions possible in systems with weak intrinsic couplings.Photon blockade, as predicted in presence of the enhanced nonlinear optomechanical interaction, leads to antibunching.However, antibunching has also been reported with Gaussian states, where optimized amplitude squeezing yields classically forbidden values of the intensity correlation. As a consequence, observing antibunching is not necessarily a signature of photon-photon interactions. To clarify the significance of the intensity correlations, we derive a sufficient condition for deducing if a field is non-Gaussian based on a intensity correlation measurement. We finally shed light on the so-called unconventional photon blockade effect predicted in a driven two-cavity setup with surprisingly weak Kerr nonlinearities, stressing that it is a particular realization of optimized Gaussian amplitude squeezing.</description><description>Dans cette thèse, on étudie théoriquement deux méthodes novatrices pour amplifier l'interaction non linéaire présente dans les cavités opto-mécaniques. On montre qu'il est possible de rendre la non-linéarité résonante dans une cavité fortement entretenue et ce, en réglant correctement la fréquence et l'intensité du laser pilote. Lorsque l'intensité est suffisamment élevée, les phonons et photons de la cavité s'hybrident, donnant lieu aux polaritons qui, à leur tour, sont couplés par la partie non linéaire de l'intéraction. On utilise une approche autocohérente dans le formalisme de Keldysh pour traiter en perturbation les conséquences de ce couplage résonant sur les fonctions de réponse et les signatures hors équilibre du système. En particulier, on se concentre sur la température effective finie des polaritons résultant de l'amplification des fluctuations du vide, ce vide provenant du laser pilote et de la dissipation mécanique. La seconde méthode consiste à amplifier les fluctuations du point zéro des vibrations mécaniques, et donc de la pression de radiation, à l'aide d'un contrôle paramétrique d'amplitude élevée et fortement désaccordé. Cette méthode génère une amplification exponentielle de la constante de couplage à un photon par l'ajout seul de ressources linéaires. Cela permet d'atteindre le régime de couplage fort à un photon pour une constante d'intéraction initialement plus faible que le taux de dissipation de la cavité et de la fréquence mécanique. Un tel contôle rend aussi possible l'implémentation de protocoles pulsés. On montre que lorsque cette approche est appliquée à un système optomécanique composé de deux modes optiques non entretenus, elle génère du blocage de photons et permet de produire des états photoniques caractérisés par une fonction de Wigner négative pour des couplages non linéaires intrinsèquement faibles.Le blocage de photons prédit en présence de forte nonlinéarités génère le phénomène de dégroupement de photons. Ce phénomène est aussi observé en présence d'états Gaussiens, où une compression optimale de l'amplitude mène à des valeurs classiquement inaccessibles de la fonction de corrélation d'intensité. Par conséquent, le dégroupement de photons n'est pas nécessairement une signature d'intéraction à deux photons. Pour clarifier l'interprétation de ces corrélations, on dérive une condition suffisante afin de déduire si un état est non Gaussien à partir de la mesure de corrélation d'intensité. Ce résultat permet aussi de faire la lumière sur le phénomène de blocage de photons non conventionnel prédit dans des cavités entretenues à deux modes en présence d'une faible non linéarité de Kerr, démontrant que c'est un exemple d'états Gaussiens compressés.</description><creator>Lemonde, Marc-Antoine</creator><contributor>Clerk, Aashish (Supervisor)</contributor><date>2016</date><subject>Physics</subject><title>Reaching the single-photon strong coupling regime in optomechanical cavities</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/jd473011s.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/xp68kk01r</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Physics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:9019s523z</identifier><datestamp>2020-03-21T14:55:17Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>On retrouve les enzymes de type chymotrypsine dans nombre d'organismes vivants; ces enzymes  servent également à différentes applications industrielles. En général, les enzymes d'origine aquatiques sont reconnus pour leur haute activité catalytique à basses températures, et en environnements plutôt  alcalins. Dans le cadre de la présente étude, nous avons purifié une chymotrypsine jusqu`à homogénéité, et effectué sa caractérisation à partir des viscères de deux espèces de calmar (L. opalescens et S. lessoniana,). Nos travaux ont également évalué l'opportunité de produire ces protéases commercialement par génie génétique, ceci comme alternative rentable à une méthode peu rentable comme l'extraction conventionnelle à partir de biomasses marines. Les deux enzymes ont été purifiés par un facteur de 300 X, avec rendement de 44% et des activités spécifiques entre 273.25 et 280 U/mg de protéine via ultrafiltration et chromatographie par affinité. Lors de l'électrophorèse sur gel de SDS-polyacrylamide, les deux chymotrypsines migrent sous forme de chaines polypeptidiques simples, de poids moléculaires respectifs 22.0 ± 2.7 kDa et 18 ± 1.7 kDa. Nous avons déterminé leurs optima de température et pH comme étant respectivement 25°C - 35°C et 7.5 – 8.5. Quant aux constantes cinétiques Km et kcat durant l'hydrolyse du benzoyl tyrosine ethyl ester, les diagrammes de Hanes ont permis de calculer un  Km de 1.43 mM et kcat de 103.43 sec-1 pour l'enzyme de Sepioteuthis avec efficacité catalytique  (kcat/Km) de 72.33 sec-1mM-1 . Dans le cas de la protéine provenant de Loligo, nous avons déterminé un Km de 0.4 mM et kcat de 349.21 sec-1 , avec (kcat/Km) s'élevant à 873.01 sec-1mM1. L'assemblage de novo à partir de données de séquençage parallèle massif a été généré avec l`ARN complet de L. opalescens à l'aide de la plateforme Illumina Genome Analyzer. Le système Trinity a permis d'assembler le transcriptome en utilisant les lectures normalisées. Pour chaque composante, la plus longue transcription a été alignée vs la base de données  uniprot à l'aide du logiciel Blastx. Un total de 61661 transcriptions ont ainsi été obtenues, avec longueur complète de 46232292 paires de bases (pb), longueur maximale 16932 pb et minimum de 201 pb. D'autre part, l'utilisation du PCR par amorces incluses a permis d'obtenir un ADNc complet; la séquence ainsi déduite comprend 292 résidus. Un  examen par bases de données sur protéines non-répétitives a indiqué un degré de similarité élevé avec une protéine hypothétique de O. bimaculoides (69%), avec une protéine de type chymotrypsinogène-A de L. anatina (45%) et également avec une sérine protéase de A. californica (45%). En contraste avec les chymotrypsines homologues provenant de mammifères, la structure primaire présentait des proportions plus élevées de méthionine, arginine, histidine et acide glutamique. La phylogénétique à haute probabilité comparant l'enzyme de L. opalescens avec les séquences  d'autres protéines analogues de vertébrés et invertébrés suggère à la fois (i) l'existence de deux principaux groupes (chymotrypsines de vertébrés et d'invertébrés) et (ii) un ancêtre commun pour la protéine de L. opalescens et la plupart de celles analogues provenant d'insectes. Nous avons élaboré un modèle homologique pour la chymotrypsine de L. opalescens en utilisant la structure cristalline de l'enzyme bovin (PDB ID:1t8o) comme échafaudage; ce modèle a aussi fait l`objet d`évaluation pour la qualité stéréochimique et l'environnement des chaines latérales. L`alignement des séquences indique un partage d'identité de 36 % entre la cible et la matrice  (1t8o). Un diagramme de Ramachandran utilisant 258 résidus a démontré une stéréochimie totale atteignant 88.5% incluant 8.3% en zone favorable additionnelle. Sur la base des données cristallographiques, la chymotrypsine de Loligo et celle d'origine bovine présentent des structures tertiaires quasi superposables. </description><description>Chymotrypsins are widely distributed among living species and have found widespread use in different industrial applications. The high catalytic activity of some aquatic enzymes at low temperatures, coupled with high pH and the relatively low thermal stability makes them robust in certain industrial applications where cold temperatures are preferred. In this study, chymotrypsin was purified to homogeneity and characterized from the viscera of two squid species (Loligo opalescens, cold water adapted and Sepioteuthis lessoniana, warm water adapted). This study also looks at the possibility of producing the enzymes using recombinant DNA technology, since it is currently not feasible or practical to extract these proteases from crude sources such as viscera for commercial application. The enzymes were purified about 300-fold, with a recovery of 44% and specific activities between 273.25 and 280 U/mg protein using ultrafiltration and affinity chromatography. Both enzymes migrated as single polypeptide chains with molecular masses of 22.0 ± 2.7 kDa and 18 ± 1.7 kDa, respectively, by SDS-polyacrylamide gel electrophoresis. The enzymes showed temperature and pH optima between 25°C - 35°C and 7.5 – 8.5, respectively. The kinetic constants Km and kcat for hydrolysis of benzoyl tyrosine ethyl ester (BTEE) were determined based on Hanes plots. Km was 1.43 mM and kcat was 103.43 sec-1 with a catalytic efficiency (kcat/Km) of 72.33 sec-1mM-1 for Sepioteuthis; while for Loligo, Km was 0.4 mM and kcat was 349.21 sec-1 with a catalytic efficiency (kcat/Km) of 873.01 sec-1mM-1. De novo assembly from massively parallel sequencing data were generated from total RNA from L. opalescens on an Illumina Genome Analyzer platform. The transcriptome was assembled on normalized reads using the Trinity assembler. Each component longest transcript was aligned against the uniprot_sprot_2013_11 protein database using the Blastx program from the NCBI BLAST family. Overall, 61661 transcripts were obtained with a total transcript length of 46232292 bp. Maximum transcript length obtained was 16932 bp, while the minimum length was 201 bp. A partial cDNA encoding L. opalescens chymotrypsin was identified from the de novo assembled transcripts using BLAST algorithms in NCBI. A full- length cDNA was obtained using nested PCR. The deduced sequence consists of 292 amino acid residues, being longer than its vertebrate analogs. A search of the non-redundant protein database showed highest identity to a hypothetical protein from Octopus bimaculoides (69%), chymotrypsinogen A-like protein from Lingular anatina (45%) and a serine protease from Aplysia californica (45%). The catalytic triad involving histidine, aspartate and serine was conserved in L. opalescens chymotrypsin. The primary structure also contained higher content of methionine, arginine, histidine and glutamic acid relative to chymotrypsin from mammalian homologues. A substitution was observed in the Loligo chymotrypsin sequence corresponding to position 124 in bovine chymotrypsin sequence from proline to alanine. A maximum likelihood phylogenetic tree comparing chymotrypsin from L. opalescens with other vertebrate and invertebrate chymotrypsin sequences suggests the existence of two main groups representing chymotrypsin from vertebrates and invertebrates and shows that L. opalescens chymotrypsin shares a common ancestor with most insect chymotrypsins. A homology model of L. opalescens chymotrypsin was built using the crystal structure of bovine chymotrypsin (PDB ID: 1t8o) as a scaffold. The model was assessed for stereochemical quality and side chain environment. Sequence alignment shows that the target and the template (1t8o) share 36% sequence identity. The Ramachandran plot using 258 residues gave a total stereochemistry of 88.5% with 8.3% in the additional allowed region. Based on crystallographic data, Loligo chymotrypsin and bovine chymotrypsin showed almost superimposable tertiary structures.</description><creator>Ackaah-Gyasi, Nana Akyaa</creator><contributor>Benjamin K Simpson (Supervisor1)</contributor><contributor>Timothy Geary (Supervisor2)</contributor><date>2016</date><subject>Food Science and Agricultural Chemistry</subject><title>Novel chymotrypsins from «Loligo opalescens» and «Sepioteuthis lessoniana»: Isolation, purification and molecular characterization</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/ws859j34p.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9019s523z</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Food Science and Agricultural Chemistry</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:2z10wt180</identifier><datestamp>2020-03-21T14:55:17Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Landauer's Principle states that there is a lower bound on the energy required to change the state of a small system from an initial state to a final state by interacting with a thermodynamic reservoir; of particular interest is when the bound is saturated and the minimal energy cost obtained for a given state transformation. We investigate Landauer's Principle in the context of repeated interaction systems (RIS), a class of physical systems in which a small system of interest interacts with a sequence of thermal probes. In particular, we show that for RIS, Landauer's bound is not saturated generically in the adiabatic limit, in which time evolution can be thought of as proceeding infinitely slowly, in contrast to the case of the interaction of a system and a single thermodynamic reservoir. However, for a specific RIS which models the small system and the probes as 2-level systems interacting via a dipole interaction in the rotating wave approximation, Landauer's bound is saturated adiabatically.  In this work, we also formulate and prove a discrete non-unitary adiabatic theorem to use for RIS.</description><description>Le principe de Landauer affirme qu'il existe une borne inférieure à l'énergie requise pour changer l'état d'un petit système d'un état initial à un certain état final en intéragissant avec un réservoir thermondynamique. La situation dans laquelle cette borne est saturée, et donc le coût énergétique minimisé, pour une transformation donnée est d'un intérêt particulier.  Nous étudions le principe de Landauer dans le contexte des systèmes à intéractions répétées (RIS), un classe de systèmes physiques dans laquelle un petit système d'intérêt intéragit avec une suite de sondes thermales.  En particulier, nous démontrons que, pour les RIS, la borne de Landauer n'est généralement pas saturée dans la limite adiabatique, dans laquelle l'évolution se fait, en un certain sens, infiniement lentement. Ce résultat présente un contraste au cas d'un système intéragissant avec un seul réservoir thermondynamique.  Toutefois, pour un RIS spécifique modelant le petit système et les sondes par des systèmes à 2 niveaux intéragissants dans l'approximation rotating wave, la borne de Landauer est saturée adiabatiquement. Dans ce travail, nous formulons et démontrons aussi un théorème adiabatique discret et non-unitaire pour usage dans les RIS.</description><creator>Hanson, Eric</creator><contributor>Vojkan Jaksic (Internal/Supervisor)</contributor><date>2016</date><subject>Mathematics and Statistics</subject><title>Landauer's principle in repeated interaction systems</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/fq977x62k.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/2z10wt180</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Mathematics and Statistics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:v405sd20r</identifier><datestamp>2020-03-21T14:55:18Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Background:Large pediatric skull defects are challenging to the plastic surgeon. Bone grafts remains the standard of care, however, donor site morbidity remains a problem. Alloplastic materials offer advantages in comparison to bone grafts, they can precisely replicate missing parts with unlimited quantities. However, there are several material-specific disadvantages. The search for the ideal alloplastic material have been going for decades, and yet not found. Degradable ceramic bone graft substitutes (Monetite) have been preclinically proven in long bone healing. We hypothesize that Monetite could serve an ideal implant for cranial defects in children by stimulating bone repair while accommodating growth of the skull. Due to the scarcity of experiments on materials that may impede skull growth, there appear to be no animal models that take into account the growing skull. Methods: 1) Manuscript one:Use of Synthetic Materials in Paediatric Craniofacial Skeleton: A Review of Literature. A search was conducted in Pubmed/ Medline/Embase for alloplastic materials used in the pediatric population. Two reviewers extracted the data separately. In addition to demographic data, pre-operative pathology, defect size, complications, and follow-up time were extracted. 2) Manuscript two: Novel Model for Critical-Size Calvarial Defects in Growing Rabbits. Rabbits with a mean age of 8.5 weeks, and a weight of 1.6 kg were used. Two rabbits had bilateral cranial defects with the recommended size utilized in adults (15 mm diameter). The other 4 rabbits had one large central defect that 15x25 mm in size. Animals were sacrificed at 8 weeks postoperatively and the calvaria were removed for histological analysis. Calvarial CT was done prior sacrificing. 3) Manuscript three: Spherical Granules For Bone Healing Of Critical-Size Cranial Defects In Growing Rabbits. Critical size cranial defects were created in 12 young New Zealand white rabbits. Two defects were left without any implants as control. High porosity monetite granules filled four defects, high porosity monetite with silicon sheet in 3, and low porosity monetite in 3. CT imaging and cephalometric analysis were performed. Results: 1) Manuscript one: 55 articles met the inclusion criteria involving 4276 patients. In  73.9% of patients, absorbable materials were used. The mean age was 3.28 years, but was different between groups of materials used. Craniosynostosis being the most common material used. The rate of any complication was found to be 7.06 % with highest being in metals.  2) Manuscript two: Control group showed complete osseous consolidation of all 4 defects. However Group 2 no complete osseous consolidation of the calvaria was appreciated. 3) Manuscript three: Critical sized defects in the control group demonstrated persistent defects. Granule migration from the defect in the high porosity monetite group limited the bone/implant interface. Bony ingrowth improved when silicone sheet was applied, despite its improvement, the low porosity monetite group showed a higher rate of bony ingrowth. We failed to statistically reject that all groups have the same change over time for all cephalometric variables. Conclusions:The review of literature showed that the optimum technique for cranioplasty remains unproven and the search for the ideal method is still ongoing. To aid the search, we have created a novel animal model that takes into account the growing skull, which is an important dimension to consider in the research of the ideal material in the pediatric population. We have also proven that different porosities of monetite have a significant role in bony ingrowth of critical-size cranial defects in rabbits, favoring lower porosities. The material was degradable and friendly to the growing skull, which may have the potential of being the ideal material for pediatric skull reconstruction.</description><creator>Shash, Hani</creator><contributor>Jake Barralet (Internal/Supervisor)</contributor><contributor>Mirko Gllardino (Internal/Cosupervisor2)</contributor><date>2016</date><subject>Surgery</subject><title>Paediatric calvarial healing and synthetic materials for its reconstruction</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/1r66j3834.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/v405sd20r</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Surgery</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:f7623g26c</identifier><datestamp>2020-03-21T14:55:19Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les études sur les cancer héréditaires ont aidé à la compréhension de la génétique du cancer. Les composantes héréditaires sont particulièrement importantes dans les cancers du sein et de l'ovaire. La technique du séquençage de l'exome (WES), qui cible la région codant pour la protéine dans le génome, a émergé comme une méthode puissante pour révéler des altérations génétiques liées au cancer. Le travail de doctorat présenté dans cette thèse porte sur la découverte de la base génétique sous-jacente du cancer du sein et de l'ovaire familial. En utilisant la technique WES comme outil d'enquête primaire, nous avons identifié les mutations délétères dans SMARCA4 présent dans tous les cas de carcinomes à petites cellules familiales de l'ovaire, de type hypercalcémie (SCCOHT) que nous avons étudié. L'analyse génomique a révélé que SCCOHT est universellement caractérisé par la perte totale de SMARCA4. Nous avons également effectué une analyse WES sur des familles québécoises avec cancer du sein sans mutations dans les gènes BRCA1 et BRCA2. Le criblage du gène candidate par séquençage de type Sanger dans des cas québécois supplémentaire a permis d'identifier RECQL comme un nouveau gène de susceptibilité au cancer du sein. Nos résultats indiquent l'importance des complexes de remodelage chromatique SWI/SNF dans le développement du SCCOHT et de la voie de réparation de l'ADN dans le développement du cancer du sein. L'identification de ces nouveaux gènes fournit des nouvelles cibles thérapeutiques de ces maladies. Dû l'importance des mutations somatiques à faible fraction allélique dans les cancers, nous avons développé un outil appelé « variant caller ». Cet outil utilise les donnés WES d'un échantillon tumoral, un échantillon apparié sain ainsi qu'un panneau de commande définie par l'utilisateur d'échantillons non-cancéreux. En comparaison avec d'autres outils existants, nous avons démontré une performance supérieure de notre algorithme, en particulier pour les échantillons de cancer de faible qualité tels que des échantillons formaline fixé et paraffine intégrée « as formalin-fixed and paraffin-embedded (FFPE) ».</description><description>Hereditary cancer studies have shed light on the understanding of cancer genetics. Inherited components are particularly important in breast cancer and ovarian cancer. Whole-exome sequencing (WES) that targets the protein-coding region of the genome has emerged as a powerful method to reveal genetic alterations in cancer. This thesis work focuses on uncovering the genetic basis underlying familial breast cancer and ovarian cancer. Using WES as the primary investigative tool, deleterious germ-line mutations in SMARCA4 were identified in all the small cell carcinoma of the ovary, hypercalcemic type (SCCOHT) families that we studied. Genomic analysis revealed that SCCOHT is universally characterized by the complete loss of SMARCA4. By performing WES analysis on French-Canadian, BRCA1 and BRCA2-negative breast cancer families followed by validation of the candidate gene in additional cases, RECQL was discovered as a new breast cancer susceptibility gene. These findings indicate the central roles of the SWI/SNF chromatin-remodeling complex and the DNA repair pathway in driving the development of SCCOHT and breast cancer, respectively, and provided novel targets for the therapeutic development of these diseases. Furthermore, motivated by accurately identifying somatic mutations with low allelic-fraction from WES data, I developed a variant caller using tumor sample and matched normal sample, plus a user-defined control panel of non-cancer samples. In comparison to other existing tools, I showed superior performance of this algorithm, especially for calling variants from low-quality cancer samples such as formalin-fixed and paraffin-embedded (FFPE) samples. </description><creator>Zhang, Jian</creator><contributor>William Foulkes (Supervisor2)</contributor><contributor>Jacek Majewski (Supervisor1)</contributor><date>2016</date><subject>Human Genetics</subject><title>Unraveling the genetics of cancer using whole-exome sequencing</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/3t945t68q.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/f7623g26c</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Human Genetics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:bn999932h</identifier><datestamp>2020-03-21T14:55:20Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>L'insertion d'un drain ventriculaire externe (DVE) externe est l'une des interventions neurochirurgicales les plus fréquemment exécutées. Le positionnement inadéquat du drain et la nécessité de recourir à de multiples passages en utilisant la technique d'insertion à main levée classique sont de plus en plus rapportés dans la littérature. Le problème est le plus fréquent dans la population avec traumatismes crânio-cérébral grave (TCC) graves. Beaucoup de méthodes proposées ont été discutées pour améliorer la précision de placement mais aucune n'a gagné suffisamment de soutien pour être mis en utilisation lors de l'insertion d'une DVE. Le but de cette étude est d'évaluer l'utilisation du guidage par neuronavigation électromagnétique pour faciliter l'insertion EVD et pour améliorer la précision et  minimiser le nombre de passages dans les patients TCC graves. La navigation a été appliquée de façon prospective pour tous les nouveaux patients TCC graves qui ont nécessité l'insertion du cathéter ventriculaire au cours d'une période de une année, et cela a été comparé à une cohorte rétrospective de patients TCC graves qui avaient eu une DVE insérée à main levée l'année précédente. Cinquante-quatre cas ont été recrutés, 35 (64,8%) ont eu leur DVE insérée avec la technique à main levée et 19 (35,2%) à l'aide du guidage de navigation. Dans le groupe de la navigation, la précision de l'emplacement de la DVE a été comme suit : 94,7% (18/19) ont obtenu un grade 1 et 5.3% (1/19) un grade 2, alors qu't aucun n'a eu de grade 3. En comparaison, l'insertion à main levée a été associée à un mauvais emplacement (grade 2 et 3) dans 42,9% des cas (valeur p = 0,009). Le nombre de passages était significativement plus faible dans le groupe de navigation avec une moyenne de 1,16 ± 0,38 {valeur p = 0,018, IC à 95% (-0,86, -0,09)}, par rapport au groupe à main levée, avec une moyenne de 1,63 ± 0,88. Ceci suggère que l'utilisation de la navigation pour guider le positionnement des DVE a été associée à une meilleure précision et moins de nombre de passages dans les cas difficiles de TCC grave, ce qui signifie moins de morbidités associées.</description><description>External ventricular drain (EVD) placement is one of the most frequently performed neurosurgical procedures. Inaccuracies in the drain positioning and the need for multiple passes using the classic freehand insertion technique are increasingly reported in the literature. The problem is seen most frequently in the severe traumatic brain injury (TBI) population. Many proposed methods were discussed to improve the placement accuracy and none gained enough support to be implemented in EVD placement. The purpose of this study is to evaluate the use of electromagnetic neuronavigation guidance to aid EVD insertion to improve the accuracy and minimize the number of passes in severe TBI patients. The navigation was applied prospectively for all new severe TBI patients who required ventricular catheter placement over a year period, and this was compared to a retrospective cohort of severe TBI patients who had EVD inserted freehand in the preceding year. Fifty-four cases were recruited, 35 (64.8%) had their EVD placed using the freehand technique and 19 (35.2%) using navigation guidance. In the navigation group, the placement accuracy was as follows: 94.7% (18/19) achieved a grade 1 and 5.3% (1/19) a grade 2, while none were in grade 3. In comparison, freehand placement was associated with misplacement (grade 2 and 3) in 42.9% of the cases (P-Value = 0.009). The number of passes was significantly lower in the navigation group with a mean of 1.16 ± 0.38 {P-Value = 0.018, 95% CI (-0.86, -0.09)}, compared to the freehand group with a mean of 1.63 ± 0.88. This suggests that using the navigation to guide EVD placement was associated with better accuracy and lower number of passes in challenging cases of severe TBI, which means less associated morbidities.</description><creator>Al-Azri, Ahmed</creator><contributor>Kosar Ali Khwaja (Internal/Cosupervisor2)</contributor><contributor>Judith Marcoux (Internal/Supervisor)</contributor><date>2016</date><subject>Surgery</subject><title>Placement accuracy of external ventricular drain when comparing freehand insertion to neuronavigation guidance in severe traumatic brain injury</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/2f75rb61z.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/bn999932h</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Surgery</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:6h440w40j</identifier><datestamp>2020-03-21T14:55:21Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Le feedback et la stimulation vibrotactile peuvent être utilisés afin de transmettre de l'information au moyen de dispositifs spécialisés rehaussés d'actionneurs qui vibrent. Afin d'établir une communication réussie à travers le sens du toucher, la conception de ces dispositifs et des effets tactiles transmis à l'utilisateur doit aborder les questions reliées à la perception, la technologie, et la cognition.Dans cette thèse, nous proposons une approche systématique de la création d'outils, d'effets, et d'icônes tactiles dans le contexte d'interprétations et de pratiques musicales. D'abord, une revue de la littérature sur la fonction du feedback et de la stimulation vibrotactile en interprétation musicale est proposée, ainsi qu'une évaluation de différents types d'actionneurs. Finalement, nous présentons des évaluations de dispositifs vibrotactiles s'étant déroulées lors de concerts et d'installations artistiques, nous concentrant sur le jugement et la performance des utilisateurs.</description><description>Vibrotactile feedback and stimulation can be used to convey information by means of specialized displays augmented with vibrating actuators. To achieve successful communications via the sense of touch, perceptual, technological and cognitive issues need to be taken into account in the design of these displays and of the tactile effects conveyed to the final user.In this thesis we propose a systematic approach to the design of tactile displays and of tactile effects and icons in the context of music performance and practice: firstly, a perceptually-informed review of the function of vibrotactile feedback and stimulation in music performance is proposed, together with an evaluation of actuator technologies; secondly, in context, user-based evaluations of several vibrotactile-augmented displays are presented, which took place during the successful performance of real-world concerts and installations.</description><creator>Giordano, Marcello</creator><contributor>Marcelo Wanderley (Supervisor)</contributor><date>2016</date><subject>Music</subject><title>Vibrotactile feedback and stimulation in music performance</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/zs25xc22d.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/6h440w40j</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Schulich School of Music</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:9c67wq56b</identifier><datestamp>2020-03-21T14:55:21Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Nous établissons un portrait du principe de correspondence en méchanique quantique appliqué aux Harmoniques sphériques normalisées selon la norme 2 Y^m_n  sur la sphère. Nous présentons d'abord une mise en contexte sur les dynamiques hamiltonienne pour ensuite démontrer que pour un flot géodésique sur la sphère, la ligne de niveau se projette sur certaines bandes ayant une largeur reliée à l'énergie. Finalement, en utilisant l'approximation BKW, nous démontrons que la séquence de fonctions propres Y^En_n se concentre sur les bandes et diminue à l'extérieur des bandes.</description><description>We provide an expository treatment of the correspondence principle in quantum mechanics as applied to the standard L^2-normalized spherical harmonics Y^m_n on the sphere. After providing some background information on Hamiltonian dynamics, we then show that for geodesic flow on the sphere the level sets project onto certain bands with width related to the energy. Finally, using WKB approximation we show that the eigenfunction sequences Y^En_n concentrate on the bands and decay outside the bands.</description><creator>Herta, Gabriel</creator><contributor>John A Toth (Internal/Supervisor)</contributor><date>2016</date><subject>Mathematics and Statistics</subject><title>L² concentration of ladders of spherical harmonics on S²</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/2514np17n.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9c67wq56b</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Mathematics and Statistics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:k0698b261</identifier><datestamp>2020-03-21T14:55:22Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Le syndrome de Birt-Hogg-Dubé se caractérise par un risque élevé de néoplasie rénale causée par des mutations dans le gène BHD codant pour le suppresseur de tumeur folliculine (FLCN). Bien que la fonction cellulaire de FLCN ne soit pas clairement compris, il a été démontré que FLCN s'associe avec la protéine kinase activée par l'AMP (AMPK), par l'intermédiaire de deux protéines partenaires de FLCN : FNIP1 et FNIP2. De plus, il a été prouvé génétiquement que FLCN et les protéines FNIP coopèrent dans la suppression tumorale rénale, mettant l'accent sur l'importance fonctionnelle de la voie  régulée par FLCN/FNIP, à savoir la voie de signalisation de l'AMPK. L'AMPK est un senseur métabolique clé et un régulateur de l'équilibre de l'énergie chez tous les eucaryotes. La dérégulation de la voie de signalisation de l'AMPK a de vastes répercussions dans les maladies humaines. Ici, nous démontrons que FLCN est un régulateur négatif de l'AMPK et que ce rôle a été conservé dans l'évolution. La perte de FLCN induit l'activation constitutive de l'AMPK qui, à son tour, augmente l'autophagie, et modifie la balance bioénergétique cellulaire pour favoriser l'adaptation métabolique et la survie au stress. L'AMPK est un complexe constitué de trois sous-unités: α (catalytique), β (échafaudage) et γ (détection de l'énergie). Son activation se produit via la phosphorylation du résidu critique Thr-172 dans le domaine catalytique, qui est régulé par des kinases en amont (par exemple LKB1) et des phosphatases (par exemple α-SNAP). Ici, nous avons constaté que FLCN s'associe avec α-SNAP via les protéines FNIP et que FLCN et α-SNAP agissent en coopération pour moduler l'activité de l'AMPK. Par ailleurs, nous démontrons que les protéines FNIP se lient à α-SNAP indépendamment de l'AMPK. Finalement, nos résultats indiquent que FNIP interagit physiquement à la fois avec AMPKα et β, et que la longueur totale de la sous-unité α ainsi que le module C-terminale de la sous-unité β sont requises pour cette interaction. En conclusion, nous suggérons que FLCN est un régulateur conservé dans l'évolution de l'AMPK via un mécanisme de liaison et de coopération avec l'AMPK phosphatase, α-SNAP, et que cet effet est médié par les protéines FNIP.</description><description>Birt–Hogg–Dube (BHD) syndrome characterized by high risk of renal neoplasia is caused by mutations in the BHD gene encoding the Folliculin (FLCN) tumor suppressor. While the cellular function/tumor suppressor mechanism of FLCN is not clearly understood, it is shown that FLCN associates with the AMP-activated protein kinase (AMPK), mediated by two FLCN interacting proteins FNIP1 and FNIP2. It was shown genetically that FLCN and FNIP proteins cooperate in the renal tumor suppression, emphasizing on the functional importance of the pathways linked to FLCN through FNIP proteins, namely AMPK signaling. AMPK has emerged as a key metabolic sensor and regulator of energy balance in all eukaryotes. Dysregulation of AMPK signaling appears to have broad implications in human diseases. Here, we demonstrate that FLCN is an evolutionarily conserved negative regulator of AMPK. Loss of FLCN results in the constitutive AMPK activation, which in turn increases autophagy, and modifies the cellular bioenergetics to enhance the metabolic adaptability and stress survival. AMPK is a complex constituted of three subunits: α (catalytic), β (scaffold) and γ (energy sensing). Its activation occurs via phosphorylation of the critical Thr172 residue in the catalytic domain, which is regulated by proteins with kinase activity (e.g. LKB1) or phosphatase activity (e.g. α-SNAP). Here we found that FLCN associates with α-SNAP via FNIP proteins, and FLCN and α-SNAP act cooperatively in the same pathway to modulate AMPK activity. Moreover, we report that FNIP protein binds to α-SNAP independent of AMPK. Finally, our results indicate that FNIP physically associates with both AMPKα and β, and the full length α subunit and the C-terminal module of the β subunit are required for this interaction. Together, we suggest that FLCN is an evolutionarily conserved regulator of AMPK cooperating with AMPK inhibitor, α-SNAP; and this effect is mediated by FNIP proteins.  </description><creator>Jalali, Zahra</creator><contributor>Arnim Pause (Supervisor)</contributor><date>2016</date><subject>Biochemistry</subject><title>Functional characterization of the folliculin tumor suppressor</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/z603r125n.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/k0698b261</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Biochemistry</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:hx11xh48j</identifier><datestamp>2020-03-21T14:55:23Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Dendritic spines are the actin-enriched protrusions on dendritic shafts that encase the postsynaptic machinery. The basis for morphological plasticity of dendritic spines is formed by changes in the actin cytoskeleton, which in turn, is orchestrated by actin binding proteins. A dynamic actin cytoskeleton allows the dendritic spines to rapidly and accordingly respond to various stimuli by changing their morphology, and this morphological plasticity ultimately leads to synaptic plasticity. In neurodegenerative diseases such as Alzheimer's disease (AD), this dynamicity inside dendritic spines is disrupted. Consequently, the dendritic spines are lost, which causes the loss of synapses.  These findings highlight the importance of understanding the regulators of actin dynamics and the mechanisms leading to loss of dendritic spines. Drebrin is a F-actin binding protein that localizes to dendritic spines in the brain. Drebrin is required for synapse formation and structural plasticity during development as well as the process of learning and memory formation. Precipitous loss of drebrin has been observed in AD and other neurodegenerative diseases with synaptic pathology. However, the regulatory factor causing loss of drebrin in AD-related synaptic pathology remains elusive. Early growth response-1 (Egr-1) is an inducible zinc-finger transcription factor expressed in the brain that binds to the GC-rich consensus sequences on target promoters to regulate expression. Upregulation of Egr-1 has been found in AD brain. Herein, we hypothesized that Egr-1 downregulates drebrin expression and leads to synaptic dysfunction. We demonstrate that Egr-1 transcription factor binds to drebrin promoter. In silico analysis was performed to identify putative Egr-1 response elements (EREs) on drebrin promoter. To substantiate this, luciferase promoter assay and chromatin immunoprecipitation assay was used and confirmed Egr-1 binding to drebrin promoter both in vitro and in vivo. Further, we demonstrate that Egr-1 negatively regulates drebrin mRNA and protein level. In primary hippocampal neurons and an inducible mouse model of Egr-1 overexpression, drebrin was downregulated upon Egr-1 upregulation. Conversely, an increase in drebrin mRNA and protein level was observed in Egr-1 -/- mouse. Furthermore, it was shown that Egr-1-mediated loss of drebrin parallels decrease in dendritic spine density. Immunocytochemical analysis revealed reduction in the density of dendritic protrusions upon Egr-1 upregulation. Reduction in spine density was observed in the CA1 region of the hippocampus in Egr-1 Tg mouse while an increase was observed in samples from Egr-1 -/- mouse. Immunocytochemical colocalization study also showed concurrent loss of vGLUT1 and PSD-95, suggesting a loss of putative functional synapses. We also demonstrate that Egr-1 upregulation mediates changes in other synaptic proteins in primary hippocampal neurons. In summary our data show that 1) Egr-1 downregulates drebrin by binding to drebrin promoter, 2) Egr-1 is inversely correlated with dendritic spine density and 3) Egr-1 mediates decrease in postsynaptic proteins and putative synaptic contacts. Therefore, we conclude that Egr-1 is a key regulator of drebrin and consequently, chronic upregulation of Egr-1 may exacerbate synaptic pathology in AD and AD-related disorders.</description><description>Les épines dendritiques protubérantes sont enrichies d'actines sur les arbres dendritiques qui encadrent la machinerie post-synaptique. La base de la plasticité morphologique est formée par la dynamique des épines dendritiques qui à leur tour sont dirigé par les protéines qui s'attachent aux actines. La dynamité de l'actine permet aux épines dendritiques de répondre rapidement et adéquatement à différent stimuli en changeant leur morphologies. De plus, cette plasticité morphologique guide la plasticité synaptique. Dans le cas de la maladie neurodégénératif telle que la maladie d'Alzheimer (MA), la dynamité  des actines dans les épines dendritiques ont été perturbés. Conséquemment, les épines dendritiques perdues causent les pertes des synapses. Ces observations surlignent l'importance de comprendre les régulateurs de la dynamité de l'actine et les mécanismes guidant la perte des épines dendritiques. Drebrin est une protéine qui s'attache à l'actine F qui est localisée dans les épines dendritiques, dans le cerveau. Drebrin est nécessaire pour la formation de la synapse et pour la plasticité structurale durant le développement et aussi durant l'apprentissage ou la formation de la mémoire. La perte brutale du drebrin était observée chez MA et dans divers maladies neurodégénératives qui montrent une pathologie synaptique. Cependant, le facteur régulateur causant la perte du drebrin chez la pathologie synaptique liée à MA reste obscur. Le gène de réponse de croissance précoce (Egr-1) est un facteur de transcription exprimé dans le cerveau qui s'attache aux séquences consensus riche de GC sur le promoteur de la cible pour réguler son expression. Une surexpression de Egr-1 a été trouvé dans le cerveau de MA. Ci-inclus, nous émettons l'hypothèse que Egr-1 sous-régule l'expression du drebrin et induit la dysfonction de la synapse. Nous démontrons que la transcription du facteur Egr-1 attache au promoteur du drebrin. L'analyse in silico est effectuée là où les éléments  répondant à l'Egr-1 (EREs) sont trouvés sur le promoteur du drebrin. Pour soutenir cette découverte, l'évaluation du promoteur luciférase et  l'immunoprécipitation de la chromatine sont utilisées pour confirmer l'attachement d'Egr-1 au promoteur drebrin à la fois in vitro et in vivo. Nous démontrons aussi que l'Egr-1 régule négativement le niveau de drebrin au niveau de l'ARNm et de la protéine. Dans les neurones primaires d'hippocampe et le model de souris inductible d'Egr-1, le souris Egr-1 Tg, le drebrin est sous-exprimé tandis que l'Egr-1 est surexprimé. Par ailleurs, l'augmentation du niveau de drebrin est observée dans le souris Egr-1 -/-. De plus, il est montré que la perte de drebrin médié par Egr-1 est en corrélation avec la diminution de la densité des épines dendritiques. L'analyse d'immunocytochimie montre une réduction de la densité de la protubérance dendritique quand l'Egr-1 est sur-régulée. Une réduction similaire dans la densité des épines est observée dans la région CA1 de l'hippocampe chez la souris Egr-1 Tg tandis qu'une augmentation est observée dans le cas de la souris Egr-1 -/-. Une étude d'immunocytochimie de la co-localisation  montre des pertes simultanées de vGLUT1 et PSD-95, suggérant une potentielle perte fonctionnelle des synapses. Nous démontrons aussi que la surexpression d'Egr-1 a un rôle médiateur des changements des autres protéines synaptiques des neurones primaires d'hippocampique. En conclusion nos données montrent que 1) Egr-1 sous-exprime le drebrin en s'attachant au promoteur du drebrin, 2) Egr-1 est inversement en corrélation avec la densité de l'épine dendritique et 3) Egr-1 a un rôle médiateur de la diminution des protéines post-synaptique et des contacts synaptique putative. Donc nous concluons que l'Egr-1 est la clé régulatrice de drebrin et conséquemment, la surexpression chronique d'Egr-1 peut exacerber la pathologie synaptique dans la MA et les maladies liées à la MA. </description><creator>Cho, Chulmin</creator><contributor>Lorraine E Chalifour (Supervisor)</contributor><date>2016</date><subject>Neuroscience</subject><title>Regulation of drebrin in dendritic spines by Egr-1 transcription factor</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/dj52w7385.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/hx11xh48j</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Integrated Program in Neuroscience</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:rn301410m</identifier><datestamp>2020-03-21T14:55:24Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>L'insuffisance rénale aigüe (IRA) est un phénomène fréquent chez les enfants hospitaliser et qui est associé a une mauvaise santé. L'IRA amène à l'insuffisance rénale chronique (IRC) et l'hypertension artérielle chez les adultes, cependant cette association n'est pas claire  chez les enfants. L'IRC est associe avec une augmentation de maladies cardiovasculaires. Actuellement les enfants en soins intensifs ne sont pas objet d'un suivi pour la surveillance de la fonction rénale. Hypothèse : L'IRA acquis pendant un séjour aux soins intensifs augmente le risque de développer l'IRC et l'hypertension artérielle. Protocole : Une étude rétrospective sur les enfants précédemment admis aux soins intensifs de Montréal et d'Edmonton. Patients sont identifiés par la poste et de la participation à des études antérieures (exclusions: maladie rénale connus avant les soins intensifs, la transplantation, la dialyse, la distance géographique). Une visite d'étude est fait à partir de 6 ans après l'admission au soins intensifs (sang, urine, examen physique, et la collection de données cliniques). Définition des résultats : IRC (un faible taux de filtration glomérulaire ou microalbuminurie) et  pré-hypertension ou hypertension (≥ 90e ou ≥95e percentiles). L'exposition principale est l'IRA acquis au cours de l'admission aux soins intensifs. Résultats : 243 enfants ont été suivis  5.8±1.l ans après admission aux soins intensifs. L'âge moyen de la population était 10.6 ± 5.6 ans. Lorsqu'on suppose qu'aucun des patients sans SCr mesurées pendant le séjour aux soins intensifs n'est atteint d'IRA, l'incidence d'IRA était de 25%. Lors du suivi, 15.5% et 4.6% de la population étaient atteint de pré-HTN et HTN, respectivement. IRC ou hypertension artérielle dans  non-IRA/IRA niveau 1 vs. niveau 2 ou 3 = 34% vs 68% (p &lt;0.05). L'IRC ou HTN dans les non-IRA/IRA niveau 1 vs. IRA niveau 2 ou 3 = 22% vs 54% (p &lt;0.05). Les IRA niveau 2 ou 3 étaient plus susceptibles de développer l'IRC ou la pré-HTN (OR ajusté:3.5, intervalle de confiance de 95% : 1.0 à 12.0). Conclusion: L'IRC et l'hypertension arrivent souvent six années post-soins intensifs, avec une différence significative entre les patients sans IRA/niveau 1 IRA et niveau 2 ou 3 IRA vis-à-vis incidence de, et chances de progression vers, l'IRC ou la pré-HTN. Cette étude permettra de créer des directives de suivi de fonction rénale pour les enfants après un séjour aux soins intensifs.</description><description>Acute kidney injury (AKI) is common in hospitalized children and associated with poor health outcomes. AKI leads to chronic kidney disease (CKD) and hypertension (HTN) in adults, however this association is unclear in children. CKD is associated with increased cardiovascular disease and currently, children admitted to the intensive care unit (ICU) are not being followed up for kidney function monitoring. Hypothesis: AKI during ICU stay increases long-term risk for CKD and HTN. Methods: An ongoing study of previously ICU-admitted children from Montreal and Edmonton identified by mailing and from participation in previous studies (exclusions: known pre-ICU renal disease, transplant, dialysis, geographical distance). Protocol: a study visit 6 years±6 months from ICU admission (blood, urine, physical exam, and clinical data collection). Outcomes: CKD (low estimated glomerular filtration rate [eGFR] or high urine albumin/creatinine ratio [ACR]), and pre-HTN or HTN (≥90th or ≥95th age-gender-height blood pressure percentile). The primary exposure is AKI during ICU. Results: 243 children were followed up 5.8+1.1 years post-ICU. Mean age of the study population was 10.6±5.6 years at follow-up. When assuming no AKI in patients without SCr measured during ICU stay, AKI incidence was 25%. At follow-up, 15.5% and 4.6% of all patients had pre-HTN and HTN, respectively. Composite outcome of CKD or pre-HTN in No AKI/AKI Stage 1 vs. AKI Stage 2 or 3 was 34% vs. 68% (p&lt;0.05). Composite CKD or HTN in No AKI/AKI Stage 1 vs. AKI Stage 2 or 3 was 22% vs. 54% (p&lt;0.05). Patients with AKI Stage 2 or 3 were more likely to develop CKD or pre-HTN (adjusted OR: 3.5. 95% confidence interval: 1.0-12.0). Conclusion: CKD and HTN are common 6 years post-ICU. Patients who develop Stage 2 or 3 AKI in ICU are at higher risk for developing long-term CKD or high blood pressure. This study will help create renal function follow-up guidelines for children after ICU stay. </description><creator>Benisty, Kelly</creator><contributor>Michael Zappitelli (Internal/Supervisor)</contributor><date>2016</date><subject>Medicine</subject><title>Long-term chronic kidney disease and hypertension in children previously admitted to the intensive care unit with and without acute kidney injury</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/b8515r21q.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/rn301410m</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Medicine</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:mp48sg31c</identifier><datestamp>2020-03-21T14:55:25Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The first part of this thesis consists of a translation from Spanish to French of Boca de lobo, the first, and up to now, only book of the Mexico-Canadian writer, Martha Bátiz. This literary work has been translated into English by Gustavo Escobedo in collaboration with the author herself, but no French version has yet appeared. The aim of the second part of this thesis is to foster a reflection on how to translate cultural elements the participation of which in the discursive hegemony is so well anchored in the source society that they do not require any clarification and are referred to implicitly. If the relevance of the unsaid is irrefutable in the original text culture, it can go unnoticed or be controversial in the target culture that is being confronted with tacit foreign elements. Emphasizing the reader's interpretation, the reception theory as elaborated by H. R. Jauss will set the basis for attempting to correct this epistemological shortcoming in translation studies.</description><description>La première partie de ce mémoire consiste en une traduction de l'espagnol au français de Boca de lobo, premier et – à ce jour – unique roman de l'écrivaine mexico-canadienne, Martha Bátiz. Cette œuvre a fait l'objet d'une traduction vers l'anglais par Gustavo Escobedo en collaboration avec l'auteure elle-même, mais aucune version française n'avait été encore réalisée. L'objet de la seconde partie de ce mémoire est de proposer une réflexion sur la présence de certains faits de culture, dans un texte à traduire, dont la participation dans l'hégémonie discursive est si bien ancrée dans la société source qu'ils ne requièrent plus d'explicitation et sont plutôt évoqués de manière sous-jacente au texte. Si la pertinence de cette part de non-dit va de soi dans la culture du texte original, elle peut passer inaperçue ou encore être controversée dans la culture qui reçoit la traduction et qui est confrontée à des éléments tacites étrangers. Soulignant l'importance de l'interprétation du lecteur, la théorie de la réception telle qu'élaborée par H. R. Jauss servira de fondement pour tenter de répondre à cette lacune épistémologique du traduire.</description><creator>Legault, Khristina</creator><contributor>Annick Chapdelaine (Internal/Supervisor)</contributor><date>2016</date><subject>French Language and Literature</subject><title>Traduction de Boca de Lobo de Martha Bátiz Traduire le non-dit : Une relecture de Jauss sous la lorgnette de la traductologie</title><language>fre</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/dr26z1000.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/mp48sg31c</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of French Language and Literature</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:q237hv325</identifier><datestamp>2020-03-21T14:55:26Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Agricultural practices contribute to greenhouse gas emissions. A four year field study was conducted to quantify and compare CO2, N2O and CH4 fluxes from sprinkler irrigated and non-irrigated onion fields in southern Quebec, Canada. Irrigation practices influence GHG emissions by changing the soil moisture content and thus impacting the soil microbial activity. The experimental plots were located on three organic soils with different degrees of stabilization. The static chamber method was used to obtain in-situ gas fluxes. Meteorological and soils data were also collected. Results for CO2, N2O and CH4 fluxes ranged from 1 to 268 mg CO2-C m-2*hr-1, -1.06 x 10-4 to 0.566 mg N2O-N m-2 * hr-1 and -0.00628 to 0.00760 mg CH4-C m-2 *hr-1, respectively. Results showed that sprinkler irrigation had minimal effects on N2O and CH4 gas fluxes, however, the CO2 fluxes increased within 24 hours of an irrigation event. In fact, CO2 fluxes were found to be more prominently influenced by the growth stage of the plant. Higher CO2 fluxes were observed, both, earlier and later in the season when root and leaf growth, respectively, were at their maximum. For N2O, higher fluxes were observed primarily in the spring after snow melt and fertilizer application. As well, N2O fluxes were influenced by heavier rainfalls (&gt;10 mm) and wetter soils (WFPS between 70 and 100%). Organic soils for this research were predominantly methane sinks with slight increases in CH4 flux observed following fertilizer application and soil tillage. Since greenhouse gas fluxes were sporadic and seldom linked to irrigation events, it is concluded that sprinkler irrigation had a limited impact on greenhouse gas emissions from the organic soils in this study.</description><description>Les gaz à effet de serre provenant des pratiques agricoles sont de très importants contributeurs aux émissions globales. Une étude sur le terrain, d'une durée de quatre ans, a été menée dans le sud du Québec au Canada afin de déterminer et comparer les émissions de CO2, N2O et CH4 de champs d'oignons irrigués par arrosage et non-irrigués. L'irrigation, en particulier, affecte les niveaux d'émissions en changeant l'humidité du sol et ainsi influençant  l'activité microbienne du sol. L'étude a été exécutée sur trois sols organiques à différents stades de stabilisation. Les flux de gaz ont été obtenus dans le champ en utilisant la méthode de chambre statique. Les données temporal et spatial par rapport au sol ainsi que les données météorologiques de la région ont été collectionnées afin d'expliquer les résultats des émissions de gaz. Les résultats pour les flux de CO2, N2O et CH4 variait de 1 à 268 mg CO2-C m-2 * hr-1, -1.06 x 10-4 à 0.566 mg N2O-N m-2 * hr-1 et -0.00628 à 0.00760 mg CH4-C m-2 * hr-1, respectivement. L'irrigation par arrosage avait des effets minimes sur les gaz N2O et CH4. L'analyse des flux de CO2 montre que dans les 24 heures après une application d'irrigation les émissions ont augmenté. Cependant, le stade de développement de la plante avait un effet majeur sur les flux de CO2. Une augmentation d'émissions de CO2 a été remarquée au début de la saison quand les racines étaient à un stade maximal de développement ainsi que plus tard dans la saison quand les feuilles étaient à un stade maximal de développement. La principale hausse d'émissions de N2O a été observée au printemps juste après la fonte des neiges et l'application des engrais. Pendant la saison d'échantillonnage, les averses de pluie (&gt;10 mm) et les sols plus humides (espace poreux rempli d'eau entre 70 et 100%) ont provoqué des augmentations de flux de N2O. Les sols organiques étudiés étaient principalement des puits de méthane. La production de CH4 a augmenté légèrement après l'application d'engrais et le labour du sol. Puisque les flux de gaz à effet de serre au-delà du niveau de base étaient irréguliers et rarement lié aux événements d'irrigation, il est conclu que l'irrigation par arrosage n'avait pas d'effet majeur sur les émissions de gaz à effets de serre des sols organiques de cette étude.</description><creator>Lloyd, Kaitlin</creator><contributor>Chandra A Madramootoo (Internal/Supervisor)</contributor><date>2016</date><subject>Bioresource Engineering</subject><title>Greenhouse gas emissions from onion fields cultivated on organic soils under sprinkler irrigation in Quebec</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/t148fk79b.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/q237hv325</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Bioresource Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:8623j166c</identifier><datestamp>2020-03-21T14:55:27Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Pregnant women are considered a high-risk group for serious influenza illness and influenza-related complications. The World Health Organization and many high-income countries currently advise vaccination of pregnant women with inactivated influenza vaccine in any trimester. Although the primary goal of influenza vaccine recommendations is to directly protect pregnant women from influenza disease, recent observational studies have suggested that maternal influenza immunization could additionally protect against adverse pregnancy outcomes such as preterm birth and fetal death. The biologic plausibility of such findings depends on there being an adverse effect of maternal influenza disease on fetal health, but high‐quality evidence for this association is lacking. The overall aim of my doctoral research was to explore the risk of preterm birth and fetal death in relation to maternal influenza illness and maternal influenza vaccination during pregnancy, with emphasis on the 2009 H1N1 influenza pandemic.The first objective of this thesis was to summarize, through a systematic evidence review, comparative studies evaluating fetal death or preterm birth associated with influenza vaccination during pregnancy. We were unable to perform meta-analyses due to high clinical and statistical heterogeneity, but found that while most studies reported no association between preterm birth or fetal death and influenza vaccination during pregnancy, several reported significant risk reductions. The second objective of this thesis was to assess the association between 2009 pandemic H1N1 (pH1N1) influenza illness during pregnancy and perinatal outcomes using a retrospective cohort study design which accounted for the time-dependent nature of influenza and changing incidence of perinatal outcomes. In the overall obstetrical population of Ontario, there was no association between clinically-diagnosed pH1N1 influenza and preterm birth or spontaneous preterm birth, but among women with pre-existing medical conditions such as asthma, a diagnosis of influenza was associated with increased risk of preterm birth (adjusted hazard ratio [aHR]=1.54, 95% confidence interval [CI]: 1.09–2.17) and spontaneous preterm birth (aHR=1.72, 95% CI: 1.12–2.65), compared with unexposed pregnancy time. Motivated by limitations in individual-level measures of influenza illness and by the distinct temporal features of influenza viral activity, the third objective was to assess the association between an ecologic measure of influenza virus circulation and short-term variation in population-level rates of adverse perinatal outcomes using a time-series study design. Across a ten-year period in Ontario, the rate of preterm birth was not associated with circulating influenza in the week preceding birth (adjusted rate ratio: 1.01, 95% CI: 1.00–1.02), nor with the level of circulating influenza during the first month of gestation. Collectively, the results from this thesis suggest that influenza disease is not a major contributor to preterm birth in the Ontario obstetrical population, including during the 2009 H1N1 pandemic, when the health of pregnant women was of unprecedented high concern. High-quality data on the relationship between maternal influenza disease and adverse perinatal outcomes are critical for clarifying expectations for improved perinatal outcomes following maternal influenza immunization. Although influenza immunization during pregnancy is efficacious in preventing influenza disease in mothers and their newborns, considering the multifactorial etiology of adverse outcomes such as preterm birth, low prevalence of influenza during pregnancy and lack of consistent evidence that fetal health is adversely affected by maternal influenza disease, immunization would not be expected to produce a large improvement in perinatal outcomes to the extent suggested by some studies.</description><description>Les femmes enceintes sont considérées comme un groupe à risque élevé de maladie sévère et  de complications liées à la grippe (influenza). L'Organisation mondiale de la santé et de nombreux pays à revenu élevé préconisent la vaccination au virus inactivé de l'influenza chez les femmes enceintes à n'importe quel trimestre de la grossesse. Bien que le principal objectif des recommandations concernant la vaccination antigrippale consiste à protéger les femmes enceintes contre la grippe, des études d'observation récentes semblent indiquer que l'immunisation des femmes enceintes pourrait aussi les protéger contre les issues de grossesse défavorables, telles que la naissance prématurée et le décès fœtal. La plausibilité biologique de ces résultats suppose que la grippe chez la femme enceinte a un effet indésirable sur la santé fœtale; cependant, il manque de données solides appuyant une telle association. L'objectif global de ma recherche doctorale visait à explorer l'association entre le risque de naissance prématurée et de décès fœtal, d'une part, et la grippe chez la femme enceinte et la vaccination antigrippale durant la grossesse d'autre part, avec une emphase particulière sur la pandémie de grippe H1N1 que l'on a connue en 2009.Le premier objectif de ma thèse était de résumer, grâce à une analyse systématique des données, les études comparatives ayant évalué le décès fœtal ou la naissance prématurée associée à la vaccination antigrippale durant la grossesse. Nous n'avons pas été en mesure de réaliser des méta-analyses en raison d'une forte hétérogénéité clinique et statistique, mais nous avons découvert que bien que la plupart des études n'aient rapporté aucune association entre la naissance prématurée ou le décès fœtal et la vaccination antigrippale durant la grossesse, plusieurs études ont noté des réductions significatives. Le second objectif de ma thèse consistait à évaluer l'association entre la pandémie de grippe H1N1 (pH1N1) de 2009 durant la grossesse et les issues périnatales au moyen d'une étude de cohorte rétrospective qui tenait compte de la nature temporelle de la grippe et de l'incidence variable des issues périnatales. Dans l'ensemble de la population obstétrique de l'Ontario, il n'y avait aucune association entre la grippe pH1N1 cliniquement diagnostiquée et la naissance prématurée ou naissance prématurée spontanée. Toutefois, chez les femmes présentant un trouble médical préexistant comme l'asthme, un diagnostic de grippe a été associé à un risque accru de naissance prématurée (rapport de taux ajusté = 1,54, intervalle de confiance [IC] à 95 % : 1,09-2,17) et de naissance prématurée spontanée (rapport de taux ajusté  = 1,72, IC à 95 % : 1,12-2,65), comparativement à la période de grossesse non exposée. Motivé par les limites inhérentes aux mesures de la grippe au niveau individuel et par les caractéristiques temporelles distinctes de l'activité grippale, le troisième objectif visait à évaluer l'association entre la mesure écologique de la circulation du virus de l'influenza et la variation à court terme des taux d'issues périnatales défavorables au sein de la population au moyen d'un protocole d'étude comportant des séries chronologiques. Sur une période de dix ans en Ontario, le taux de naissances prématurées n'a pas été associé au virus de la grippe circulant la semaine précédant l'accouchement (rapport de taux ajusté = 1,01, IC à 95 % : 1,00-1,02), ni avec le niveau de virus de l'influenza en circulation au cours du premier mois de grossesse. </description><creator>Fell, Deshayne</creator><contributor>Robert William Platt (Supervisor)</contributor><date>2016</date><subject>Epidemiology and Biostatistics</subject><title>Influenza illness and influenza vaccination during pregnancy and risk of preterm birth and fetal death</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/8w32r8267.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/8623j166c</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Epidemiology and Biostatistics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:z316q425d</identifier><datestamp>2020-03-21T14:55:27Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Des bacilles, Bacillus licheniformis (14580), Bacillus amyloliquefaciens (23350, OB6), Bacillus subtilis (B26) et Geobacillus stearothermophilus Donk (12980) sont explorées comme sources microbiennes pour la production des exopolysaccharides (EPS) dans trois milieux de culture de composition différentes: (i) un milieu de base minéral additionné d'extrait de levure (M1), (ii) un milieu de base au succinate additionné d'extrait de levure (M2), et (iii) un milieu au tryptone et à l'extrait de levure (M3). Ces milieux ont été utilisés sous forme solide et sous forme liquide et contiennent tous du saccharose comme un précurseur pour la production d'EPS. Des résultats ont montré que la production d'EPS dépend non seulement de l'espèce bactérienne, mais aussi du milieu de culture et des paramètres physico-chimiques de fermentation. Parmi les souches étudiées, Gb. stearothermophilus Donk n'a pas produit de quantités significatives d'EPS dans tous les milieux de culture étudiés. En revanche, B. amyloliquefaciens (OB6) a produit le plus haut rendement d'EPS de &lt;5 kDa (54.14 g/L) après 144 heures de fermentation dans le milieu de culture M2. Les EPS produits sont composé composés principalement de glucose (63.4–93.8%), de xylose (5.4–18.6%) et de fructose (0.4–15.9%). Le deuxième plus haut rendement en EPS de 5-30 kDa (48.57 g/L) était obtenu avec B. licheniformis (14580) après 48 heures de fermentation dans le milieu de culture M2, et avec un profil de monosaccharides particulièrement hétérogène avec le galactose (1.5–87.5%), le fructose (5.1–60.7%) et le glucose (1.9–32.9%) comme constituants majeurs. Pour B. amyloliquefaciens (23350) et B. subtilis (B26) le rendement en EPS était de 6.74 et 6.59 g/L dans les milieux de culture M1 et M3 après 11 et 72 heures de fermentation, respectivement. Les EPS synthétisés par ces bactéries étaient de faibles poids moléculaires (&lt;5 kDa) et principalement composés de glucose (70.3–96.3%). Le rendement le plus bas était obtenu avec B. licheniformis (14580) dans le milieu M1, à la concentration de 3.5 g/L après 144 heures de fermentation. Les EPS obtenus étaient de haut poids moléculaires (30–100 kDa) et principalement composés de galactose (44.7–51.0%) et de glucose (33.0 - 40.0%). Les effets de la concentration en certains nutriments (extrait de levure à 10 - 200g/L, succinate de sodium à 0–100g/L, en plus du précurseur, le saccharose, à 100–400g/L) sur la production d'EPS par B. licheniformis (14580) ont été étudiés par la méthode des surfaces de réponses (Box et Wilson). L'interaction entre les concentrations de succinate de sodium et du saccharose avait un effet prépondérant sur les rendements en biomasse entre 48 et 96 heures de fermentation. Cependant, à 120 heures, l'interaction entre la concentration de l'extrait de levure et du succinate de sodium est devenue plus significative. Un rendement supérieur était obtenu en maximisant la concentration du succinate de sodium et la concentration du saccharose, et en minimisant celle de l'extrait de levure dans les milieux minéraux de base. Par contre, la quantité en protéines produite (g/g biomasse) a augmenté en fonction de la concentration en extrait de levure dans les milieux de cultures.</description><description>Selected bacilli, including Bacillus licheniformis (14580), Bacillus amyloliquefaciens (23350; OB6), Bacillus subtilis (B26), and Geobacillus stearothermophilus Donk (12980), were explored as microbial sources for the production of exopolysaccharides (EPS). Three media with different nutrient compositions were investigated as culture media: (i) mineral base-medium with added yeast extract (M1), (ii) succinate-containing mineral base-medium with added yeast extract (M2) and (iii) tryptone and yeast extract-containing base-medium (M3) as both semi-solid and liquid media. Sucrose was utilized as the inducer for the production of EPS. The EPS production was not only dependent on the type of strain, but also on the media and the fermentation conditions. Gb. stearothermophilus Donk did not produce significant EPS in all investigated media. While B. amyloliquefaciens (OB6), produced the greatest yield of &lt;5 kDa sized EPS (54.14 g/L, M2 medium) over the fermentation time course of 144 hours; this EPS was composed primarily of glucose (63.4–93.8%), xylose (5.4–18.6%) and fructose (0.4–15.9%). The second most significant yield of 5-30 kDa EPS (48.57 g/L, M2 medium) was obtained with B. licheniformis (14580) after 48 hours of fermentation, with an exceptionally heterogeneous monosaccharide profile containing greater quantities of galactose (1.5–87.5%), fructose (5.1–60.7%) and glucose (1.9–32.9%). For B. amyloliquefaciens (23350) and B. subtilis (B26), the yielded EPS quantities were 6.74 and 6.59 g/L in M1 and M3 media at 11 and 72 hours, respectively. The EPS produced by both of these bacteria were low molecular weight (&lt;5 kDa) and dominantly composed of glucose (70.3–96.3%). The lowest yields were observed with B. licheniformis (14580) in M1 medium at a concentration of 3.50 g/L after 144 hours. These EPS were higher molecular weight heteropolymers (30-100 kDa) primarily composed of galactose (44.7–51.0%) and glucose (33.0– 40.0%). The effects of the concentration of selected nutrients (yeast extract of 10–200 g/L; sodium succinate of 0–100 g/L) and the inducer, sucrose (100–400 g/L) on the EPS production by B. licheniformis (14580) were studied using response surface methodology. The sodium succinate/sucrose concentration interaction had the greatest effect on the biomass yield from 48–96 hours. At 120 hours, the interactions between the concentration of yeast extract and sodium succinate became the most significant one. Greater yields of EPS (g/L culture) were obtained upon maximizing sodium succinate and sucrose concentrations and minimizing yeast extract content in the mineral media, and greater content of contaminating proteins (g/g biomass) were observed in the presence of high concentrations of yeast extract.</description><creator>Malick, Afshan</creator><contributor>Salwa Karboune (Internal/Supervisor)</contributor><date>2016</date><subject>Food Science and Agricultural Chemistry</subject><title>Exploring biodiversity for the production of exopolysaccharides from selected «Bacillus» species and characterization of their structural properties</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/f1881p827.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/z316q425d</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Food Science and Agricultural Chemistry</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:ht24wm99s</identifier><datestamp>2020-03-21T14:55:28Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The ever-growing world population has changed the dynamics between the demand and supply of food, materials and energy, which, in turn, has challenged us to introduce sustainable alternatives across the diverse spectrum of human needs. Therefore, as a synthetic chemist, I was particularly interested in proposing sustainable catalysis, thereof. Cellulose nanocrystals (CNCs), termed as ‘the sustainable material of 21st century' by the Technical Association of Pulp and Paper Industries, proved to be an interesting template for deposition of metal nanoparticles. The dissertation begins with introducing the family of crystalline cellulose in the nano-domain, hereby referred to as nanocelluloses, which includes cellulose nanocrystals, cellulose nanofibers and bacterial cellulose nanofibers. In the first chapter the applications of nanocelluloses in catalysis is reviewed, with emphasis on their role as support for metal nanoparticles. Next, the importance for characterisation of the CNCs and their metal-hybrid composites is highlighted. This work presents a robust and reproducible method to image CNCs by transmission electron microscopy (TEM), without the need for staining. In the following chapter, we establish the role of CNCs in the enantioselective hydrogenation of prochiral ketones, using Pd metal. By a careful choice of substrate, we could achieve enantiomeric excesses (ees) of up to 65%, which is unprecedented for a system where the chirality is solely carried by the unmodified biomass support. By using high-end microscopy techniques, namely cryo-TEM and tomography in conjunction with a direct detection device (DDD) camera, we demonstrated that palladium was present in the catalyst as sub nanometric patches, in direct contact with their low-density support. In addition, we constructed the 3D tomograms of CNCs and the CNC-metal hybrid composite. Conceptually, these results offer an opportunity to use cellulose, in the form of the highly crystalline CNC, directly in asymmetric catalysis. The subsequent chapter presents a highly atom-economical synthetic method to access nanocatalysts from bulk metal. A water suspension of cellulose nanocrystals was exposed to an Ag wire, under air and light exposure. In 2 weeks, Ag nanoparticles of size 1.3 ± 0.3 nm were deposited onto the biopolymer. These species were active for the hydrogenation of aldehydes, 4-nitrophenol, alkenes and alkynes. Specifically this work is the first example of the reduction of nitroarene using H2 as an atom economical reducer, using Ag as a catalyst. The ensuing chapter describes the synthesis of Ru nanoparticles from RuCl3 under mild H2 pressure within a suspension of cellulose nanocrystals. X-ray photoelectron spectroscopy and TEM revealed that the small Ru (0) nanoparticles (3.3 ± 1 nm) were deposited onto their cellulosic support. This hybrid proved to be a highly efficient arene hydrogenation catalyst operational at 4 bars and room temperature, conditions rivaling in mildness with the best published works. Finally, a perspective is presented on the directions which could be taken in the future to widen the applications of CNCs in catalysis. </description><description>La croissance constante de la population affecte la dynamique entre l‘offre et la demande des ressources en nourriture, matières premières et énergie, ce qui à son tour nous enjoint à mettre en œuvre des altératives durables pour l'étendue des besoins humains. En conséquence, en tant que chimiste de synthèse, j'étais particulièrement intéressée par l'idée de proposer de nouveaux modèles catalytiques durables. Les nanocristaux de cellulose (NCCs), désignés comme le « matériau durable du 21ème siècle » par l'association technique des industries des pâtes et papiers, se sont avérés être d'excellents supports de catalyseurs.  Ce manuscrit commence par l'introduction de la famille de la cellulose cristalline dans le domaine nanométrique, appelée de façon générique nanocellulose, et qui comprend les nanocristaux de cellulose, les nanofibres de cellulose et les nanofibres de cellulose bacterienne. Dans le premier chapitre, les applications des nanocelluloses en catalyse sont passées en revue, avec un accent sur leur rôle comme support de nanoparticules de métaux. Ensuite l'importance de la caractérisation des NCCs et de leur composites hybrides avec des métaux est mis en évidence. Ce travail présente une méthode reproductible pour visualiser les NCCs par microscopie électronique à transmission (MET) sans avoir recours à la teinture. Dans le chapitre suivant, nous établissons le rôle des NCCs dans l'hydrogénation de cétones chirales, catalysée par le palladium. En choisissant avec attention le substrat, on peut obtenir un excès énantiomérique de plus de 65%, ce qui est une première pour des systèmes où la chiralité est présente uniquement au niveau du support issu de la biomasse et non-modifié. En utilisant des techniques de microscopie avancées, telles que le MET-cryo et la tomographie en conjonction avec une caméra « direct detection device (DDD) », nous avons démontré que le palladium était présent sur le catalyseur sous forme de patches de taille sous nanométrique, eux-mêmes en contact direct avec leur support de basse densité. De plus, nous avons reconstruit des tomogrammes en 3 dimensions des NCCs et des composites hybrides NCCs-métal. Conceptuellement, ces résultats montrent l'opportunité d'utiliser la cellulose, sous sa forme NCC hautement cristalline, directement en catalyse asymétrique. Le chapitre suivant présente une méthode synthétique hautement atome-économique pour accéder à des nanocatalyseurs à partir de métal macroscopique. Une suspension aqueuse de cellulose a été exposée à un fil d'argent, à l'air et à la lumière du soleil. En deux semaines des nanoparticles d'argent de taille 1.3 ± 0.3 nm se sont déposés sur le biopolymère. Ces espèces sont actives pour l'hydrogénation des aldéhydes, du 4-nitrophénol, des alcènes et des alcynes. En particulier, ce travail est le premier exemple de réduction des nitroarènes avec l'H¬2 comme réducteur atome économique, avec l'argent comme catalyseur. Ensuite vient un chapitre qui décrit la synthèse de nanoparticules de ruthénium à partir de RuCl3, réduit sous basse pression de H2 dans une suspension de NCCs. La spectroscopie photo-électronique aux rayons X et le MET ont révélé que de petites nanoparticules de Ru(0) (3.3 ± 1 nm) se sont déposées sur le support cellulosique. Cet hybride s'est révélé très efficace pour l'hydrogénation des arènes à 4 bars et à température ambiante, des conditions qui rivalisent avec les plus douces publiées. Enfin, une perspective est présentée sur les directions qui pourraient être prises dans le futur pour ouvrir de nouvelles applications aux NCCs en catalyse.</description><creator>Kaushik, Madhu</creator><contributor>Audrey Moores-François (Supervisor)</contributor><date>2016</date><subject>Chemistry</subject><title>Cellulose nanocrystals as versatile support for catalysis</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/gb19f8703.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/ht24wm99s</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Chemistry</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:0r967646b</identifier><datestamp>2020-03-21T14:55:29Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Puisque le réchauffement climatique affecte directement l'écosystème et l'humanité durant le 21e siècle, des solutions sont donc recherchées afin de réduire les émissions de gaz à effet de serre. Le dioxyde de carbone (CO2) est d'un intérêt particulier dû à son augmentation de niveaux atmosphériques et à sa contribution au  réchauffement climatique. En réponse à ce défi, le gouvernement canadien signe l'accord de Copenhag, pour ensuite signer récemment l'accord de Paris avec les efforts internationaux conjoints afin de restreindre la croissance des émissions du CO2. Pour atteindre cet objectif, plusieurs méthodes s'avèrent utiles; parmi les technologies disponibles, la réduction électrochimique de CO2 est un domaine assez vaste dont son objectif n'étant pas uniquement la réduction des niveaux du CO2 mais aussi la conversion de ce produit indésirable dans des molécules à valeur ajoutée. Toutefois, le processus est complexe et implique plusieurs facteurs, chacun ayant une influence sur l'efficacité, la sélectivité et le rendement. Il a été établi que la cathode (la réduction de l'électrode du CO2) est le composant principal du processus car il sert de plate-forme sur laquelle la réaction prend place. Chaque électrode matérielle possède des propriétés uniques qui s'imposent sur la réduction potentielle du CO2, l'efficacité énergétique et faradique, la distribution du produit et la sélection désirée à l'égard des produits d'électroréduction. En plus, l'électrolyte joue un rôle significatif en tant que moyen de transfert de charge entre l'électrode et l'espèce électroactif dans la solution. D'autres paramètres comme la température et la pression sont également des déterminants importants dans le processus dû à l'influence que ces facteurs ont sur le transfert de masse dans l'électrolyte. Cette thèse est composée de 2 parties principales. La première partie présente une critique compréhensive de la littérature scientifique sur la réduction électrochimique du CO2 avec un objectif de produire des produits de valeur ajoutée. La deuxième partie présente les résultats expérimentaux sélectionnés obtenus par l'auteur de la thèse. Particulièrement, la réduction électrochimique du CO2 pour produire des produits à valeur ajoutée en solution dans un électrolyte aqueux a été étudiée en utilisant du Ru et Ir / Ru revêtements d'oxyde métallique mixte déposé sur un substrat en titane, en tant que fonction du potentiel de l'électrode, de pH et de température. Bien que des expériences électrochimiques potentiodynamiques ont indiqué que les électrodes peuvent réduire le CO2, aucun produit dissous (restant) dans la phase aqueuse n'a été détecté dans les conditions expérimentales étudiées. Par conséquent, il est suggéré que les produits de réduction de CO2 se trouvent en phase gazeuse (par exemple, CO, CH4, C2H4), ce qui n'a pas été analysée en raison de la construction de la cellule électrochimique utilisée dans le projet.</description><description>As global warming directly affects the ecosystem and humankind in the 21st century, solutions are continuously being sought to reduce the emissions of greenhouse gases. Of a particular interest is carbon dioxide (CO2) due to its increasing levels in the atmosphere and contribution to global warming. In response to this challenge, the government of Canada signed onto the Copenhagen accord, and recently the Paris accord in concert with the joint international efforts to curb the mounting CO2 emissions. To achieve this goal, several methods prove to be useful; among the available technologies, electrochemical reduction of CO2 is an emerging field that aims not only to reduce the levels of CO2 but also to convert this undesirable product into value-added molecules. However, the process is complex and involves several factors, each of which has an influence on the efficiency, selectivity, and yield. It has been established that the cathode (CO2-reducing electrode) is the main component in the process as it serves as a platform on which the reaction takes place. Each electrode material possesses unique properties that dictate the CO2 reduction potential, faradaic and energy efficiency, the product distribution and the selectivity toward desired CO2 electroreduction products. In addition, the electrolyte plays a significant role as the charge-transfer medium between the electrode and the electroactive species in the solution. Other parameters such as temperature and pressure are also important determinants in the process due to the influence that those factors have on the mass transfer in the medium. This thesis is composed of two main parts. The first part presents a comprehensive review of the scientific literature on the electrochemical CO2 reduction with the aim of producing value-added products. The second part presents selected experimental results obtained by the thesis author. Namely, electrochemical reduction of CO2 to produce value-added products dissolved in an aqueous electrolyte was investigated using Ru and Ir/Ru mixed metal oxide coatings deposited on a titanium substrate, as function of electrode potential, pH and temperature. Although potentiodynamic electrochemical experiments indicated that the electrodes can reduce CO2, no products dissolved (remained) in the aqueous phase were detected under the investigated experimental conditions. Thus, it is suggested that the products of CO2 reduction are in the gaseous phase (e.g. CO, CH4, C2H4), which was not analyzed due to the construction of the electrochemical cell used in the project.</description><creator>Rammal, Mahmoud</creator><contributor>Sasha Omanovic (Internal/Supervisor)</contributor><contributor>Gregory Patience (Internal/Cosupervisor2)</contributor><date>2016</date><subject>Chemical Engineering</subject><title>Electrochemical reduction of carbon dioxide to low- molecular-weight organic molecules</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/n009w510n.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/0r967646b</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Chemical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:zg64tp62c</identifier><datestamp>2020-03-21T14:55:30Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>L'entraînement cognitif, généralement administré de manière informatisée, est enraciné dans la réhabilitation cognitive et repose sur le concept que la formation directe peut conduire à une réorganisation des fonctions neuronales. La neuroplasticité permet à l'anatomie et le fonctionnement du cerveau de continuellement changer, suite à l'expérience. Par conséquent, l'entraînement cognitif a le potentiel de diminuer les dysfonctionnements cognitifs et comportementaux et à devenir une nouvelle option de traitement pour les enfants et les adultes. Puisque les enfants en développement ont une plasticité accrue, le cerveau est plus vulnérable aux interventions. Malgré l'absence de consensus sur l'efficacité de l'entraînement cognitif, un certain nombre de conclusions ont démontré des effets sur l'intelligence verbale et non verbale, la mémoire de travail, et les capacités académiques. L'étude expérimentale qui suit examine la possibilité qu'un programme d'entraînement d'attention informatisé puisse produire des améliorations significatives sur les mesures neuropsychologiques et sur le comportement, chez les enfants en santé et les enfants ayant des troubles de comportement. L'essai critique ultérieure aborde le marché très influent de l'entraînement du cerveau, dans lequel nous révisons les programmes d'entraînement cognitif, leurs approches de publicité et ainsi que les normes juridiques sur lesquelles ils se reposent. Mots-clés: entraînement cognitif, attention, neuroplasticité</description><description>Cognitive training, typically administered in a computerized manner, is engrained in cognitive rehabilitation and relies on the concept that direct training can lead to a reorganization of neural functions. Neuroplasticity allows brain maps to continually change as a result of experience. Consequently, cognitive training has the potential to diminish cognitive and behavioural dysfunctions and to become a new treatment option for both children and adults. Since children display increased plasticity, the developing brain is more susceptible to interventions. Despite a lack of consensus concerning the effectiveness of cognitive training, a number of findings have demonstrated effects on verbal and nonverbal intelligence, working memory, and academic capacities. The following experimental study examines the possibility for a computerized attention training program to yield significant improvements on neuropsychological measures and behaviour, in healthy children and children with behavioural disorders. The subsequent critical review discusses the highly influential brain training market, and reviews cognitive training programs, advertising approaches, and the legal norms that apply to them. Keywords: cognitive training, attention, neuroplasticity</description><creator>Napoleon, Jenilee-Sarah</creator><contributor>Amir Raz (Internal/Supervisor)</contributor><date>2016</date><subject>Psychiatry</subject><title>Computerized cognitive training: From the laboratory to the real world</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/kh04ds353.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/zg64tp62c</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Psychiatry</discipline></degree></thesis></metadata></record><resumptionToken completeListSize="47894">oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):7975</resumptionToken></ListRecords></OAI-PMH>