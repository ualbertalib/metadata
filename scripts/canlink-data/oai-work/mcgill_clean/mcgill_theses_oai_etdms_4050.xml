<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/assets/blacklight_oai_provider/oai2-b0e501cadd287c203b27cfd4f4e2d266048ec6ca2151d595f4c1495108e36b88.xsl"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd"><responseDate>2020-07-24T23:05:42Z</responseDate><request resumptionToken="oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):4050" verb="ListRecords">https://escholarship.mcgill.ca/catalog/oai</request><ListRecords><record><header><identifier>oai:escholarship.mcgill.ca:d504rn54b</identifier><datestamp>2020-03-21T05:11:36Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>A Latin square L of order n is an n × n array filled with elements of {1,2,...,n} such that each value appears exactly once in each column and each row. A critical set in a Latin square is a minimal set of entries that uniquely identifies it among all Latin squares of the same size. It is conjectured by Nelder in 1979, and later independently by Mahmoodian, and Bate and van Rees that the size of the smallest critical set is ⌊n2/4⌋.We confirm the quadratic order predicted by this conjecture by establishing a lower-bound of n^2/104 for sufficiently large n. Previously the best known lower-bound was of order Ω(n^(3/2)). Our proof uses a recent graph decomposition theorem due to Barber, Kühn, Lo, Osthus and Taylor. To be more self-contained, we will present two major steps in the proof of this graph decomposition theorem.From the point of view of computational learning theory, the size of the smallest critical set corresponds to the minimum teaching dimension of the set of Latin squares. We study two related notions of dimension from learning theory. We also prove a lower-bound of n^2 − (e + o(1))n^(5/3) for both of the VC-dimension and the recursive teaching dimension of class of Latin squares in this thesis.</description><description>Un carré Latin L d'ordre n est un tableau n × n rempli d'éléments parmi {1,2,...,n} tel que chaque élément apparaisse exactement une fois dans chaque colonne et dans chaque rangée. Un ensemble critique dans un carré Latin est un ensemble minimal d'entrées qui l'identifie de manière unique parmi tous les carrés Latins de la même taille. Il a été conjecturé par Nelder en 1979, et plus tard indépendamment par Mahmoodian, et Bate et van Rees que la taille du plus petit ensemble critique est ⌊n2/4⌋.Nous confirmons l'ordre quadratique prédit par cette conjecture en établissant une borne inférieure de n^2/104 pour un n suffisamment grand. Auparavant, la meilleure limite inférieure connue était d'ordre Ω(n^(3/2)). Notre preuve utiliseun théorème récent de décomposition de graphe dûà Barber, Kühn, Lo, Osthus et Taylor. Afin que notre preuve soit autonome, nous présenterons deux étapes majeures dans la d ́emonstration de ce théorème de décomposition de graphe.Du point de vue de la théorie de l'apprentissage machine, la taille du plus petit ensemble critique correspond à la dimension d'enseignement minimale de l'ensemble des carrés Latins. Nous étudions deux notions connexes de la dimension de la théorie de l'apprentissage. Nous démontrons aussi une limite inférieure de n^2 − (e + o(1))n^(5/3) pour la dimension VC et la dimension d'enseignement récursive de la classe des carrés Latins dans cette thèse.</description><creator>Qian, Ying Jie</creator><contributor>Hamed Hatami (Internal/Supervisor)</contributor><date>2018</date><subject>Mathematics and Statistics</subject><title>Smallest critical sets of Latin squares</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/v979v517z.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/d504rn54b</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Mathematics and Statistics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:k930c063p</identifier><datestamp>2020-03-21T05:11:37Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La batterie à flux redox est un dispositif de stockage d'énergie à grande échelle prometteur. Bien qu'étant fondamentalement efficace, la batterie à flux reste défiée par les coûts en raison d'une faible densité de puissance. Cette thèse décrit le développement d'électrodes de batterie à flux optimisées via des médias fibreux électrofilés préparés sur mesure. Un modèle de continuum bidimensionnel a été développé pour modéliser les performances d'une batterie à flux de type bromure d'hydrogène avec une électrode de carbone fibreuse. En utilisant ce modèle, une vaste étude paramétrique a été réalisée pour élucider les effets de deux paramètres morphologiques, la porosité et le diamètre de la fibre, ainsi que plusieurs paramètres externes affectant la conception du champ d'écoulement. Les résultats de l'étude ont proposé un diamètre de fibre optimal de 1-2 μm ainsi que la plus grande porosité possible. Les conditions d'électrofilage ont été identifiées pour produire des matériaux à cette échelle, plusieurs fois plus grands que ceux produits par l'électrofilage typique. La superficie, les dimensions des pores et des fibres, la conductivité, la porosité et la perméabilité de ces électrodes ont été caractérisées. Selon les résultats, le matériau que l'on pensait être le plus approprié a été testé dans une cellule d'écoulement tout-vanadium, et ceci a realisé des résultats nettement mieux qu'un matériau disponible sur le marché. Malgré cette excellente performance, la caractérisation et les essais électrochimiques ont suggéré que même le meilleur matériau présentait des problèmes d'uniformité matérielle et que des améliorations dans leur fabrication et leur production peuvent fournir des avances encore plus significatifs. Pour mieux comprendre ces hétérogénéités matérielles, une sélection des matériaux électrofilés et de leurs analogues carbonisés a été imagée en 3D à l'aide de la tomographie par ordinateur à rayons X. Une variété de méthodes de calcul et de simulations ont été appliquées aux images pour déterminer les propriétés telles que la porosité, la distribution de la taille des pores, la taille des fibres ainsi que la perméabilité et les distributions d'écoulement à travers les médias. On a constaté que la taille de la fibre changeait constamment tout au long du processus d'électrofilage, ce qui entraînait des incohérences matérielles. Plus important encore, la distribution de la porosité était en grande partie régionale, certaines zones ayant des morphologies complètement différentes des autres. L'écoulement entraîné par la pression a été modélisé à travers les matériaux en utilisant la méthode Lattice Boltzmann (LB) pour simuler les conditions de la batterie à flux, et un excellent accord entre les résultats expérimentaux et la littérature à été démontré. Les simulations, en conjonction avec l'analyse du matériau, illustrent la nature hautement hétérogène de l'écoulement: la majeure partie de l'écoulement est concentrée dans des régions de haute porosité, avec une grande partie de l'électrode privée de l'écoulement. Une méthode pour calculer le coefficient de transfert de masse dans des milieux fibreux en utilisant la tomographie à rayons X a été développée. Cette méthode a résolu l'équation d'advection-diffusion avec le champ d'écoulement généré avec les simulations générées par LB pour simuler le flux convectif-réagissant dans une batterie à flux. Les simulations ont été effectuées sur trois matériaux différents, en particulier les fibres électrofilées avec et sans anisotropie, ainsi que les feutres de carbone disponibles sur le marché. Le but était de déterminer les corrélations de transfert de masse sans dimension pour ces matériaux et d'analyser l'effet de différents plans d'anisotropie. Les résultats ont démontré une forte dépendance à la perméabilité. Les matériaux ayant une perméabilité plus élevée avaient des coefficients de transfert de masse plus faibles, et vice versa.</description><description>The redox flow battery is a promising large-scale energy storage device. Despite being fundamentally efficient the flow battery remains cost challenged stemming from a low power density. This thesis describes the development of optimized flow battery electrodes via custom electrospun fibrous media. A 2-dimensional continuum model was developed to model the performance of a hydrogen-bromide flow battery with a fibrous carbon electrode. Using this model, a large parametric study was performed to elucidate the effects of the porosity and fiber diameter, as well as several external parameters affecting the flow field design. To extend the study the reaction kinetics were also varied, allowing the results to be as general as possible. The results of the study proposed an optimal fiber diameter of 1-2 μm as well as the highest possible porosity. Electrospinning conditions were identified to produce materials of this scale, several times larger than those typically produced through electrospinning. These materials were then carbonized, making them adequate for use in a flow battery. The surface area, pore and fiber sizes, conductivity, porosity, and permeability of these electrodes were characterized. The material thought to be most suitable was tested in an all-vanadium flow cell and performed meaningfully better than a commercially available material. Despite this excellent performance the characterization and electrochemical testing suggested that even the best material had issues with material consistency, and that improvements in their manufacture and production could provide even more significant advances. To better understand these material heterogeneities a selection of the electrospun materials and their carbonized analogues were imaged in 3D using X-ray computed tomography. A variety of computational methods and simulations were applied to the images to determine properties such as porosity, pore size distribution, fiber size as well as permeability and flow distributions throughout the media. The fiber size was found to constantly change throughout the electrospinning process, leading to material inconsistencies. More importantly the porosity distribution varied regionally, with some areas having notably different morphologies than others. Pressure driven flow was modelled through the material tomograms using the Lattice Boltzmann (LB) method, to simulate flow battery conditions. Excellent agreement with literature and experimental results was found. The simulations in conjunction with the material analysis demonstrate the highly heterogeneous nature of the flow. Most of the flow is concentrated to regions of high porosity, with much of the electrode starved for flow. A method for estimating the mass transfer coefficient in fibrous media using X-ray computed tomograms was developed. This method solved the advection-diffusion equation with the flow field generated with LB simulations to simulate the convective-reacting flow in a flow battery. The simulations were performed on three different materials, specifically electrospun fibers with and without anisotropy as well as commercially available carbon felts. The purpose was to determine dimensionless mass transfer correlations for these materials and analyze the effect of different planes of anisotropy. The results showed a strong dependence on permeability. Materials with higher permeability had lower mass transfer coefficients and vice versa. The body of work presented in this thesis has contributed significantly to understanding the pore scale mass and momentum phenomena taking place in reactive fibrous media. It highlights the preparation of this media through electrospinning as well as numerous numerical and experimental methods for characterizing and understanding these processes. All the work presented here promoted the development of flow batteries through better understanding of the flow battery electrode. </description><creator>Kok, Matthew</creator><contributor>Jeff Gostick (Supervisor1)</contributor><contributor>Richard L Leask (Supervisor2)</contributor><date>2018</date><subject>Chemical Engineering</subject><title>Advanced nanofibrous electrode structures for flow batteries via electrospinning</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/kp78gj78d.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/k930c063p</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Chemical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:hh63sz302</identifier><datestamp>2020-03-21T05:11:38Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Cette thèse se penche sur les défis logistiques auxquels font face les agences humanitaires en livrant de l'aide alimentaire dans des régions souffrant de malnutrition chronique. Les problèmes décrits dans cette thèse sont principalement inspirés des défis encourus par la plus grande organisation humanitaire luttant contre la faim: le Programme alimentaire mondial de l'Organisation des Nations unies (PAM). Cette thèse comporte trois projets de recherche portant sur la distribution de l'aide alimentaire dans des pays en voie de développement. Dans le premier projet, j'ai mené une recherche sur le terrain au Kenya afin de comprendre les principaux défis auxquels le PAM était confronté en ce qui concerne le domaine du transport. J'ai visité des points critiques de la chaîne d'approvisionnement du PAM et j'ai mené des entretiens avec des agents du PAM ainsi qu'avec des transporteurs contractés pour distribuer de l'aide alimentaire. Ces entretiens ont révélé que le PAM fait face à des défis considérables avec ses transporteurs. Premièrement, le PAM établit des contrats, pour une période de six mois, avec les transporteurs qui offrant les prix les plus bas sur les différents segments du réseau. Cette stratégie permet au PAM de réduire ses coûts logistiques, mais on constate que les taux contractés sont généralement inférieurs aux taux moyens du marché, ce qui génère certaines difficultés. De plus, les fluctuations des coûts encourus par les transporteurs, causés par les variations du prix du pétrole, ne sont pas reflétées dans ces contrats. Deuxièmement, les transporteurs refusent souvent les requêtes de transport du PAM afin de profiter de meilleures possibilités sur le marché puisqu'il n'y a pas de clauses de pénalités ni de primes dans les contrats établis entre le PAM et ses transporteurs. Troisièmement, il existe des écarts importants entre les taux des différentes paires origine-destination ainsi que pour différents contrats. Dans le deuxième projet, j'ai développé un cadre méthodologique qui estime les taux contractés et qui reflètent la dynamique du marché en apportant les ajustements nécessaires aux contrats lorsque le prix du pétrole augmente considérablement afin d'inciter les transporteurs à répondre à temps aux requêtes du PAM. En utilisant les données sur des prix de marché recueillis auprès de plusieurs transporteurs du Kenya, j'ai construit un modèle économétrique qui saisit des prix du marché du transport. De plus, j'ai proposé une nouvelle forme de contrat, basé sur des options de type barrière, qui permet d'améliorer le niveau de service des transporteurs en actualisant les tarifs en fonction des fluctuations du prix du pétrole pendant la durée du contrat. Dans le troisième projet, j'analyse une solution plus radicale aux coûts logistiques et aux défis opérationnels associés: des transferts en espèces et en bons d'échange pour l'aide alimentaire en contrepartie à la distribution physique de nourriture. Récemment, de nombreuses organisations humanitaires ont mené des études sur ces nouvelles modalités d'aide. Les résultats empiriques de ces études montrent que la mise en œuvre de programmes de transferts en espèces et de bons d'échange peut améliorer trois objectifs à considérer lors de la distribution de l'aide alimentaire: les coûts logistiques, les bénéfices nutritionnels et la contribution à l'économie locale. Ainsi, j'ai développé un modèle mathématique qui permet de sélectionner les modalités d'aide en optimisant ces trois objectifs d'un programme d'aide alimentaire. En outre, j'ai incorporé le comportement des bénéficiaires dans une structure de modèle d'optimisation à deux niveaux afin de considérer leurs préférences en ce qui concerne leurs dépenses en espèces. Enfin, je montre comment ce modèle peut être utilisé pour la conception de programmes d'aide et pour l'évaluation de politiques en utilisant un ensemble de données réelles pour la région de Garissa au Kenya.</description><description>This thesis focuses on the logistical challenges that the humanitarian agencies face while delivering food aid to regions suffering chronic hunger. Although the problems described in the thesis are common among the humanitarian organizations and the outcomes are transferable to other settings, they are inspired by the world's largest humanitarian organization fighting against hunger: United Nations' World Food Programme (WFP). This thesis consists of three research projects. In the first project, I conducted a field research in WFP Kenya headquarters in order to understand the major challenges that WFP faces in the transportation domain. I have visited critical points in the WFP's food aid supply chain, conducted interviews with WFP officers and the third-party transporters contracted for food aid delivery. These interviews revealed that the WFP is facing considerable challenges with the transporters. First, WFP signs contracts with transporters that provide the lowest bid for a six-month period. This mechanism enables WFP to decrease its logistics costs, however, the contracted rates usually fall below the average market rates. In addition, the transportation cost fluctuations due to oil price changes are not reflected in the contracts. Second, the transporters usually turn down the requests from WFP for better paying opportunities since there are neither penalty nor bonus clauses in WFP contracts. Third, there is a significant variance among the rates for different origin-destination pairs as well as different contracts. To address these challenges, in my second project, I develop a framework that calculates contract rates reflecting the market dynamics and provides the necessary adjustments in the contracts, so that the transporters respond WFP's cargo requests on time. Using the market rate data gathered from the Kenyan transporters, I build an econometric model that captures the variation in transport market prices. In addition, I devise a new barrier-type option contract that can increase the transporters' service levels by updating the rates according to the oil price fluctuations during the course of the contract. The numerical experiments on real-life data demonstrate that significant improvements in service levels without incurring additional costs to WFP can be achieved for certain origin-destination pairs that are not desirable for the transporters. In the third project, I explore a more radical solution to the excessive logistics costs and related operational challenges: providing cash and vouchers instead of physical food distribution. Recently, many humanitarian organizations ran pilot studies on these newer aid modalities. Empirical evidence emanated from these studies shows that implementing cash and voucher programs can improve three main objectives: the logistics costs, the nutritional outcomes, and the contribution to the local economy. I develop a generic model that selects the aid modalities by measuring the improvements in these three program objectives. In addition, I incorporate the consumption behaviour of the beneficiaries in a bilevel optimization model structure to capture their cash spending preferences. Finally, I show how this model can be used for aid program design and policy evaluation purposes by using a real-data set for Garissa county of Kenya.</description><creator>Sahinyazan, Feyza</creator><contributor>Nafiz Vedat Verter (Supervisor)</contributor><date>2018</date><subject>Management</subject><title>Food aid logistics in resource constrained environments</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/8623j127p.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/hh63sz302</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Desautels Faculty of Management</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:jm214r48j</identifier><datestamp>2020-03-21T05:11:39Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Un complexe minier est une chaîne d'approvisionnement où le minerai est extrait de différentes mines et passe au travers d'un réseau de traitement pour être transformé en un produit commercialisable. Cette chaîne d'approvisionnement est sujette à plusieurs sources d'incertitude à différents niveaux, que ce soit au niveau de la mine et les attributs géologiques du gisement ou au niveau des instances opérationnelles et installations de traitement qui permettent d'amener le produit sur le marché. Les modèles stochastiques d'optimisation simultanée pour les complexes miniers ont démontré leur efficacité à générer des plans stratégiques fiables qui maximisent la valeur présente nette du projet minier tout en contrôlant et réduisant les risques y associés. Cependant, à cause des incertitudes qui gouvernent un complexe minier, en particulier les incertitudes liées aux attributs géologiques qui définissent les ressources du système, il est primordial d'inclure des mécanismes de flexibilité pour permettre au projet minier de s'adapter lorsque plus d'information devient disponible. Dans le cadre de cette adaptabilité, optimiser les décisions d'investissement en capital de grande ampleur est une priorité vu l'impact important de ces décisions sur les liquidités annuelles de la compagnie minière et leur effet sur la planification de l'extraction. Cette thèse présente une méthodologie dont l'objectif est d'inclure de la flexibilité dans les chaines d'approvisionnement minières en permettant à la planification stratégique de considérer dynamiquement des options et alternatives réalisables pour réagir et s'adapter aux changements futurs. Pour cela, une étude portant sur l'optimisation de la capacité est tout d'abord présentée, suivie par le développement d'un mécanisme pour appréhender les variables complexes d'un gisement afin de respecter les contraintes de mélanges et atteindre les objectifs de production. Ces deux composantes sont ensuite intégrées dans un modèle d'optimisation dynamique. Ce modèle optimise la planification de l'extraction sous incertitude géologique en intégrant des alternatives d'investissement flexibles, ainsi que des modes opératoires qui permettent un meilleur contrôle des attributs géologiques complexes et non-linéaires.Le modèle dynamique développé produit une séquence d'extraction initiale unique, tout en conservant une planification à long terme flexible et viable pour des décisions d'investissement futures, si elles deviennent nécessaires. Cette méthode introduit un nouveau modèle stochastique multi-étapes adapté qui étend l'approche à deux étapes en réalisant plusieurs étapes de recours, optimisées de manière itérative, et qui permet de générer des designs parallèles dans une structure d'arbre de scénarios. Le modèle précédent est finalement étendu pour inclure des alternatives sur les modes opératoires à différents niveaux de la chaîne d'approvisionnement minière. Plus précisément, le modèle permet de choisir des modes opératoires optimaux à chaque période. Les principales implications et bénéfices sont présentées dans une application sur un complexe minier de cuivre et d'or, où une augmentation de 10.5% de la valeur présente nette est obtenue comparativement à une méthode basée sur une formulation stochastique traditionnelle à deux étapes.La formulation dynamique proposée dans cette thèse permet d'inclure de la flexibilité dans l'optimisation de la planification stratégique de la chaîne d'approvisionnement minérale. Cela permet de tenir compte d'éventuelles alternatives qui peuvent être considérées, étant donné les configurations du complexe minier, ses capacités et ses contraintes. Les modèles et les méthodes proposés sont capables de générer une planification réalisable et opérationnelle, tout en procurant une vision plus éclairée de la performance du complexe minier, ce qui facilite la transition à de possibles changements lorsque l'incertitude est révélée.</description><description>Mining complexes are mineral value chains where extracted material from different mines is transformed into sellable products through a set of processing streams. This value chain is governed by uncertainties at different levels, from the geological attributes of the orebody at the mine(s), to the different operational and processing components that lead the sellable products to the market. Stochastic simultaneous optimization formulations for industrial mining complexes have proven to be effective in generating reliable strategic plans that maximize net present value and, at the same time, manage and reduce risk. However, because of the uncertainties governing a mining complex, particularly the ones related to the geological attributes which define the supply of the system, it has become a priority to integrate flexibility mechanisms that allow a mining project to change and adapt as more information becomes available. Within this adaptability, optimizing the investment timing of high-magnitude capital expenditures throughout the life-of-mine is a priority, due to their high impact on the annual cash-flows and on their effects over the physical mining schedule. Additionally, to improve a mining complex's ability to meet production targets and overall performance, advanced mechanisms should be developed to ensure complex blending constraints are met, managing the geometallurgical variables of the deposit.This thesis presents a methodology to embed flexibility into mineral value chains, by allowing the strategic mine plan of a mining complex to dynamically consider possible options and alternatives for reacting and adapting to future changes. For this, first, a study on extraction capacity optimization is presented, followed by the development of a mechanism to deal with complex variables of the deposit to meet blending constraints and production targets. These two components are later integrated into a dynamic optimization model, which optimizes the mining complex's mine plan under geological uncertainty, integrating flexible investment alternatives, as well as operational modes.The dynamic model developed produces a unique initial extraction sequence, while keeping a viable flexible long-term plan for future investment decisions, as may be needed. The flexible long-term plan is obtained through a dynamic optimization which allows making transitioning plans upfront to facilitate change. This method introduces a new adapted multistage stochastic programming model which expands upon the two-stage framework by performing multiple recourse stages that are solved iteratively, allowing parallel designs to be generated in a scenario-tree structure. In this model, dynamic decisions over capital expenditures are made sequentially over time, based on information that becomes available over production time. The above model is subsequently extended to include alternatives over operating modes at different levels of the mineral value chain. More specifically, optimal operating modes are chosen per period, selecting blasting patterns at the mine, and processing relations of throughput and recovery at the plant. The practical implications of the proposed method are demonstrated through an application over a copper-gold mining complex, where the dynamic model presents a 10.5% increase in net present value compared to a traditional two-stage stochastic formulation.The dynamic mining complex formulation proposed is able to include flexibility into the optimization of the strategic plan of a mineral value chain. This enables possible developments within the feasible set of alternatives that can be taken, considering the mining complex's configuration, capacities, and constraints. The proposed model is able to generate feasible, operational schedules, while providing a wider view of the mining complex's performance, easing the transition to possible changes due to the periodic unveiling of uncertainty.</description><creator>Del Castillo Suarez, Maria</creator><contributor>Roussos G Dimitrakopoulos (Supervisor)</contributor><date>2018</date><subject>Mining and Materials</subject><title>Dynamic simultaneous optimization of mineral value chains under resource uncertainty</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/sx61dp71k.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/jm214r48j</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Mining and Materials</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:ng451k860</identifier><datestamp>2020-03-21T05:11:40Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>L'utilisation de la lumière solaire pour décomposer l'eau en atomes d'oxygène et d'hydrogène (photolyse de l'eau) est considéré comme l'une des approches les plus prometteuses et respectueuses de l'environnement pour produire des ressources énergétiques renouvelables et durables. Notamment, cette approche permet la production d'hydrogène à grande échelle. Dans ces dernières décennies, d'énormes efforts ont été effectués afin d'améliorer les cellules photoélectriques utilisées dans la photolyse de l'eau. Cependant, ces cellules ne permettent toujours pas de décomposer l'eau pure au pH neutre efficacement sans biais ou agent sacrificiel. La décomposition globale de l'eau par photocatalytique direct est toujours aussi peu efficace et peu fiable à long terme. Dans cette étude, nous démontrons que grâce à l'incorporation de dopant contrôlable dans les hétéro-structures Ga(In)N de nanofils, les propriétés de charges de surface peuvent être ajustées pour fournir un niveau adéquat de Fermi et/ou une bande de flexion adéquate. Ceci permet à la décomposition photochimique de l'eau à un taux élevé avec une efficacité quantique apparente (EQA) d'environ 20%. En outre, l'EQA peut être augmenté jusqu'à environ 45% dans une nanostructure de diode Ga(In)N photochimique en créant une jonction latérale p-p&lt;sup&gt;+&lt;/sup&gt; à l'échelle nanométrique, afin d'induire un flux unidirectionnel de porteurs de charge photo-générés. Par conséquent, on atteint un rendement lumière-hydrogène (STH) d'environ 3,3%, ce qui est nettement plus élevé que la plupart des rendements par le dernier cri de la technologie utilisée pour la photolyse directe de l'eau. Nous avons également montré qu'en combinant l'effet synergique des co-catalyseurs d'oxydation de l'eau et celui de réduction des protons (Co&lt;sub&gt;3&lt;/sub&gt;O&lt;sub&gt;4&lt;/sub&gt; et Rh/Cr&lt;sub&gt;2&lt;/sub&gt;O&lt;sub&gt;3&lt;/sub&gt;, respectivement) et en optimisant les propriétés électroniques de surface, les nanofils p-GaN/InGaN peuvent démontrer des performances avec une durée de plus de 580 heures dans de conditions photocatalytiques plus réalistes, spécifiquement, dans des conditions d'eau pure et de lumière solaire concentrée.  Cette durée remarquable est la plus longue qui n'a jamais été mesurée pour la décomposition solaire artificielle non-assisté d'eau, dont le STH est supérieure à 1%, par des photoélectrodes/photocatalyseurs semi-conducteurs sans couches de protection/passivation. Cette étude explore en outre l'effet de l'incorporation de Sb dans Ga(In)N pour ajuster les bords de bande sélectivement pour une meilleure absorption. Le système photocatalytique Ga(In)N de nanofils de cette étude surpasse la majorité des photocatalyseurs connus en fonction de l'efficacité STH et de la stabilité pour la décomposition d'eau, qui est non-assisté et photocatalytique ou photochimique globale.   Également, il fournit des idées subtiles pour la réalisation de la photosynthèse artificielle à haute performance qui comprend la réduction efficace et sélective du CO&lt;sub&gt;2&lt;/sub&gt; en hydrocarbures.</description><description>Direct solar water splitting is considered one of the most promising approaches for an environmental-friendly renewable and sustainable energy resource. Significantly, the capacity to directly split water is ideally suited for large-scale hydrogen fuel production. While tremendous progress has been made in photoelectrochemical (PEC) water splitting in the past decades, it is still not suitable to split pure pH neutral water efficiently without bias or sacrificial agent. On the other hand, direct photocatalytic overall water splitting still suffers from critical issues including low efficiency and poor long-term stability. In this study, we demonstrate that, through controllable dopant incorporation in Ga(In)N nanowire heterostructure, the surface charge properties can be tuned to provide the appropriate Fermi level and/or band bending. This allows the photochemical water splitting to proceed at high rate with an apparent quantum efficiency (AQE) ~20%. Furthermore, the AQE can be boosted up to ~45% in a Ga(In)N photochemical diode nanostructure by creating a p-p&lt;sup&gt;+&lt;/sup&gt; lateral junction at nanoscale, to induce unidirectional flow of photogenerated charge carriers. Consequently, a solar-to-hydrogen (STH) efficiency of ~3.3% is achieved, which is significantly higher than many of the state-of-the-art efficiencies in direct water splitting. We have further shown that, by combining the synergistic effect of water oxidation and proton reduction co-catalysts (Co&lt;sub&gt;3&lt;/sub&gt;O&lt;sub&gt;4&lt;/sub&gt; and Rh/Cr&lt;sub&gt;2&lt;/sub&gt;O&lt;sub&gt;3&lt;/sub&gt;, respectively) and by optimizing the surface electronic properties, p-GaN/InGaN nanowires can exhibit substantially extended long-term performance-stability for &gt;580 hrs in more realistic photocatalytic conditions, that is pure water and concentrated sunlight. Such remarkable long-term stability is the longest ever measured for any semiconductor photocatalysts/photoelectrodes without protection/passivation layers in unassisted solar water splitting with STH &gt;1%. This study further explores the effect of Sb-incorporation in Ga(In)N to selectively tune the band-edges for enhanced absorption. The Ga(In)N nanowire photocatalytic system in this study not only outperforms most of the typical photocatalysts reported so far, in the aspects of both STH efficiency and stability for unassisted overall photocatalytic or photochemical water splitting, but also provides critical insight in achieving high efficiency artificial photosynthesis, including the efficient and selective reduction of CO&lt;sub&gt;2&lt;/sub&gt; to hydrocarbon fuels.</description><creator>Chowdhury, Mohammad</creator><contributor>Zetian Mi (Supervisor2)</contributor><contributor>Ishiang Shih (Supervisor1)</contributor><date>2018</date><subject>Electrical and Computer Engineering</subject><title>Unassisted photocatalytic overall pure water splitting using lll-nitride nanostructures</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/2r36v0796.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/ng451k860</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:6395w9745</identifier><datestamp>2020-03-21T05:11:41Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Objectives: The function of connective tissues depend on the physical and biochemical properties of their extracellular matrix (ECM), which are in turn dictated by ECM protein composition. We performed a systematic review and meta-analysis of publications containing quantitative information on the protein composition of human connective tissues. The primary objective was to obtain quantitative estimates for absolute and relative amounts of ECM proteins. The secondary objectives were to quantify the changes in ECM composition in distinct pathologies, and to build quantitative estimates of whole tissue composition. Methods: Relevant articles were extracted from the Medline (OVID), EMBASE, and SCOPUS databases, screened by two co-authors, and included in meta-analysis if they contained absolute or relative quantification of proteins found in the ECM of human bone, adipose tissue, tendon, ligament, cartilage, as well as skeletal muscle.Results: We generated absolute quantitative estimates for collagen in articular cartilage, intervertebral disc (IVD), skeletal muscle, tendon, and adipose tissue. In addition, quantifications for sulfated glycosaminoglycans were synthesized in articular cartilage, tendon and skeletal muscle; total proteoglycan in IVD and articular cartilage, fibronectin in tendon, ligament and articular cartilage, and elastin in tendon and IVD cartilage. We identified significant increases in collagen content in the annulus fibrosus of degenerating IVD and osteoarthritic articular cartilage, and in elastin content in degenerating disc. In contrast, IVD collagen content was decreased in the scoliotic IVD. Finally, we built quantitative whole-tissue breakdowns.Conclusions: Quantitative estimates improve our understanding of composition of human connective tissues, providing insights into their function in physiology and pathology. This knowledge can further guide the development of tissue-mimetic scaffolds and implants.</description><description>Objectifs: La fonction des tissus conjonctifs dépend des propriétés physiques et biochimiques de leur matrice extracellulaire (ECM), qui sont à leur tour dictées par la composition des protéines ECM. Nous avons effectué une revue systématique et une méta-analyse de publications contenant des informations quantitatives sur la composition protéique des tissus conjonctifs humains. L'objectif principal était d'obtenir des estimations quantitatives pour les quantités absolues et relatives de protéines ECM. Les objectifs secondaires étaient de quantifier les changements dans la composition de l'ECM dans des pathologies distinctes et de construire des estimations quantitatives de la composition tissulaire totale.Méthodes: Les articles pertinents ont été extraits des bases de données Medline (OVID), EMBASE et SCOPUS, sélectionnés par deux co-auteurs et inclus dans la méta-analyse s'ils contenaient une quantification absolue ou relative des protéines trouvées dans l'ECM de l'os, tissu adipeux, tendon, ligament, cartilage, ainsi que le muscle squelettique humain.Résultats: Nous avons généré des estimations quantitatives absolues pour le collagène dans le cartilage articulaire, le disque intervertébral (DIV), le muscle squelettique, le tendon et le tissu adipeux. De plus, les glycosaminoglycanes sulfatés ont étés quantifiés dans le cartilage articulaire, le tendon et le muscle squelettique — protéoglycane totale dans le DIV et le cartilage articulaire, fibronectine dans le tendon, le ligament et le cartilage articulaire, et l'élastine dans le tendon et le cartilage DIV. Nous avons identifié des augmentations significatives de la teneur en collagène dans l'anneau fibreux du DIV dégénératif et du cartilage articulaire arthrosique, et dans la teneur en élastine dans le disque dégénératif. En revanche, la teneur en collagène DIV a diminué dans la DIV scoliose. Enfin, nous avons construit des pannes quantitatives de tissus entiers.Conclusions: Les estimations quantitatives améliorent notre compréhension de la composition des tissus conjonctifs humains, fournissant un aperçu de leur fonction en physiologie et en pathologie.</description><creator>Mckee, Turney</creator><contributor>Dieter Reinhardt (Internal/Cosupervisor2)</contributor><contributor>Svetlana Komarova (Internal/Supervisor)</contributor><date>2018</date><subject>Dentistry</subject><title>Extracellular matrix composition of connective tissues: systematic review and meta-analysis</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/6t053j50k.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/6395w9745</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Faculty of Dentistry</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:f4752k19q</identifier><datestamp>2020-03-21T05:11:42Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The 3D organization of the human genome remains an important and unsolved problem in biology. Current advances in quantifying and visualizing this organization through Chromosome Conformation Capture techniques (Hi-C/3C/4C/5C) have generated massive amounts of biological data that may provide a wealth of information. Much of these data, however, are often sparse and dependent on experimental biases. In this thesis, we analyze several machine models when applied to raw Hi-C data. We primarily explore how machine learning approaches can be used to improve the data sparsity. In addition, we examine biological signals that these machine models extract from the underlying data and the significance of these signals.</description><description>L'organisation 3D du génome humain reste un problème important et non résolu en biologie. Les progrès actuels dans la quantification et la visualisation de cette organisation par les techniques de capture de conformation chromosomique (Hi-C / 3C / 4C / 5C) ont généré des quantités massives de données biologiques pouvant fournir une mine d'informations. Une grande partie de ces données, cependant, sont souvent rares et dépendent de biais expérimentaux. Dans cette thèse, nous analysons plusieurs modèles de machine appliqués à des données Hi-C brutes. Nous explorons principalement comment les approches d'apprentissage automatique peuvent être utilisées pour améliorer la rareté des données. En outre, nous examinons les signaux biologiques que ces modèles de machines extraient des données sous-jacentes et de la signification de ces signaux.</description><creator>Guo, Hong Chuan</creator><contributor>Mathieu Blanchette (Internal/Supervisor)</contributor><date>2018</date><subject>Computer Science</subject><title>Machine learning for learning human Hi-C data</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/sn00b119r.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/f4752k19q</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:76537349v</identifier><datestamp>2020-03-21T05:11:43Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Suite au rapport final émis par la Commission de la Vérité et de la Réconciliation (TRC) publié en 2015, le paysage canadien de l'éducation change en cherchant maintenant à inclure le savoir et les perspectives des populations autochtones pour tous les étudiants en apprentissage. Depuis le renouvellement du programme en 2005, le Ministère de l'Éducation de la Saskatchewan a intégré les Sciences-Connaissances Autochtones (S-CA) à leur programme de science au niveau primaire et secondaire (Aikenhead &amp; Elliott, 2005). Dans ce projet de doctorat, j'ai exploré la question des enjeux de l'intégration du contenu et des perspectives autochtones dans le programme des sciences en Saskatchewan. Pour conceptualiser le programme en tant que texte, j'ai suivi le modèle à trois niveaux de Fairclough's (1989). Conséquemment, ce projet inclus: 1) un niveau textuel: une analyse des documents officiels des programmes du niveau primaire et secondaire ; 2) un niveau de pratique discursive: entrevues avec les divers intervenants (p. ex., les consultants en éducation scientifique du ministère de l'Éducation, les enseignants, les coordonnateurs de l'éducation des Premières Nations et des Métis ainsi que les professeurs d'université); 3) un niveau de pratique historique: l'exploration du contexte historique et politique du développement des S-CA en Saskatchewan. En valorisant autant le processus que les résultats (Kovach, 2009; Wilson, 2008), ce projet se présente comme une re/cherche plutôt qu'une approche positiviste de la recherche. Dès lors, cette dissertation se concentre sur la présentation de l'ensemble du processus et du fruit de ce dernier: la vocation personnelle et académique du projet; les façons d'aborder les diverses histoires et théories des érudits et gardiens du savoir d'origine autochtone ou non; le développement et la conceptualisation du plan (i.e., le modèle de l'Amoeba Dansant); et les changements de l'enquête au gré des relations établies (ou l'absence de), la méthodologie, le processus d'analyse et les résultats. Les résultats de l'étude suggèrent que l'intégration des S-CA au programme de science actuel est un processus à paliers multiples qui requiert une implication politique du gouvernement fédéral et provincial, du milieu académique, du professorat ainsi que des mouvements populaires. L'exploration des contextes historiques et politiques illustrent les façons dont les Connaissances-Sciences Occidentales Modernes (C-SOM) ont obtenu le statut universel du seul type de science à être inclus au programme d'enseignement. Les découvertes faites lors de l'analyse curriculaire démontrent les diverses façons par lesquelles les S-CA ont été conceptualisées pour l'enseignement de la science. Les entrevues avec les différents acteurs mettent en relief l'importance de la formation des enseignants et du développement professionnel pour procurer une opportunité d'apprentissage authentique où les enseignants ont la chance de bâtir des liens avec les aînés autochtones et les gardiens du savoir. À mon tour, je soutiens que les enseignants devraient se concentrer sur la création d'un «lieu d'échange» où les enseignants et les élèves sont engagés dans la construction et le renforcement des relations entre eux, les peuples autochtones locaux et la Terre. Je conclus que penser, apprendre et agir selon le précepte de la science inspirée des S-CA est un processus d'apprentissage continu qui souligne l'importance des relations qui estompent la frontière de la logique coloniale (Donald, 2009) et qui nous aident à avancer ensemble vers l'avenir.</description><description>With the final publication of the Truth and Reconciliation Commission (TRC) report in 2015, the landscape of Canadian education is changing to include local Indigenous peoples' knowledges and perspectives for all students' learning. Since the 2005 curriculum renewal, the Saskatchewan Ministry of Education has focused on creating Indigenous knowledges-science (IK-S)–infused K-12 science curricula (Aikenhead &amp; Elliott, 2005). In this doctoral project, I explored the question: What are the relationships at play in integrating Indigenous perspectives and content in science curricula in Saskatchewan?            In conceptualizing curriculum as a text, I followed Fairclough's (1989) three-tiered model. As such, this project involved: 1) a textual level: analysis of K-12 official curriculum documents; 2) a discursive practice level: interviews with diverse stakeholders (e.g., Ministry of Education science education consultants, teachers, First Nations and Métis education coordinators, and university professors); and 3) a historical practice level: the exploration of the historical and political contexts of the development of IK-S–infused science curricula in Saskatchewan. Situated as re/search, rather than the positivist notion of research, this project valued both the process and outcome of the project (Kovach, 2009; Wilson, 2008). As such, this dissertation focuses on showing the whole process and the product of the project: the personal and academic purposes of the project; the ways in which I engaged with theories and stories from Indigenous scholars and knowledge keepers and non-Indigenous scholars; the development of the conceptual framework (i.e., the Dancing Amoeba Model); and changes of the inquiry based on the relationships built (or lack thereof), the methodology, the analysis process, and the findings. The findings from the study suggest that the integration of IK-S in science curricula is a multilevel process involving political pressure from federal and provincial governments, academia, classrooms teachers, as well as grassroots movements. The exploration of the historical and political contexts illustrate the ways Western modern knowledge-science (WMK-S) obtained its status as the universal and only kind of science to be included in curricula. The findings from the curriculum analysis show the diverse ways in which IK-S has been conceptualized for science teaching. The interviews with the stakeholders emphasize the importance of teachers' education and professional development that provide true authentic learning opportunities, wherein teachers can have opportunities to build relationships with Indigenous Elders and knowledge keepers. In turn, I argue that teachers should focus on creating a "sharing place" wherein teachers and students are engaged in building and strengthening relationships with each other, local Indigenous peoples, and the Land. I conclude that thinking, learning, and acting with IK-S–infused science curricula is a lifelong learning process and emphasize the importance of relationships that diminish the colonial logic frontier (Donald, 2009) and help us to move forward to our shared future.</description><creator>Kim, Eun-Ji</creator><contributor>Anila Asghar (Supervisor2)</contributor><contributor>Steve Jordan (Supervisor1)</contributor><date>2018</date><subject>Integrated Studies in Education</subject><title>The relationships at play in integrating Indigenous knowledges-sciences (IK-S) in science curriculum: A case study of Saskatchewan K-12 science curriculum</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/zk51vk10v.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/76537349v</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Integrated Studies in Education</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:4b29b832x</identifier><datestamp>2020-03-21T05:11:44Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Le virus de la grippe infecte le système respiratoire et provoque 3 à 5 millions de cas graves chaque année. Le vaccin contre la grippe constitue la mesure préventive la plus efficace. En effet due aux mutations antigéniques du virus, les vaccins doivent être produits chaque année. Medicago Inc a créé un vaccin à base de particules pseudovirales (VLPs) dérivé de plantes, contenant des protéines d'hémagglutinine (HA) du virus de la grippe, et qui induit des réponses cellulaires et humorales démontrées lors d'essais cliniques. Précédemment, notre laboratoire a démontré que les VLPs peuvent activer la réponse immunitaire innée associée aux cellules dendritiques (CDs). Pour élucider les composants du vaccin VLP impliqués dans la stimulation, nous avons examiné les effets du VLP vide (eVLP), c'est-à-dire le VLP sans protéines HA. Nous avons observé que les mécanismes d'activation des CDs par les VLPs étaient similaires aux effets produits par les motifs moléculaires caractéristiques des micro-organismes, et que le récepteur de type Toll 4 (TLR4) était nécessaire pour avoir un effet, du moins chez la souris. En utilisant la cytométrie en flux et des tests ELISA, nous avons démontré que l'eVLP avait augmenté l'activation des CDs contrôles, mais pas celle des CDs déficients en TLR4. Le système co-culture avec les lymphocytes T a été utilisé pour mesurer la capacité des CDs activées par l'eVLP à stimuler les lymphocytes T. Les CDs contrôle stimulées par l'eVLP ont augmenté la prolifération, l'activation, et la production des cytokines par les lymphocytes T, alors que les CDs déficients en TLR4 n'ont pas été capable de provoquer ces augmentations après stimulation par l'eVLP. In vivo, une accumulation des CDs a été observée chez les souris contrôles après une injection d'eVLP dans les coussinets, mais aucune accumulation n'a été observée chez les souris Tlr4-/-. La capacité stimulante des eVLPs dans les CDs humains dérivés de monocytes a été évaluée par immunobuvardage de type Western. L'augmentation des signaux cellulaires (cascade de kinases) après l'activation par l'eVLP suggère une signalisation par voie MyD88. Dans la mesure où le TLR4 a été suggéré comme important dans la protection contre la grippe, nous avons démontré que l'eVLP peut aider à stimuler les CDs de manière TLR4-dépendante. Cette voie peut ajouter des propriétés immunogéniques aux VLPs afin d'entraîner efficacement une réponse appropriée post-vaccination. Une compréhension plus profonde de chaque élément du vaccin pourrait aider à l'optimisation de la formulation vaccinale afin d'induire une réponse plus efficace et protective.</description><description>Influenza is a virus that infects the respiratory tract causing severe illness in 3 to 5 million individuals annually. Vaccines are a potent preventative measure against influenza. Due to antigenic drift or shift of the virus, vaccines must be made annually. Medicago Inc. has manufactured a plant-derived virus-like particle (VLP) vaccine containing the influenza hemagglutinin (HA) that has been seen to effectively elicit both humoral and cellular poly-functional immune responses in human clinical trials. Our lab has previously demonstrated that the VLPs have inherent innate stimulatory capacity in dendritic cells (DCs). To elucidate the stimulatory components of the VLP vaccine, we investigated the stimulatory capacity of the empty VLP (eVLP), the VLP without HA proteins. We found that the mechanisms triggered to promote DC activation by VLPs resembled those of classic microbe-associated molecules and that at least in mouse, Toll-like Receptor 4 (TLR4) was required to mediate these effects. Using flow cytometry and ELISA, we showed that the eVLP increased activation of control DCs but not TLR4-deficient DCs. Co-cultures of eVLP-stimulated DCs with T cells were used to measure the effect of the eVLP on stimulating T cell responses. eVLP-stimulated control DCs increased the proliferation, activation and cytokine production by T cells, but activated TLR4-deficient DCs were unable to induce such increases. In vivo, accumulation of DCs was observed in control mice upon eVLP injection in footpads, but not seen in Tlr4-/- mice. The stimulatory ability of the eVLPs in human monocyte-derived DCs (moDCs) was demonstrated by Western blots. Kinase cascades were activated upon eVLP stimulation suggesting MyD88-dependent signaling. Because TLR4 engagement has been suggested to be important in protective innate immunity against influenza, we demonstrated that the eVLP may stimulate DCs in a TLR4-dependent mechanism providing additional immunogenic properties to the VLPs to effectively elicit an immune response upon vaccination. Further understanding of the stimulatory actions of each component of the VLPs may allow for optimization of the vaccine formulation to elicit a robust protective response. </description><creator>Won, So Yoon</creator><contributor>Connie Krawczyk (Internal/Supervisor)</contributor><date>2018</date><subject>Physiology</subject><title>Stimulatory action of plant-based virus-like particle in dendritic cells</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/3f4627753.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/4b29b832x</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Physiology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:8g84mp71t</identifier><datestamp>2020-03-21T05:11:45Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Intrinsically disordered proteins (IDPs) or Intrinsically disordered regions (IDRs) in proteins can exhibit a partially folded or unfolded state under physiological conditions but confer several functional advantages. IDRs can fold into a stable tertiary structure when bound to their partner molecule, a transition that can be promoted by post-translational modifications (PTMs). Intrinsic disorder is found in all domains of life but is prevalent in eukaryotes. This thesis investigates the composition and evolutionary behaviour of disordered regions that undergo disorder-to-order transition and the evolutionary trend of PTMs in IDRs across eukaryotes using computational methods and tools. Bioinformatical parsing of human folding-on-binding (FB) proteins into four subsets (ordered, FBs, disordered regions that surround FBs, and other disordered regions) was performed to examine whether the composition and evolutionary behaviour (across vertebrate orthologs) are different in these four subsets. This analysis revealed that compositionally, ordered protein regions are distinct from the three other subsets, but the FB regions are of comparable evolutionary conservation to the ordered regions. Disordered regions surrounding FB regions are more negatively charged and less conserved than their adjacent FB regions. The presented results suggest the role of hydrophilic or charged residues around FBs in steering FB regions towards the binding sites of partner molecules. The insights gained from analysis of evolutionary conservation for FBs provided motivation to examine a related question, namely the evolutionary conservation of PTMs in IDPs/IDRs, in comparison to PTMs in ordered regions. In another bioinformatical approach, the conservation and emergence of methylation, acetylation and ubiquitination sites in ordered and disordered regions were examined across 11 evolutionary clades down from the whole eukaryotic domain to the ape superfamily. These sites occur mainly at arginine and lysine residues. It was discovered that MAU PTM is a major driver of conservation for arginines and lysines in both ordered and disordered regions, across the 11 levels, most significantly across the mammalian clade. Furthermore, the emergence of a significant number of new lysine MAU sites is found in the disordered regions of proteins in deuterostomes and mammals. In histones, MAU sites exhibit a distinct significant conservation pattern evident as far back as the last common ancestor of mammals. In a separate multiple evolutionary level analysis of the experimentally-verified human FB regions, a significant enrichment of conserved ubiquitination sites in FB regions was identified at all evolutionary levels back as far as mammals. Similarly, FB regions showed a significant preference for sites with multiple MAU modifications when treated both as a sample of ordered and of disordered regions. These results indicate the need to consider sequence analysis of IDRs at multiple evolutionary levels in order to understand their complex evolutionary patterns. The presented study as a whole demonstrates the distinctive amino acid composition, PTM preference and conservation of IDRs that exhibit different conformational states (e.g. disordered, disordered around FB and FB regions), and the interplay between these properties.</description><description>Les protéines intrinsèquement désordonnées (IDPs) ou les régions intrinsèquement désordonnées (IDRs) dans les protéines peuvent montrer un état partiellement replié ou non-replié dans des conditions physiologiques mais confèrent plusieurs avantages fonctionnels. Les IDRs peuvent se replier en une structure tertiaire stable quand elles se lient à leur molécule associée, une transition qui peut être facilité par des modifications post-traduction (PTMs). Le désordre intrinsèque se rencontre dans tous les domaines du vivant mais est très fréquent chez les eucaryotes. Cette thèse étudie la composition et le comportement évolutif des régions désordonnées qui subissent une transition du désordre vers l'ordre et la tendance évolutive des PTMs dans les IDRs chez les eucaryotes grâce à des méthodes et des outils informatiques. Le classement bioinformatique des protéines humaines se pliant en se liant (FB) en quatre ensembles (ordonnées, FBs, régions désordonnées qui entourent les FBs, et les autres régions désordonnées) a été effectué pour examiner si la composition et le comportement évolutif (chez les différents vertébrées orthologues) sont différent dans ces quatre ensembles. L'analyse a révélé que par la composition, les régions ordonnées des protéines sont distincts des trois autres ensembles, mais les régions FB montrent une conservation évolutive similaire aux régions ordonnées. Les régions désordonnées qui entourent les régions FB sont plus négativement chargées et moins conservées que leurs régions FB adjacentes. Les résultats présentés suggèrent le rôle joué par les résidus hydrophiles ou chargés autour des FBs pour piloter les régions FB vers les sites de liaison des molécules associées. La connaissance fournie par l'analyse de conservation évolutive pour les FBs encourage à étudier une question associée, à savoir la conservation évolutive des PTMs dans les IDPs/IDRs, comparé aux PTMs des régions ordonnées. Dans une autre approche bioinformatique, la conservation et l'émergence de sites de méthylation, acétylation, et ubiquitination dans les régions ordonnées et désordonnées ont été étudiées sur 11 clades évolutifs transmis depuis le domaine eucaryote entier jusqu'à la superfamille des grands singes. Ces sites se rencontrent surtout dans les résidus arginine et lysine. Il a été montré que MAU PTM joue un rôle majeur dans la conservation pour les arginines et les lysines à la fois dans les régions ordonnées et désordonnées, dans tous les 11 niveaux, de manière plus significative dans le clade des mammifères. Il a été montré qu'un nombre significatif de nouveaux sites MAU lysine apparaît dans les régions désordonnées des protéines chez les deutérostomes et les mammifères. Dans les histones, les sites MAU montrent un patron de conservation significativement distinct et évident jusque chez le plus lointain ancêtre commun des mammifères. Dans une analyse séparée des niveaux évolutifs multiples des régions FB humaines vérifiées expérimentalement, un enrichissement significatif des sites d'ubiquitination conservés dans les régions FB a été découvert dans tous les niveaux évolutifs des mammifères. De manière similaire, les régions FB montrent une préférence significative pour les sites avec de multiples modifications MAU quand elles sont traitées à la fois comme des régions ordonnées ou désordonnées. Ces résultats indiquent la nécessité de considérer l'analyse des IDRs à des niveaux évolutifs multiples afin de comprendre leurs patrons évolutifs complexes. La présente étude dans son ensemble démontre la composition distincte en acides aminés, la préférence PTM et la conservation des IDRs qui montrent différent états de conformation (e.g., désordonnées, désordonnées autour des FB et les régions FB), et les inter-relations entre ces propriétés.</description><creator>Narasumani, Mohanalakshmi</creator><contributor>Paul Harrison (Supervisor)</contributor><date>2018</date><subject>Biology</subject><title>Bioinformatical analysis of intrinsically disordered regions in eukaryotes: Insights into the evolution of folding-on-binding regions and post-translational modifications</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/kw52jb34t.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/8g84mp71t</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Biology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:g158bk568</identifier><datestamp>2020-03-21T05:11:46Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La dosimétrie est un processus crucial en radiothérapie pour assurer la précision de la dose de radiation administrée aux patients. Un certain nombre de protocoles de dosimétrie différents sont utilisés à tous les stades du déroulement de la radiothérapie externe. Les progrès récents en radiothérapie ont posés des défis dosimétriques en raison de l'utilisation de champs de radiation très modulés et de grandes doses par fraction de traitement. Par conséquent, il y a un besoin pour de nouvelles techniques de dosimétrie qui soient volumétriques, qui ne perturbent pas le faisceau de radiation et qui soient proche du temps-réel. La tomodensitométrie acoustique par rayons-X (XACT) est une modalité d'imagerie émergente qui détecte les ondes acoustiques générées dans un objet par l'effet thermoacoustique suivant une impulsion unique d'irradiation de rayons-X. En utilisant ces signaux de transducteur, une image de l'acumulation de la pression différentielle peut être reconstruite. Comme les images XACT peuvent être liées à la dose de radiation déposée dans l'objet irradié, il a été proposé que XACT puisse être un outil de dosimétrie de valeur en radiothérapie. Le but de cette thèse est de démontrer la faisabilité d'utiliser XACT pour la dosimétrie relative dans un réservoir d'eau et pour des applications in vivo en radiothérapie externe à photons. Premièrement, les propriétés des ondes acoustiques induites suite a l'irradiation de blocs de métal ont été systématiquement examinées par mesures experimentales. Simultanément, un travail de simulation capable de modeliser l'induction et la propagation des ondes acoustiques suivant une impulsion d'irradiation d'un accélérateur linéaire (linac) clinique a été développé et validé en utilisant les mesures expérimentales des blocs de métal. Cette étude a établi les relations entre les propriétés des ondes acoustiques induites par radiation et la distribution de la dose déposée. Ensuite, l'aptitude à détecter les ondes acoustiques induites par radiation dans un réservoir d'eau homogène et à imager la distribution de dose déposée ont été démontrées. Les images XACT ont été formées de distribution de dose d'une variété de formes et tailles et comparées à des mesures de chambres ioniques et films pour vérifier la relation linéaire entre la grandeur de l'image XACT et la dose de radiation. De plus, l'acquisition des images XACT a été largement caractérisée et la répétabilité, la sensibilité, et la dose requise pour imager étaient adaptées pour des applications de dosimétrie relative dans un réservoir d'eau. La partie finale de cette thèse comprend une étude de simulation pour étudier XACT comme outil pour la dosimétrie in vivo. Les ondes acoustiques induites dans un patient souffrant d'un cancer de la prostate traité avec des champs rectangulaires statiques et un plan d'arcthérapie volumétrique modulée ont été modelisés pour simuler le signal détecté par un transducteur placé au niveau du périné. Il a été observé que la position des gradients de la distribution de dose dans le patient pouvait être inferré en retroprojetant le signal du transducteur sur une image de tomodensitométrie (CT) ou ultrason du patient. Ce travail démontre que XACT est très prometteur comme technique de dosimétrie pour radiothérapie, en particulier pour des applications relatives en réservoir d'eau et in vivo. Le travail futur dans ce domaine devrait se concentrer sur l'amélioration de la technologie des transducteurs et la reconstruction de l'image pour augmenter la sensibilité de la technique. En définitive, XACT pourrait étre utilisé comme un outil pour dosimétrie volumétrique rapide en réservoir d'eau pour des champs de traitement complexes et être combiné à des images ultrason anatomiques pour la dosimétrie in vivo proche du temps-réel et le suivi des traitements.</description><description>Dosimetry is a crucial process in radiation therapy to ensure that radiation dose is accurately delivered to patients. A number of different dosimetry protocols are used at all stages of the external beam radiation therapy workflow. Recent advancements in radiation therapy delivery have posed a dosimetry challenge due to the use of highly modulated radiation fields and large dose per treatment fraction. There is therefore a need for novel accurate dosimetry techniques that are volumetric, non beam-perturbing, and near real-time. X-ray acoustic computed tomography (XACT) is an emerging imaging modality that detects the acoustic waves generated in an object via the thermoacoustic effect following a single pulse of x-ray irradiation. Using these transducer signals, an image of the differential pressure build-up can be reconstructed. Since XACT images can be related to radiation dose, it has been proposed that XACT could be a valuable tool for radiotherapy dosimetry. The goal of this thesis was to demonstrate the feasibility of using XACT for relative water tank and in vivo dosimetry applications in photon external beam radiation therapy. First, the properties of the acoustic waves induced following the irradiation of metal blocks were systematically investigated through experimental measurements. Simultaneously, a simulation workflow capable of modelling the induction and propagation of acoustic waves following a pulse of clinical linear accelerator (linac) radiation was developed and validated using the experimental metal block measurements. This study established the relationships between the properties of radiation-induced acoustic waves and the deposited dose distribution. Next, the ability to detect radiation-induced acoustic waves in a homogeneous water tank and image the deposited dose distribution was demonstrated. XACT images of dose distributions of a variety of shapes and sizes were formed and compared to ion chamber and film measurements to verify the linear relationship between XACT image magnitude and deposited radiation dose. In addition, the acquisition of XACT images was extensively characterized, and the repeatability, sensitivity, and required imaging dose were found to be promising for relative water tank dosimetry applications. The final portion of this thesis comprises a simulation study to investigate XACT as a tool for in vivo dosimetry. The acoustic waves induced in a prostate patient during irradiation with static rectangular fields or a volumetric modulated arc therapy plan were modelled to simulate the signal detected by a transducer placed at the perineum. It was observed that the position of dose distribution gradients in the patient could be inferred by back-projecting the transducer signal onto a computed tomography (CT) or an ultrasound image of the patient. This work demonstrates that XACT has great promise as a radiotherapy dosimetry technique, particularly for relative water tank and in vivo applications. Future work in the field should focus on the improvement of transducer technology and image reconstruction to enhance the sensitivity of the technique. Ultimately, XACT could be used as a tool for rapid volumetric water tank dosimetry of complex treatment fields and be combined with anatomical ultrasound imaging for near real-time in vivo dosimetry and treatment monitoring.</description><creator>Hickling, Susannah</creator><contributor>Issam El Naqa (Supervisor2)</contributor><contributor>Jan Peter Frans Seuntjens (Supervisor1)</contributor><date>2018</date><subject>Physics</subject><title>Demonstration of x-ray acoustic computed tomography as a radiotherapy dosimetry tool</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/c247dv52w.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/g158bk568</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Physics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:t435gg31d</identifier><datestamp>2020-03-21T05:11:47Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les variables instrumentales sont largement utilisées dans les statistiques appliquées et l'économétrie pour réaliser l'identification et effectuer l'inférence dans les modèles qui contiennent des variables explicatives endogènes. Dans la configuration habituelle, la fonction d'intérêt est supposée connue jusqu'à un nombre fini de paramètres inconnus et les variables instrumentales aident à l'identification de ces paramètres. Cependant, cette hypothèse est rarement justifiée par la théorie économique. Les méthodes non paramétriques offrent donc une alternative plus flexible aux données endogènes du modèle, en ce sens qu'aucune hypothèse sur la forme paramétrique d'une fonction n'est requise. Dans cette thèse, nous examinons d'abord le rôle d'une seule variable instrumentale pour réaliser l'identification dans un modèle linéaire à travers l'hypothèse plus forte de restriction de moment conditionnel qui est habituellement imposée dans le cadre non-paramétrique. Nous faisons cela en approximant la restriction de moment conditionnel par une séquence croissante de restriction de moments qui correspondent à la discrétisation / binning de la variable instrumentale. Enfin, nous examinons le modèle de variable instrumentale non paramétrique lorsque la variable explicative a été discrétisée pour fournir une approximation croissante de la fonction inconnue et que la variable instrumentale a été discrétisée pour approcher la restriction du moment conditionnel.</description><description>Instrumental variables are widely used in applied statistics and econometrics to achieve identification and carry out inference in models that contain endogenous explanatory variables. In the usual setup the function of interest is assumed to be known up to finitely many unknown parameters and instrumental variables aid in identification of these parameters. However, this is a strong assumption that is rarely justified by economic theory and so nonparametric methods provide a more flexible alternative to model endogenous data in the sense no assumptions on the parametric form of a function are required. In this thesis we first examine the role of a single instrumental variable to achieve identification in a linear model through the stronger conditional moment restriction assumption that is usually imposed in the nonparametric framework. We do this by approximating the conditional moment restriction by an increasing sequence of moment restrictions that correspond to discretizing/binning the instrumental variable. Finally, we examine the nonparametric instrumental variable model when the explanatory variable has been discretized to provide a growing approximation of the unknown function and the instrumental variable has been discretized to approximate the conditional moment restriction.</description><creator>Kankanala, Sidharth</creator><contributor>Masoud Asgharian-Dastenaei (Internal/Supervisor)</contributor><contributor>Russell Steele (Internal/Cosupervisor2)</contributor><date>2018</date><subject>Mathematics and Statistics</subject><title>Nonparametric instrumental variable models</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/c247dv535.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/t435gg31d</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Mathematics and Statistics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:x346d657t</identifier><datestamp>2020-03-21T05:11:48Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Cette thèse présente deux études portant sur la diffraction simple réalisées entre 2013 et 2018. L'analyse principale est une mesure des sections efficaces differentielles inclusives d'événements diffractifs simples à partir de données de collision proton-proton collectées par le détecteur ATLAS. Il s'agit de la première mesure non-élastique à sqrt(s) = 8 TeV à faire usage des spectromètres frontaux d'ALFA pour tracer les protons défléchis. Les sections efficaces sont déterminées pour plusieurs observables: la largeur du gap de rapidité, la variable de Mandelstam t et la fraction de quantité de mouvement perdue par le proton, reconstruite à partir des cinématiques du proton et du système diffractif. Les événements sont sélectionnés de façon à maximiser la significance du signal vis-à-vis du bruit. Le bruit restant est quantifié à l'aide d'une méthode basée en partie sur les données. Un algorithme de déconvolution est utilisé pour corriger les effets des détecteurs. La section efficace differentielle en t est extraite par régression linéaire: une pente B_(SD) = 7.55+/- 0.18 GeV^2 est obtenue. L'ordonnée à l'origine de la trajectoire du Pomeron est déterminée pour la valeur moyenne de t de la mesure en"fittant" la cinématique du proton et du système diffractif. Les valeurs alphaP(0) = 1.071 +/- 0.028 et alphaP(0) = 1.059 +/- 0.012 sont obtenues respectivement.La seconde étude s'intéresse à la diffraction dans un régime d'énergie different. Il s'agit d'une étude de faisabilité qui explore la possibilité d'analyser l'asymétrie de charge des bosons électro-faibles W produits diffractivement. Cette observable est sensible au contenu en quarks de valence du singulet de couleur échangé durant l'interaction diffractive. La production du W nécessitant un niveau d'énergie suffsamment élevé, cela implique d'utiliser le détecteur AFP récemment installé pour mesurer la cinématique du proton défléchi. La quantité de données nécessaires pour effectuer une telle étude est évaluée grâce à une simulation prenant en compte les contraintes en terme d'acceptance. Il ressort que 300 pb^(-1) de données devraient suffir à tester le contenu en saveur du Pomeron en ne considérant que le canal de désintégration muonique du W.</description><description>The work presented in this thesis covers two studies performed between 2013 and 2018. The main analysis is an inclusive measurement of the differential cross sections of single-diffractive events recorded in 2012 from proton-proton collisions in ATLAS. This measurement is the first of its kind at sqrt(s) = 8 TeV making use of the forward ALFA spectrometers to tag the scattered proton. Cross sections are measured for three observables: the size of the rapidity gap, the proton momentum transfer, t, and its fractional energy loss reconstructed from the kinematics of the proton and of the diffractive system. Events are selected such as to maximize the signal significance. The remaining background contribution is assessed using a partially data-driven technique. Distributions are "unfolded" to correct for detector smearing. A t-slope B_(SD) = 7.55 +/- 0.18 GeV^2 is obtained from fitting the cross section differential in t. The Pomeron intercept at the mean value of t for this measurement is found to be alphaP(0) = 1.071 +/- 0.028 and alphaP(0) = 1.059 +/- 0.012 from fitting the proton and diffractive system distributions respectively. The second study explores the regime of hard diffraction and the possibility of using the W boson as a probe to infer on the quarkonic content of the colourless singlet exchanged in diffractive hard interactions. The hardness of the process is such that the recently installed AFP detector is needed to tag the scattered proton. A simulation of diffractive interactions is used to assess the statistical needs for such study to be performed within acceptance constraints. The study suggests that 300 pb^(-1) of data are sufficient to probe the Pomeron flavour in the W -&gt; mu nu channel.</description><creator>Chuinard, Annabelle</creator><contributor>Francois Corriveau (Supervisor)</contributor><date>2018</date><subject>Physics</subject><title>Single diffraction studies with the ATLAS detector at the large hadron collider</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/ng451k878.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/x346d657t</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Physics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:j6731632s</identifier><datestamp>2020-03-21T05:11:49Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La dépression majeure est un trouble mental sévèrement incapacitant, traité principalement pharmacologiquement par les antidépresseurs. Leur efficacité est cependant relative, puisque près d'un tiers des patients sous traitement n'atteignent pas la rémission et cela même après plusieurs traitements. Compte tenu de l'absence de critères objectifs et systématiques pour établir un diagnostic et pour définir une stratégie thérapeutique adaptée, la découverte de biomarqueurs prédictifs de la réponse aux antidépresseurs faciliterait considérablement la prise en charge clinique des patients vers la rémission.Au-delà des facteurs génétiques, les facteurs environnementaux contribuent aussi grandement à l'étiologie de la dépression et la variabilité dans la réponse aux antidépresseurs. Dans ce contexte, les mécanismes épigénétiques sont des indicateurs pertinents de l'effet de l'environnement sur nos gènes. Ces mécanisme modifient l'architecture de la chromatine et donc l'expression de nos gènes sans pour autant affecter leur séquence ADN.Pour cette raison, un biomarqueur épigénétiques sera plus à même de prendre en compte le caractère multidimensionnel des facteurs influençant la réponse individuelle aux antidépresseurs. La méthylation de l'ADN est le type de modification épigénétique le plus largement décrit et étudié dans le contexte de la réponse au traitement antidépresseur. Ces études sont cependant limitées à des approches basées sur des hypothèses précises se focalisant sur des gènes candidats. En effet aucune à ce jour n'a tenté de déterminer la pertinence des modifications de la méthylation de l'ADN en tant que biomarqueur de la réponse aux antidépresseurs dans l'ensemble du génome. Ce travail de thèse vise à identifier des biomarqueurs prédictifs et fonctionnels de la réponse aux antidépresseurs. Il utilise une nouvelle méthode pangénomique à partir d'échantillons de sang périphérique. Premièrement, nous avons observé des changements significatifs dans plusieurs positions différentiellement méthylées (PDM) à partir de données basées sur des puces à ADN. Lors de la sélection des PDM pour la validation et la réplication des résultats, nous avons sélectionné des PDM situées dans des gènes différentiellement exprimés, sur la base de nos données préalablement obtenues d'expression transcriptomique. Cela a révélé trois PDM d'intérêt dont la méthylation différentielle a été validée et partiellement reproduite. Nous avons également effectué une analyse d'annotation qui a fourni d'autres perspectives fonctionnelles. Collectivement, cette thèse propose de nouveaux candidats pour prédire la réponse individuelle aux antidépresseurs, avec un aperçu des mécanismes moléculaires possibles qui caractérisent ces réponses.</description><description>Major depressive disorder (MDD) is a severe and debilitating disease that is primarily treated with antidepressants. However, many patients fail to respond to medication, even after multiple attempts. Given the lack of objective clinical diagnostic and treatment guidelines, a predictor biomarker for antidepressant response (ADR) would largely improve clinical practice for treating MDD, and decrease the time required to effectively treat patients.In addition to genetic factors, environmental factors are also associated with MDD etiology and treatment efficacy. Epigenetic mechanisms better reflect the interaction between genetic and environmental induced effects through chromatin structure modifications, without affecting the DNA sequence directly. An epigenetic biomarker would thus be more sensitive and functional in accounting for the multifactorial basis of treatment response variation in patients. DNA methylation is the best-known type of epigenetic modification, and has been studied in the context of treatment response. However, current studies are based on hypothesis driven approaches, and no genome wide investigations have been made.This thesis aims to identify predictive, functional biomarkers for ADR using a novel genome wide method from peripheral blood samples. Firstly, we observed multiple significantly differentially methylated positions (DMPs) from microarray-based data. When selecting DMPs for validation and replication, we selected DMPs located in differentially expressed genes identified from our genome wide expression analysis. This revealed three DMPs of interest that were validated and partially replicated. We also performed functional annotation analysis which provided further functional perspectives as well. Collectively, this thesis discusses our exploratory findings of new candidates for predicting ADR, along with an overview of possible molecular mechanisms that characterize ADR. </description><creator>Ju, Chelsey</creator><contributor>Gustavo Turecki (Internal/Supervisor)</contributor><date>2018</date><subject>Neuroscience</subject><title>Differential DNA methylation as a predictor biomarker of antidepressant response in patients with major depressive disorder</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/ft848s81t.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/j6731632s</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Integrated Program in Neuroscience</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:mk61rk392</identifier><datestamp>2020-03-21T05:11:50Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>T cells are important orchestrators of host defense against pathogen infections as well as damaged tissue.  T cells play an especially important role in cancer immunosurveillance, although tumour cells are frequently able to evade immune destruction through immunosuppressive mechanisms.  In order to enhance T cell anti-tumour responses, some of the most successful immunotherapy techniques involve enhancing T cell metabolism.  AMPK is an energy sensor that is required for regulating T cell metabolic plasticity, and emerging evidence has shown that activating AMPK may enhance T cell-mediated anti-tumour immunity.  However, many of the current methods used to activate AMPK are indirect, and therefore there is no direct evidence showing the effect of activating AMPK on T cell function and anti-tumour immunity.  Therefore, we hypothesized that AMPK activity is required for T cell-mediated anti-tumour immunity.  We have found that activating AMPK in T cells can modulate T cell effector function in vitro, and anti-tumour immunity in vivo.  Using a pharmacological method of activating AMPK, we found that T cell effector function was unchanged in vitro and in vivo, but T cells did have a growth advantage in nutrient-limiting conditions.  Using the FLCN KO model of activating AMPK, we found that both AMPK and mTORC1 signalling were increased in T cells, as well as cytokine production and proliferation.  In vivo, we observed a weaker FLCN KO T cell primary immune response towards L. monocytogenes.  In the tumour model context, tumour growth was decreased in FT mice, although tumour growth was greater in mice receiving an adoptive transfer of FLCN KO T cells.  Altogether, this research shows that important T cell functions can be enhanced by AMPK activation, and demonstrates the context-dependent role of AMPK in T cell function and in anti-tumour immunity</description><description>Les lymphocytes T sont des orchestrateurs importants de la défense de l'hôte contre les infections par les agents pathogènes et les tissus endommagés. Les lymphocytes T jouent un rôle particulièrement important dans l'immunosurveillance du cancer, mais les cellules tumorales sont souvent capables d'échapper la destruction immunitaire par des mécanismes immunosuppresseurs. Afin d'améliorer les réponses anti-tumorales des lymphocytes T, certaines des techniques d'immunothérapie les plus réussies impliquent l'amélioration du métabolisme des lymphocytes T. AMPK est un senseur énergétique qui est nécessaire pour réglementer la plasticité métabolique des lymphocytes T, et des preuves émergentes ont montré que l'activation de l'AMPK peut améliorer l'immunité antitumorale médiée par les lymphocytes T. Cependant, plusieurs des méthodes utilisées en ce moment pour activer l'AMPK sont indirectes, et par conséquent il n'y a aucune preuve directe montrant l'effet de l'activation de l'AMPK sur la fonction des lymphocytes T et l'immunité anti-tumorale. Par conséquent, nous avons émis l'hypothèse que l'activité de l'AMPK est nécessaire pour l'immunité anti-tumorale médiée par les lymphocytes T.Nous avons trouvé que l'activation de l'AMPK dans les lymphocytes T peut moduler la fonction des lymphocytes T in vitro et l'immunité anti-tumorale in vivo. En utilisant une méthode pharmacologique d'activation de l'AMPK, nous avons trouvé que la fonction des cellules T n'était pas changée in vitro et in vivo, mais les lymphocytes T avaient un avantage de croissance dans des conditions avec moins des nutriments. En utilisant le modèle FLCN KO de l'activation de l'AMPK, nous avons trouvé que les signaux AMPK et mTORC1 étaient augmentés dans les lymphocytes T, et aussi la production des cytokines et la prolifération. In vivo, nous avons observé que la réponse immunitaire primaire des lymphocytes T FLCN KO contre L. monocytogenes est plus faible. Dans le contexte du modèle tumoral, la croissance tumorale était diminuée dans les souris FT, mais la croissance tumorale était augmenté dans les souris recevant un transfert adoptif de lymphocytes T FLCN KO. En conclusion, cette recherche montre que les fonctions importantes des lymphocytes T peuvent être améliorées par l'activation de l'AMPK, et démontre que le rôle de l'AMPK dans la fonction des lymphocytes T et dans l'immunité anti-tumorale est dépendant du contexte nutritionnel et énergétique.</description><creator>Wong, Alison</creator><contributor>Russell Jones (Internal/Supervisor)</contributor><date>2018</date><subject>Physiology</subject><title>Investigating the effect of AMPK activation on T cell-mediated anti-tumour immunity</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/w66346033.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/mk61rk392</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Physiology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:ks65hf542</identifier><datestamp>2020-03-21T05:11:51Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The endoplasmic reticulum (ER) is an interconnected membrane network of tubules and sheets found in all eukaryotic cells. The formation of this interconnected network requires homotypic fusion of ER membranes, which is mediated by a family of dynamin-like large Atlastin GTPases, including mammalian Atlastins, yeast Sey1p and plant RHD3 (ROOT HAIR DEFECTIVE 3). As a plant member of Atlastin GTPases, the mechanistic basis of how RHD3 acts in ER membrane fusion process is largely unknown.In the first part of the thesis, a systemic structure-function analysis of the action of different RHD3 domains in mediating ER fusion was conducted. Similar to Atlastins in mammalian cells and Sey1p in yeast cells, RHD3 has a GTPase domain in the N-terminus, a 3-helix bundle (3HB) enriched middle domain, two transmembrane domains and amphipathic C-terminal domain. I found that the GTPase domain and the first and second 3HBs in the middle domain promote the dimerization of RHD3. This dimerization of RHD3 is required for efficient ER membrane fusion. On the other hand, the third and fourth 3HBs are required for the protein stability of RHD3. I also found that the transmembrane domains (TMs) of RHD3 not only serve as an ER membrane anchor, but also facilitate the oligomerization of RHD3. In the C-terminal tail of RHD3, there is an amphipathic helix. I revealed that this amphipathic helix has a special membrane anchoring ability and is required for efficient ER membrane fusion. With this work, I contribute to a deeper understanding of the mechanistic basis of action of RHD3 in mediated ER membrane fusion.To maintain the ER homeostasis, the fusion action of Atlastin GTPases must be regulated and balanced. However, the knowledge of the regulation of action of Atlastin GTPses is very limited. Lunapark proteins (LNPs), a family of proteins known to be required for maintaining a normal tubular ER morphology, have been recently found to act antagonistically with Sey1p in yeast cells. But the exact molecular mechanisms how LNPs antagonize the action of Atlastin GTPases remain unclear. In the second part of the thesis, I found that there are two LNP homologs, LNP1 and LNP2 in Arabidopsis, both of them interact with RHD3 on 3-way junctions of the ER. Loss of LNPs in Arabidopsis cause plants to grow short root hairs and to be dwarfed. Additionally, massive sheet ER containing dense 3-way junctions is found in the cells. LNP1 and LNP2 are localized to 3-way-junctions of the ER where they stabilize the newly formed 3-way junctions of the ER. I revealed that LNPs are recruited by RHD3, after the ER membrane fusion, to the newly formed 3-way junctions. They can inhibit the fusion action of RHD3 likely by promoting the protein degradation of RHD3. With this work, I propose a novel post-membrane fusion regulation for RHD3 in which the RHD3 protein is degraded by the action of LNPs to avoid excessive fusion for the generation of an interconnected ER with an open polygonal network.</description><description>Le réticulum endoplasmique est un organite dans les cellules eucaryotes composé de tubules et de plaques membraneuses. Ces tubules et plaques interconnectées sont crée par des fusions homotypiques entre le réticulum endoplasmique, ce qui est contrôlé par une famille de protéines appelés Atlastin GTPases (similaire à la dynamine). Cette famille inclut des Atlastins mammifères, Sey1p des cellules levures, et RHD3 (ROOT HAIR DEFECTIVE 3) des plantes. Le mécanisme dont RHD3 régule la fusion des membranes du réticulum endoplasmique n'est pas connu.  La première partie de cette thèse s'agit d'une analyse systémique de la structure et fonction de chaque domaine protéique de RHD3 par rapport à son rôle dans la fusion des membranes réticulum endoplasmique. Comme les Atlastins (mammifères) et Sey1p (cellules de levure), RHD3 a: une domaine GTPase à son N-terminale, des faisceau de trois hélices dans la milieu domaine protéique, et aussi deux domaines transmembranaire et une domaine amphipathique à son C-terminale. Les donnés démontrent que la domaine GTPase et le premier et deuxième faisceau d'hélices se sont responsables pour la dimérisation de RHD3. La dimérisation de RHD3 est requit pour la fusion du réticulum endoplasmique. Par contre, le troisième et quatrième faisceau d'hélices sont requises pour la stabilité protéique de RHD3. Les domaines transmembranaires contrôlent l'oligomérisation de RHD3, et la domaine amphipathique à la C-terminale est capable d'ancrer RHD3 au réticulum endoplasmique, ce qui est requit pour maximiser la fusion membranaire. Ce travail aide à mieux comprendre les mécanismes par lesquels RHD3 fonctionne pour réguler la fusion membranaire du réticulum endoplasmique. Pour maintenir l'homéostasie du réticulum endoplasmique, la fonction des Atlastin GTPases doivent être régulés précisément, ce qui n'est pas bien connu. « Lunapark proteins (LNPs) », une famille de protéines qui maintiennent la morphologie tubulaire du réticulum endoplasmique, était récemment démontré d'avoir un effet antagoniste avec Sey1p dans les cellules de levure. Comment LNP fonctionne pour avoir un effet antagoniste avec Atlastin GTPases n'est pas claire. J'ai identifié deux homologues de LNP, LNP1 et LNP2 dans Arabidopsis. LNP1 et LNP2 interagirent avec RHD3 aux jonctions de trois surfaces du réticulum endoplasmique. La perte de fonction des LNPs dans Arabidopsis résulte dans des plus petites plantes avec des poils racinaires raccourcis, et du réticulum endoplasmique en forme de plaques avec plusieurs jonctions de trois surfaces. LNP1 et LNP2 sont localisés jonctions de trois surfaces du réticulum endoplasmique et jouent un rôle stabilisateur; ils stabilisent les jonctions de trois surfaces qui étaient récemment crée. J'ai démontré que les LNPs sont recrutés aux jonctions après la fusion membranaire du réticulum endoplasmique par RHD3. Avec ces donnés, je propose que RHD3 est régulé par LNP dans le façon suivant: après la fusion membranaire, RHD3 est dégradé (suivant un signal de LNP) pour éviter d'avoir trop de fusion membranaire dans le réticulum endoplasmique, ce qui empêcherait le réticulum de fonctionner comme il faut.</description><creator>Sun, Jiaqi</creator><contributor>Huanquan Zheng (Supervisor)</contributor><date>2018</date><subject>Biology</subject><title>Mechanistic basis of RHD3 function in formation of interconnected tubular ER network</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/n870zs88n.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/ks65hf542</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Biology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:5x21th777</identifier><datestamp>2020-03-21T05:11:52Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Concerns about the safety of the pill have come to the fore recently, due in large part to the public outcry over deaths allegedly caused by popular contraceptives Yaz and Yasmin. Media reports link the drugs to at least 23 deaths in Canada and over 100 in the U.S. as well as thousands of injuries worldwide, as a result of a purported increased incidence of blood clots. The question of what should be considered an acceptable risk threshold for approved contraceptive pills has been contested by many groups, including regulatory bodies, medical professionals, epidemiologists, and consumers. This thesis provides an in-depth sociological examination of the Yaz/Yasmin controversy through qualitative analysis of stakeholder interviews and content analysis of key medical, regulatory, and legal documents. I examine the most recent safety debates in order to analyze the central phenomena that play a role in the regulation and risk/benefit assessment of oral contraceptives: managing data uncertainty, calculating reproductive risks against ancillary benefits, and the precariousness of informed consent. After an introductory chapter in which I situate the thesis within the larger scholarly conversations on contraceptive assessment specifically and technological risk more generally, the findings are presented in three article-length manuscripts. In the first article, I investigate strategies that regulatory bodies and professional associations use to assure the public of the safety of Yaz and Yasmin. I found that a discourse of pregnancy risks is employed in official risk communication. I argue that this has gendered implications for the development of contraceptives and their risk assessment. In the second article, I explore how pill users who have experienced side effects understand the risks of hormonal contraception and advocate for changes in risk communication and drug regulation. I found that women highlighted the inadequacy of risk information received from both doctors and pharmaceutical companies. In addition, affected users rejected the use of reproductive risk as the primary comparative risk when assessing pill safety. In the third paper, I look at processes through which individual stakeholders measure and debate contraceptive risk. Here, I highlight how contraceptive risk assessment is characterized by systemic uncertainty and doubt. Furthermore, the paper stresses the tough choices that users have to make in a climate of indecision coupled with pharmaceutical companies' involvement in research and marketing. While we know that the history of the pill has been fraught with many debates about its safety, less attention has been paid to the current changing context and how different social actors still contest the measurement and meaning of contraceptive risk. I found that many questions about risks are unresolved or dealt with in ways that create divergence between professionals and affected users. In the concluding chapter, I discuss the sociological implications of my findings, the limitations of this study and potential directions for future research on the evaluation of contraceptive risk. The Yaz/Yasmin controversy has amplified contemporary critiques of the pill. In documenting and analyzing the dynamics of this risk debate, this thesis contributes to a deeper understanding of how the risks and benefits of contraception are currently assessed in the North American context.</description><description>Les inquiétudes concernant l'innocuité de la pilule ont récemment été au cœur de toutes les discussions et ce en grande partie à cause du tollé général provoqué par les décès vraisemblablement entraînés par les contraceptifs Yaz et Yasmin, très répandus sur le marché. Les rapports des médias associent ces médicaments à au moins 23 morts au Canada et plus de 100 aux États-Unis, ainsi qu'à des milliers de victimes à travers le monde par suite d'une incidence supposée accrue de caillots sanguins. La question de savoir quel devrait être le seuil de risque acceptable pour les pilules contraceptives approuvées a été débattue par de nombreux groupes, parmi lesquels des organismes de réglementation, des professionnels du milieu médical, des épidémiologistes et des consommatrices. La présente thèse fournit une analyse sociologique en profondeur de la controverse Yasmin/Yaz à travers une analyse qualitative des entretiens effectués avec les parties prenantes et une analyse de contenu de documents clés sur les plans médical, réglementaire et juridique. Nous examinerons les débats les plus récents concernant l'innocuité afin d'analyser les principaux événements qui influent sur la réglementation et l'évaluation du rapport risque/avantage des contraceptifs oraux: la gestion de l'incertitude des données, le calcul des risques liés à la procréation par rapport aux avantages complémentaires, et la précarité du consentement éclairé. Après un chapitre introductif dans lequel nous situerons la présente thèse au sein des discussions académiques plus étendues au sujet de l'évaluation contraceptive en particulier et du risque technologique en général, les résultats seront présentés sous forme de trois manuscrits de la longueur d'un article. Dans le premier article, nous enquêterons sur les stratégies déployées par les organismes de réglementation et les organisations professionnelles pour assurer au public l'innocuité de Yaz et Yasmin. À cette occasion, nous avons constaté qu'un discours concernant les risques de grossesse est utilisé dans le cadre de la communication officielle des risques. Dans le deuxième article, nous examinerons la manière dont les utilisatrices de la pilule qui ont subi des effets secondaires perçoivent les risques de la contraception hormonale et militent en faveur de changements en matière de communication des risques et de réglementation des médicaments. Nous avons découvert que les femmes ont souligné l'insuffisance d'informations en matière de risques délivrées par les médecins et les entreprises pharmaceutiques. En outre, les utilisatrices affectées ont rejeté l'utilisation du risque sur le plan de la reproduction comme comparatif principal. Dans le troisième article, nous nous pencherons sur les processus utilisés par chacune des parties prenantes pour évaluer et aborder le risque lié à la contraception. Cet article met en lumière les choix difficiles que doivent faire les utilisatrices dans un climat marqué par l'incertitude des risques encourus et l'implication des entreprises pharmaceutiques dans la recherche et la commercialisation des médicaments. Nous sommes parvenu à la conclusion que de nombreuses questions concernant les risques restent en suspens ou sont traitées d'une manière qui entraîne des divergences entre les professionnels et les utilisatrices concernées. Dans le chapitre final, nous aborderons les conséquences sociologiques de nos découvertes, les limites de la présente étude et les orientations possibles pour des recherches futures concernant l'évaluation des risques liés à la contraception. La controverse Yaz/Yasmin a accru les critiques actuelles au sujet de la pilule. À travers la documentation et l'analyse des dynamiques de ce débat concernant les risques, la présente thèse contribue à une meilleure compréhension de la manière dont les risques et les avantages de la contraception sont analysés à l'heure actuelle dans le contexte nord-américain. </description><creator>Geampana, Alina</creator><contributor>Jennifer Fishman (Supervisor)</contributor><date>2018</date><subject>Sociology</subject><title>"Beyond birth control:" the Yaz/Yasmin controversy and the risk evaluation of hormonal contraceptives</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/5q47rr124.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/5x21th777</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Sociology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:pc289m30r</identifier><datestamp>2020-03-21T05:11:53Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Dans son état actuel, l'étude de textures musicales formées à partir d'éléments indépendants superposés fait défaut de par son manque de précision terminologique. La notion de polytonalité reste elle-même sans consensus définitif, faisant l'objet de nombreuses controverses. Abordant ce problème langagier, j'effectue d'abord un survol du travail théorique actuel afin d'en déceler ses faiblesses. Je propose ensuite un modèle de différenciation de strates qui décrit la manière dont plusieurs couches texturales indépendantes peuvent se distinguer structurellement l'une de l'autre. Ce modèle fait usage de langage concis, précis et mis à jour. Dans un dernier chapitre, afin d'avancer son utilité en tant qu'outil analytique, j'en démontre l'usage dans le contexte de passages d'Ireland, Britten et Vaughan Williams. Enfin, la notion de différenciation de strates offre un regard théorique sur la polytonalité et ses dérivés plus efficace et plus cohérent.</description><description>Music-theoretical research into textures featuring superimposition of independent layers of music suffers from considerable terminological fragmentation and imprecision, with notions such as "polytonality" remaining ill-defined and subject to semantic controversy. I first review existing research into the topic, highlighting these weaknesses. In order to address them, I then propose a differentiation model, an analytical tool that employs concise, precise and more up-to-date theoretical terminology to describe and quantify the way in which musical strata may be differentiated through divergences in construction. Finally, I apply the differentiation model to excerpts by Ireland, Britten and Vaughan Williams in order to demonstrate its relevance to music analysis. Ultimately, I argue that the differentiation model provides a more effective, consistent theoretical framework for analyzing layered musical construction.</description><creator>Bergeron-Dumaine, Holly</creator><contributor>Jonathan Wild (Internal/Supervisor)</contributor><date>2018</date><subject>Music</subject><title>Differentiation of Concurrent Musical Strata</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/9w0325325.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/pc289m30r</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Schulich School of Music</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:vm40xv060</identifier><datestamp>2020-03-21T05:11:54Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Smooth muscle has a unique property, called the latch-state, during which force is maintained for long periods of time at low energy consumption and low myosin activation (phosphorylation) levels. This property has been observed at the whole muscle level and is mostly associated with tonic rather than phasic smooth muscle. To explain the latch-state, theories have been elaborated that invoke different molecular mechanisms, but have never been verified. One such theory states that, during the cross-bridge cycle, if smooth muscle myosin gets dephosphorylated while attached to actin, it will remain attached, in a load-bearing mode. Other theories involve regulatory proteins, like caldesmon, for force maintenance to occur. In an attempt to reproduce the latch-state at the molecular level, we used the in vitro motility assay to measure the velocity (Vmax) of fluorescently labeled actin filaments when propelled by myosin molecules on a coverslip. A threshold velocity was chosen, above which the filaments were considered to be moving, so that motile fraction (fmot), the percentage of filaments moving, could be calculated. An injection chamber was added to the motility assay so that myosin light chain phosphatase (MLCP) could be injected during the assay to efficiently dephosphorylate myosin without creating bulk flow. We dephosphorylated separately phasic and tonic smooth muscle myosin. Our data suggested that a load was created during dephosphorylation because both Vmax and fmot decreased. However, these data were very noisy because they were obtained at very low levels of activation. Thus, the next protocol involved the injection of MLCP to a mixture of smooth and skeletal muscle myosin. The latter not being regulated by phosphorylation assured that the motility would continue after MLCP injection. The rationale behind this protocol was that if the latch-state occurs, a transient decrease in Vmax and fmot should be observed, due to the load induced by the attached, dephosphorylated SM myosin. The motility would eventually increase back to the level of skeletal muscle myosin after the detachment of the latch bridges. The effect of caldesmon was also tested. We observed a transient decrease in both Vmax and fmot suggesting a load-bearing effect. These findings suggest that the dephosphorylation created latch-bridges. Enhancement of this transient load-bearing phase was observed when adding caldesmon. Unexpectedly, this synergistic transient effect of MLCP and caldesmon did not appear to be muscle specific as the same behavior was observed when the measurements were repeated with skeletal muscle myosin alone. In conclusion, a force-maintenance state was reproduced at the molecular level, which could be the underlying mechanism of the latch-state.</description><description>Le muscle lisse a une propriété unique, appelée l'état-« latch », durant lequel la force est maintenue pour de longues périodes de temps à faible consommation d'énergie et à faible niveau d'activation de la myosine (faible niveau de phosphorylation). Cette propriété a été observée au niveau du muscle entier et est principalement associée au muscle lisse tonique plutôt que phasique. Pour expliquer l'état-latch, des théories ont été élaborées, qui invoquent différents mécanismes moléculaires, mais elles n'ont jamais été vérifiées. Une de ces théories suggère que, pendant le cycle ATPasique de l'actomyosine, si la myosine du muscle lisse se déphosphoryle alors qu'elle est attachée à l'actine, elle restera attachée, en mode porteur. D'autres théories impliquent des protéines régulatrices, comme la caldesmone, pour le maintien de la force. Dans une tentative de reproduire l'état-latch au niveau moléculaire, nous avons utilisé l'essai de motilité in vitro pour mesurer la vitesse (Vmax) des filaments d'actine, marquée par fluorescence, lorsqu'ils sont propulsés par des molécules de myosine sur une lamelle de microscope. Une vitesse de seuil a été choisie, au-dessus de laquelle les filaments sont considérés comme en mouvement, de sorte que la fraction motile (fmot), le pourcentage de filaments en mouvement, peut être calculée. Une chambre d'injection a été ajoutée à la chambre de motilité de sorte que la phosphatase de la chaîne légère de la myosine (MLCP) puisse être injectée pendant l'expérience, pour déphosphoryler efficacement la myosine sans créer de flux de masse. Nous avons déphosphorylé séparément la myosine du muscle lisse phasique et tonique. Nos résultats suggèrent qu'une charge a été créée pendant la déphosphorylation parce que Vmax et fmot ont diminué. Cependant, ces résultats étaient très variables car ils ont été obtenus à de très faibles niveaux d'activation. Ainsi, le protocole suivant impliquait l'injection de MLCP dans un mélange de myosine musculaire lisse et squelettique. Cette dernière myosine n'étant pas régulée par la phosphorylation, elle assurait que la motilité continuerait après l'injection du MLCP. Le raisonnement derrière ce protocole était que si l'état-latch se produisait, une diminution transitoire de Vmax et de fmot devrait être observée, en raison de la charge induite par la myosine du muscle lisse déphosphorylée et attachée. La motilité finirait par remonter au niveau de celle de la myosine du muscle squelettique après le détachement des ponts latchs. L'effet de la caldesmone a également été testé. Nous avons observé une diminution transitoire à la fois de Vmax et de fmot suggérant un effet porteur. Ces résultats suggèrent que la déphosphorylation a créé des charges latch. L'amplification de cette phase transitoire de charge a été observée lors de l'ajout de la caldesmone. Surprenamment, cet effet transitoire synergique du MLCP et de la caldesmon ne semble pas être spécifique au muscle lisse car le même phénomène a été observé quand les mesures ont été répétées avec la myosine du muscle squelettique seule. En conclusion, un état de maintenance de la force a été reproduit au niveau moléculaire, qui pourrait être le mécanisme sous-jacent de l'état-latch.</description><creator>Balassy, Zsombor</creator><contributor>Anne-Marie Lauzon (Internal/Supervisor)</contributor><date>2018</date><subject>Atmospheric and Oceanic Sciences</subject><title>Can we reproduce the latch-state in vitro at the molecular level?</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/q237hv040.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/vm40xv060</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Bioengineering and Biomedical Engineering Program</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:kh04dr86c</identifier><datestamp>2020-03-21T05:11:55Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Dans les systèmes de nuages bas, tels que les cumulus ou stratocumulus, des larges distributions de taille de gouttelettes et des temps de formation de pluie rapides sont fréquemment observés en utilisant des radars et des mesures in-situ. Cependant, ces observations ne peuvent pas être représentées par la théorie classique de la croissance par condensation. Une hypothèse suggère que la turbulence accélère la formation de gouttes de pluie en améliorant le processus de collision-coalescence des gouttelettes de nuage. Dans cette thèse, l'approche de simulation numérique directe (DNS) est utilisée pour étudier le rôle de la turbulence dans les processus de microphysique des nuages durant l'initiation de la pluie chaude et quantifier l'effet de la turbulence sur le taux de collision entre gouttelettes. Nous avons développé un cadre de modélisation précis et sophistiqué qui couple les processus dynamiques et thermodynamiques, permettant ainsi de combiner la croissance des gouttelettes par des processus simultanés de condensation et de collision dans diverses conditions turbulentes. Tout au long de la thèse, trois séries d'expériences numériques sont menées pour étudier l'impact de la turbulence sur: 1) le taux de collision géométrique des gouttelettes, 2) le taux de collision hydrodynamique et 3) les interactions entre la croissance de condensation et la croissance collisionnelle. Les résultats des deux premières séries d'expériences montrent que pour les paires de gouttelettes de tailles différentes, la turbulence modifie la réponse hydrodynamique des gouttelettes au flux de perturbation locale et crée les regroupements de gouttelettes dans l'espace. Conséquemment, une amélioration significative de l'efficacité de la collision et une légère amélioration du noyau de collision géométrique en résultent. D'autre part, pour les paires de gouttelettes de taille similaire, l'amélioration de la turbulence dans les interactions géométriques de collision et dans les interactions de l'hydrodynamiques des gouttelettes est forte. Puisque la croissance par condensation des gouttelettes produit une distribution de la taille des gouttelettes (DSD) qui est étroite, nous émettons l'hypothèse que la turbulence élargit effectivement le spectre étroit en augmentant les collisions de taille similaire. Cette hypothèse est en outre vérifiée en effectuant une simulation de l'évolution DSD par collision-coalescence pour diverses conditions d'écoulement. On constate que la turbulence élargit significativement le DSD et que les collisions de taille similaire contribuent à 21-24% des collisions totales contre seulement 9% dans les expériences en l'absence de vent. Finalement, nous étudions l'interaction de la thermodynamique et de la dynamique et son impact sur la croissance des gouttelettes en permettant aux gouttelettes de croître simultanément par condensation et collision dans des environnements turbulents et non-turbulents. Les résultats montrent que le processus de condensation favorise les collisions dans un environnement turbulent tout en réduisant les collisions en l'absence de vent, indiquant un impact positif de la dynamique sur l'interaction de la condensation et de la collision. En outre, nous étudions l'importance relative des différentes échelles d'écoulement turbulent sur les statistiques de collision en faisant varier la taille du domaine de calcul. On constate que pour les petites gouttelettes, leurs mouvements et collisions sont principalement affectés par les plus petites échelles de turbulence. Ceci suggère que les statistiques de collision turbulente peuvent être obtenues en utilisant des ressources computationnelles relativement petites, et le nombre de Reynolds de calcul devrait être retiré de la paramétrisation du noyau de collision turbulent. En conséquence, une paramétrisation améliorée du noyau de collision turbulent de gouttelettes est proposée, ce qui est hautement cohérent avec les résultats du DNS.</description><description>In shallow cloud systems, such as cumulus or stratocumulus clouds, broad droplet size spectra and fast rain formation times are frequently observed using radar and in-situ measurements. However, these observations cannot be represented by classical condensational growth theory. Turbulence has been hypothesized to accelerate the formation of raindrops by enhancing the cloud droplet collision-coalescence process. In this thesis, the direct numerical simulation (DNS) approach is used to investigate the role of turbulence in cloud microphysics processes during warm-rain initiation and to quantify the effect of turbulence on the collision rate between droplets. We developed an accurate and sophisticated modeling framework that couples dynamics and thermodynamics, thus allowing the incorporation of droplet growth by simultaneous condensational and collisional processes under various turbulent conditions. Throughout the thesis, three sets of numerical experiments are conducted to study the turbulence impact on various droplet growth processes: 1) the droplet geometric collision, i.e., collisions without considering the disturbance flow induced by the presence of droplets, 2) the droplet hydrodynamic collisions, by including the disturbance flow, and 3) the interactions between condensational growth and collisional growth by further including the thermodynamic fields. The results of the first two sets of experiments demonstrate that for droplet pairs with different sizes (r1/r2&lt;0.8), turbulence plays a dominant role in modifying the droplet hydrodynamic response to the local disturbance flow, weakly increasing the droplet relative velocity and creating the clustering of droplets in space. Consequentially, a significant enhancement of the collision efficiency and a mild enhancement of geometric collision kernel resulted. On the other hand, for droplet pairs with similar sizes (r1/r2&gt;0.8), the turbulence enhancement in geometric collision and droplet hydrodynamic interactions is strong. Since droplet condensational growth produces a narrow droplet size distribution (DSD), we hypothesize that turbulence effectively widens the narrow spectrum by boosting similar-sized collisions. This hypothesis is further verified by conducting simulations of DSD evolution through collision-coalescence at various flow conditions. It is found that turbulence significantly broadens the DSD, and similar-sized collisions contribute to  21-24% of the total collisions compared to only 9% in the still-air experiments. Finally, we study the interaction of thermodynamics and dynamics and its impact on droplet growth by allowing droplets to simultaneously grow by condensation and collision in turbulent and non-turbulent environments. The results show that the condensational process promotes collisions in a turbulent environment while it reduces the collisions when in still air, indicating a positive impact of dynamics (turbulence) on the interaction of condensation and collision.In addition, we investigate the relative importance of different scales of turbulent flow on the collision statistics by varying the computational domain size. It is found that for small droplets (r &lt; 25 microns), their motions and collisions are mainly affected by the smallest scales of turbulence (i.e. the Kolmogorov length scale) and the large-scale motion has negligible influence on modifying the collision rate. This suggests that on the one hand, turbulent collision statistics can be obtained by using relatively small computational resources, and on the other hand, the computational Reynolds number should be removed from the parameterization of the turbulent collision kernel. As a consequence, an improved parameterization of droplet turbulent collision kernel is proposed that is highly consistent with the DNS results. </description><creator>Chen, Sisi</creator><contributor>Peter Bartello (Supervisor2)</contributor><contributor>Man K Yau (Supervisor1)</contributor><date>2018</date><subject>Atmospheric and Oceanic Sciences</subject><title>Impacts of turbulence on cloud microphysics and warm-rain initiation</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/fx719p65p.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/kh04dr86c</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Atmospheric and Oceanic Sciences</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:xk81jn83h</identifier><datestamp>2020-03-21T05:11:56Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Indigenous communities experience a greater burden of ill health than all other communities in Canada. In the Eeyou Istchee territory of northern Quebec, all nine James Bay Cree communities experience similar health challenges. In 2014, the Cree Board of Health and Social Services for James Bay (CBHSSJB) supported an initiative to stimulate local community prioritization for health change. While many healthcare challenges identified were specific to youth (defined as less than 35 years of age), youth's perspectives in these reports to date have been limited. We hence sought to understand how Cree youth perceived youth health and their engagement in health and health planning across Eeyou Istchee. As part of a CBHSSJB-McGill partnership, this qualitative descriptive study used a community-based participatory research approach. In collaboration with Cree community partners, ten Cree youth were recruited to participate in two focus groups, and five Cree youth coordinators were recruited to participate in key informant interviews. Thematic analysis was conducted; inductive codes were grouped into thematic categories. Cree participants characterized youth engagement in the following levels and capacities: participation in community and recreational activities; membership in youth councils at the local and regional levels; and, in decision-making as planners of health-related initiatives. Cree youth recommended greater use of social media, youth assemblies, and youth planners to further strengthen youth engagement and youth health in the region. Our findings revealed an interconnectedness between youth health and youth engagement; James Bay Cree youth described how they need to be engaged to be healthy, and need to be healthy to be engaged. Cree participants contributed novel and practical insights to engage Indigenous youth in health planning across Canada.</description><description>Les communautés autochtones font face au fardeau des problèmes de santé par rapport aux autres communautés en Canada. Dans le territoire d'Eeyou Istchee au nord du Québec, les neufs communautés cries de la baie James sont ainsi confrontées à des défis semblables. En 2014, le conseil Cri de la santé et des services sociaux de la Baie James (CBHSSJB) a soutenu une initiative visant à encourager les communautés locales pour définir leurs propres objectifs prioritaires en vue d'améliorer leur santé. Bien que de nombreuses priorités identifiées concernent surtout les jeunes (défini comme ayant moins de 35 ans), les perspectives des jeunes dans ces rapports à ce jour on été limités. Nous avons donc cherché à comprendre comment les jeunes Cris percevaient la santé des jeunes et leur engagement dans la santé et la planification de la santé dans la région d'Eeyou Istchee. Dans le cadre de ce CBHSSJB-McGill partenariat, cette étude descriptive et qualitative a utilisé une approche de recherche participative dans la collectivité. En collaboration avec nos partenaires cris, dix jeunes cris ont été recrutés pour participer à deux groups de discussion, et cinq coordonnateurs jeunesse cris ont été recrutés pour participer aux entrevues d'informateurs clés. Une analyse thématique a été menée; les codes inductifs ont été regroupés en catégories thématiques. Les participants cris ont caractérisé l'engagement des jeunes cris dans les niveaux et capacités suivantes : participation dans les activités communautaires et récréatives; l'adhésion aux conseils de la jeunesse locaux et régionaux; et, à la prise de décisions en tant que jeunes planificateurs en soins de santé. Les jeunes participants cris ont recommandé davantage l'utilisations des médias sociaux, des assemblées de jeunes, et des jeunes planificateurs en soins de santé pour renforcer encore l'engagement de la jeunesse. Nos résultats dévoilent une interconnexion entre la santé des jeunes et l'engagement des jeunes; les jeunes Cris de la baie James ont expliqué comment ils doivent être engagés pour être en santé, et comment ils doivent être en santé pour pouvoir s'engager. Les participants cris ont aussi contribué des idées nouvelles et pratiques pour mieux engager les jeunes autochtones à la planification de la santé au Canada.</description><creator>Merati, Nickoo</creator><contributor>Gillian Bartlett-Esquilant (Supervisor1)</contributor><contributor>Susan Law (Supervisor2)</contributor><date>2018</date><subject>Family Medicine</subject><title>Cree youth, health (miyupimaatisiiun), and engagement in health planning</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/5h73pz36z.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/xk81jn83h</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Family Medicine</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:k643b339c</identifier><datestamp>2020-03-21T05:11:57Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The present event-related brain potentials (ERP) study investigates questions concerning the neurocognitive mechanisms underlying the processing of semantic and morphosyntactic information in French sentence comprehension. Using an audio/visual sentence-picture matching paradigm, we investigate two types of anomalies: (i) lexico-conceptual semantic mismatches between visually presented actions and spoken verbs, and (ii) morphosyntactic number mismatches between the visually presented image and the spoken sentence. We varied the type and amount of number cues available in each sentence by adding two manipulations: (1) verb type, whereby each sentence contained either a verb whose number cue was only audible at the junction between the verb and the preceding subject pronoun by a liaison (Type-2), or a verb whose number cue was only audible on the verb ending (Type-3), (2) a context manipulation, whereby each sentence was preceded by either a neutral context phrase or a subject noun phrase (NP), the former providing no additional cue as to number and the latter containing a sentence-initial determiner as a cue. To our knowledge, we are the first to investigate the contribution of different number cues in such a systematic fashion.This study was designed as part of a larger research project aiming to provide a better understanding of French language acquisition and comprehension abilities in children with developmental language impairment (DLI). ERP studies investigating DLI are scarce, and hardly any of these investigate French. In order to meaningfully interpret the child data that will be collected later on, we tested a control group of 16 neurotypical adult French native speakers to establish the prototypical ERP correlates for the anomalies included in the experimental paradigm. By comparing adult data to the data obtained later from children, we will be able to determine whether children with DLI demonstrate relative strengths/weaknesses in different linguistic areas (i.e., semantics, morphosyntax) and whether they exhibit immature or atypical processing strategies.For Type-2 verbs, adult participants reliably exhibited distinct ERP components for auditory-visual verb-action mismatches (N400) and auditory-visual morphosyntactic number mismatches (LAN/P600), extending research conducted in the visual domain (i.e., reading studies) to include our cross-modal design and French stimuli. Our context manipulation demonstrated that if multiple cues are available to identify the subject number (and therefore also to detect number match or mismatches with the image), adult participants use the first available cue in the sentence to detect the mismatch, and do not show an additional mismatch effect at the position of the second cue. Future steps involve investigating the sociolinguistic and phonological factors that may have affected interpretation of a subset of sentences, and completing data analysis so we can begin our studies on children with DLI.</description><description>La présente étude utilise les potentiels évoqués (PÉs) afin d'étudier les mécanismes neurocognitifs sous-tendant le traitement de l'information sémantique et morphosyntaxique lors de la compréhension de phrases en français. Utilisant un paradigme d'appariement d'images et de phrases présentées en modalité auditive, deux types d'incongruences ont été étudiées : (i) des incongruences relevant de la sémantique lexico-conceptuelle entre l'action présentée visuellement et le verbe présenté oralement, (ii) des incongruences morphosyntaxiques concernant l'accord en nombre entre l'image présentée visuellement et la phrase présentée oralement. Deux manipulations permettaient de varier le type ainsi que la quantité d'indices relatifs au nombre disponibles dans chaque phrase. Premièrement, le type de verbe utilisé plaçait l'indice de nombre à différentes positions dans la phrase :  soit au niveau de la liaison entre le verbe et le pronom sujet qui le précédait (verbes de Type-2), soit au niveau de la terminaison du verbe (verbes de Type-3). Deuxièmement, le syntagme précédant chaque phrase permettait de manipuler le contexte : un syntagme contextuellement neutre ne fournissait pas d'indice de nombre supplémentaire, tandis qu'un syntagme nominal sujet incluait dès le début un déterminant comme indice de nombre. À notre connaissance, notre étude est la première à examiner de manière aussi systématique la contribution de différents indices de nombre dans la compréhension de la phrase. Cette étude fait partie d'un projet de recherche visant à mieux comprendre l'acquisition du français ainsi que les habiletés de compréhension du langage des enfants avec un trouble développemental du langage (TDL). Les études en PÉs étudiant le TDL sont rares et presque qu'aucune d'entre-elles ne s'intéresse au français. Un groupe contrôle composé de 16 adultes neurotypiques ayant le français comme langue maternelle a été testé afin d'identifier les PÉs prototypiques correspondant aux différentes anomalies de notre paradigme expérimental. Ces résultats permettront ainsi d'interpréter adéquatement les données qui seront ultérieurement recueillies chez les enfants. En effet, en comparant les données des enfants à celles des adultes, il sera possible de déterminer si les enfants ayant un TDL démontrent certaines forces ou des faiblesses dans différents domaines linguistiques (ici sémantique et morphosyntaxe) et s'ils présentent des stratégies de traitement immatures ou atypiques. Pour les verbes de Type-2, les participants adultes ont systématiquement démontré des composants PÉs distincts entre les incongruences auditives-visuelles relevant de la sémantique lexico-conceptuelle (N400), et les incongruences auditives-visuelles morphosyntaxiques au niveau de l'accord en nombre (LAN/P600). Ces données résultant de notre design intermodal et de nos stimuli en langue française viennent enrichir la recherche conduite en modalité visuelle (p.e. les études portant sur la lecture). La manipulation du contexte à l'aide de différents syntagmes a démontré que les adultes utilisent le premier indice disponible dans la phrase pour détecter l'incongruence, et ne démontrent pas d'effet additionnel si un deuxième indice est présent par la suite. Les étapes suivantes porteront, d'une part, sur l'étude des facteurs sociolinguistiques et phonologiques pouvant influencer l'interprétation d'un sous-ensemble de nos phrases, et d'autre part sur la finalisation de nos analyses afin de pouvoir débuter nos études s'intéressant aux enfants ayant un TDL.</description><creator>Martignetti, Lisa</creator><contributor>Royle, Phaedra (Internal/Cosupervisor2)</contributor><contributor>Steinhauer, Karsten (Internal/Supervisor)</contributor><date>2018</date><subject>Communications Sciences &amp; Disorders</subject><title>An event-related brain potential (ERP) study on cross-modal action/verb and grammatical number matching in French: Adult control data for a follow-up study on developmental language impairment (DLI)</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/9z903221v.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/k643b339c</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Communication Sciences and Disorders</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:0p096956c</identifier><datestamp>2020-03-21T05:11:58Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Des études antérieures ont révélé que les apprenants en classe de français langue seconde (L2) bénéficiaient d'un enseignement centré sur la forme (ECF) ciblant une conscientisation morphologique de la terminaison des noms, c'est-à-dire les indices sublexicaux, dans l'acquisition des genres grammaticaux en français. Les travaux précédents, cependant, ont fait ressortir que les apprenants en classe de français L2 développaient une stratégie de prononciation ambigüe des articles, utilisant une forme hybride entre 'un' et 'une' et entre 'le' et 'la'. Afin que les apprenants en français L2 démontrent la compétence souhaitée pour le genre grammatical, cette étude formule ainsi l'hypothèse que l'ECF, visant la prononciation spécifique de l'article défini et indéfini de même que les indices sublexicaux, devrait être intégré à l'enseignement en classe. Plus encore, étant donné l'importance des capacités de fonction exécutive chez les apprenants dans l'acquisition de la L2, cette étude prédit également que les gains issus de l'ECF seront déterminés par les capacités de fonction exécutive, opérationnalisées par le contrôle inhibitoire, la mémoire de travail non verbale et visuo-spatiale et la flexibilité cognitive. Dans le but d'examiner ces hypothèses, une étude quasi-expérimentale a été menée auprès de six classes intactes en français L2 pour des apprenants de niveau universitaire (N = 140) comprenant trois conditions (deux classes par condition) : (a) ECF ciblant les indices sublexicaux seulement (n = 41) ; (b) ECF ciblant les indices sublexicaux et la prononciation (n = 49) ; (c) groupe témoin (n = 50). Les étudiants ayant été soumis aux deux conditions de l'ECF ont reçu des séances d'enseignement de 80 minutes ciblant le genre grammatical, tandis que le groupe témoin a suivi le programme régulier de français L2. Pour mesurer les effets des conditions de l'ECF sur l'acquisition du genre grammatical en français, un pré-test, un post-test immédiat et un post-test différé ont été administrés, chacun d'eux incluant des tâches de jugement grammatical, de complétion de texte, de choix binaire, de lecture à voix haute, de description d'illustrations et d'accord ou de désaccord entre article et nom. Dans l'objectif d'évaluer les capacités de fonction exécutive, le test Simon, le test de Corsi et le test de classement de cartes du Wisconsin ont été conduits pour les trois tests. Les résultats montrent que les participants dans les deux groupes ayant reçu l'ECF se sont améliorés à leurs post-tests, notamment pour les tâches de jugement grammatical, de complétion de texte et d'accord ou de désaccord entre article et nom. En ce qui a trait aux tâches de lecture à voix haute et de description d'illustrations, les participants ayant bénéficié de l'ECF ciblant et les indices sublexicaux et la prononciation ont obtenu des résultats significativement plus élevés à leur post-test que le groupe témoin, alors que les participants ayant reçu l'ECF portant uniquement sur les indices sublexicaux n'ont pas démontré de progrès significatif avec le temps dans les tâches de lecture à voix haute et de description d'illustrations. Les analyses de régression multiples confirment que la connaissance phonologique en L2 est un prédicteur important de l'amélioration du participant quant à la précision du genre grammatical en français. Pour les participants soumis aux conditions de l'ECF, la mémoire de travail non verbale et visuo-spatiale s'est avérée un prédicteur important des gains relatifs aux apprentissages dans la tâche de jugement grammatical, tandis que le contrôle inhibitoire a été révélateur des progrès réalisés dans la tâche de lecture à voix haute. L'étude présente met en lumière l'importance de la connaissance phonologique et de l'enseignement de la prononciation de la L2 dans l'acquisition du genre grammatical en français, de même que les rôles exercés par les capacités de fonction exécutive dans l'apprentissage de la L2.</description><description>Previous studies (Harley, 1998; Lyster, 2004; Lyster &amp; Izquierdo, 2009; Warden, 1997) found that learners of French as a second language (L2) benefit from form-focused instruction (FFI) targeting morphological awareness of noun endings (i.e., sublexical cues) in the acquisition of French grammatical gender. A noteworthy finding from previous studies, however, is that L2 learners developed an interlanguage strategy of pronouncing French articles in an ambiguous manner as hybrid forms between 'un' and 'une' and between 'le' and 'la'. Thus, the present study hypothesizes that, in order for L2 learners to demonstrate targetlike performance regarding French grammatical gender, FFI targeting the pronunciation of gender-specific definite and indefinite articles as well as sublexical cues should be implemented in classroom instruction. Moreover, given the importance of L2 learners' executive function (EF) skills in L2 acquisition (Darcy, Mora, &amp; Daidone, 2016; Kapa &amp; Colombo, 2014; Linck, Osthus, Koeth, &amp; Bunting, 2014), the current study also predicts that the extent to which L2 learners benefit from FFI will be mediated by their EF skills operationalized as inhibitory control, nonverbal visuospatial working memory, and cognitive flexibility. To examine the hypotheses, a quasi-experimental study was conducted in six intact French L2 classrooms for university-level learners (N = 140) comprising three instructional conditions (two classrooms per condition): (a) FFI on only sublexical cues (n = 41); (b) FFI on both sublexical cues and pronunciation (n = 49); (c) control (n = 50). Those in the two FFI conditions received six 80-minute instructional sessions targeting grammatical gender and those in the control condition continued with their regular French L2 program. To measure the effects of the instructional treatments on the acquisition of French grammatical gender, a pretest, an immediate posttest, and a delayed posttest were administrated, each of which included grammatical judgment, text-completion, forced-choice identification, read-aloud, picture-description, and article-noun congruent/incongruent tasks. To measure their EF skills, the Simon Test, the Corsi Block-Tapping Test, and the Wisconsin Card Sorting Test were administered at each of the three testing times. Results show that participants in both FFI conditions made significant gains on the posttests in the grammatical judgment, text-completion, and article-noun congruent/incongruent tasks. In the read-aloud and picture-description tasks, participants receiving FFI on both sublexical cues and pronunciation attained significantly higher scores compared to their pretest scores and to those of the control group on the posttests, whereas participants receiving FFI only on sublexical cues did not demonstrate any significant improvement over time on either of these tasks. The multiple regression analyses confirmed that L2 phonological knowledge is a significant predictor of improving participants' accuracy regarding French grammatical gender. In the forced-choice identification task, all participants, regardless of condition, achieved maximum scores at all three testing times, meaning that participants did not have any difficulty perceptually categorizing the sounds of 'un', 'une', 'le', and 'la'. Participants in the control condition made no significant improvement on any measures. For participants in both FFI conditions, nonverbal visuospatial working memory was a significant predictor of the learning gains in the grammatical judgment task, while inhibitory control was a significant predictor of the gains made in the read-aloud task. The current study sheds light on the importance of L2 phonological knowledge and L2 pronunciation instruction in the acquisition of French grammatical gender in addition to the roles of EF skills in L2 acquisition.</description><creator>Lee, Andrew</creator><contributor>Roy Lyster (Supervisor)</contributor><date>2018</date><subject>Integrated Studies in Education</subject><title>The effects of different instructional and cognitive variables on the acquisition of grammatical gender by second language learners of French</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/8g84mp723.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/0p096956c</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Integrated Studies in Education</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:bz60cz929</identifier><datestamp>2020-03-21T05:11:59Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Avoidance of environmental dangers depends on nociceptive topognosis or the ability to localize painful stimuli. In mammals, nociceptive signals originating from one side of the body are relayed to the contralateral brain hemisphere by spinothalamic fibres, resulting in an inverted left-right somatosensory representation of the body. To address how the laterality of spinothalamic fibres affects nociceptive topognosis, the phenotypes of mutations to the netrin1 receptor Dcc/DCC gene, which is necessary for commissural axon guidance, was assessed. To this end, a spinal-specific conditional knockout mouse line for Dcc (DccSpKO) was generated. In parallel, the perception of stimuli was assessed in congenital mirror movement disorder (MM) patients bearing mutations in the DCC gene.DccSpKO mice were viable and had normal sensitivity to mechanical or thermal stimulation. However, adult DccSpKO animals displayed a large increase in the proportion of neurons projecting to the ipsilateral thalamus. As a result, an abnormal simultaneous activation of both cortical hemispheres in DccSpKO mice was observed. When these animals were noxiously stimulated by formalin injection in the hindpaw, they displayed licking behaviour misdirected to non-affected body parts, suggesting a change in the spatial perception of pain. Accordingly, human subjects bearing DCC mutations displayed mirrored sensations, where they had a bilateral perception of stimuli applied to only one side of the body.Altogether, this study describes a role of Dcc/DCC in the organisation of circuits encoding the spatial location of nociceptive stimuli in the brain. This supports the theory that topographic organisation of somatosensory circuits is critical for appropriate behavioural outputs allowing animals to avoid environmental dangers.</description><description>La topognosie nociceptive, ou l'abilité de localiser les stimuli douloureux, est ce qui nous permet d'éviter les sources de danger dans notre environnement. Chez les mammifères, les signaux nociceptifs originaires d'un côté du corps sont relayés à l'hémisphère cérébral controlatéral par les fibres spinothalamiques, résultant en une représentation du corps inversé dans le cerveau. Pour investiguer comment la latéralité des fibres spinothalamiques affecte la topognosie nociceptive, les phénotypes des mutations du gène Dcc/DCC, qui code pour le récepteur de netrin1 et qui est nécessaire au guidage des axones commissuraux de la moëlle épinière, ont été examinés. Ainsi, une lignée de souris dont Dcc a été conditionnellement aboli dans la moëlle épinière (DccSpKO) a été générée. Parallèlement, la capacité de localiser des stimuli a été investiguée chez des humains atteint du syndrome de mouvements miroir causé par des mutations dans le gène DCC.Les souris DccSpKO sont viables et ont une sensitivité normale aux stimuli mécaniques et thermiques. Cependant, on dénombre un plus grand nombre de neurones spinaux qui projettent ipsilatéralement au thalamus chez les souris DccSpKO adultes. Ceci entraîne une activation simultanée anormale des deux hémisphères corticaux. Quand ces animaux reçoivent un stimulus douloureux par injection de formaline à la patte arrière, ces derniers y répondend en léchant plusieurs parties du corps non-affectées par ce stimulus. Ceci indique un changement dans la perception spatiale de la douleur. Conformément, les sujets humains portant des mutations dans DCC ont démontré une perception miroir à des stimuli appliqués unilatéralement sur le corps.En somme, cette étude met en lumière un rôle jusqu'ici inconnu de Dcc/DCC dans l'organisation des circuits qui codent pour la localisation des stimuli nociceptifs dans le cerveau. Ceci supporte la théorie de que l'organisation topographique des circuits somatosensoriels est cruciale dans l'expression des comportements qui permettent les animaux d'éviter les dangers environnementaux.</description><creator>da Silva, Ronan</creator><contributor>Artur Kania (Supervisor)</contributor><date>2018</date><subject>Neuroscience</subject><title>Spinal commissural axon guidance in the development of somatosensory topography and topognosis</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/47429c65z.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/bz60cz929</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Integrated Program in Neuroscience</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:rx913s19p</identifier><datestamp>2020-03-21T05:12:00Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Multiple-input multiple-output (MIMO)-aided wireless relaying can improve the quality of the communication links between the source and destination nodes, hence significantly increasing system throughput, especially in multi-user networks. Relaying strategies can mainly be classified as amplify-and-forward (AF) and decode-and-forward (DF). The AF relaying technique imposes lower signal processing complexity and latency; therefore, it is preferred in many operational applications. In this regard, transceiver design becomes crucial to fully leverage the benefits of multi-user MIMO relay systems. The primary objective of this thesis is to develop new transceiver design approaches for multi-user MIMO relay networks from the perspectives of robustness, energy efficiency and secrecy. First, we propose new transceiver design approaches for a multi-user MIMO AF relay network. It is well known that the performance of wireless relaying is significantly deteriorated under realistic conditions such as imperfect channel state information (CSI) for radio links involved in the transmission. To address this issue, two popular CSI error models, namely, the statistical and norm-bounded models, are considered. Based on these models, a robust joint transceiver design framework relying on modern convex optimization theory is proposed. The resulting design algorithms lead to a relaying performance that is notably less sensitive to different types of CSI errors, as demonstrated by the simulation results. Then, we address the energy efficient design of a multi-user cooperative relay network. Assuming a flexible centralized network structure where relays can be adaptively activated/deactivated, we formulate the problem as a quality-of-service (QoS)-based network energy minimization problem that facilitates joint relay selection and transceiver optimization. An iterative solution based on re-weighted L1-norm minimization along with a block-coordinate descent (BCD)-type algorithm is proposed and its convergence properties investigated. The new algorithm is shown to provide a significantly lower energy consumption of the relay network than that required by a conventional relaying scheme. Finally, we propose a secure transceiver design approach for an MIMO relay network in the presence of multiple eavesdroppers. Under a realistic assumption of imperfect knowledge of the eavesdropper channels, we formulate the relay transceiver design as a signal-to-interference-plus-noise ratio (SINR) maximization subject to robust secrecy constraints. To solve the resulting non-convex problem, a penalized difference-of-convex (DC) algorithm is developed and its properties analyzed. Results show that the proposed algorithm can improve the secrecy of the relay-aided transmission at the physical layer.</description><description>Le relayage sans fil à entrées multiples et sorties multiples (MIMO) peut améliorer la qualité des liaisons de communication entre les nœuds source et destination, augmentant ainsi considérablement le débit detransmission, en particulier dans les réseaux multi-utilisateurs. Les stratégies de relayage peuvent principalement être classifiées comme amplification-et-transfert (AF) et décodage-et-transfert (DF). La technique de relais AF impose une complexité de traitement du signal et une latence plus faibles; par conséquent, elle est préférée dans de nombreuses applications pratiques. À cet égard, la conception de l'émetteur-récepteur devient cruciale pour tirer pleinement parti des avantages des systèmes de relais MIMO multi-utilisateurs. L'objectif principal de cette thèse est de développer de nouvelles approches de conception d'émetteurs-récepteurs pour les réseaux de relais MIMO multi-utilisateurs du point de vue de la robustesse, de l'efficacité énergétique et de la confidentialité. Nous proposons tout d'abord nouvelles approches de conception d'émetteurs-récepteurs pour un réseau de relais MIMO AF multi-utilisateurs. Il est bien connu que les performances des relais sans fil sont considérablement détériorées dans des conditions réalistes d'utilisation, par exemple lorsque les informations d'état de canal(CSI) pour les liaisons radio impliquées dans la transmission sont impreécises. Pour résoudre ce problème, deux modèles d'erreur CSI, sont pris en compte, à savoir les modèles statistique et normés. Sur la base de ces modèles, un cadre de conception d'émetteur-récepteur robuste reposant sur la théorie moderne de l'optimisation convexe est proposé. Les algorithmes de conception qui en résultent conduisent à une performance de relais notablement moins sensible aux différents types d'erreurs CSI, comme le démontrent nos résultats de simulation. Nous abordons ensuite la conception d'un réseau de relais coopératif multi-utilisateurs utilisateurs du point de vue de l'économie de l'énergie. En supposant une structure de réseau centralisée souple où les relais peuvent être activés/désactivés de manière adaptative, nous formulons le problème de conception comme celui de la comme un problème de minimisation d'énergie de réseau avec contrainte sur la qualité de service (QoS) permettant ainsi la sélection conjointe des relais et l'optimisation de l'émetteur-récepteur. Une solution itérative basée sur la minimisation de la norme L1 repondérée et l'algorithme de type descente de coordonnées par blocs (BCD) est proposée et ses propriétés de convergence étudiées. Les résultats de simulations montrent que le nouvel algorithm peut fournir une consommation d'énergie significativement plus faible du réseau de relais que celle requise par un schéma de relayage conventionnel. Enfin, nous proposons une approche de conception d'émetteur-récepteur sécurisé pour un réseau de relais MIMO en présence de multiples écouteurs clandestins. Sous l'hypothèse réaliste d'une connaissance imparfaite des canaux de ces écouteurs, nous formulons la conception de l'émetteur-récepteur relais comme une maximisation du rapport signal-à-interférence-plus-bruit (SINR) soumise à des contraintes de confidentialité. Pour résoudre le problème non convexe qui en résulte, un algorithme de différence de convexité (DC) pénalisé est développé et ses propriétés analysées. Les résultats montrent que l'algorithme proposé peut améliorer la confidentialité de la transmission assistée par relais au niveau de la couche physique.</description><creator>Yang, Jiaxin</creator><contributor>Benoit Champagne (Supervisor)</contributor><date>2018</date><subject>Electrical and Computer Engineering</subject><title>Multi-User MIMO relay transceiver optimization: robust, energy-efficient and secure design approaches</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/pn89d8828.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/rx913s19p</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><resumptionToken completeListSize="47894">oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):4075</resumptionToken></ListRecords></OAI-PMH>