<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/assets/blacklight_oai_provider/oai2-b0e501cadd287c203b27cfd4f4e2d266048ec6ca2151d595f4c1495108e36b88.xsl"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd"><responseDate>2020-07-24T23:09:01Z</responseDate><request resumptionToken="oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):4875" verb="ListRecords">https://escholarship.mcgill.ca/catalog/oai</request><ListRecords><record><header><identifier>oai:escholarship.mcgill.ca:1c18dj05r</identifier><datestamp>2020-03-21T05:26:09Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La réaction alcali-silice (ASR) est l'une des principales causes de maintenance et de réhabilitation des structures en béton. ASR est une réaction entre l'alcali du ciment et la silice réactive des agrégats. Le but principal de cette thèse était d'étudier la possibilité de réduction ou d'élimination de l'ASR dans le béton par un durcissement précoce par carbonatation. L'objectif secondaire était de déterminer le temps d'exposition optimal à la carbonatation précoce qui conduit à la plus forte concentration et à la séquestration de gaz carbonique dans le béton. L'effet de la maturation rapide de la carbonatation sur l'expansion de l'ASR a été évalué au moyen d'essais normalisés d'augmentation de la longueur tels que l'essai accéléré au mortier (AMBT) et l'essai au mortier accéléré modifié (MAMBT). Les agrégats de Spratt ont été utilisés comme agrégats réactifs aux alcalis dans les essais de barres de mortier. Quatre lots ont été testés, y compris la référence d'hydratation humide, la référence d'hydratation sèche à l'air, la carbonatation à 2 heures et la carbonatation à 18 heures. Il a été constaté que la carbonatation de 2 h et de 18 h réduit significativement l'expansion de l'ASR. Après 14 jours, l'expansion dans la barre de mortier carbonatée était de 0,01-0,02%, considérablement inférieure à la valeur seuil de 0,1%, tandis que les deux références d'hydratation présentaient une expansion dans une plage de 0,32-0,35%, confirmant que les agrégats de Spratt étaient réactifs. La réduction de l'ASR par carbonatation précoce est attribuée au fait que la carbonatation précoce convertit l'hydroxyde de calcium, un composé essentiel dans la réaction ASR, en carbonate de calcium et que la densification du mortier diminue le débit d'eau essentiel à la réaction ASR. De plus, la résistance à la compression de 112 jours des cubes de mortier est plus élevée dans les échantillons carbonés (63,3 et 59,3 MPa) que dans les références hydratées (46,3 et 41,9 MPa), ce qui augmente la résistance aux fissures induites par dilatation. L'absorption de dioxyde de carbone par les barres de mortier durcies par carbonatation 2h et 18h était de 15,8 et 22,8%. Il était indicatif que la carbonatation précoce est efficace dans l'utilisation et la séquestration du carbone. La durée de la carbonatation a un effet sur l'absorption du carbone, mais pas sur le gain de force et le degré de réduction de l'ASR.</description><description>Alkali-silica reaction (ASR) is one of the principal causes of maintenance and rehabilitation in concrete structures. ASR is a reaction between alkali from cement and reactive silica from aggregates. The primary aim of this thesis was to investigate the possibility of ASR reduction or elimination in concrete by early carbonation curing. The secondary goal was to determine the optimum early carbonation exposure time that leads the highest strength and carbon dioxide gas sequestration in concrete. The effect of early carbonation curing on ASR expansion was assessed via length increase standard tests such as accelerated mortar bar test (AMBT) and modified accelerated mortar bar test (MAMBT). Spratt aggregates were used as alkali-reactive aggregates in mortar bar tests. Four batches were tested including moist hydration reference, air dry hydration reference, 2-hour carbonation and 18-hour carbonation. It was found that both 2-h and 18-h carbonation reduce significantly the ASR expansion. At 14 days, the expansion in carbonated mortar bar was 0.01-0.02%, considerably lower than the threshold value of 0.1% while the two hydration references experienced an expansion in a range of 0.32-0.35%, confirming that Spratt aggregates were reactive.  ASR reduction by early carbonation is attributed to the facts that early carbonation converts calcium hydroxide, an essential compound in ASR reaction, to calcium carbonate, and the surface densification of mortar decreases water flow which is essential for ASR reaction. Moreover, the 112 days' compressive strength of mortar cubes is higher in carbonated samples (63.3, and 59.3 MPa) than that in hydrated references (46.3 and 41.9MPa), leading to more resistance to expansion induced cracking. The carbon dioxide uptake by 2h and 18h carbonation cured mortar bars were 15.8 and 22.8 %. It was indicative that early carbonation is effective in carbon utilization and sequestration. The carbonation duration has an effect on carbon uptake, but not on strength gain and the degree of ASR reduction. </description><creator>Mohammad, Naweed</creator><contributor>Yixin Shao (Internal/Supervisor)</contributor><date>2018</date><subject>Civil Engineering &amp; Applied Mechanics</subject><title>Effect of early carbonation curing on alkali-silica reaction in concrete</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/t148fk39c.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/1c18dj05r</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Civil Engineering and Applied Mechanics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:st74cs91t</identifier><datestamp>2020-03-21T05:26:10Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Le cancer du sein triple-négatif, caractérisé par l'absence de récepteurs d'œstrogène et de progestérone ainsi que celle des récepteurs Her2/ErbB2 surexprimés, a un pauvre pronostic en partie en raison du manque de cibles thérapeutiques pour ce type de cancer. Dans le cadre de ce projet de thèse, nous procèderons à l'investigation du rôle et des implications précliniques de l'autophagie dans la prolifération et la progression du cancer du sein triple-négatif expérimental. Nous avons pu démontrer que l'autophagie régule la stabilité des Adhésion Focales (FAs), un processus fondamental pour la locomotion et l'invasion des cellules cancéreuses. Une sous-régulation de l'autophagie par l'intermédiaire de molécules et autres approches pharmacologiques bloque le FA 'turnover', la migration des cellules et la progression vers les métastases dans les modèles préclinique. De plus, nous avons découvert un rôle essentiel de la phosphorylation site-spécifique de la tyrosine 118 de paxilline (Y118-p-paxilline) dans le recrutement des autophagosomes qui initie le "turnover" rapide des FAs. Également, nous avons démontré que c-Cbl, une ligase E3 ubiquitine, joue le rôle d'un récepteur cargo qui interagit directement avec Y118-p-paxillin et LC3, indépendamment de son activité ligase ubiquitine E3. Tous ces résultats mettent en lumière l'implication d'un mécanisme régulateur complexe de l'autophagie dans la régulation de l'invasion des cellules du cancer du sein. Dans le but d'étudier en profondeur l'utilité du potentiel thérapeutique ciblant l'autophagie, nous avons identifié une nouvelle classe de molécules, SLLN-15 capable d'induire l'activité antiproliférative dans des modèles cellulaires de cancer du sein triple-négatif à la fois in vitro et in vivo. Nous avons démontré que SLLN-15 cause une sous régulation des kinases Aurora, ce qui a pour conséquence l'arrêt de la phase G2/M du cycle cellulaire. De plus, SLLN-15 induit la mort cellulaire médiée par l'autophagie et associée à l'inhibition de l'activation Akt/mTOR. Ensemble, ces résultats ouvrent de futurs horizons pour découvrir de nouvelles approches thérapeutiques pour les cancers invasives du sein en ciblant l'induction de l'autophagie.</description><description>Triple-negative breast cancer (TNBC), which is characterized by the absence of estrogen and progesterone receptors as well as Her2⁄ErbB2 receptor overexpression, has a poor prognosis in part due the lack of targeted therapeutics for this cancer subtype. In this thesis project, the role and implication of autophagy in TNBC proliferation and progression was investigated. We demonstrated that autophagy regulates focal adhesion (FA) turnover, which is a fundamental turning point for cancer cell locomotion and invasion. Downregulation of autophagy using molecular and pharmacological approaches inhibits FA turnover, cell migration and metastasis formation in TNBC preclinical model. Moreover, we uncovered an essential role of tyrosine 118 site-specific phosphorylation of paxillin for recruitment of autophagosomes to trigger FA turnover in TNBC. We demonstrated that c-Cbl, an E3 ubiquitin ligase, serves as a cargo receptor to bridge Y118Y-p-paxillin and LC3 and this is independent from c-Cbl E3 ubiquitin ligase activity. These results pinpoint a complex regulatory mechanism of autophagy in the regulation of breast cancer cell invasiveness. To investigate the potential therapeutic utility of autophagy targeting, we identified a novel small molecule (SLLN-15) capable of inducing antiproliferative activity using a panel of TNBC cell models in vitro and in vivo. Using alternative biochemical assays, we demonstrated that SLLN-15 downregulates Aurora kinases, resulting in G2/M cell cycle arrest. In addition, SLLN-15 is capable of inducing autophagy-mediated cell death, which was associated with inhibition on Akt/mTOR activation. Together these results open a future direction for discovery of a novel alternative therapeutic approach for TNBC aimed at inducing autophagy.</description><creator>Chang, Chia-Hao</creator><contributor>Moulay A Alaoui-Jamali (Supervisor)</contributor><date>2017</date><subject>Pharmacology &amp; Therapeutics</subject><title>Deciphering the role of autophagy-mediated focal adhesion turnover in cancer cells and therapeutic implications</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/r781wj442.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/st74cs91t</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Pharmacology and Therapeutics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:1r66j3567</identifier><datestamp>2020-03-21T05:26:11Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les verres bioactifs et solubles présentent un grand potentiel dans les applications biomédicales dans l'ingénierie des tissus durs et mous. La vitesse à laquelle ces verres génèrent une réponse, ou leur réactivité, est un paramètre important pour la guérison de l'efficacité. En raison de leur coordination tétraédrique, les verres à base de silicate présentent une solubilité lente et incomplète, ce qui limite leur application dans la réparation des tissus mous. Par conséquent, il y a un grand intérêt dans le développement de formulations de verre bioactif plus solubles et réactives basées sur l'oxyde formant un réseau de borate, qui peut être à la fois coordonné trigonalement et tétraédriquement. Il a été démontré que les verres à base de borate ont une réactivité plus élevée que les verres à base de silicate attribués à la structure de leur réseau de verre.Les limitations des méthodes conventionnelles telles que le manque de précision et la consommation de temps pour examiner la réactivité / bioactivité et les propriétés de surface des verres bioactifs et solubles ont conduit à un intérêt accru pour trouver et étudier de nouvelles techniques telles que la DVS et la chromatographie en phase gazeuse inverse (IGC). Il a été démontré que la DVS était capable de mesurer et de corréler les valeurs isothermes de vapeur de Bioglass® 45S5 dérivé de la fusion-trempe: (46.1) SiO2- (26.9) CaO- (24.4) Na2O- (2.6) P2O5 (mol%) tailles de particules (surfaces) avec la réactivité, la bioactivité et la vitesse de libération des ions des verres. Une surface plus élevée conduit à une sorption de vapeur et une réactivité plus élevées. De plus, la IGC a été utilisée pour examiner les propriétés de surface des verres phosphatés (PG) dérivés de la fusion-fusion dopés à la fois avec SiO2 et TiO2 (50P2O5-40CaO-xSiO2- (10-x) TiO2, où x = 7, 5, 3 et 0% en mole). Il a été montré que la IGC était plus sensible que d'autres techniques conventionnelles telles que la mesure de l'angle de contact l'effet de la teneur en silice. En conclusion, cette dissertation a évalué la complémentarité potentielle de DVS et IGC dans la caractérisation de la réactivité aqueuse et les propriétés de surface des verres bioactifs et solubles.De plus, les complications dans la cicatrisation des plaies chroniques ont conduit à une forte demande pour le développement d'un remplacement de pansement par des biomatériaux. Les verres à base de borate ont récemment été approuvés pour la réparation de plaies qui sont dérivées de la fusion-fusion, mais les verres de borate fabriqués par le procédé sol-gel ont les avantages d'une vitesse de dissolution plus élevée, ce qui pourrait entraîner une réparation plus rapide. Cependant, le potentiel des verres de borate dérivés de sol-gel, en particulier, des verres à base de borate dopés à l'argent (AgBG) pour la réparation des tissus mous n'a pas encore été étudié. Dans cette thèse, des AgBG anti-bactériennes dans le système B2O3Ag2O-CaO-P2O5 ont été fabriquées grâce à l'optimisation du procédé sol-gel et de la composition du verre. La vitesse de libération des ions argent et l'activité antibactérienne étaient corrélées et démontraient une efficacité dépendante de la dose contre les bactéries Escherichia coli ou Staphylococcus aureus et Pseudomonas aeruginosa. En outre, les AgBG ont été systématiquement examinés pour déterminer leurs effets sur les fonctions cellulaires par culture cellulaire in vitro de lignées cellulaires de kératinocytes humains dérivés (HaCat) et de lignées fibroblastiques dérivées de souris (NIH / 3T3). Il a été vérifié que la libération d'argent à partir d'AgBG n'était pas toxique pour les deux cellules à des concentrations plus faibles (&lt;1 ppm) et a la capacité de stimuler la migration des cellules HaCat, in vitro. En conclusion, cette dissertation a introduit une nouvelle classe de verres à base de borate dopés à l'argent dérivés de sol-gel en tant que candidats prometteurs pour des applications de cicatrisation.</description><description>Bioactive and soluble glasses exhibit great potential in biomedical applications in both hard and soft tissue engineering. The rate at which these glasses generate a response, or their reactivity, is an important parameter for healing efficacy. Owing to their tetrahedral coordination, silicate-based glasses exhibit slow and incomplete solubility, which limit their application in soft tissue repair. Therefore, there is great interest in developing more soluble and reactive bioactive glass formulations based on the borate network forming oxide, which can be both trigonally and tetrahedrally coordinated. It has been shown that borate-based glasses have higher reactivity than silicate-based glasses attributed to their glass network structure.  Limitations in conventional methods such as the lack of accuracy and time-consumption to examine reactivity/bioactivity and surface properties of bioactive and soluble glasses have led to an increased interest in finding and investigating new techniques, such as dynamic vapour sorption (DVS) and inverse gas chromatography (IGC). It was demonstrated that DVS has the ability to measure and predict the bioactivity/reactivity of silicate-, phosphate- and borate- based glasses with various specific surface areas/particle sizes or formulations. It was shown that DVS was able to measure and correlate the vapour isotherm values of melt-quench derived Bioglass® 45S5: (46.1)SiO2-(26.9)CaO-(24.4)Na2O-(2.6)P2O5 (mol %) of three different particle sizes (surface areas) with the reactivity, bioactivity and ions release rates of glasses. Higher surface area led to the higher vapour sorption and reactivity. Additionally, IGC was utilized to examine the surface properties of melt-quench derived phosphate glasses (PGs) doped with both SiO2 and TiO2 (50P2O5-40CaO-xSiO2-(10 − x) TiO2, where x = 7, 5, 3, and 0 mol%). It was shown that IGC was more accurate and sensitive than other conventional techniques such as contact angle measurement in determining the effect of silica content on the surface properties of PGs. In conclusion, this dissertation has assessed the potential complementarity of DVS and IGC in the characterization of aqueous reactivity and surface properties of bioactive and soluble glasses.Moreover, complications in the healing of chronic wounds in patients who are at constant risk of infections have led to a great demand for the development of biomaterial based wound dressing replacement. Borate-based glasses have recently been approved for wound repair which are melt-quench derived, yet borate glasses fabricated through the sol-gel process have the benefits of higher dissolution rate, which could potentially lead to the more rapid wound repair. However, the potential of sol-gel derived borate glasses, in particular, silver doped borate-based glasses (AgBGs) for soft tissue repair has so far not been investigated. In this thesis, anti-bacterial AgBGs in the B2O3Ag2O-CaO-P2O5 system were fabricated through optimization of sol-gel process and glass composition. Silver ion release rate and anti-bacterial activity were correlated and demonstrated dose dependent efficacy against Escherichia coli or Staphylococcus aureus  and Pseudomonas aeruginosa bacteria. In addition, AgBGs were systematically examined to determine their effects on cellular functions such as metabolic activity, cell viability and migration through in vitro cell culture of human derived keratinocyte (HaCat) and mouse derived fibroblastic (NIH/3T3) cell lines. It was verified that silver release from AgBGs was not toxic to both cells at lower concentrations (&lt;1 ppm) and has the ability to stimulate the HaCat cell migration, in vitro. In conclusion, this dissertation has introduced a new class of sol-gel derived silver doped borate-based glasses as promising candidates for wound healing applications. </description><creator>Naseri, Shiva</creator><contributor>Showan Nazhat (Supervisor)</contributor><date>2018</date><subject>Mining and Materials</subject><title>Highly reactive silver doped sol-gel-derived borate glasses for wound healing applications</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/bz60cz98z.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/1r66j3567</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Mining and Materials</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:8k71nk59s</identifier><datestamp>2020-03-21T05:26:12Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La production de fruits de mer s'est améliorée au cours des années, et notre consommation est prévue d'augmenter avec l'accroissement de la population et la promotion des bienfaits de la consommation de protéines maigres pour la santé. Lors du traitement des produits de la mer, un gaspillage d'environ 50% de la masse totale de la matière première est encouru. La mauvaise élimination de ces déchets cause des dommages à l'environnement, alors que leur élimination sécuritaire est coûteuse. Les stratégies d'utilisation des déchets de produits de la mer au présent sont la production de farine de poisson, d'ensilage et l'extraction bioactive. Toutes ces fonctions utilisent seulement une partie des déchets. Un inconvénient majeur commun à toutes ces technologies est qu'elles laissent derrière elles ou génèrent de nouveaux déchets, qui nécessitent un traitement supplémentaire. Par conséquent, nous avons besoin d'une technologie additionnelle ou alternative pour permettre l'utilisation complète des déchets de produits de la mer.Un tel processus, la carbonisation hydrothermale (HTC) attire de plus en plus d'attention en tant que technologie efficace de gestion des déchets. Contrairement à la pyrolyse, la HTC peut traiter les déchets riches en humidité. La HTC convertit la biomasse en un matériau semblable au charbon appelé hydrochar et une liqueur aqueuse bio-brute après un traitement à haute température (150-250 °C) pendant quelques heures. Plus récemment, la HTC a été utilisée pour traiter des flux de déchets complexes tels que les boues d'épuration, les déchets biologiques humains et les déchets municipaux qui sont riches en humidité et sont un mélange de biomasse lignocellulosique et non-lignocellulosique. D'autre part, les déchets marins sont principalement constitués de protéines et de graisses non-lignocellulosiques, les glucides ne formant qu'une très petite fraction de la masse totale. Leur compatibilité avec l'HTC était inconnue jusqu'à présent. Tout d'abord, Il a été constaté que de soumettre les déchets de fruits de mer directement à l'HTC avec de l'acide ou avec une hydrolyse alcaline est inefficace. Toutefois, l'utilisation d'un prétraitement enzymatique a été efficace à la production d'hydrochar suggérant qu'il est essentiel d'hydrolyser les déchets de fruits de mer avant le traitement de l'HTC. D'autres études ont été réalisées pour l'optimisation de l'hydrolyse pour des déchets de produits de la mer. Deuxièmement, deux modes de chauffage différents ont été utilisés pour optimiser la production d'hydrochar. L'optimisation des paramètres de la procédure de carbonisation hydrothermale, par hyperfréquence (MHTC) pour maximiser la production d'hydrochar à partir de déchets de produits de la mer, a précédé le processus de carbonisation hydrothermale plus conventionnel et traditionnel (CHTC). Le résultat de MHTC et de CHTC utilisant des déchets de fruits de mer ont produit une hydrochar avec des propriétés élémentaires, proches, énergétiques et de surface qui sont largement comparables à l'hydrochar produit à partir de déchets lignocellulosiques de faible qualité et aux déchets mixtes tels que les eaux usées. Cependant MHTC a permis des temps de remontée plus courts avec de meilleures propriétés de microstructure. De plus, le cas des déchets de crevettes par le MHTC a entraîné un meilleur rendement de l'hydrochar que celui du CHTC. Troisièmement, la liqueur bio-brute laissée après les processus de MHTC et de CHTC est également riche en composés commercialement attractifs. Pris ensemble, cela rend le processus HTC doublement intéressant parce qu'il peut apporter de multiples avantages à l'industrie de la transformation, avec une valeur économique réalisable pour l'hydrochar et la liqueur bio-brute. Notre étude a démontré, pour la première fois au monde, que la HTC peut être appliquée pour utiliser complètement les déchets de fruits de mer et apporte une contribution à la gestion efficace des déchets de produits de la mer.</description><description>Seafood production has improved globally over the years, leading to a predicted rise in consumption with increasing world population and our greater awareness of the health benefits of lean protein consumption. During the processing of seafood, a wastage of around 50% of the total mass of the raw material incurs. Fish and shrimp wastes are generated in large quantities every year in seafaring countries, including Canada. The improper disposal of such wastes is detrimental to the environment, while their safe disposal is expensive. Current strategies of seafood waste utilization primarily involve the production of fish meal, silage, and bioactive extraction all of which utilize only part of the seafood waste. One major disadvantage that is common to all these technologies is that they all leave behind or generate new wastes, which need further processing. Therefore, we need an alternate or supplemental technology to enable complete utilization of seafood waste.   Most of the raw materials used by waste management technologies, including pyrolysis, employ lignocellulosic material that is rich in carbohydrates to achieve better yields. One such process called hydrothermal carbonization (HTC) has been gaining increasing attention as an efficient waste management technology. Unlike, pyrolysis, HTC can handle moisture rich waste. HTC converts biomass into a coal-like material called hydrochar and an aqueous bio-crude liquor upon treatment at high temperatures (150-250° C) for a few hours. More recently, HTC has been used to treat complex waste streams such as sewage sludge, human biowastes and municipal wastes that are moisture rich and are a mixture of lignocellulosic and non-lignocellulosic biomass. Seafood waste, on the other hand is completely non-lignocellulosic, consisting of primarily proteins and fats, where carbohydrates form only a very small fraction. Their suitability to HTC was unknown until now.This thesis aims to fill this gap. First, this thesis evaluated the suitability of seafood waste for processing by HTC. It was found that subjecting seafood waste to HTC directly, with acid, or with alkali hydrolysis proved to be ineffective. However, the use of an enzyme pre-treatment led to the production of hydrochar suggesting that it is critical to hydrolyze the seafood waste prior to HTC. Further optimization studies were performed to maximize the hydrolysis of seafood waste. Second, two different heating modes were employed to optimize the production of hydrochar. The optimization of microwave hydrothermal carbonization (MHTC) process parameters to maximize the production of hydrochar from seafood waste preceded the more traditional conventional hydrothermal carbonization (CHTC) process. MHTC and CHTC of seafood waste yielded hydrochar of elemental, proximate, energy, and surface properties that are largely comparable to hydrochar produced from lignocellulosic wastes such as saw dust, and mixed wastes such as sewage. However, MHTC resulted in shorter come up times and better microstructural properties. Further, MHTC of shrimp waste resulted in a higher hydrochar yield than CHTC. Third, the bio-crude liquor left behind after the MHTC and CHTC was also found to be rich in commercially attractive compounds. Taken together, this makes the HTC process doubly attractive with multifaceted benefits to the processing industry as both the hydrochar and bio-crude liquor could be of economical value. Our study therefore has shown for the first time that HTC can be used to completely utilize seafood waste and thus contributes to efficient seafood waste management. This study paves the way for the utilization of other underused wastes such as meat wastes, and leather industry wastes that are protein rich and low in carbohydrates. Finally, this study has opened the possibility for future research on HTC as a more holistic basis not only for treating complex biowastes but also for the sustainable production of value added products.</description><creator>Kannan, Shrikalaa</creator><contributor>G S Vijaya Raghavan (Supervisor)</contributor><date>2018</date><subject>Bioresource Engineering</subject><title>Microwave and conventional hydrothermal carbonization of seafood waste</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/gx41mm320.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/8k71nk59s</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Bioresource Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:9593tx48w</identifier><datestamp>2020-03-21T05:26:13Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Le but de cette thèse est de présenter une étude détaillée de la mise enoeuvre du filtre IMM et de ses composants, avec comme objectif principal l'évaluation de la performance du filtre, appliqué aux systèmes hybrides. Tous les systèmes de mesure ont des erreurs de lecture provenant du capteur, qui est corrompue par plusieurs bruits. Même si ce bruit est de faiblevariance, il doit toujours être pris en compte pour obtenir des estimations deposition précises. Les techniques de filtrage aident à éliminer le bruit et donc à améliorer le suivi dynamique du système. Il n'est pas possible d'obtenir des résultats précis pour le suivi des cibles en mouvement en utilisant un filtre basé sur l'approche conventionnelle à un seul modèle. La thèse propose et évalue la technique de filtrage multiple, appelée filtrage IMM (Interacting Multiple Model), comme la solution au problème ci-dessus.</description><description>The aim of this thesis is to present a detailed study and implementation of the Interacting Multiple Model (IMM) filter and its components, with the principle objective of doing the performance evaluation of the filter in application to hybrid systems. All measurement systems have errors in the readings coming from the sensor, which are corrupted by several noise models. Even if this noise is of low variance, it still needs to be accounted for to get the accurate position estimates of manoeuvring objects that are being tracked. The filtering techniques help to remove the noise and hence improve the dynamic tracking capability of the system. It not possible to obtain accurate results for tracking of maneuvering targets using a filter based on conventional single model approach. The thesis suggests and evaluates the multi filtering technique, named the Interacting Multiple Models (IMM) filtering, as the solution to the above problem.</description><creator>Iqbal, Ayesha</creator><contributor>Hannah Michalska (Internal/Supervisor)</contributor><date>2018</date><subject>Electrical and Computer Engineering</subject><title>Performance evaluation of an IMM tracker in application to estimation of hybrid systems</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/cc08hh99k.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9593tx48w</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:1j92g9777</identifier><datestamp>2020-03-21T05:26:14Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Obesity and type 2 diabetes mellitus (T2D) are metabolic disorders often accompanied by elevated blood glucose and fatty acid levels. Chronic hyperglycemia and increased free-fatty acid (FFA) concentrations lead to the build-up of reactive oxygen species and toxic metabolites that are harmful to beta-cells and eventually cause their progressive deterioration. Both T2D and obesity are characterized by an excess deposition of triacylglycerol (TAG) and subsequent lipid droplet (LD) accumulation in adipose tissue. Perilipin-2 (PLIN2) is a ubiquitously expressed LD-associated protein that regulates TAG metabolism and LD formation. However, PLIN2 expression in the pancreas and its potential role in the pathogenesis of T2D remain unknown. We hypothesized that PLIN2 is upregulated in the islets of obese (NDO), type-2 diabetic (T2DN), and type-2 diabetic obese (T2DO) patients in response to lipid overload. Our immunolabelling shows increased PLIN2 in islet beta cells stained immunopositive for c-peptide in type-2 diabetic patients. Gene expression analysis (RT-PCR) confirmed an upregulation of PLIN2 expression in the pancreas of T2DN and T2DO, as well as significant changes in lipid metabolism, autophagy, and oxidant defense genes in T2DN and T2DO. A possible explanation for the increased LD buildup in T2DN and T2DO could be due to the suppression of autophagic systems which would decrease the rate of lipophagy. Transcription factor EB (TFEB) is a master regulator of autophagy and lysosome biogenesis. Immunolabeling revealed that TFEB is active in normal islets but is suppressed in islets from T2DN. Similarly, TFEB activation as well as lysosomal associated membrane protein 1 (LAMP1), Sequestosome (SQSTM1/p62), and microtubule-associated protein 1A/1B-light chain 3 (LC3) expression is significantly downregulated by the combination of hyperglycemia and elevated FFA in cultured cells. Taken together, elevated glucose and fatty acids levels may inhibit autophagic processes from efficiently clearing lipids which accumulate and lead to lipotoxicity in type-2 diabetic and obese patients.</description><description>L'obésité et le diabète sucré de type 2 (T2D) sont des troubles métaboliques souvent accompagnés par des niveaux élevés de glucose et d'acides gras dans le sang. L'hyperglycémie chronique et les acides gras libres (FFA) conduisent à une accumulation d'espèces d'oxygène réactives et de métabolites toxiques qui endommagent les cellules bêta et causent leur détérioration progressive. Le T2D et l'obésité sont caractérisés par un dépôt excédentaire de triacylglycérols (TAG) et l'accumulation subséquente de gouttelettes lipidiques (LD) dans les tissus adipeux. La périlipine-2 (PLIN2) est une protéine exprimée de manière ubiquiste en association avec les LD qui régule le métabolisme des TAG et la formation de LD. Cependant, l'expression de PLIN2 dans le pancréas et son rôle potentiel dans la pathogenèse du T2D restent inconnus.Nous avons émis l'hypothèse que PLIN2 est régulée positivement dans les îlots de patients obèses (NDO), diabétiques de type 2 (T2DN) et diabétiques de type 2 obèses (T2DO) en réponse à une surcharge lipidique. Notre immunomarquage montre un niveau accru de PLIN2 dans les îlots de cellules bêta immunopositives pour le peptide c chez les patients de T2D. L'analyse d'expression génique (RT-PCR) confirme la régulation positive de PLIN2 dans le pancréas de patients T2DN et T2DO, en plus de changements significatifs dans le métabolisme lipidique, l'autophagie et les gènes de défense anti-oxydative. Une possible explication pour l'accumulation accrue de LD chez les patients T2DN et T2DO pourrait être la suppression des systèmes autophagiques, ce qui diminuerait le niveau de lipophagie. Le facteur de transcription EB (TFEB) est un régulateur maître de l'autophagie et de la biogenèse des lysosomes. L'immunomarquage révèle que TFEB est active dans les îlots normaux en réponse à une surcharge lipidique, mais est inhibé dans les îlots de patients T2DN. De plus, l'activation de TFEB et l'expression de la protéine membranaire lysosomale 1 (LAMP1), du Sequestosome (SQSTM1/p62) et de la protéine associée aux microtubules 1A/1B chaîne légère 3 (LC3) sont inhibées de façon significative par la combinaison de l'hyperglycémie et un niveau élevé de FFA chez les cellules en culture.Globalement, l'hyperglycémie et l'hyperlipidémie pourraient empêcher les processus d'autophagie d'éliminer les lipides efficacement, entraînant la lipotoxicité chez les patients obèses et diabétiques de type 2.</description><creator>Ji, Jeff</creator><contributor>Dusica Maysinger (Internal/Supervisor)</contributor><date>2018</date><subject>Pharmacology &amp; Therapeutics</subject><title>Autophagy dysregulation and lipid droplet accumulation in pancreatic beta-cells under metabolic stress</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/gm80hx90w.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/1j92g9777</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Pharmacology and Therapeutics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:2f75rb19z</identifier><datestamp>2020-03-21T05:26:15Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Formal deductive systems are very common in computer science. They are used to represent logics, programming languages, and security systems. Moreover, writing programs that manipulate them and that reason about them is important and common. Consider proof assistants, language interpreters, compilers and other software that process input described by formal systems. This thesis shows that contextual types can be used to build tools for convenient implementation and reasoning about deductive systems with binders. We discuss three aspects of this: the reconstruction of implicit parameters that makes writing proofs and programs with dependent types easier, the addition of contextual objects to an existing programming language that make implementing formal systems with binders easier, and finally, we explore the idea of embedding the logical framework LF using contextual types in fully dependently typed theory. These are three aspects of the same message: programming using the right abstraction allows us to solve deeper problems with less effort. In this sense we want: easier to write programs and proofs (with implicit parameters), languages that support binders (by embedding a syntactic framework using contextual types), and the power of the logical framework LF with the expressivity of dependent types.</description><description>Les systèmes critiques comme les systèmes embarqués dans les avions requièrent un niveau de sécurité élevé qui peut seulement être obtenu par des systèmes formels. Les compilateurs certifiés ainsi que les assistants de preuve sont des programmes qui manipulent et qui raisonnent sur ces systèmes. Dans cette thèse, nous utilisons les types contextuels afin de construire de tels outils permettant notamment de raisonner sur des systèmes formels avec lieurs (binders). En particulier, nous abordons les trois points suivants : la reconstruction des paramètres implicites, ce qui simplifie l'écriture des preuves et programmes avec types dépendants ; l'ajout d'objets contextuels à un langage de programmation existant qui facilitent la mise en œuvre des systèmes formels avec des lieurs ; et l'intégration des types contextuels avec des types dépendants au-dessus du cadre logique (logical frameworks) LF. Ces trois facettes reflètent le message suivant : le choix d'une abstraction adéquate nous permet de construire des outils capables de résoudre des problèmes plus complexes plus facilement. Ceci se traduit par la construction de langages de programmation utilisant des paramètres implicites, supportant des lieurs (en intégrant un cadre syntaxique utilisant des types contextuels), et qui utilisent la puissance du cadre logique LF jointe à une théorie des types a la Martin-Löf.</description><creator>Ferreira Ruiz, Francisco</creator><contributor>Brigitte Pientka (Supervisor)</contributor><date>2018</date><subject>Computer Science</subject><title>Proofs and programs about open terms</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/t435gg35h.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/2f75rb19z</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:rb68xf129</identifier><datestamp>2020-03-21T05:26:16Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Focal segmental glomerulosclerosis (FSGS) is a histopathological lesion characterized by podocyte injury, during which the podocyte's actin-rich projections, called foot processes, retract (i.e. efface) back into the cell body. RhoGTPases, such as Rac1, contribute to the organization of the actin cytoskeleton and both in vivo animal studies and human genetics studies suggest that Rac1 hyperactivity leads to foot process effacement, proteinuria (the leakage of protein from blood into the urine), and FSGS. While Rho guanine nucleotide exchange factors (GEFs) are typically known for activating RhoGPTases, it remains unclear if any GEFs are responsible for Rac1 activity in FSGS. This study investigates this by using two methods: a candidate and an unbiased approach. Candidate GEFs were discovered using RNA-sequencing on two lines of cultured human podocytes, followed by analysis of which GEFs have upregulated mRNA in humans with FSGS compared to healthy control; this led us to investigate Trio. Trio knockout (KO) in cultured human podocytes decreased Rac1 activity, cell size, attachment, and motility. Furthermore, while the profibrotic cytokine that contributes to glomerulosclerosis progression, transforming growth factor 1 (TGFB1), increases Rac1 activity in control cells, it decreases Rac1 activity in Trio KOs. This may due to simultaneous activation of a Rac1-GTPase activation protein (GAP) called Arhgap31. Additionally, the unbiased approach, which consisted of the proximity-based BioID assay, led us to study B-PIX. TGFB1 increases the amount of -PIX isolated by BioID and by pulldown with Rac1. Thus, in conclusion, we have found that two GEFs, Trio and B-PIX, contribute to the Rac1 activation in podocytes. </description><description>La glomérulosclérose segmentaire focale (FSGS) est une maladie rénale caractérisée par une lésion des podocytes, au cours de laquelle les projections riches en actine du podocyte, appelées processus du pied, se rétractent (c'est-à-dire s'effacent) dans le corps cellulaire. La famille des petites protéines Rho-GTPases, comme Rac1, joue un rôle déterminant dans l'organisation du cytosquelette d'actine et des études animales in vivo et des études sur la génétique humaine suggèrent que l'hyperactivité Rac1 entraîne un effacement du pied, une protéinurie (fuite du sang dans l'urine) et une FSGS. Alors que les protéines guanine facteurs d'échange nucléotidique (GEFs) sont connues pour activer les protéines Rho-GTPases, il n'est pas clair si des GEFs sont responsables de l'activité Rac1 dans FSGS. Cette présente examine cela en utilisant deux méthodes: un candidat et une approche impartiale. Les GEF candidats ont été découverts en utilisant le séquençage de l'ARN sur deux lignées de podocytes humains cultivés, suivi par l'analyse des ARNm de GEFs qui sont régulés à la hausse chez les humains avec la FSGS; cela nous a conduit à enquêter sur Trio. Le knockout du trio (KO) dans les podocytes humains cultivés a diminué l'activité de Rac1, la taille des cellules, l'attachement et la motilité. En outre, alors que la cytokine profibrotique qui contribue à la progression de la glomérulosclérose, facteur de croissance transformant 1 (TGF1), augmente l'activité Rac1 dans les cellules témoins, elle diminue l'activité Rac1 chez les Trio KO. Ceci est dû à l'activation simultanée d'une protéine d'activation Rac1-GTPase (GAP) appelée Arhgap31. De plus, l'approche non biaisée, qui consistait en un dosage BioID basé sur la proximité, nous a conduit à étudier B-PIX. TGFB1 augmente la quantité de B-PIX isolé par BioID et par pulldown avec Rac1. Ainsi, en conclusion, nous avons trouvé que deux GEF, Trio et B-PIX, contribuent à l'activation de Rac1 dans les podocytes.</description><creator>Maier, Mirela</creator><contributor>Tomoko Takano (Internal/Supervisor)</contributor><date>2018</date><subject>Medicine</subject><title>Guanine nucleotide exchange factors activate Rac1 in podocytes</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/wh246v33f.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/rb68xf129</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Medicine</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:g732dc28k</identifier><datestamp>2020-03-21T05:26:17Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Introduction: L'hôpital Bernard Mevs Hospital Project Medishare est le seul hôpital de soins critiques et de traumatologie de toute la nation, limitant ainsi considérablement l'accès aux soins critiques pour les blessés. On en sait peu sur l'épidémiologie et le fardeau croissant des maladies liées aux traumatismes en Haïti. Les objectifs de cette thèse sont de quatre ordres: décrire l'épidémiologie des traumatismes; déterminer le fardeau économique et social des maladies; effectuer une évaluation médico-économique de la mise en œuvre d'une meilleure surveillance routière; et effectuer une évaluation médico-économique des soins de traumatologie.Méthodes: Cette étude rétrospective, transversale, en milieu hospitalier, a été réalisée du 1er décembre 2015 au 31 janvier 2016, à la HBMPM, située dans la capitale, Port-au-Prince, en Haïti. Tous les patients se présentant pour l'évaluation des blessures traumatiques étaient admissibles à l'inclusion. Les données ont été obtenues grâce à l'examen du principal registre des patients de l'hôpital, des dossiers médicaux des patients et des formulaires de registre des traumatismes. Les coûts ont été calculés en utilisant la méthode du capital humain. Les coûts ont été répartis en trois sections: les coûts médicaux directs, les coûts indirects et les coûts intangibles. Afin de modéliser le rapport coût-efficacité de l'amélioration de la surveillance routière, le modèle de Bishai et Hyder a été utilisé. Afin de modéliser le rapport coût-efficacité d'un centre de traumatologie, la méthode McCord et Chowdhury a été utilisée.Résultats: Un total de 410 patients ont été évalués pour le traitement des blessures traumatiques. L'âge moyen était de 30 ans; la majorité des patients identifiés étaient mâle (66,3%) et moins de 41 ans (78.4%). Cet étude a identifié 6,6 blessures par jour. Les accidents de la route représentaient 43,0% des traumatismes. La durée moyenne d'hospitalisation était de 6,6 jours. 9,0% des patients ont subi un traumatisme grave et 21,0% ont subi une lésion cérébrale traumatique sévère. Les coûts totaux pour tous les patients étaient de 501 706 $ avec un coût moyen par patient de 1 224 $. Les coûts chirurgicaux représentaient la majorité des coûts médicaux directs (29%). Les patients avec des blessures par balle ont eu les coûts moyens les plus élevés (1 556 $). Les coûts moyens selon la gravité des blessures variaient de 62 $ pour les blessures mineures de 13 675 $ pour les blessures critiques. En supposant que l'augmentation de la surveillance routière réduira la mortalité et l'incapacité permanente de 25%, on estime que 3 313 disability-adjusted life years (DALY) sont épargnées par million de personnes par année. Compte tenu du coût total associé au renforcement de cette augmentation de surveillance routière, estimé à 32 316 $, le coût par DALY épargné variera de 10 $ à 39 $ par DALY épargné. En ce qui concerne la rentabilité d'un centre de traumatologie, environ 1 605 DALY ont été encourues par des patients admis. On estime que 565 DALYs ont été évitées. Les coûts variables et fixes ont totalisé 135 897 $ au cours de la période. Le coût par DALY évité calculs indique que 241 $ sont dépensés par DALY évitée. Conclusion: Les blessures entraînent un fardeau économique important pour les personnes traitées à la HBMPM. La qualité de l'information au dossier médical était variable et les formulaires du registre des traumatismes étaient rarement utilisés. Des interventions visant à améliorer la documentation et la surveillance des traumatismes afin de mieux définir le fardeau des traumatismes sont nécessaires. Les programmes visant à réduire les blessures, réduiraient probablement le fardeau économique de la nation. Les interventions visant à fournir des soins critiques et de traumatologie sont très rentables.</description><description>Introduction: Haiti is currently facing a public health crisis, exacerbated by the lack of pre- and in-hospital care. The Bernard Mevs Hospital Project Medishare is the only critical and trauma care hospital in the entire nation; thus significantly limiting access to critical care for the injured. Little is known about the epidemiology and growing burden of trauma-related disease in Haiti, as there is no formal injury surveillance system or trauma registry. The objectives of this thesis are four-fold: To describe the epidemiology of traumatic injuries; to determine the economic and social burden of disease; to conduct a cost-effective analysis of implementing better traffic enforcement; and to conduct a cost-effective analysis of trauma care.Methods: This retrospective, hospital-based, cross sectional chart review study was conducted for the period December 1, 2015 to January 31, 2016, at HBMPM, located in the capital city of Port-au-Prince, Haiti. All patients presenting for evaluation and treatment of traumatic injuries during the study period were eligible for inclusion. Data were obtained through review of the hospital's main patient logbook, patient medical charts, and trauma registry forms. Costs were calculated using the human capital approach, measured from the patient's perspective. Costs were divided into three sections: direct medical costs, indirect costs, and intangible costs. In order to model the cost-effectiveness of improved traffic enforcement, the Bishai and Hyder model was used, adapted to the Haitian setting with a government perspective. In order to model the cost-effectiveness of a trauma center in Port-au-Prince, Haiti, the McCord and Chowdhury method was used, with simplified estimates of risk of death or permanent disability, and effectiveness of treatment.Results: A total of 410 patients were evaluated for treatment of traumatic injuries during the 2-month study. The mean age in years was 30, with 66.3% male and 78.4% less than 41 years of age. There were 6.6 injuries per day and no correlation between frequency of injury and day of the week. Road traffic accidents accounted for 43.0% of trauma modes. The mean (median) length of stay 6.6 (3.0) days. 9.0% of patients suffered severe trauma and 21.0% suffered severe traumatic brain injury. 22.7% of patients were admitted, and 15.1% patients underwent at least one surgical procedure. Total costs for all patients were $501,706 with a mean cost of $1,224. Direct medical costs represented 19% of all costs, indirect costs 63%, and intangible costs 18%. Surgical costs accounted for the majority of direct medical costs (29%). Patients with gunshot wounds had the highest mean costs ($1,556). Mean costs by injury severity ranged from $62 for minor injuries to $13,675 for critical injuries. Assuming an intervention of increased traffic enforcement reduces mortality and permanent disability by 25% at a 1:1 ratio, an estimated 3,313 DALY's are saved per million persons per year. Given an estimated total cost of $32,316 for traffic enforcement for this intervention, the cost per DALY saved ranges from $10 to $39 per DALY saved. With regards to the cost-effectiveness of a trauma center, an estimated 1,605 DALYs were incurred by trauma patients with an estimated 565 DALYs were averted. Variable and fixed cost totaled $135,897 during the 2-month period. Cost per DALY averted calculations indicate that $241 are spent per DALY averted. Conclusion: Injuries lead to a significant economic burden to individuals in Haiti. Medical record documentation was variable, and trauma registry forms were seldom used. Interventions aimed at improving documentation and trauma surveillance to better define the burden of trauma are needed. Programs aimed at reducing injuries, particularly road traffic accidents, would likely reduce the economic burden to the nation. Interventions aimed at providing critical and trauma care are highly cost-effective.</description><creator>Zuraik, Christopher</creator><contributor>John Sotirios Sampalis (Supervisor)</contributor><date>2018</date><subject>Surgery</subject><title>The burden of traumatic injury: evidence from a trauma hospital in Port-au-Prince, Haiti</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/0c483m56c.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/g732dc28k</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Surgery</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:c247dv63d</identifier><datestamp>2020-03-21T05:26:18Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Channel coding enables reliable communication over unreliable, noisy channels: by encoding messages with redundancy, it is possible to decode the messages in such a way that errors introduced by the channel are corrected. Modern channel codes achieve very low error rates at long block lengths, but long blocks are often not acceptable for low-latency applications.While there exist short block codes with excellent error-correction performance when decoded optimally, designing practical, low-complexity decoding algorithms that can achieve close-to-optimal results for short codes is still an open problem. In this thesis, we explore an approach to decoding short block codes in which the decoder is recast as a machine learning algorithm.After providing the background concepts on error-correcting codes and machine learning, we review the literature on learning algorithms for error correction, with a special emphasis on the recently introduced ``neural belief propagation'' algorithm. We then describe a set of modifications to neural belief propagation which improve its performance and reduce its implementation complexity. We also propose a new syndrome-based output layer for neural error-correcting decoders which takes the code structure into account during training to yield decoders with lower frame error rate.Finally, we suggest some future work.</description><description>Le codage de canal permet une communication fiable sur des canaux non fiables et bruyants. En ajoutant de la redondance aux messages, il est possible de décoder les messages de telle sorte que les erreurs introduites par le canal soient corrigées. Les codes de canal modernes atteignent des taux d'erreur très faibles à des longueurs de blocs longues, mais les blocs longs ne sont souvent pas acceptables pour les applications à faible latence. Bien qu'il existe des codes en blocs courts avec d'excellentes performances de correction d'erreur lorsqu'ils sont décodés de manière optimale, la conception d'algorithmes de décodage pratiques et peu complexes qui peuvent obtenir des résultats proches de l'optimum pour les codes courts reste un problème ouvert. Dans cette thèse, nous explorons une approche de décodage de codes en blocs courts dans laquelle le décodeur est appréhendé comme un algorithme d'apprentissage automatique. Après avoir fourni les concepts de base sur les codes correcteurs d'erreurs et l'apprentissage automatique, nous passons en revue la littérature sur les algorithmes d'apprentissage pour la correction d'erreurs, en mettant l'accent sur l'algorithme "neural belief propagation" récemment introduit. Nous décrivons ensuite un ensemble de modifications à cet algorithme qui améliorent ses performances et réduisent sa complexité de mise en œuvre. Nous proposons également une nouvelle couche de sortie à base de syndrome pour les décodeurs de correction d'erreur neuronaux qui prend en compte la structure du code pendant l'apprentissage, ce qui permet de réduire le taux d'erreur de trame. Enfin, nous suggérons de pistes de recherche future.</description><creator>Lugosch, Loren</creator><contributor>Warren Gross (Internal/Supervisor)</contributor><date>2018</date><subject>Electrical and Computer Engineering</subject><title>Learning algorithms for error correction</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/6d56zz930.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/c247dv63d</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:s1784p111</identifier><datestamp>2020-03-21T05:26:19Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les invasions biologiques sont l'une des principales menaces pour les systèmes d'eau douce, contribuant à la perte croissante de biodiversité dans ces habitats. Certains des impacts écologiques les plus dramatiques et les mieux étudiés dans les communautés aquatiques ont été liés à l'introduction de prédateurs et à leurs effets sur les communautés de proies indigènes. Cependant, les prédateurs invasifs peuvent avoir de forts effets sur les prédateurs indigènes, par la compétition avec et / ou la prédation sur les juvéniles, entraînant des changements écologiques tels que des changements alimentaires et trophiques chez les indigènes. Dans cette étude, je me suis concentrée sur le poisson prédateur (Cichla monoculus), qui a été introduit dans le lac Gatun au Panama à la fin des années 1960, et j'ai étudié ses potentiels effets sur l'alimentation et l'écologie trophique d'un poisson prédateur indigène: Hoplias microlepis. J'ai testé l'hypothèse selon laquelle H. microlepis diversifiait son alimentation et élargissait sa niche en présence du prédateur invasive dans le lac Gatun. Pour ce faire, j'ai d'abord quantifié la niche alimentaire des prédateurs introduits et indigènes en sympatrie. Et en second lieu, j'ai comparé la niche alimentaire du prédateur indigène en présence ou en absence du prédateur introduite. J'ai utilisé une combinaison d'analyse du contenu stomacal et d'analyse de isotopes stables pour estimer les niches alimentaires. En présence du prédateur introduit, H. microlepis a diversifié son alimentation et a étendu sa niche isotopique. Les niches isotopiques de H. microlepis et de C. monoculus étaient généralement de taille similaire et se chevauchaient significativement entre les sites du lac Gatun, à l'exception du site de Chagres où le chevauchement était modéré. Un chevauchement de niches isotopiques entre les espèces suggère qu'elles peuvent se nourrir de ressources similaires, mais H. microlepis incluait plus de proies invertébrées dans son alimentation que C. monoculus. De plus, des morceaux de poisson récupérés par H. microlepis représentaient 26% de son alimentation dans le lac Gatun, mais H. microlepis ne se nourrissait pas des restes de poisson en absence de C. monoculus, et ces restes ne faisaient pas parti de l'alimentation de C. monoculus non plus. Ces morceaux de poisson récupérés se composaient de C. monoculus et d'Oreochromis niloticus (Tilapia du Nil), deux espèces introduits très récoltées dans le lac Gatun. Les pêcheurs retournent au lac des morceaux de poisson attrapés en filets sur les quais, ce qui donne probablement l'occasion à H. microlepis de se nourrir d'eux. Je propose que le prédateur invasive facilite indirectement le prédateur indigène en fournissant une subvention trophique et que ceci est médié par l'homme par la pêche. Cette étude met en évidence la complexité des interactions qui se produisent dans les systèmes envahis, ainsi que l'importance d'utiliser des approches complémentaires et d'intégrer la dimension humaine dans leur étude.</description><description>Human-mediated biological invasions are one of the main threats to freshwater systems, contributing to the escalating biodiversity loss in these habitats. Some of the most dramatic and well-studied ecological impacts in aquatic communities have been linked to the introduction of predators and their effects on native prey communities. However, invasive predators are also likely to have strong effects on native predators, through competition and/or intraguild predation, resulting in ecological changes such as dietary and trophic shifts in the native species. In this study, I focused on the predatory peacock bass (Cichla monoculus, Family Cichlidae) that was introduced into Lake Gatun, Panama in the late 1960's, and explored its potential effects on the diet and trophic ecology of a native predatory fish, Hoplias microlepis (Family Erythrinidae). Specifically, I tested the hypothesis that H. microlepis diversified its diet and broadened its niche in the presence of the peacock bass in Lake Gatun. To do so, I first quantified the dietary niche of both the introduced and native predators in sympatry. Second, I compared the dietary niche of the native predator in the presence vs. absence of the introduced peacock bass. I used a combination of stomach content analysis and stable isotope analysis to estimate the dietary niches. I found evidence to suggest that in the presence of the peacock bass, H. microlepis diversified its diet and expanded its isotopic niche. The isotopic niches of H. microlepis and C. monoculus were generally similar in size and overlapped significantly across sites in Lake Gatun, except for one site (Chagres) where overlap was moderate. An isotopic niche overlap between species suggests that they may be feeding on similar resources, however H. microlepis included more invertebrate prey in its diet than C. monoculus. In addition, scavenged fish chunks comprised 26% of the diet of H. microlepis in Lake Gatun, but scavenging was not recorded in H. microlepis in the absence of C. monoculus nor in C. monoculus. Scavenged fish chunks consisted of peacock bass and Oreochromis niloticus (Nile tilapia) remains, both heavily harvested, non-native species in Lake Gatun. In the three main sites that we sampled in Lake Gatun, it is common for fishers to return scraps of fish filleted at the docks into the lake where H. microlepis presumably scavenges on them. Although the extent of this pattern across Lake Gatun as a whole is currently unknown, I propose that at given locations the invasive peacock bass indirectly facilitates the native predator by providing a trophic subsidy and that this is human-mediated through fishing. This study highlights the complexity of interactions occurring in invaded systems, as well as the importance of using complementary approaches and incorporating the human dimension in their study.</description><creator>Valverde, Marisol</creator><contributor>Lauren Chapman (Internal/Supervisor)</contributor><contributor>Mark Torchin (Internal/Cosupervisor2)</contributor><date>2018</date><subject>Biology</subject><title>Potential impacts of the introduced peacock bass, «Cichla monoculus», on the diet and trophic ecology of a native predator in Lake Gatun, Panama</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/g445cg78j.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/s1784p111</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Biology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:zw12z764z</identifier><datestamp>2020-03-21T05:26:20Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Over their lifetime, people make education and occupational decisions that affect their income and wellbeing for the rest of their lives. Understanding how individuals make these human capital investments helps economists evaluate the efficiency of individual sorting into schools and occupations and predict the pace of market adjustment following changes in labor market conditions. This dissertation analyzes various factors that impact an individual's educational and occupational choices in different contexts. The second chapter studies how native skilled workers' occupational choices are affected by inflows of skilled immigrants. Many of the immigrants to the US in the last decades were highly skilled.The unbalanced inflows of skilled immigrants affect market prices for native labor differently across different occupations. Native skilled workers reoptimize their occupational choices in response to foreign labor competition. In this chapter, the occupational sorting of native skilled workers according to their comparative advantages serves as a pressure valve mitigating and diffusing consequences of the inflow of skilled migration. Specifically, I explicitly model native workers' occupational decisions with ability heterogeneity and occupational specific human capital accumulation. I also estimate the demand for skilled labor across different occupations. My estimates indicate that skilled immigrants and natives are imperfect substitutes in some occupations and complements in others. With the structural estimates, I quantify the impact of increasing recruitment of foreign workers in science and engineering related occupations over the past 20 years. Even large inflows of foreign skilled workers have a limited impact on domestic workers. I find that a selective immigration policy based on occupations could achieve higher welfare gains for native compared to an overall cap on total skilled immigrants. My counterfactual exercises also indicate that had native workers been temporarily deprived of the option to reoptimize occupations when market conditions change, their life-time utility would be adversely affected. The third chapter of this dissertation studies what determines the schooling of a worker relative to her peers in the same occupation. The observed within occupation schooling dispersion raises potential concerns about over-education, skill mismatch and inefficient allocation of workers to jobs. To address this concern, the third chapter introduces a vertical schooling and occupational sorting framework based on a single dimensional human capital index in a competitive equilibrium setting. In this setup, workers are heterogeneous in terms of their cognitive ability but do not perfectly observe the ability. The cost of obtaining education is lower for more competent workers. Schooling augments individual's productivity and can substitute for the cognitive ability in the human capital function. When employed, worker's productivity performance is revealed, and based on this performance both the market and workers make inference s about the unobserved aptitudes through Bayesian learning. This model derives novel testable implications. It predicts a negative correlation between cognitive ability and educational attainment conditional on occupational sorting. It also predicts that the low cognitive ability workers tend to stay longer in occupations where they have more schooling than their peers. These model implications are consistent with patterns found in the National Longitudinal Survey of Youth (NLSY79). My empirical findings test against the pure signalling hypothesis of Spence(1979). Moreover, the current empirical patterns are more consistent with a human capital model with information friction. Since schooling compensates individual's ability in the human capital function, this rationalizes the observed within occupation schooling dispersion without the implication of suboptimal educational choices. </description><description>Au cours de leur vie, les individus prennent des décisions éducatives et professionnelles qui affectent leur revenu et leur bien-être pour le reste de leur vie. Comprendre comment les individus réalisent ces investissements en capital humain va aider les économistes à évaluer l'efficacité du triage individuel dans les écoles et les professions et à prédire le rythme de l'ajustement du marché à la suite des changements dans les conditions du marché du travail. La thèse analyse différents facteurs, qui influencent les choix éducatifs et professionnels d'un individu, dans différents contextes. Le deuxième chapitre de cette thèse examine comment les choix professionnels des travailleurs qualifiés domestiques sont affectés par les arrivés d'immigrants qualifiés. Aux États-Unis, au cours des dernières décennies, beaucoup d'immigrants étaient qualifiés. L'afflux déséquilibré d'immigrants qualifiés influe différemment sur les prix du marché du travail domestique dans différentes professions.Les travailleurs domestiques réoptimisent leurs choix de carrière en réaction à la concurrence étrangère. Dans ce chapitre, selon leurs avantages comparatifs, le triage des travailleurs qualifiés sert de soupape de pression qui atténue et diffuse les conséquences de l'afflux de travailleurs qualifiés. Concrètement, je modélise explicitement les décisions de travail des travailleurs domestiques en fonction de l'hétérogénéité des compétences et de l'accumulation de capital humain propre à la profession.Par la suite, j'estime également la demande de main-d'œuvre qualifiée dans différentes professions. Mes estimations indiquent que les immigrants qualifiés et les travailleurs domestiques sont des substituts imparfaits dans certaines professions et des compléments dans d'autres. Avec les estimations structurelles, je aussi quantifie l'impact de l'augmentation du recrutement de travailleurs étrangers dans les professions liées aux sciences et à l'ingénierie au cours des 20 dernières années. Les flux importants de travailleurs qualifiés étrangers ont un impact limité sur les travailleurs domestiques. Je trouve que, par rapport à un plafond global pour l'ensemble des immigrants qualifiés, une politique sélective d'immigration basée sur les professions pourrait améliorer les bien-êtres des travailleurs domestiques. Le troisième chapitre de cette dissertation s'intéresse à ce qui détermine la scolarité d'un travailleur par rapport à ses pairs dans la même profession. La dispersion de la scolarité observée au sein de l'emploi soulève des préoccupations potentielles au sujet de suréducation, décalage des compétences et allocation inefficace des travailleurs aux emplois. Pour répondre à cette préoccupation, le troisième chapitre introduit un cadre de scolarisation verticale et de triage des professions fondé sur un indice de capital humain unidimensionnel dans un contexte d'équilibre concurrentiel. Dans cette configuration, les travailleurs sont hétérogènes en termes de capacité cognitive et n'observent pas parfaitement la capacité. Le coût de l'éducation est plus bas pour les travailleurs qui sont plus compétents. La scolarité augmente la productivité individuelle et peut remplacer la capacité cognitive dans la fonction du capital humain. Lorsqu'il est employé, le rendement de la productivité du travailleur est révélé et, sur la base de cette performance, le marché et les travailleurs font des inférences sur les aptitudes non observées à l'aide de l'apprentissage bayésien. Ce modèle propose de nouvelles implications testables. Il prédit une corrélation négative entre la capacité cognitive et le niveau d'éducation conditionnel au triage professionnel. Il prédit également que les travailleurs à faible capacité cognitive ont tendance à rester plus longtemps dans les professions où ils ont plus de scolarité que leurs pairs. Les implications du modèle sont cohérentes avec les modèles de l'Enquête longitudinale nationale sur la jeunesse (NLSY79). </description><creator>Ma, Jie</creator><contributor>Fabian Lange (Supervisor1)</contributor><contributor>Theodore Papageorgiou (Supervisor2)</contributor><date>2018</date><subject>Economics</subject><title>Two essays on educational and occupational choices</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/t722hc22p.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/zw12z764z</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Economics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:zc77ss23f</identifier><datestamp>2020-03-21T05:26:21Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>On considère un type jeu joué sur un arbre binaire, dit un jeu de parité. Cette thèse est motivée par le travail de Michalewski et Mio, qui ont donné une procédure pour calculer la mesure d'un "class regular tree languages", et ont utilisé cette procédure pour démontrer l'existence d'une stratégie gagnante pour un jeu de parité généré au hasard. Notre oeuvre consiste de montrer utilisant des méthodes élémentaires, que pour un jeu d'arbre généré au hazard, une stratégie générée au hazard peut être modifée à une stratégie gagnante de manière délimitée, ce qui fortifie leur résultat.</description><description>We consider a particular type of two player game played on a binary tree, known as a parity game. This work was motivated by the work of Michalewski and Mio, who gave a procedure for calculating the measure of a class regular tree languages, and were able to use this procedure to show the existence of a winning strategy for a randomly generated tree game. Our work is to show using elementary methods that for a randomly generated tree game, a randomly generated strategy for player one can be modi ed to a winning strategy in a bounded way, thus strengthening their result.</description><creator>Kones, Ira</creator><contributor>Prakash Panangaden (Internal/Supervisor)</contributor><contributor>Marcin Sabok (Internal/Cosupervisor2)</contributor><date>2018</date><subject>Computer Science</subject><title>Almost-random winning strategies for two player binary tree games</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/fn1071407.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/zc77ss23f</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:fj2364575</identifier><datestamp>2020-03-21T05:26:22Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>APIs (Application Programming Interfaces) offer interfaces to reusable software components. With the advent and proliferation of online developer forums as informal documentation, developers often share their opinions about the APIs they use. Thus, opinions of others can shape developer perception and decisions related to software development. To understand how and why developers share opinions about APIs, we conducted two surveys with a total of 178 software developers. Through an exploratory analysis of the survey responses, we found that developers seek for opinions about APIs to support diverse development needs. The developers wish for tool support to analyze the huge volume of such opinions and usage scenarios scattered across many forum posts. The developers consider opinions about APIs as a form of API documentation, and analyze both the opinions and the usage scenarios posted about an API during the adoption of the API in their development tasks. They reported that they rely on opinions posted in forum posts to validate a usage examples in API formal documentation, because the official documentation is often incomplete and ambiguous. To understand the common problems that developers face while using API formal documentation, we conducted two surveys with a total of 323 software developers at IBM. We asked the developers to give us examples of three problems with API official documentation they recently encountered. Each example contained the description of a task and a link to the corresponding API documentation unit that was considered as problematic during the completion of the task. We observed 10 common documentation problems that manifest in the development practices of software developers. To compensate for the problems in the API formal documentation, the API reviews and usage scenarios posted in the forum posts can be leveraged. To assist the developers in their exploration of opinions about APIs from developers, we developed a suite of techniques to mine and summarize opinions about APIs from the forum posts. We implemented the techniques in our tool, named Opiner. Opiner is an online search and summarization engine for API artifacts. In Opiner, developers can search for an API by its name and see the mined opinions about the API in our two proposed summarization algorithms (Statistical and Aspect-based) and six other summarization algorithms (e.g., contrastive viewpoint summarizer). We evaluated the API review summaries in Opiner by conducting two user studies, both involving professional and Industrial software developers. We observed promising results of leveraging the Opiner API review summaries to support diverse development needs, such as, API selection, documentation, being staying aware, and so on. In two API selection tasks involving four open source APIs, we found that the Industrial developers made more correct API choices while using Opiner and Stack Overflow together than while using only Stack Overflow. To assist the developers in their usage of APIs, we further developed a framework to automatically mine and summarize usage scenarios about APIs from developer forums. In Opiner, we developed four different summarization algorithms for API usage scenarios mined from developer forums. In three user studies involving both professional software developers and students, we found that the participants were able to complete their coding tasks with more accuracy, and in less time and effort while using Opiner usage summaries compared to when they used Stack Oveflow only or API official documentation only. The developers mentioned that the usage summaries in Opiner can offer improvements to both API formal and informal documents. More than 80% developers wished for Opiner usage summaries to be integrated into the API formal documentation. The Opiner online search and summarization engine website is hosted at: http://opiner.polymtl.ca</description><description>Les API abstraites (interfaces de programmation d'applications) offrent des interfaces aux composants logiciels réutilisables. Avec l'avènement et la prolifération des forums de développeur en ligne, les développeurs partagent souvent leurs opinions sur les APIs qu'ils utilisent. Ainsi, les opinions des autres peuvent façonner la perception des développeurs et influencer leurs décisions relatives aux APIs . Pour comprendre comment et pourquoi les développeurs partagent des opinions sur les APIs, nous avons mené deux sondages avec un total de 178 développeurs de logiciels. Grâce à une analyse exploratoire des réponses de l'enquête, nous avons constaté que les développeurs recherchent des avis sur les APIs pour soutenir divers besoins de développement, comme. Les développeurs souhaitent un support d'outil pour analyser le volume énorme de ces avis, ainsi que les multiples scénarios d'utilisation d'API dispersés dans de nombreux messages postés sur les forums. Les développeurs considèrent les avis sur les APIs comme une forme de documentation de ces API, et analysent à la fois les opinions et les scénarios d'utilisation affichés sur une API au cours de l'adoption de l'API pour leurs tâches de développement. Ils ont rapporté qu'ils comptent sur les opinions affichées sur les forums pour valider des exemples d'utilisation dans la documentation officielle de l'API, car la documentation est souvent incomplète et ambiguë. Pour comprendre les problèmes courants rencontrés par les développeurs lors de l'utilisation de la documentation formelle des APIs, nous avons réalisé deux sondages avec un total de 323 développeurs de logiciels chez IBM. Nous avons demandé aux développeurs de nous donner trois exemples de problèmes qu'ils ont récemment rencontrés en travaillant avec la documentation officielle d'un API. Nous avons observé 10 problèmes de documentation communs qui se sont manifestés dans les pratiques de développement de ces développeurs. Pour compenser les problèmes dans la documentation formelle des APIs, les opinions émises sur les APIs ainsi que les scénarios d'utilisation partagés sur les forums peuvent être exploités. Pour aider les développeurs dans leur exploration des opinions partagées sur les forums, nous avons développé et implémenté dans notre outils Opiner, une suite de techniques permettant de résumer les avis émis sur les APIs dans les messages partagés sur un forum. Opiner est un moteur de recherche et de synthèse en ligne d'information sur des APIs. Dans opiner, les développeurs peuvent rechercher une API par son nom et voir les avis partagés sur l'API grâce à nos deux algorithmes de synthèse (statistiques et à base d'aspect) et six autres algorithmes de synthèse (par exemple, une synthèse de point de vue contrastés sur un API). Nous avons évalué les résumés de Opiner en effectuant deux études d'utilisateurs, impliquant des professionnels et les développeurs de logiciels industriels. Lors de deux tâches de sélection d'APIs impliquant quatre APIs à code source ouvert, nous avons constaté que les développeurs industriels ont fait de meilleurs choix d'API lorsqu'ils utilisaient Opiner et Stack Overflow ensemble, que lorsqu'ils n'utilisaient que Stack Overflow. Dans Opiner, nous avons aussi développé quatre algorithmes de synthèse de scénarios d'utilisation des API extraits des forums de développeurs. Dans trois études d'utilisateurs impliquant à la fois des développeurs de logiciels professionnels et des étudiants, nous avons constaté que les participants étaient en mesure de compléter leurs tâches de codage avec plus de précision, et en moins de temps et d'effort lorsqu'ils utilisaient Opiner, que lorsqu'ils utilisaient seulement Stack Overflow ou la documentation officielle de l'API. Plus de 80% de développeurs souhaitaient que les résumés d'Opiner soient intégrés dans la documentation formelle des APIs. Le siteWeb du moteur de recherche et de synthèse Opiner est hébergé à: http://opiner.polymtl.ca</description><creator>Uddin, Mohammad</creator><contributor>Jérôme Waldispuhl (Supervisor1)</contributor><contributor>Foutse Khomh (Supervisor2)</contributor><date>2018</date><subject>Computer Science</subject><title>Automatic summarization of API artifacts from informal documentation</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/z316q390h.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/fj2364575</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:xk81jn916</identifier><datestamp>2020-03-21T05:26:23Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Après une revue du corpus de la critique littéraire sur Borges, cette thèse questionne l'espace limité qui a été accordé à l'analyse d'aspects liés à la culture italienne et à la relation de Borges avec l'Italie dans son travail, et ce malgré le fait que Dante soit l'un des auteurs qu'il a le plus étudié dans sa vie. Qui plus est, entre autre choses, Borges vivait dans un quartier éminemment italien, il était activement lié à des réseaux d'intellectuels italiens et avait reçu par le biais de l'Italie ou d'italiens (directement ou indirectement) un plus grand nombre de prix littéraires que de ceux originaires de n'importe quel autre pays. Quels aspects de la culture populaire italienne et/ou des lectures que Borges a effectués de matériel italien, ou lié à la culture italienne, sont absorbés dans son travail, lesquels sont rejetés pourquoi? Comment, et pour quelles raisons, ce processus d'incorporation ou rejet varie-t-il ou cours des différentes périodes de création de Borges? Pourquoi Borges a-t-il eu un impact historique positif sans précédent sur une génération entière d'écrivains et d'érudits en Italie? Comment la critique littéraire, la réception de ses travaux et les liens entretenus avec l'Italie influencent-ils la carrière de Borges et sa production littéraire? Comment le style le plus mémorable de Borges et sa production littéraire la plus acclamée sont liés à Dante? Quels sont les écrans de fumée ou les vrais motifs qui ont détourné l'attention des critiques de ces importantes questions ayant trait aux études italiennes dans les travaux de Borges? Cette thèse vise non seulement à trouver des réponses à ces questions fondamentales (ainsi qu'à d'autres questions importantes), mais aussi à lancer la construction d'une vaste analyse organique sur des thèmes relatifs à l'Italie et aux études italiennes, jusqu'ici étonnamment peu explorées dans l'étude de travaux de Borges. La première partie de la thèse retrace les premiers contacts de Borges avec le monde italien, qui ont été à la fois la culture populaire qui l'entourait dans le quartier italien de Palerme pendant son enfance et sa jeunesse, ainsi que ses lectures littéraires italiennes et ses intérêts changeants à différentes périodes de sa carrière. Le deuxième chapitre se concentre sur l'impact que Borges a eu sur l'Italie: l'influence énorme qu'il a eu sur toute une génération d'écrivains et l'attribution sans précédent dans l'histoire des prix que l'Italie lui octroie, combinant singulièrement les sphères académiques, culturelles, politiques et médiatiques, qui à son tour causent un impact direct positif sur la carrière de Borges. Le troisième chapitre retrace l'importance, ainsi que l'assimilation et l'applicabilité que certaines lectures de matériel italien ont trouvées dans l'œuvre de Borges. En particulier l'étude prolongée de Dante Alighieri, qui a intervenu dans la consolidation du style plus mûr de Borges. Beaucoup de ces aspects ont été pris d'un groupe d'étude comprenant (mais non limité à) Alfonso Reyes, et le styliste Amado Alonso.Cette thèse soutient à partir de preuves textuelles que certaines des caractéristiques stylistiques les plus emblématiques de Borges proviennent de réflexions créatives sur des sujets et traits stylistiques dantesques; que certaines des œuvres les plus reconnues de Borges ont été écrites dans des périodes d'étude particulièrement intensive des thèmes italiens; que Borges a été sensible et réactif à la critique italienne et à la réception très favorables de ces travaux en Italie; que Borges maintient une relation symbiotique et un contact avec un réseau spécifique d'intellectuels italiens; et qu'en ouvrant la critique littéraire générale à certains aspects italiens, on peut ouvrir de nouvelles possibilités d'interprétation et de recherche dans le domaine des études borgesiennes.Mots clés: Jorge Luis Borges, Études Italiennes, Dante Alighieri, Style Littéraire, Auteurs Classiques, Prix Littéraires, Lunfardo.</description><description>Following a review of the corpus of literary critique about Borges, this thesis questions the limited space that has been given to the analysis of aspects related to Italian elements and concerns in his work, despite the fact that Dante is one of authors he studied the most in his life, he lived in an eminently Italian neighborhood, he was actively connected to networks of Italian intellectuals and received from Italians (directly or indirectly) a greater number of literary prizes than from any other country, among other things.What aspects of Italian popular culture and/or readings were absorbed in Borges' work and which were rejected? What where the reasons for his acceptances and/or rejections and how did it vary through Borges' different creative periods? Why did Borges have such a positive and unprecedented historical impact on a full generation of writers and scholars in Italy? How did the literary critique, reception and links with Italy affect Borges' career and his literary production? How was Borges' most memorable style and most praised production linked to Dante? What smokescreens or real motives have there been that have diverted the attention of critics away from these important Italian issues?This thesis aims not only to find answers to these and other fundamental questions, but also to start constructing a wide scope organic analysis about themes pertaining to Italy and Italian studies, hitherto surprisingly little explored in Borges. The first part of the thesis traces the Italian background of Borges, both of the popular culture that surrounded him in the Italian neighborhood of Palermo during his childhood and youth, as well as his Italian literary readings and changing interests at different periods of his career. The second chapter focuses on the impact that Borges had over Italy: the enormous influence he had on an entire generation of writers and the unprecedented chain of awards that Italy bestowed him. These events unusually combined the academic, cultural, political and mediatic spheres. This in turn had a quite positive, and direct impact on Borges' career. The third chapter traces the importance as well as the assimilation and applicability that certain Italian readings found in Borges' work. The prolonged study of Dante Alighieri, that started within a group including (but not limited to) Alfonso Reyes, and the stylist Amado Alonso, intervened in particular in the consolidation of Borges' more mature style.This thesis argues from textual evidence that some of the most emblematic stylistic features of Borges originate from creative reflections on Dantesque topics or stylistic traits; that some of Borges' most recognized works were written in periods of particularly intensive study of Italian themes; that Borges was sensitive and reactive to the highly favorable Italian critique and reception, and he maintained contact and a symbiotic relationship with a specific network of Italian intellectuals. Opening up the general literary criticism to certain Italian aspects can unfold enriching and new possibilities of interpretation and research in Borgesian studies.Key-words: Jorge Luis Borges, Italian Studies, Dante Alighieri, Literary Style, Classics, Literary Awards, Italian Popular Culture, Argentine, Lunfardo.</description><creator>Fonseca Acosta, Alejandro</creator><contributor>Matteo Soranzo (Supervisor1)</contributor><contributor>Jose Jouve-Martin (Supervisor2)</contributor><date>2018</date><subject>Languages, Literatures, and Cultures</subject><title>Jorges Luis Borges and Italian Literature: a general organic approach</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/pr76f599p.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/xk81jn916</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Languages, Literatures, and Cultures</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:rj430709m</identifier><datestamp>2020-03-21T05:26:24Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>This thesis provides foundations for the development of glacial drift prospecting techniques applied to iron oxide alkali-alteration systems (IOAA) that can host deposits from the broad iron oxide apatite (IOA) and iron oxide copper-gold (IOCG) families. The potential of using drift prospecting as an exploration tool in these complex metasomatic systems is explored with a till matrix geochemical study and an indicator mineral study within the Great Bear magmatic zone (GBMZ). Both of these drift prospecting methods offer promising leads towards exploration vectors for IOA and IOCG mineralization as well as their IOAA system footprint in glaciated terrain. The discontinuity of the till cover, the high compositional variability of the till due to heterogeneity within the source bedrock, the extensive size of alteration halos and the abundance of minor satellite mineralization in areas of interest complicate the application of surface exploration methods. However, Fe, Co, Ni, Cu, As, Mo, Bi, La, Th, U and W were identified as the most common potential vectoring elements towards mineralization in the GBMZ till matrix fraction based on a comparisons between a lithogeochemical dataset of the GBMZ (n= 707 samples) and a till geochemical dataset (n=101 samples). Anomalous concentration thresholds were established using the median values of elemental concentrations found in GBMZ background samples ± two times their standard deviation. Potential vectoring elements are dependent on the chosen analytical protocol, i.e. till matrix size fraction analyzed and digestion method used. In order to target the metasomatic halos of the mineralized systems, an innovative quantitative approach was developed based on the ratio of a selected element concentration from two analytical techniques. As such, mapping the ratios of the concentrations of either La or Th obtained from a near-total digestion method over those obtained from a partial digestion method in the silt+clay-sized fraction of till defines a more consistent target than any element concentrations from any single digestion method used alone. This ratio reflects a variation in the element host mineral caused by metasomatic alteration. This approach was tested for the Sue Dianne deposit due to the higher number of till samples collected in its vicinity.The potential of apatite to serve as an indicator of the presence of alteration systems and associated deposits in the GBMZ was also investigated. Apatite was selected due to its preservation in GBMZ till and its key role in the apatite-amphibole-magnetite assemblages as a signature alteration product of IOAA systems. The distinct fluorapatite chemistry that evolves within these systems can record metasomatic processes within IOA and IOCG deposits. Apatite from least-altered bedrock and from some IOAA systems have green to yellow-green cathodoluminescence responses. In contrast, apatite rich in REEs and poor in Mn, have a blue or blue and green-zoned cathodoluminescence response. REE-rich apatite crystals form during high temperature sodic-calcic-ferric/ferrous and calcic-ferric/ferrous metasomatism. As temperatures decline and the fluid chemistry evolves, localized REE leaching takes place within apatite and leads to the growth of secondary REE-bearing minerals. Apatite characteristics inherited from metasomatic history, such as irregular zoning, dissolution pits and mineral inclusions are visible in grains picked from the heavy mineral concentrates of till samples. Their presence may serve as a regional vector towards IOAA systems. The presence of blue cathodoluminescence response in apatite grains from till samples may serve as a local exploration tool for REE-rich IOA to IOCG prospects.</description><description>La présente étude établit les bases scientifiques nécessaires au développement de méthodes d'exploration glaciosédimentaire appliquées aux systèmes d'altérations alcalines à oxydes de fer pouvant servir d'hôtes aux gîtes de la famille des oxydes de fer-apatite (IOA) et oxyde de fer cuivre et or (IOCG). Le potentiel de la prospection glaciosédimentaire appliquée à ces sytèmes au métasomatisme complexe a été exploré par une étude géochimique du till et une étude des minéraux indicateurs dans la zone magmatique du Grand lac de l'Ours (ZMGO). L'évaluation de ces deux méthodes a engendré des outils prometteurs pouvant servir de vecteurs vers des minéralisations IOCG et IOA ainsi que vers l'empreinte de leurs systèmes d'altérations. Le Fe, Co, Ni, Cu, As, Mo, Bi, La, Th, U et W ont été identifiés comme étant les éléments ayant le meilleur potentiel de vectorisation d'après des analyses de variance effectuées sur 707 échantillons de la lithogéochimie des roches encaissantes, alterées et mineralisées de la ZMGO et 101 échantillons de la géochimie du till, ainsi que des tests statistiques effectués en tenant compte de taux de confidence significatif. Les seuils de teneurs anormales de ces éléments ont été établis en utilisant les valeurs médianes des teneurs de fond dans la ZMGO ± deux fois leur déviation standard. L'identification d'éléments indicateurs de minéralisation est sensible au protocole analytique, i.e. la fraction granulométrique du till analysée et la méthode de digestion. Une méthode statistique innovatrice basée sur la cartographie des variations entre les minéraux hôtes d'éléments sélectionnés a été développée de manière à cibler les halos d'altérations alcalines. Cette méthode exploite les rapports entre les concentrations de La ou de Th obtenues après digestion quasi totale et celles obtenues après digestion partielle de la fraction des silts et argiles du till et définit une cible plus nette que la concentration de quelconques éléments utilisés seuls. Cette approche a été testée au gîte Sue Dianne. Une méthode d'exploration spécifique aux systèmes d'altérations de la ZMGO et gîtes associés a été développée en utilisant l'apatite comme minéral indicateur. L'apatite a été sélectionnée pour une étude détaillée puisque ce minéral est préservé dans le till de la ZMGO et joue un rôle clé dans l'assemblage apatite-amphibole-magnétite, une signature des systèmes IOAA. Leur composition est un marqueur potentiel de leur processus de formation due au registre du métasomatisme. Les grains d'apatite provenant des roches moins altérées de la ZMGO, de même que la plupart des grains d'apatite provenant des systèmes IOAA et gîtes IOA et IOCG émettent, sous activation par cathodoluminescence, une lumière visible de couleur variant du vert au jaune et vert. En contraste, les grains d'apatite enrichis en terres rares et pauvres en Mn émettent une réponse bleue et/ou contiennent des zones irrégulières bleues et vertes. Ces grains d'apatite sont le résultat de métasomatisme à haute température sodique calcique-fer et calcique-fer. Lors de la baisse de température subséquente et en fonction de l'évolution des fluides métasomatiques, une lixiviation localisée des terres rares prend place dans l'apatite et produit des phases minérales secondaires riches en terres rares. Les caractéristiques de l'apatite résultant de leur origine métasomatique et des altérations subséquentes, tel que des zones irrégulières, des traces de lixiviations et des inclusions de minéraux secondaires, sont visibles sur des grains récupérés de concentrés de minéraux lourds des échantillons de till. Leur présence peut potentiellement servir d'outil de vectorisation régionale vers les systèmes IOAA. La présence de grains d'apatite à cathodoluminescence bleue est potentiellement un outil de vectorisation pour l'exploration de gîtes IOA à IOCG riches en terres rares.</description><creator>Normandeau, Philippe</creator><contributor>Jeanne Paquette (Supervisor1)</contributor><contributor>Isabelle McMartin (Supervisor2)</contributor><date>2018</date><subject>Earth and Planetary Sciences</subject><title>Drift prospecting applied to iron oxide alkali-altered systems and iron oxide copper-gold deposits in the Great Bear magmatic zone, Northwest Territories, Canada</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/6682x6271.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/rj430709m</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Earth and Planetary Sciences</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:d791sj73r</identifier><datestamp>2020-03-21T05:26:25Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La rigidité dynamique d'une articulation est la relation dynamique entre sa position angulaire et son moment de torsion. Il a deux composantes: 1) intrinsèque, en raison de l'inertie des membres, de la viscoélasticité du système muscle-tendon et des propriétés actives de la contraction musculaire; et 2) réflexe, résultant de changements dans l'activation musculaire dus au réflexe d'étirement. Les deux composants sont modulés par des états cinématiques neuromusculaires et cinétiques et par le système nerveux central pour contrôler la posture et le mouvement. Des études quasi stationnaires près d'un point de fonctionnement (PF), définies par la position de l'articulation et le niveau d'activation, ont identifié ces changements en utilisant des méthodes invariantes dans le temps pour de nombreux PF isolés de manière discrète. Cette thèse développe de nouvelles méthodes mathématiques et expérimentales pour identifier des modèles précis, prédictifs et non linéaires de la rigidité articulaire à partir de données non stationnaires. Il utilise une approche d'identification par paramètre variable (PV) où les structures du modèle ressemblent à des systèmes non linéaires ou linéaires (N/LPV) mais dont les paramètres varient avec une ou plusieurs variables d'ordonnancement (VO). Le cadre PV a été choisi puisque: 1) Il est physiologiquement pertinent car la position et l'activation peuvent être utilisées comme VOs. 2) Les modèles N/LPV captent la dynamique non linéaire sous-jacente au comportement non-stationnaire et peuvent ainsi prédire la réponse aux nouvelles trajectoires VO.La thèse apporte trois contributions principales: tout d'abord, elle démontre que le modèle masse-ressort-amortisseur de second ordre couramment utilisé pour décrire les moments de la cheville ne décrit pas adéquatement la dynamique intrinsèque de rigidité à toutes les fréquences. Au contraire, la thèse montre qu'un troisième modèle est nécessaire pour décrire complètement la rigidité intrinsèque; de plus, il a été démontré que ce nouveau modèle est compatible avec la structure musculo-squelettique agoniste-antagoniste de la cheville. Deuxièmement, la thèse développe une nouvelle méthode non paramétrique NPV Hammerstein (NPNPV-H) pour identifier les changements dans la non-linéarité statique réflexe et la dynamique linéaire avec la VO. Troisièmement, elle met au point une nouvelle méthode de NPV parallèle en cascade (NPNPV-PC) pour identifier la rigidité des articulations variant dans le temps et utilise une technique de projection orthogonale pour décomposer la rigidité totale en ses composantes intrinsèque et réflexe. La méthode est également un outil pour déterminer l'ordre de dépendance de chaque élément de modèle de rigidité sur la VO.Les études de simulation Monte-Carlo (MC) ont démontré que les méthodes NPV sont précises et robustes au bruit de mesure variant dans le temps. Leur utilité pratique a été démontrée en les appliquant à des données expérimentales acquises chez des sujets sains lors de mouvements imposés de la cheville au repos. Ceci a démontré que la rigidité intrinsèque et la non-linéarité statique réflexe changeaient substantiellement et systématiquement avec la position de la cheville alors que la dynamique réflexe était invariante par rapport à la position. Il est important de noter que les modèles NPV identifiés prédisaient avec précision la réponse aux nouvelles trajectoires de mouvement.Les résultats de cette thèse fournissent les moyens de: 1) Quantifier le temps des changements et des contributions relatives de la rigidité intrinsèque et réflexe au cours du mouvement. 2) Développer les modèles prédictifs nécessaires pour la conception de prothèses biomimétiques et leur contrôle, basé sur des modèles d'orthèses et de dispositifs de réhabilitation. Les résultats peuvent également fournir les moyens d'évaluer objectivement et efficacement les effets des troubles neuromusculaires sur la rigidité du joint et ses composants.</description><description>Dynamic joint stiffness is the dynamic relationship between a joint's angular position and the torque about it. It has two components: 1) intrinsic due to limb inertia, viscoelasticity of the muscle-tendon complex, and active properties of contracting muscle; and 2) reflex arising from changes in muscle activation due to the stretch reflex mechanism. Both components are modulated by neuromuscular kinematic and kinetic states and the central nervous system to control posture and movement. Quasi-stationary studies near an operating point (OP), defined by joint position and activation level, have identified these changes using time-invariant methods at many discretely isolated OPs. However, these methods cannot be used during non-stationary functional tasks where there are continuous, large changes in position and/or activation. There are two more challenges: 1) Even near an OP, reflex stiffness is a nonlinear Hammerstein system consisting of a static nonlinearity followed by linear dynamics. 2) Only the total torque, not individual intrinsic and reflex torques, can be measured.This thesis develops novel mathematical and experimental methods to identify accurate, predictive, nonlinear models of joint stiffness from non-stationary data. It uses a parameter varying (PV) identification approach where model structures resemble non/linear systems (N/LPV) but whose parameters vary with one or more scheduling variables (SVs). The PV framework was chosen since: 1) It is physiologically relevant as the position and activation can be used as SVs. 2) N/LPV models capture the nonlinear dynamics underlying non-stationary behaviour and so can predict the response to novel SV trajectories. The thesis makes three main contributions: First, it demonstrates that the commonly used 2nd order, mass-spring-damper model does not describe ankle intrinsic stiffness dynamics adequately at all frequencies. Rather, it shows that a 3rd model is required to fully describe intrinsic stiffness; furthermore, this new model is demonstrated to be consistent with the ankle's agonist-antagonist musculoskeletal structure. Second, it develops a novel, non-parametric NPV Hammerstein (NPNPV-H) method to identify changes in both reflex static nonlinearity and linear dynamics with the SV. Third, it develops a novel NP NPV Parallel-Cascade (NPNPV-PC) method to identify time-varying joint stiffness and uses an orthogonal projection technique to decompose the total stiffness into its intrinsic and reflex components. The method is also a tool to determine the order of the dependency of each stiffness model element on the SV. Monte-Carlo (MC) simulation studies demonstrated that the NPV methods are accurate, precise, and robust to coloured time-varying measurement noise. Their practical utility was demonstrated by applying them to experimental data acquired from healthy subjects during imposed ankle movements at rest. This demonstrated that intrinsic stiffness and reflex static nonlinearity changed substantially and systematically with ankle position while the reflex dynamics were position invariant. Importantly, the identified NPV models accurately predicted the response to novel movement trajectories; a goal that quasi-stationary or time-varying methods have failed to achieve. The findings of this thesis provide the means to: 1) Quantify the time-course of the changes in and relative contributions of intrinsic and reflex stiffness during movement. 2) Develop the predictive models needed for biomimetic prosthesis design and model-based control of orthotic and rehabilitation devices. They may also provide the means to objectively and efficiently assess the effects of neuromuscular disorders and treatments on joint stiffness and its components.</description><creator>Sobhani Tehrani, Ehsan</creator><contributor>Robert E Kearney (Supervisor1)</contributor><contributor>Philippe Archambault (Supervisor2)</contributor><date>2018</date><subject>Biomedical Engineering</subject><title>Nonlinear parameter varying identification of time-varying ankle dynamic stiffness</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/70795b10c.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/d791sj73r</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Biomedical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:6d56zz948</identifier><datestamp>2020-03-21T05:26:26Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La mortalité chez les patients cancéreux est principalement associée à la formation de métastases. Alors que l'importance de la synthèse protéique dans la formation des tumeurs est bien établie, son rôle dans leur dissémination demeure inexploré. Pour étudier cet aspect du cancer, la présente thèse porte sur un phénomène régulatoire important dans la traduction des ARNm en protéine : la phosphorylation d'eIF4E. Ce facteur d'initiation est un oncogène qui est fréquemment surexprimés dans divers cancers, et son hyperactivité est associée à un mauvais pronostic.  La phosphorylation sur la serine 209 est requise pour son activité : ainsi, il a été démontré que les souris porteuses d'une mutation à ce site (S209A) sont résistantes au développement du cancer de la prostate. À l'aide de ce modèle animal, cet œuvre permet d'établir que les cellules cancéreuses incapables de phosphoryler eIF4E sont moins aptes à procéder à la transition épithéliale-mésenchymateuse et à envahir la matrice extracellulaire. De plus, les tumeurs mammaires S209A sont moins métastatiques que les tumeurs de type sauvage, ce qui est causé par leur capacité réduite à traduire les ARNm encodant MMP3 et SNAIL. Surprenamment, la phosphorylation d'eIF4E dans les cellules non-transformées de l'hôte joue aussi un rôle dans le processus métastatique, puisqu'il y a une corrélation entre son expression dans les cellules du microenvironnement tumoral et la survie des patientes atteintes du cancer du sein. De plus, les souris S209A sont résistantes à la formation de métastases, même lorsque celles-ci proviennent de tumeurs 66cl4 exprimant la version sauvage d'eIF4E. Les neutrophiles sont responsables de ce phénomène, puisque leur accumulation anormale est requise pour la colonisation des poumons par les cellules 66cl4, alors que la traduction d'ARNm anti-apoptotiques nécessaires à leur survie et leur accumulation dépend de la phosphorylation d'eIF4E. De plus, un inhibiteur de plusieurs kinases, merestinib, bloque la phosphorylation d'eIF4E dans les cellules 66cl4 et les neutrophiles in vivo, permettant de prévenir leur accumulation et la formation de métastases. Ainsi, cette étude souligne l'importance de la traduction dans la dissémination métastatique, a permis de découvrir son rôle dans les cellules du microenvironnement tumoral, et identifie une cible thérapeutique dont l'inhibition à la fois dans la tumeur et le système immunitaire permet de combattre les métastases.</description><description>Most cancer related deaths are due to metastatic progression. While deregulated protein synthesis in cancer cells is recognized as playing a major role in tumorigenesis, the association between the translational machinery and cancer dissemination have remained largely unexplored. To begin addressing this situation, the present thesis focuses on a single regulatory event: the phosphorylation of the cap-binding protein eIF4E. eIF4E is an oncogene that is overexpressed in human cancers, and its levels and activity correlate with poor survival. Phosphorylation on serine 209 is required for its oncogenic activity, and mice bearing a non phosphorylatable alanine mutant of eIF4E (S209A) are resistant to the development prostate cancer. Utilizing these mice and cells isolated therefrom, the current work establishes that cancer cells unable to phosphorylate eIF4E display reduced epithelial-to-mesenchymal transition (EMT) and invasive capacities. Furthermore, mammary tumors bearing the S209A mutation are less metastatic than their wild-type counterparts due to reduced translation of mRNAs encoding MMP3 and SNAIL. Surprisingly, eIF4E phosphorylation in non-transformed cells of the host also plays a role in metastatic progression of mammary tumors, as its detection in the tumor microenvironment correlates with poor survival in breast cancer patients. Consistently, S209A mice are resistant to metastasis, even when bearing tumors derived from 66cl4 cells that express wild-type eIF4E. Neutrophils are, at least in part, responsible for this phenotype: their aberrant accumulation is critical for lung colonization from 66cl4 tumors, however, the translation of anti-apoptotic mRNAs necessary for neutrophils to survive and accumulate is dependent on eIF4E phosphorylation. Interestingly, the small molecule inhibitor merestinib inhibits eIF4E phosphorylation in 66cl4 cells and in neutrophils in vivo, resulting in reduced neutrophil accumulation and the prevention of metastasis. Thus, the experiments outlined herein highlight the importance of translation in the metastatic process, uncover its important role in cells of the tumor microenvironment, and identify a therapeutic target whose inhibition in both the tumor and immune system contributes to the prevention of metastasis. </description><creator>Robichaud, Nathaniel</creator><contributor>Nahum Sonenberg (Supervisor)</contributor><date>2018</date><subject>Biochemistry</subject><title>Metastasis and the impact of translation in the tumor and host: a phospho-eIF4E story</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/br86b582r.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/6d56zz948</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Biochemistry</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:765373568</identifier><datestamp>2020-03-21T05:26:27Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Detonation propagation in a compressible medium wherein the energy release has been made spatially inhomogeneous is examined via numerical simulations. The inhomogeneity is introduced via concentrating reactive material into regions which are separated by inert gaps while maintaining the same average energy density. The propagation velocity and propagation limit of detonation waves under the influence of these imposed inhomogeneities are put to a rigorous examination.Spatial inhomogeneities are introduced to adiabatic detonation systems with a hierarchy of complexities. In a system governed by one-dimensional Euler equations with a simplified mechanism of instantaneous energy deposition, i.e., a source triggered by the passage of leading shock after a prescribed delay time, the resulting averaged propagation speed over hundreds of spatially discrete sources is compared to the ideal Chapman-Jouguet (CJ) speed for an equivalent amount of energy release. Velocities in excess of the CJ speed are found as the reactive regions are made increasingly discrete, with deviation above CJ being as great as 15%. The deviation above the CJ value increases with decreasing values of specific heat ratio γ. When the sources are sufficiently spread out so as to make the energy release of the media nearly continuous, the classic CJ solution is obtained for the average wave speed. In the limit of highly discrete sources, time-averaged mean wave structure shows that the effective sonic surface does not correspond to an equilibrium state. The average state of the flow leaving the wave in this case does eventually reach the equilibrium Hugoniot, but only after the effective sonic surface has been crossed. Thus, the super-CJ waves observed in the limit of highly discretized sources can be understood as weak detonations due to the non-equilibrium state at the effective sonic surface. The investigation on how detonation velocity is influenced by the presence of spatial inhomogeneities is then extended to one- and two-dimensional systems with a more realistic mechanism of energy release, i.e., single-step Arrhenius kinetics. In the case of sufficiently inhomogeneous media wherein the spacing between the reactive zones is greater than the inherent reaction zone length, average wave speeds significantly greater than the corresponding CJ speed of the homogenized medium are obtained.  If the shock transit time between reactive zones is less than the reaction time scale, then the classical CJ detonation velocity is recovered. The super-CJ wave propagation is also identified in the cases with a two-dimensional arrangement of spatial inhomogeneities. The correspondence of the super-CJ behavior identified in this study with real detonation phenomena that may be observed in experiments is discussed. Finally, a random distribution of spatially discrete sources is implemented into a two-dimensional detonation system confined by an inert, compressible layer of gas. In this system, detonation waves experience losses due to lateral expansion behind a curved shock front and, thus, propagate at a velocity lower than the ideal CJ velocity. As the thickness of the reactive layer within the confinement decreases, the deficit in propagation velocity increases; below a critical thickness, detonations can no longer propagate in a self-sustained manner. The critical thickness for a steady propagation is determined for a homogeneous reactive medium and a mixture with randomly distributed, discrete reactive sources. The simulation results show that, for a sufficiently high activation energy, the spatial inhomogeneities assist a detonation wave to propagate beyond the limit that is encountered in a homogeneous reactive medium. This enhancing effect of the spatial inhomogeneities on the near-limit propagation of detonation waves is found to be more pronounced with increasing activation energy.</description><description>L'étude de la propagation d'une onde de détonation dans un milieu compressible inhomogène est menée à l'aide de simulations numériques. L'inhomogénéité du milieu est introduite artificiellement en imposant une concentration plus importante de matières réactives dans certaines régions séparées les unes des autres par du gaz inerte tout en conservant une densité d'énergie moyenne constante. L'influence des inhomogénéités spatiales sur la vitesse de propagation du front d'onde et sur la limite de propagation des ondes de détonation est étudiée avec rigueur et précision. Les inhomogénéités spatiales sont introduites dans des systèmes adiabatiques avec un degré de complexité croissante. Dans un système unidimensionnel inhomogène gouverné par les équations d'Euler et avec un mécanisme de déposition d'énergie simplifié (une source est déclenchée lors du passage du front d'onde après un certain intervalle de temps), la vitesse de propagation moyenne de l'onde est mesurée puis comparée à la vitesse de propagation obtenue dans les conditions idéales de Chapman-Jouguet (CJ) dont la quantité d'énergie libérée est identique. A mesure que les régions réactives sont de plus en plus discrètes, on observe des vitesses supérieures à la vitesse CJ, la déviation pouvant atteindre jusqu'à 15%. L'écart (excédentaire) avec la vitesse CJ est d'autant plus grand que le coefficient adiabatique  décroît. Lorsque les sources sont suffisamment dispersées, tout en conservant une quantité l'énergie libérée identique, on retrouve la vitesse CJ pour la vitesse de propagation moyenne. Dans le cas limite où les sources discrètes sont fortement éparpillées, la structure moyenne de l'onde révèle que la surface sonique effective ne correspond pas à un état d'équilibre. L'état thermodynamique moyen du milieu quittant le système d'ondes peut éventuellement atteindre l'équilibre d'Hugoniot mais une fois seulement que la surface sonique effective a été dépassée. Ainsi, les ondes super-CJ observées dans le cas limite où les sources discrètes sont très espacées peuvent être considérées comme de faibles détonations dues à l'état de non-équilibre de la surface sonique effective. Enfin, une distribution aléatoire de sources discrètes est implémentée dans un système de détonation bidimensionnel isolé par une couche de gaz compressible inerte. Dans ce système, l'onde de détonation perd une certaine quantité d'énergie à cause de l'expansion latérale se produisant avec une onde de choc incurvée, d'où une vitesse de propagation plus faible que dans le cas idéal de CJ. A mesure que l'épaisseur de la couche réactive dans le système confiné décroît, la vitesse de propagation décroît également et l'écart avec le cas idéal augmente; en dessous d'une valeur limite, la détonation ne peut plus avoir lieu de manière auto-entretenue. L'épaisseur limite pour avoir une propagation stable et auto-entretenue est déterminée pour le cas d'une détonation dans un milieu réactif homogène et pour un système avec des sources actives discrètes réparties aléatoirement dans le domaine. Les résultats des simulations montrent que, pour une énergie d'activation suffisamment grande, les inhomogénéités discrètes présentes dans le domaine contribuent à la propagation des ondes de détonation au-delà de la limite précédemment trouvée pour un milieu réactif homogène. Cet effet des inhomogénéités sur la limite de propagation est d'autant plus prononcé que l'énergie d'activation est grande.</description><creator>Mi, XiaoCheng</creator><contributor>Andrew J Higgins (Supervisor)</contributor><date>2018</date><subject>Mechanical Engineering</subject><title>Detonation in spatially inhomogeneous media</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/rv042w38p.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/765373568</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Mechanical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:wp988n45z</identifier><datestamp>2020-03-21T05:26:28Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La fibrose kystique est une maladie causée par des mutations génétiques dans le canal du régulateur de la conductance transmembranaire de la fibrose kystique (CFTR), entraînant un dysfonctionnement du transport des ions chlorure. Les manifestations cliniques de la maladie comprennent la fibrose pancréatique, la malnutrition et, surtout, l'échec de la clairance mucociliaire. Les interventions médicamenteuses ont considérablement amélioré la qualité et le pronostic des patients atteints de mucoviscidose. Cependant, la sévérité de la maladie reste assez variable d'un patient à l'autre. Par exemple, l'exposition à des polluants atmosphériques, tels que la fumée de cigarette, peut affecter de manière significative les résultats des patients atteints de mucoviscidose. Bien que des études épidémiologiques et cliniques aient montré des effets néfastes de l'exposition à la fumée secondaire sur la fonction CFTR, le mécanisme moléculaire par lequel l'exposition à la fumée altère l'activité CFTR reste obscur. Dans cette étude, nous étudions les effets de la fumée passive sur WT-CFTR et corrigé F508del-CFTR. Conformément aux rapports précédents, l'exposition à 30% de CSE pendant 1 h a supprimé la stimulation subséquente du courant de court-circuit (Isc) par la forskoline, entraînant une diminution de la fonction CFTR. Notamment, le F508del-CFTR corrigé s'est révélé plus sensible à la fumée que le WT-CFTR. En plus d'inhiber la réponse à la forskoline, l'exposition au CSE a également provoqué une augmentation importante et transitoire de l'Isc basale qui était absente lorsque les cellules étaient prétraitées avec CFTRinh-172 et lorsque les cellules CFBE exprimant F508del CFTR étaient exposées au CSE. Cette stimulation transitoire a été bloquée par H89 (un inhibiteur de la PKA) et NS398 (un inhibiteur de l'AMPc), suggérant que cette activation était une activation de la protéine kinase dépendante de l'AMPc. Il a déjà été démontré que le peroxyde d'hydrogène stimule la fonction CFTR et que la fumée de cigarette contient des oxydants. Nous avons donc étudié le rôle des espèces réactives de l'oxygène en prétraitant les cellules avec de la N-acétylcystéine (NAC). La stimulation par CSE a été fortement atténuée après 10 mM NAC, ce qui correspond à l'implication des espèces réactives de l'oxygène. Ensuite, nous avons évalué le rôle de la prostaglandine E2 en pré-traitant les cellules avec un antagoniste puissant du récepteur EP4, GW-627368. L'augmentation induite par la fumée de tabac de la sécrétion de chlorure médiée par CFTR était significativement réduite en présence de l'antagoniste du récepteur EP4.La réponse sécrétoire aiguë au CSE peut être un mécanisme de défense de l'hôte qui élimine les stimuli nocifs de la surface épithéliale, ce qui est apparemment perdu chez les patients CF l'expression de la mutation DelF508-CFTR.</description><description>Cystic Fibrosis is a disease caused by genetic mutations in the cystic fibrosis transmembrane conductance regulator (CFTR) channel resulting in dysfunctional chloride ion transport.  Clinical manifestations of the disease include pancreatic fibrosis, malnutrition, and most importantly, failure of the mucociliary clearance.  Drug intervention have significantly improved the quality and prognosis for CF patients.   However, disease severity remains quite variable from patient-to-patient.  For instance, exposures to air pollutants, such as cigarette smoke, can significantly affect the outcome of CF patients.  Although epidemiological and clinical studies have shown adverse effects of second-hand smoke exposure on CFTR function, the molecular mechanism by which smoke exposure alters CFTR activity remains obscure.  In this study, we investigate passive smoke effects on WT-CFTR and corrected F508del-CFTR.  Consistent with previous reports, exposure to 30% CSE for 1 h suppressed the subsequent stimulation of short circuit current (Isc) by forskolin, resulting in a decrease in CFTR function.  Notably, corrected F508del-CFTR was found to be more sensitive to smoke than WT-CFTR.  In addition to inhibiting the forskolin response, CSE exposure also caused a large, transient increase in basal Isc which was absent when cells were pretreated with CFTRinh-172 and when CFBE cells expressing F508del CFTR were exposed to CSE.  This transient stimulation was blocked by H89 (a PKA inhibitor) and NS398 (a cAMP inhibitor), suggesting that this activation was cAMP-dependent protein kinase activation.  Hydrogen peroxide has been shown previously to stimulate CFTR function, primarily through the autocrine signaling pathway prostaglandin E2 binding primarily to the prostaglandin type E4 receptor to initiate the activation of CFTR.  Since cigarette smoke contains oxidants, we first explored the role of reactive oxygen species by pre-treating cells with N-acetylcysteine (NAC). The stimulation by CSE was strongly attenuated after 10mM NAC, consistent with the involvement of reactive oxygen species.  Next, we assessed the role of prostaglandin E2 by pre-treating cells with potent antagonist of the EP4 receptor, GW-627368.  The tobacco smoke-induced increase in CFTR-mediated chloride secretion was significantly reduced in the presence of the EP4 receptor antagonist.  The acute secretory response to CSE may be a host defense mechanism that clears noxious stimuli from the epithelial surface, which is seemingly lost in CF patients with the DelF508-CFTR mutation.  </description><creator>Wong, Francis</creator><contributor>John W Hanrahan (Internal/Supervisor)</contributor><date>2018</date><subject>Physiology</subject><title>Cigarette smoke stimulates cystic fibrosis transmembrane conductance regulator (CFTR) function in airway epithelial cells</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/dn39x3775.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/wp988n45z</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Physiology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:g445cg79t</identifier><datestamp>2020-03-21T05:26:29Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La biominéralisation des tissus squelettiques résulte d'interactions cellulaires, protéiques à l'origine de la synthèse d'une matrice extracellulaire appropriée (essentiellement de collagène de type I). Cette matrice va ensuite se minéraliser par l'apposition de cristaux d'hydroxyapatite.  Ce processus est contrôlé par les déterminants moléculaires qui régulent la déposition et la croissance cristalline. Une de ces molécules régulatrices est l'ostéopontine (OPN) – un constituant sécrété de la matrice extracellulaire osseuse, avec des fonctions spécifiques pour contrôler la minéralisation et l'adhésion cellulaire. OPN est une glycoprotéine phosphorylée (sites abondants de phosphosérine) avec une teneur élevée en acides aspartique et glutamique et une structure intrinsèquement désordonnée qui lui permet de se lier aux cations situés à la surface des cristaux, tel que l'hydroxyapatite. De plus, elle possède des motifs liant les intégrines qui permettent l'adhésion, la migration et la chimiotaxie des cellules dans plusieurs tissus. La multifonctionnalité de l'OPN dans l'os est permise non seulement par son profil d'expression mais aussi par les modifications post-traductionnelles qu'elle a subi. L'objectif de cette thèse était d'identifier et de caractériser des nouvelles modifications post-traductionnelles de l'OPN et leurs conséquences sur la fonction de l'OPN dans l'os. Dans cette étude, PHEX a été identifiée comme une nouvelle enzyme protéolytique qui dégrade considérablement l'OPN, donc désactivant sa fonction inhibitrice de la minéralisation. Ces résultats sont soutenus par des études in vivo qui montrent qu'en l'absence d'activité de PHEX, l'OPN et ses fragments s'accumulent dans le tissu osseux. Ceci contribuerait ainsi à une inhibition locale de la minéralisation qui serait indépendante des facteurs circulants. La polymérisation d'OPN par la transglutaminase 2 a aussi été démontrée comme atténuant les propriétés inhibitrices de minéralisation de l'OPN monomérique par la modification de sa structure secondaire et de sa taille. Enfin, l'OPN a été identifiée comme un nouveau substrat pour la proprotéine convertase de type 5/6 (PC 5/6) dans l'os. Le clivage de l'OPN par PC 5/6 affecterait les propriétés d'adhésion cellulaire de l'OPN en exposant ses sites de liaison Intégrine. Ces résultats permettent de mieux comprendre le rôle de l'OPN dans la régulation fine du processus de minéralisation osseuse.</description><description>Biomineralization in skeletal tissues is a cell- and protein-mediated process involving the production of an appropriate extracellular matrix (predominantly fibrillar type 1 collagen) that is hardened (mineralized) by hydroxyapatite crystals. This process is controlled by molecular determinants that regulate crystal deposition and crystal growth. One of these regulatory molecules is osteopontin (OPN) – a secreted, extracellular matrix constituent of bone, with characterized functions in regulating mineralization and cell attachment. OPN is a phosphorylated (abundant P-Ser) glycoprotein having a high content of acidic amino acids (Asp and Glu) and an intrinsically disordered structure that allows it to bind to the cations on the surface of mineral crystals such as hydroxyapatite. Furthermore, it has centrally located integrin-binding motifs that are known to elicit cell attachment, cell migration and chemotaxis in multiple tissues. The precise roles that OPN performs in bone are determined not only by its expression pattern, but also by its post-translational modifications, thus allowing it to be a multifunctional protein. The aim of this dissertation was to identify and characterize novel post-translational modifications and their influence on OPN function in bone. In this study, PHEX was identified as a novel proteolytic enzyme that extensively degrades OPN, thus inactivating its mineralization-inhibiting function. This was supported by in vivo findings showing that in the absence of PHEX activity, OPN and OPN fragments accumulated in bone tissue, thus contributing to a locally controlled mineralization-inhibiting effect independent of circulating factors. The polymerization of OPN by tissue transglutaminase 2 was also shown to attenuate the mineralization-inhibitory properties of monomeric OPN by affecting its secondary structure and size. Lastly, OPN was identified to be a novel substrate for proprotein convertase 5/6 (PC5/6) in bone, and cleavage by PC5/6 was proposed to affect the cell attachment properties of OPN by exposing its integrin-binding sites. These findings further the understanding of the role of OPN in the finely tuned regulation of mineralization processes in bone. </description><creator>Hoac, Betty</creator><contributor>Marc D McKee (Supervisor1)</contributor><contributor>Monzur Murshed (Supervisor2)</contributor><date>2018</date><subject>Dentistry</subject><title>Enzymatic modifications of osteopontin and their role in mineralization</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/47429c74x.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/g445cg79t</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Faculty of Dentistry</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:cr56n3560</identifier><datestamp>2020-03-21T05:26:30Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Background The use of massage has been suggested to maximize pain relief, however its effectiveness on pain relief in the intensive care unit remains unknown. Objectives This study aimed to evaluate the effectiveness of hand massage on the pain intensity, unpleasantness and interference, muscle tension, anxiety, and vital signs of critically ill patients after cardiac surgery. Methods A 3-arm randomized controlled trial was conducted in a intensive care unit. Patients were included if they were 18 years or older, able to speak French or English and self-report symptoms, underwent cardiac surgery, and without a high risk of postoperative complications and contraindications to hand massage. Patients were randomly allocated (1:1:1) to standard care plus either three 20-minute hand massages (experimental), three 20-minute hand holdings (active control), or three 20-minute rest periods (passive control). Pain intensity, pain unpleasantness, anxiety, muscle tension and vital signs were evaluated before, immediately after and 30 minutes later for each intervention administered within 24 hours postopoperatively. Pain-related interference with functioning was assessed on the second postoperative day. The 0-10 numeric rating scale was used to assess pain intensity, pain unpleasantness and anxiety. Muscle tension was evaluated using the muscle tension item of the Critical-Care Pain Observation Tool. Vital signs were collected from the patients' bedside monitors. The Brief Pain Inventory was used to assess pain interference with functioning.  Results 138 patients were screened, 95 were eligible, 83 patients agreed to participate and 60 were randomized (20 hand massage, 19 hand holding, 21 rest). After controlling for baseline scores, the hand massage group reported significantly lower pain intensity, pain unpleasantness and anxiety for the 1st data collection set compared to both hand holding and rest (ANCOVA, p&lt;0.02) with an average decrease of 2 points on a 0-10 scale. No statistically significant differences were noted between the control groups for any of the symptoms. For the 2nd data collection set (n=43), pain intensity was lowest for the hand massage group compared to both hand holding and rest (ANCOVA, p=0.034). The decrease in pain unpleasantness and anxiety was not significantly different across groups (ANCOVA, p&gt;0.05). Insufficient data was obtained for the 3rd data collection set to run statistical analyses. Muscle tension and fluctuations in vital signs were similar across groups at all time points. The hand massage group reported a maximum pain intensity throughout the first postoperative day (median=5.75) that was lower than the hand holding (median=6.50) and rest groups (median=6.25), but not statistically significant. The hand massage group was more likely to reach 0 pain intensity throughout a 24-hour period (median=0) compared to the hand holding (median=2) and rest groups (median=1.75). Conclusions Findings suggest that a 20-minute hand massage in addition to analgesia can concomitantly reduce pain intensity, pain unpleasantness and anxiety by 2 points on average on a 0-10 scale. Hand massage could help patients experience longer periods of time without pain and lower levels of maximum pain intensity. </description><description>Toile de Fond L'utilisation du massage a été suggéré afin de maximiser le soulagement de la douleur, par contre ses effets sur la douleur en soins intensifs sont peu connus. Objectifs Cette étude vise à évaluer l'efficacité du massage des mains sur l'intensité, l'aspect désagréable et l'interférence reliés à la douleur, la tension musculaire, l'anxiété, et les signes vitaux des patients post chirurgie cardiaque en soins intensifs. Méthode Un essai contrôlé randomisé a été mené dans une unité de soins intensifs. Les patients étaient éligibles s'ils étaient âgés de 18 ans et plus, s'ils parlaient français ou anglais, s'ils pouvaient autoévaluer leurs symptômes, s'ils avaient subi une chirurgie cardiaque, et s'ils ne présentaient pas des complications postopératoires et des contre-indications au massage des mains. Les patients éligibles ont été alloués de façon aléatoire (1 :1 :1) aux soins usuels plus trois sessions de massage des mains de 20 minutes (groupe expérimental) ou trois sessions de toucher des mains de 20 minutes (groupe contrôle actif) ou trois périodes de repos de 20 minutes (groupe contrôle passif). L'intensité, l'aspect désagréable et l'interférence de la douleur, la tension musculaire et les signes vitaux ont été évalués avant, après et 30 minutes plus tard pour chacune des interventions dans les 24 heures après la chirurgie. L'interférence de la douleur a été évaluée lors du deuxième jour postopératoire. L'échelle numérique de 0 à 10 a été utilisée pour l'évaluation de l'intensité, de l'aspect désagréable de la douleur et de l'anxiété. La tension musculaire a été évaluée à l'aide de l'item de tension musculaire de l'outil Critical-Care Pain Observation Tool. Les signes vitaux ont été documentés via les moniteurs de chevet des patients. L'outil Brief Pain Inventory a été utilisé pour évaluer l'interférence de la douleur avec le fonctionnement. Résultats Les critères d'éligibilité ont été vérifiés pour 138 patients, 95 étaient éligibles, 83 ont accepté de participer et 60 ont été randomisés (20 au groupe massage, 19 au groupe toucher des mains, 21 au groupe repos). Pour la première collecte de données et après avoir contrôlé l'effet des scores pré-intervention, le groupe massage a rapporté des scores d'intensité et de sensation désagréable de la douleur, et d'anxiété plus bas en comparaison aux groupes du toucher des mains et du repos (ANCOVA, p&lt;0.02) avec une baisse significative moyenne de 2 points sur une échelle de 0-10. Aucune différence significative n'a été observée pour aucun des symptômes entre les groupes contrôle. Pour la deuxième collecte de données (n=43), le groupe massage a rapporté une plus faible intensité de douleur en comparaison au groupe du toucher des mains et au groupe du repos (ANCOVA, p=0.034). La sensation désagréable de la douleur et l'anxiété n'ont pas été différentes entre les groupes (ANCOVA, p&gt;0.05). Lors de la troisième collecte, les données étaient insuffisantes pour effectuer des tests d'inférence statistiques. La tension musculaire et les signes vitaux ont été similaires entre les groupes à tous les temps de mesure. Le groupe massage a rapporté une intensité maximale de douleur (médiane=5.75) plus basse que le groupe du toucher des mains (médiane=6.50) et le groupe du repos (médiane=6.25), mais la différence n'était pas statistiquement significative. Le groupe massage a été plus susceptible à atteindre une intensité de la douleur de 0 lors des dernières 24 heures (médiane=0) comparativement au groupe du toucher des mains (médiane=2) et au groupe du repos (médiane=1.75). Conclusions Les résultats suggèrent que le massage des mains d'une durée de 20 minutes en plus de l'analgésie peut réduire l'intensité et la sensation désagréable de la douleur, et l'anxiété de 2 points en moyenne sur une échelle de 0-10. Le massage peut aider les patients à être sans douleur pendant de plus longues périodes et à expérimenter une intensité maximale de douleur plus faible. </description><creator>Boitor, Madalina</creator><contributor>Céline Gélinas (Supervisor)</contributor><date>2018</date><subject>Nursing</subject><title>The effectiveness of hand massage on the pain of cardiac surgery critically ill - a randomized controlled trial</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/jm214r567.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/cr56n3560</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>School of Ingram School of Nursing</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:zw12z7657</identifier><datestamp>2020-03-21T05:26:31Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>        Cette thèse catalogue et réexamine les principales caractéristiques architecturales qui ont été découvertes dans la ville de Khirbet Qeiyafa. Le site a été fouillé pendant sept saisons au total sous la direction du Dr Yosef Garfinkel de l'Université hébraïque et de Saar Ganor au nom des autorités israéliennes des antiquités; Michael G. Hasel de l'Université Adventiste du Sud a rejoint Garfinkel et Ganor pour les saisons de fouilles 2009-2011. Les fouilleurs ont proposé que le site soit identifié comme le site biblique de Sha'arayim, signifiant «deux portes», mentionné trois fois dans la Bible hébraïque (Josué 15:36, 1 Samuel 17:52, 1 Chroniques 4: 31). Leur identification de Khirbet Qeiyafa comme appartenant au royaume de Juda a suscité beaucoup de controverse parmi les érudits qui soutiennent les théories actuelles sur la formation de l'État au Levant à l'âge du fer. Ces savants, dits «minimalistes», soutiennent qu'il n'y a aucune preuve archéologique pour soutenir une monarchie unifiée et insistent sur le fait que le royaume du nord d'Israël n'a émergé qu'au début du 9ème siècle avant JC, et le royaume de Juda seulement à la fin du 8ème siècle BCE, environ 300 ans plus tard que les événements comme censés avoir eu lieu dans le récit biblique (Lemche 1988, Finkelstien 1996, Thompson 1999)" ((Garfinkel, Y., Streit, K. Ganor, S., and Hasel, M.G. "State Formation in Judah: Biblical Tradition, Modern Historical Theories and Radiometric Dates at Khirbet Qeiyafa". Radiocarbon 54, no.3-4 (2012): p. 359.). Les vestiges architecturaux de la cité de l'âge du fer à Khirbet Qeiyafa ont été particulièrement importants dans la discussion concernant l'identité sociopolitique et l'affiliation territoriale du site. Certains érudits ont affirmé que: "le seul indice de l'affiliation territoriale du site [Kh. Qeiyafa] vient de sa tradition architecturale. D'après l'analyse de quatre autres sites présentant tous des caractéristiques architecturales similaires à celles de Khirbet Qeiyafa, il est clair, d'un point de vue architectural, qu'il n'y a aucun moyen de savoir avec certitude si Khirbet Qeiyafa était un site Israélite ou Judaïte. Cependant, ce qui est également clair, c'est qu'il est raisonnable "d'affilier les constructeurs de Khirbet Qeiyafa avec les hauts plateaux".  La principale difficulté avec l'identification de Khirbet Qeiyafa comme site Judaïte est que les partisans de cette identification n'ont pas réussi à démontrer de manière concluante que le phénomène architectural des «murs de casemates avec les structures contiguës» était une tradition judaïque unique et une tradition destinée à démontrer l'hégémonie Judaïte et identité. La question de savoir ce qui constitue les traditions architecturales Judaïtes par opposition aux traditions architecturales israélites du Nord demeure ouverte à l'enquête future.</description><description>        This work catalogues and re-examines the main architectural features that were uncovered at the Iron Age city of Khirbet Qeiyafa. The site was excavated for a total of seven seasons under the direction of Dr. Yosef Garfinkel of the Hebrew University and Saar Ganor on behalf of the Israel Antiquities Authorities; Michael G. Hasel of the Southern Adventist University joined Garfinkel and Ganor for the 2009-2011 excavation seasons. The excavators have proposed that the site be identified as the biblical site of Sha’arayim, meaning "two gates", mentioned three times in the Hebrew Bible (Joshua 15:36, 1 Samuel 17:52, 1 Chronicles 4: 31). Their identification of Khirbet Qeiyafa as belonging to the kingdom of Judah has stirred much controversy amongst scholars who support current theories of state formation in the Levant during the Iron Age. These scholars, so called 'minimalists', maintain that there is no archaeological evidence to support an United Monarchy, and insist that the northern Kingdom of Israel only emerged in the early 9th century BC, and the kingdom of Judah only in the late 8th century BCE, some 300 years later than the events as purported to have happened in the biblical narrative (Lemche 1988; Finkelstein 1996; Thompson 1999)" (Garfinkel, Y., Streit, K. Ganor, S., and Hasel, M.G. "State Formation in Judah: Biblical Tradition, Modern Historical Theories and Radiometric Dates at Khirbet Qeiyafa". Radiocarbon 54, no.3-4 (2012): p. 359.). The architectural remains of the Iron Age city at Khirbet Qeiyafa have been particularly important in the discussion regarding the socio-political identity and the territorial affiliation of the site. Some scholars have asserted that: "the only clue to the territorial affiliation of the site [Kh. Qeiyafa] comes from its architectural tradition. From this work's analysis of four other sites all exhibiting similar architectural features such as those found at Khirbet Qeiyafa, it has become clear from the architectural perspective, that although one cannot identify conclusively whether or not Khirbet Qeiyafa was an early Israelite city belonging to the northern kingdom or a Judahite city, it is reasonable "to affiliate the builders of Khirbet Qeiyafa with the highlands".  The main difficulty with identifying Khirbet Qeiyafa as a Judahite site was that the supporters of this identification have failed to conclusively demonstrate that the architectural phenomenon of the 'casemate walls with the abutting structures' was a uniquely Judahite tradition and a tradition intended to demonstrate Judahite hegemony and identity. The question of what constitutes Judahite as opposed to Northern Israelite architectural traditions remains open to future inquiry.</description><creator>Ko, Rachel</creator><contributor>Patricia Kirkpatrick (Internal/Supervisor)</contributor><date>2018</date><subject>Religious Studies</subject><title>The architectural phenomenon of "Casemate Wall with Abutting Structures" at Khirbet Oeiyafa: the archaeology of architecture and its implications for Khirbet Oeiyafa's identity</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/j3860932j.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/zw12z7657</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>School of Religious Studies</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:qz20sw252</identifier><datestamp>2020-03-21T05:26:32Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>In bulk nanostructured (NS) materials produced by powder metallurgy routes, adequate consolidation of the NS powders typically requires high temperature application for extended periods of time. This increases the likelihood of grain growth in the nanocrystalline material and therefore loss in strength and hardness. Spark Plasma Sintering (SPS), with short sintering cycles and mechanisms peculiar to the process, reduces grain growth and improves consolidation of milled powders compared to conventional processes. Multi-stage SPS is investigated for sintering cryomilled NS Al-Mg powders to improve the consolidation while minimizing the grain growth. The effects of change in powder composition, i.e.: microalloying, on the grain growth in cryomilled Al-Mg alloys are also studied. Improved consolidation of cryomilled Al powders was obtained under two-stage (TSS) versus one-stage (OSS) sintering processes. With properly selected parameters T1 and T2 (TSS: T1 &gt; T2, t1 &lt; t2) a two-stage sintering process allowed for enhanced sintering while avoiding excessive grain growth. The increased duration of the second hold (from 5 to 20 minutes) marginally increased the Weibull Modulus (from 23 to 25). The best sintering schedule for milled Al 5356 was determined as the 500 TSS-20 schedule (i.e.: 500 °C for 1 minute + 350 °C for 20 minutes). Minimal grain growth occurred during the TSS regime, with 68 ± 46 nm after one-stage and 73 ± 46 nm after two-stage sintering. Al-Mg-Er powders – final compositions of Al-4.65Mg-0.08Er (0.1 Er) and Al-4.48Mg-0.44Er (0.5 Er) – were investigated. Prolonged cryomilling for 30 hours resulted in substantial oxygen contamination in the final milled powders, ~8 and ~13 wt.% in 0.1 Er and 0.5 Er, respectively. Grain growth was observed at 180 °C in the 0.1 Er powder, but the as milled grain size of ~20 nm was maintained till 400 °C (0.8 Tm) in the 0.5 Er powders. Evidence of nanoscale L12 structured Al3Er precipitation was not observed by X-ray or electron diffraction. Crystalline oxides (spinel) were observed for powders annealed at 500 °C and higher. Densification and consolidation of the milled Al-Mg-Er powders with TSS processes was dependent on the sintering temperature, maximum pressure, and heating rate. Consolidation was improved under a heating rate of 300 °C·min-1 and maximum pressure of 60 MPa during the 550 TSS 20 schedule (i.e.: 550 °C for 0.5 minute + 350 °C for 20 minutes). Average grain size was 86 ± 52 nm and 50 ± 21 nm in the 0.1 Er and 0.5 Er samples, respectively, after the 550 TSS 20 schedule. Crystalline oxide formation (spinel) during sintering was dependent on the powder composition and selection of T1. Oxide particles of Al-Mg-Er-Fe-O, Al-Mg-Er-Fe-O-N, and Al-Mg-O-N content were observed in the 0.5 Er powders sintered at 550 °C.Three-stage sintering (MSS: T1 &lt; T2 &lt; T3) improved the consolidation of cryomilled 0.1 Er powder compared to results from the two-stage sintering process (TSS: T1 &gt; T2). Higher fracture strength and hardness were obtained with samples from MSS schedules versus TSS schedules. MSS samples also exhibited smaller standard deviations (~20 nm) in fracture strength, hardness, and nanocrystalline grain size. Best results were obtained with the 350 MSS 5 condition (i.e.: 350 °C for 10 minutes + 450 °C for 5 minutes + 500 °C for 5 minutes). MSS sintering schedules limited the average grain growth to ~60 nm, compared to ~70 nm after TSS sintering. Clusters of Er and Ti were observed in TSS samples. Nanoscale precipitation of Al-Fe and Al-Fe-Ni phases were observed in MSS samples after 30 minutes of sintering. </description><description>Dans le cas de matériaux nanocristallins (NC) massifs produits par métallurgie des poudres, une consolidation adéquate de ces poudres requiert généralement l'utilisation de hautes températures pendant de longues périodes de temps. Cela augmente la probabilité de croissance de grains au sein de matériaux NC, ce qui mène à une diminution de la résistance et de dureté du matériau. Le frittage par décharge plasma (FDP) réduit la croissance des grains et améliore la consolidation des poudres broyées par rapport aux procédés de frittage classiques. Le FDP à plusieurs étapes a ainsi été mis en œuvre pour le frittage de poudres NC d'Al-Mg broyées cryogéniquement pour améliorer la consolidation des poudres, tout en minimisant la croissance des grains. Les effets de la composition des poudres sur la croissance des grains dans les alliages d'Al-Mg broyés cryogéniquement ont également été étudiés.En sélectionnant adéquatement les paramètres T1 et T2 (F2E: T1 &gt; T2, t1 &lt; t2), le processus de frittage en deux étapes a permis d'améliorer la consolidation obtenue tout en évitant une croissance excessive des grains. La durée accrue de la deuxième étape (de 5 à 20 minutes) du cycle a légèrement augmenté le module Weibull (de 23 à 25). Le meilleur cycle de frittage pour l'Al 5356 broyé a ainsi été déterminé comme étant un cycle à 500 °C pendant 1 minute suivi d'une seconde étape à 350 °C pendant 20 minutes. Une croissance des grains minimale a été observée pendant le cycle F2E, avec une taille de grains de 68 ± 46 nm après la première étape et 73 ± 46 nm après la seconde étape.Des poudres d'alliage d'Al-Mg-Er dont les compositions finales étaient Al-4.65Mg-0.08Er (0.1 Er) et Al-4.48Mg-0.44Er (0.5 Er) ont été analysées. Un broyage prolongé de 30 heures a mené en oxygène au sein des poudres finales, ~8% et ~13% en poids pour les poudres 0.1 Er et 0.5 Er, respectivement. Une croissance des grains a été observée à 180 °C au sein de la poudre 0.1 Er, alors qu'une taille des grains broyés d'environ 20 nm a été maintenue jusqu'à 400 °C (0.8 Tm) au sein de la poudre 0.5 Er. La précipitation de la phase L12 d'Al3Er à l'échelle nanométrique n'a cependant pas été observée. Des oxydes cristallins (spinelle) au sein des poudres recuites à 500 °C et plus ont néanmoins été mis en évidence. La densification et consolidation des poudres broyées d'Al-Mg-Er via des procédés de F2E a ainsi été améliorée en utilisant une vitesse de chauffage de 300 °C min-1 et une pression maximale de 60 MPa au cours du cycle de frittage à 550 °C pendant 0.5 minute suivi d'une seconde étape à 350 °C pendant 20 minutes. La taille moyenne des grains a 86 ± 52 nm et 50 ± 21 nm au sein des poudres 0.1 Er et 0.5 Er, respectivement, après ce cycle de frittage. La formation d'oxyde cristallin (spinelle) pendant le frittage dépendait de la composition de la poudre et de la température T1 sélectionnée.Le frittage en trois étapes (F3E: T1 &lt; T2 &lt; T3) a amélioré la consolidation de la poudre 0.1 Er broyée cryogéniquement par rapport aux résultats obtenus lors du processus de F2E (T1 &gt; T2). Une plus grande résistance à la fracture et dureté ont été obtenues avec des échantillons issus de F3E par rapport à ceux de provenant de F2E. Les échantillons produits via F3E ont également présenté des écarts-types de résistance à la fracture, dureté et taille des grains nanocristallins plus petits. Les meilleurs résultats ont été obtenus en utilisant un cycle de 350 °C pendant 10 minutes, suivi d'une seconde étape de 450 °C pendant 5 minutes et d'une troisième étape de 500 °C pendant 5 minutes. Les cycles de frittage F3E ont également limité la croissance moyenne des grains à ~60 nm, par rapport à ~70 nm après un cycle de F2E. Par ailleurs, des agrégats d'Er et de Ti ont été observés au sein d'échantillons préparés par F2E. De même, la précipitation de phases nanométriques d'Al-Fe et d'Al-Fe-Ni a été observée au sein d'échantillons de F3E après 30 minutes de frittage.</description><creator>Akinrinlola, Bamidele</creator><contributor>Raynald Gauvin (Supervisor2)</contributor><contributor>Mathieu Brochu (Supervisor1)</contributor><date>2018</date><subject>Mining and Materials</subject><title>Strategies for producing bulk nanocrystalline Al-Mg alloys by cryogenic milling and SPS consolidation</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/7w62fb72g.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/qz20sw252</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Mining and Materials</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:7d278w74s</identifier><datestamp>2020-03-21T05:26:37Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>This dissertation is a study of musical instruments in 1960s popular music organized around the theme of electrification. New electrical technologies for tone production, timbral modulation, and amplification prompted radical shifts in the instrumentation used in the popular music of this period, leading musicians to borrow instruments from other cultures, such as the harpsichord and sitar, and to engage novel technologies, including synthesizers and effect pedals. Nonetheless, electricity became a ubiquitous feature of popular music rather late relative to other domains, such as domestic appliances and transportation. The adoption of electrification, like any new technology, is based on a balance of both technical considerations and social contexts. Why did electricity come to feature prominently in the production of popular music when it did and in the ways that it did? My principal objective with this project, then, is to account for the various socio-cultural agents responsible for the eventual widespread availability of electrical instrument technologies (including instrument designers, manufacturers, and retailers), the diverse sounds arising from their use in the hands of amateur and professional musicians, as well as the myriad meanings ascribed to them by musicians, critics, and fans alike. In order to account for the sounds, techniques, and gestures that emerged as a result of this process of electrification, I develop an interdisciplinary musicological perspective informed by studies of technology and genre.</description><description>Cette thèse est une étude des instruments de musique employés dans la musique populaire des années soixante organisée autour du sujet de l'électrification. Les nouvelles technologies électriques pour la production du son, la modulation de la sonorité, et l'amplification ont poussé les musiciens à changer radicalement leurs outils ; en particulier, ils ont adopté des instruments d'autres cultures, comme le clavecin et le sitar, et des instruments novateurs, comme les pédales et le synthétiseur. Néanmoins, l'électricité est devenue tardivement une caractéristique omniprésente dans la musique populaire relativement à d'autres domaines, comme ceux des appareils domestiques et de la transportation. L'adoption d'électrification, comme toutes les nouvelles technologies, est fondée sur l'équilibre entre des considérations techniques et des contextes sociaux. Pourquoi l'électricité est-elle devenue une caractéristique proéminente dans la production de la musique populaire à ce moment et de cette façon ?  Mon objectif principal, donc, avec ce projet, est d'expliquer les agents socioculturels différents qui sont responsables pour l'éventuelle disponibilité répandue des technologies électriques des instruments (incluant les designers, les fabricants, et les détaillants), les sons divers produits par les musiciens professionnels et amateurs, ainsi que la myriade des sens assignés à ces appareils tout comme par les critiques, les supporteurs, et les musiciens. Pour expliquer les sons, les techniques, et les gestes qui ont émergé en conséquence de ce processus d'électrification, je développe une perspective musicologique interdisciplinaire informée par les études de la technologie et du genre.</description><creator>Miller, Farley</creator><contributor>David Brackett (Supervisor)</contributor><date>2018</date><subject>Music</subject><title>Popular music and instrument technology in an electronic age, 1960-1969</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/b8515q895.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/7d278w74s</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Schulich School of Music</discipline></degree></thesis></metadata></record><resumptionToken completeListSize="47894">oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):4900</resumptionToken></ListRecords></OAI-PMH>