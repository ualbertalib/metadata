<?xml version="1.0" encoding="UTF-8"?><rdf:RDF xmlns:oai="http://www.openarchives.org/OAI/2.0/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:ual="http://terms.library.ualberta.ca/" xmlns:bibo="http://purl.org/ontology/bibo/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:schema="https://schema.org/" xmlns:etdms="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A8s45qc38s"><dcterms:title>Local stability method for hypergraph Turán problems</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>School of Computer Science</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Yepremyan, Liana</ual:dissertant><dc:abstract>One of the earliest results in Extremal Combinatorics is Mantel's theorem from 1907 which says that the largest triangle-free graph on a given number of vertices is the complete bipartite graph with sizes of partition classes as equal as possible. In 1961 Turan asked the analogous question for 3-uniform hypergraphs - what is the largest 3-uniform hypergraph on a given vertex set with no  tetrahedron? To this date, this number is unknown even asymptotically. Since the original question by Turan a new branch in Combinatorics, called hypergraph Turan-type problems, emerged. A typical Turan-type problem for an r-uniform hypergraph F asks for the maximum number of edges in an r-uniform hypergraph on given number of vertices without a copy of F; this number is called the Turan number of F. The major part of this thesis is devoted to such problems.  In particular, we generalize and extend the classical stability method; a method pioneered by Erdos and Simonovits that is ubiquitous in the study of Turan-type problems. The developed method, referred as local stability method, is generically applicable and is of independent interest. In particular, it allows us to find new Turan numbers of several families of hypergraphs. Furthermore, we solve a conjecture of Frankl and Furedi from 1980's by determining the Turan number of a hypergraph called generalized triangle, for uniformities five and six. In the final part of the thesis we make some progress on one of the old conjectures of Erdos which states that every triangle-free graph on n vertices contains a subset of n/2 vertices that spans at most n^2/50 edges. We prove the conjecture  under several natural assumptions, improving and generalizing previous results of of Keevash, Krivelevich and Sudakov.</dc:abstract><dc:abstract>L'un des premiers résultats en Combinatoire Extrémale est le théorème de Mantel de 1907: le plus grand graphe sans triangle sur un certain nombre de sommets est le graphe biparti complet avec des classes de séparation ayant des tailles aussi égales que possible. En 1961 Turan a posé la question analogue sur les hypergraphes 3-uniforme: quel est le plus grand  hypergraphe 3-uniforme sur un ensemble de sommets dépourvu de tétraèdre? À ce jour, ce nombre est inconnu, même asymptotiquement. La question initiale de Turan a poussé à la création d'une nouvelle branche de la Combinatoire, portée sur l'étude des problèmes similaires, dits de type Turan, sur les hypergraphes. Un problème typique de type Turan  pour un hypergraphe r-unforme  demande le nombre maximum d'arêtes dans un  hypergraphe r--uniforme sur le nombre de sommets sans copie de F, nombre appelé nombre de Turan. La majeure partie de cette thèse est consacrée à de tels problèmes. En particulier, nous généralisons et  étendons la méthode de stabilité classique initiée par Erdos et Simonovits et qui est omniprésente dans l'étude des problems de type Turan. La méthode développée, appelé méthode de stabilité locale, est génériquement applicable et présente un intérêt indépendant. En particulier, elle nous permet de trouver de nouveaux  nombres de Turan pour plusieurs familles de hypergraphes. En outre, nous résolvons une conjecture de Frankl et Furedi  de 1980 par la détermination du nombre de Turan d'un hypergraphe appelé triangle généralisé pour des uniformités de cinq ou six. Enfin, dans la dernière partie de la thèse, nous faisons des progrès sur une ancienne conjecture de Erdos qui postule que tout graphe de n sommets sans triangles contient un sous-ensemble de  n/2 sommets qui produit au plus n^2/50 arêtes. Nous prouvons cette conjecture sous plusieurs hypothèses naturelles, améliorant et généralisant ainsi des résultats antérieurs de Keevash, Krivelevich et Sudakov.</dc:abstract><ual:supervisor>Sergey Norin (Supervisor1)</ual:supervisor><ual:supervisor>Hamed Hatami (Supervisor2)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/nv935557r.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/8s45qc38s</ual:fedora3Handle><dc:subject>Computer Science</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ad504rn87w"><dcterms:title>Co-composting poultry manure with biochar: effects on gas emissions and plant growth</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Bioresource Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Peachey, Brendan</ual:dissertant><dc:abstract>Co-composting with biochar is beneficial because biochar provides a habitat for microbes, promotes aeration, and absorbs moisture, nutrients, and dissolved organic matter (Li et al., 2014; Schultz et al., 2013). Biochar compost in soil sequesters carbon and improves soil quality and plant growth (Biederman and Harpole, 2012). Co-composting with biochar has sometimes also been reported to have detrimental effects, perhaps due to variability in the feedstock used for pyrolysis, the process temperature, or postproduction treatment (Beesley et al., 2011; Masiello, 2004).This research investigated the effects of biochar particle size on the composting process and plant growth. Three sizes of biochar [fine (&lt;1.6 mm), medium (6.4 – 3.2 mm), and coarse (19.2 – 12.8 mm)] were mixed with poultry manure, wheat straw, and softwood shavings, in proportion of 4:6:1:3 (vol.). The control treatment included extra wood shavings in place of biochar. Gas emissions, pH, bulk density, and temperature were compared. Emergence tests were then conducted with spring barley (Hordeum vulgare L) grown in mixtures of 0, 20, 40, 60, 80, and 100% compost with soil. A growth trial was then conducted using lettuce (Lactuca sativa Butterhead).Biochar influenced gas emissions and physical aspects of the compost, although the effects differed among gases. Coarse biochar reduced the concentrations of CO2, NO, and NH3 in the exhaust air. Finer biochar had more pronounced effects on the emission of N2O and CH4 and was associated with slightly higher concentrations of SO2. Biochar particle size affected compost bulk density. All biochar treatments were less dense than the control, compost with medium biochar was less dense than that with fine (p &lt; 0.005). Coarse biochar significantly increased peak compost temperatures (r = -0.31, p &lt; 0.0001) and accelerated the return to ambient temperatures as compared with finer biochar. This suggests that coarse biochar benefits compost microbial activity more than finer biochar (Oviedo-Ocaña et al., 2015). Biochar particle size had variable effects on the exhaust concentrations of CH4, CO, and SO2, and compost pH.The percentage of biochar compost in the soil significantly affected the barley stem length in the emergence trials (H = 12.04, p = 0.0005). Soil with 40-60% compost supported plants with the longest stems, independent of biochar particle size. Plants grown in 40 and 60% compost with medium biochar had the highest wet weight (H = 4.19, p = 0.04). The barley dry weight was affected by biochar particle size (H = 4.41, p = 0.04) and particle size (H = 10.94, p = 0.0009). Barley in soil with coarse or medium biochar produced the most biomass, while plants in soil with the control compost produced the least. These results demonstrated that soil with 20 and 40% compost was best suited for plant growth.Compost had a significant effect on lettuce wet weight in the growth trials (F = 4.78, p = 0.0018), with the heaviest plants growing in soil with 40% fine biochar compost (p = 0.016). Similar trends were observed for lettuce dry biomass, moisture content, and number of leaves. Studies similar to the one presented here have likewise yielded both positive and negative results. As such, understanding of the nature of the interaction between compost, biochar, and plant growth, remains equivocal. Additional research is required to elucidate the relationships, which can eventually be used for a meta-analysis. This research adds to that growing body of evidence.</dc:abstract><dc:abstract>Le co-compost avec du charbon (à usage agricole) est bénéfique puisque celui-ci sert d'habitat pour les microbes, tout en y favorisant l'aération, l'absorption de l'humidité et des nutriments et la dissolution de la matière organique dans le sol (Li et coll., 2014; Schultz et coll., 2013). Ce compostage peut avoir des effets néfastes, probablement dus à la variabilité dans la matière première utilisée pour la pyrolyse, ainsi que la température du procédé, ou le post traitement de production (Beesley et coll., 2011; Masiello, 2004). Les effets de la taille des particules du charbon sur le processus de compostage et de la croissance des plantes ont été examinés. Trois tailles de particules de charbon [fin (&lt;1.6 mm), moyen (6.4 – 3.2 mm), et gros (19.2-12.88 mm)] ont été mélangées avec du fumier de volaille, de la paille de blé et des copeaux de bois, dans des proportions de 4:6:1:3 (volume). Un dispositif témoin incluant des copeaux de bois en remplacement du charbon a été utilisé. Les émissions de gaz, le pH, la densité apparente et la température ont été comparés. Des tests d'émergence ont ensuite été menés avec l'orge de printemps (Hordeum vulgare L) cultivée dans des mélanges de 0, 20, 40, 60, 80 et 100% de compost avec le sol. Un essai de croissance a aussi été réalisé avec la laitue (Lactuca sativa).Le charbon influence les émissions de gaz, bien que les effets diffèrent entre les gaz. Les grosses particules de charbon réduisent les concentrations de CO2, NO et NH3 dans l'air. Le charbon de taille fine a des effets prononcés sur les émissions de N2O et CH4 et a été associé à une légère augmentation des concentrations de SO2. La grosseur des particules affecte la densité apparente. Tous les traitements au charbon ont obtenu une plus faible densité que le témoin et le compostage avec des particules moyennes, que celui fait avec des particules fines (p &lt; 0.005). De plus grosses particules ont significativement augmenté la température du compost (r = -0.31, p &lt; 0.0001) et ont accéléré le retour à une température ambiante, comparé au charbon plus fin. Cela suggère que des particules plus grosses de charbon augmentent l'activité microbienne du compost, plus que lors de l'utilisation de particules fines (Oviedo-Ocaña et coll., 2015). La taille des particules du charbon a eu des effets variables sur les concentrations d'émission de CH4, CO et SO2, et sur le pH du compost.Le pourcentage de compost avec du charbon dans le sol a significativement affecté la longueur de la tige de l'orge dans les essais d'émergence (H = 12.04, p = 0.0005). Les mélanges de 40-60% de compost ont obtenu de plus longues tiges, indépendamment de la taille des particules de charbon. Les plantes cultivées dans 40 et 60% de compost avec charbon ont obtenu un poids humide plus élevé (H = 4.19, p = 0.04). Le poids de l'orge sec a été affecté par la taille des particules du charbon (H = 4.41, p = 0.04, et H= 10.94, p = 0.0009). L'orge cultivée avec du charbon de taille grosse ou moyenne a produit la plus grande biomasse, et celle cultivée avec le témoin en a produit le moins. Ces résultats ont démontré que l'ajout de 20 et 40% de compost était le mieux adapté pour la croissance des plantes. Le compost a eu un effet significatif sur le poids humide de la laitue dans les essais de croissance (F = 4.78, p = 0.0018), avec les plants les plus pesant se développant dans des sols ayant 40% de compost à particule fine de charbon (p = 0.016). Des tendances similaires ont été observées pour la biomasse de la laitue sèche et de la teneur en humidité.D'autres études ont également obtenu des résultats positifs et négatifs. La compréhension de la nature de l'interaction entre le compost, le charbon et la croissance des plantes, reste équivoque. D'amples recherches sont nécessaires pour déterminer les relations, lesquelles peuvent possiblement être utilisées pour une méta-analyse. Cette recherche et ces résultats ajoutent et contribuent à ce domaine en pleine effervescence.</dc:abstract><ual:supervisor>Grant Clark (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/6d5700218.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/d504rn87w</ual:fedora3Handle><dc:subject>Bioresource Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Arb68xf39q"><dcterms:title>Service parochialism and the defense planning process: a case study of the title 10 wargames</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of Political Science</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>McCabe, Kathleen</ual:dissertant><dc:abstract>Ce mémoire examine les répercussions de l'esprit de clocher qui imprègne le service militaire sur l'une des plus grandes et des plus longues séries de jeux de guerre (« wargames ») militaires professionnels aux États-Unis, les « Title 10 wargames ». En examinant cette importante caractéristique des plans de défense modernes américains, cette étude permet d'identifier l'effet que l'esprit de clocher qui prévaut dans le service militaire peut avoir sur différents aspects du processus de planification de la défense, notamment en ce qui concerne tant l'acquisition de capacités militaires que l'élaboration de la doctrine et la structure des forces armées. L'analyse survole une période débutant en 1979 avec la création du prédécesseur des « Title 10 wargames » modernes, le « Global War Game », et se terminant avec les événements reliés aux jeux de guerre de 2014. Ce mémoire tire ses conclusions d'une analyse du contenu de nombreux documents officiels concernant les « Title 10 wargames » enrichie par des données obtenues lors d'entrevues avec des experts. La recherche décèle une tendance dans les « Title 10 wargames » à s'éloigner des jeux de guerre compétitifs et au vaste champ d'application de la série originale du « Global War Game ». Par conséquent, les implications stratégiques des événements de jeux de guerre sont limitées. Ces changements dans leur conception font en sorte que les « Title 10 wargames » restent vulnérables face à l'influence empreinte d'esprit de clocher du service qui les organise.</dc:abstract><dc:abstract>This thesis examines the impact of service parochialism on one of the largest and longest running series of professional military wargames in the United States, the Title 10 wargames. By examining this important feature of modern American defense planning, the research identifies the effect that service parochialism can have on all aspects of the defense planning process, from capabilities acquisition to the formation of doctrine to force structuring. The time period of the analysis begins in 1979 with the predecessor to the modern Title 10 wargames, the Global War Game, and continues to the wargame events played in 2014. The conclusions of this research have been derived from a content analysis of official published documents pertaining to the Title 10 wargames and supplemented by data obtained through expert interviews. The research shows there is a trend in the modern Title 10 wargames to move away from the wide-scope, competitive wargames played during the original Global War Game series. As a consequence, the strategic implications of the wargame events are limited. These design changes render the Title 10 wargames susceptible to continued parochial influences by their organizing service.</dc:abstract><ual:supervisor>Rex J Brynen (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/sn00b149g.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/rb68xf39q</ual:fedora3Handle><dc:subject>Political Science</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A6w924f35p"><dcterms:title>Recycling of aerospace aluminum components into new valuable products</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Mining and Materials</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Muñiz Lerma, Jose</ual:dissertant><dc:abstract>La possibilité de recycler certains alliages d'aluminium (AA) présents dans la composition des aéronefs en fin de vie (EOL), tout en maintenant la qualité de ces alliages, est traitée dans cette thèse. Le contrôle des impuretés au cours du recyclage devient alors un défi de taille à l'obtention d'alliages de qualité. Les sources d'impuretés sont associées aux revêtements contre la corrosion, aux hauts taux d'éléments d'alliages présents, ainsi qu'aux éléments externes présents lors de la manutention des rebuts d'aéronefs, tel que le Fe et le Si. Deux voies ont été explorées afin d'éliminer les impuretés reliées au décapage des revêtement anticorrosion: le procédé thermique, et le procédé chimique. Le premier est reconnu comme étant une méthode efficace et viable pour enlever les revêtements de protection des aéronefs. Il a été démontré que le temps d'immersion et la température requise pour le décapage thermique des substrats d'aluminium est de 4 minutes et 480°C. Ces conditions ont permis la dégradation du revêtement associée à une barrière énergétique de 170 kJ/mol. De plus, la concentration de Cr(VI) dans l'apprêt, suite au décapage, a été évaluée à 2,6 µg de Cr(VI)/mm2 de substrat d'aluminium. Ce niveau de concentration suggère qu'un contrôle environnemental adéquat est requis lors du procédé de décapage thermique afin de limiter la contamination au Cr(VI). Le décapage par procédé chimique, est un procédé alternatif à l'élimination des enduits organique d'aéronefs. L'évaluation de ce procédé a été effectuée en utilisant des solutions décapantes commerciales sans dichlorométhane, remplacé par du diméthyl sulfoxyde ou par du N-méthyle-2-pyrrolidone, comme solvant actif. L'efficacité de décapage de ces solutions commerciales a été évaluée sur des sections externes et internes. Il a été démontré que le revêtement présent à l'extérieur pouvait être décapé efficacemen. Cependant le revêtement de la partie intérieure n'a été décapé uniquement que par la solution contenant un mélange de diméthyl sulfoxyde, d'hydroxyde de sodium et d'un activateur, propriété de Greensolv®, en 2h10. L'efficacité de la solution suit le modèle de Flory-Rehner, selon une combinaison de facteurs tels que le volume molaire du solvant actif, le degré de vieillissement de l'enduit, ainsi que l'alcalinité de la solution.L'autre source d'impureté associée au recyclage d'aéronefs en EOL provient de la grande quantité d'éléments d'alliage présents. Suite au mélange des alliages rebutés provenant des différentes composantes d'un appareil CRJ-100ER, la composition chimique finale a été estimée suivant une approche de bilan massique et est présentée à l'Annexe A. Il est cependant possible d'obtenir des alliages de qualité, respectant les tolérances requises par l'industrie aéronautique, en mélangeant certaines sections de l'aéronef. Un démantèlement précis et bien planifié est donc recommandé dans le cas où la production d'alliage recyclé de grade aéronautique est ciblée. Il est préconisé d'éviter tout matériaux n'appartenant pas aux séries AA2000 et AA7000 afin de recycler efficacement ces dernières. Après démantèlement de l'aéronef, le décapage et le tri des matières, suit le raffinage. Un modèle de prédiction de l'efficacité a été développé avec l'utilisation de rebuts représentatifs. L'effet combiné de l'agitation et de la vitesse de solidification, a été incorporé et étudié dans un modèle de solidification à une dimension, qui inclut la rétrodiffusion dans le solide. L'utilisation de ce modèle a permis de déterminer une vitesse de solidification optimale entre 10-6 et 10-5 m/s, avec une agitation de moyenne à élevée. L'efficacité de récupération d'un AA raffiné a été estimée à 31% massique du liquide initial lorsqu'une vitesse de solidification de 10-6 m/s et les taux de concentration de Fe et de Si étaient respectivement de 1% et 2%. L'augmentation d'une de ces deux impuretés, viendrait par conséquent faire chuter le taux de récupération de l'aluminium.</dc:abstract><dc:abstract>The possibility of recycling the Al present in end-of life (EOL) aircraft while avoiding downgrading of the alloys is addressed in this thesis. Controlling the impurities during the recycling process is viewed as the most important challenge concerning the recycling of high-value alloys. The source of impurities associated with the aircraft recycling process are related with the corrosion protection coating used in aircraft fuselages, the high amount of alloying elements present in the airframe, and the pickup of impurities such as Fe and Si during the handling of the aircraft scrap. To study the removal of impurities associated with the corrosion protection coating, two routes were explored: thermal decoating and chemical stripping. Thermal decoating was proven to be a viable method to remove the aircraft protection coating. The optimal residence time and temperature for thermal decoating were 4 minutes holding time at 480 °C. These conditions allowed the thermal degradation of the coating with an associated energy barrier of 170 kJ/mol. After thermal decoating the concentration of Cr(VI) in the aged primer was 2.6 µg of Cr(VI)/mm2 of Al substrate. This concentration level suggests that adequate environmental controls are required to limit Cr(VI)-containing particulate matter during the thermal decoating of aircraft substrates.The chemical stripping route is an alternative method to remove the organic aircraft coatings. The evaluation of this route was carried out using commercial stripping solutions free of dimethyl chloride; instead either dimethyl sulfoxide or N-methyl-2-pyrrolidone was the active solvent in the presence and absence of an alkaline media. The stripping efficiency was evaluated in the external and internal sections of the fuselage. The coating present in the external section of the fuselage can be effectively removed by all the tested stripping solutions. However, the coating on the internal section was only removed by the stripping solution composed of a mixture of dimethyl sulfoxide, sodium hydroxide, and activators property of Greensolv® in 2.10 h. The effectiveness of this solution was correlated to the Flory-Rehner model and attributed to a combination of factors such as molar volume of the active solvent, the degree to which the coating was aged, and the alkalinity of the solution. The other class of impurities associated with the recycling of EOL aircraft is the high amount of alloying elements present in EOL airframes. The chemical compositions of Al scrap, after blending different Al components from a CRJ-100ER aircraft was estimated using a mass balance approach and presented in Appendix A. By commingling different aircraft sections it was found that the chemical compositions of premium aerospace alloys can be obtained. Hence, a smart dismantling process is recommended if the production of high-value alloys is targeted. However, any other material not belonging to the AA2000 and AA7000 series must be avoided in the scrap stream.After the EOL aircraft is dismantled, sorted, and decoated, the next step in the recycling process is refining. The prediction of the refining efficiency of fractional crystallization was carried out on a representative scrap chemical composition. The combined effect of stirring and solidification velocity, was incorporated and explored in a one-dimension solidification model which included back diffusion in the solid. Using this model, it was found that the optimum solidification velocities able to yield the highest refining and recovery efficiencies was between 1 x 10-6 m/s and 1 x 10-5 m/s when medium to high stirring levels were applied. The recovery efficiency of refined Al has been estimated as 31 wt% of the initial liquid when the process is carried out at 1 x 10-6 m/s and the Fe and Si concentrations are 1 % and 2 %, respectively. If any of these impurities increase, the Al recovery is reduced.</dc:abstract><ual:supervisor>In-Ho Jung (Supervisor2)</ual:supervisor><ual:supervisor>Mathieu Brochu (Supervisor1)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/ns064860v.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/6w924f35p</ual:fedora3Handle><dc:subject>Mining and Materials</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Arf55zb47n"><dcterms:title>Using external fields to control topological insulators and topological superconductors</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Physics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Farrell, Aaron</ual:dissertant><dc:abstract>The work in this thesis is dedicated to creating and manipulating topological states of matter in condensed matter systems through the use of external fields. In particular, the research in this dissertation is focused on topological superconductors and topological insulators. These states of matter are of interest because of their unique edge-states. In a topological superconductor the edge-states are Majorana modes and have potential applications in quantum computation. Meanwhile, in a topological insulator the edge-states amount to counter propagating, helical channels with interesting transport and photo-voltaic properties. Topological states of matter are also of interest for more fundamental reasons. This is because they represent a strong departure from our standard understanding of states of matter. The ability to tune a topological state of matter is of vital importance to both isolating these states in the laboratory, and to utilizing the properties of these states in physical applications. The work in this document begins by focusing on creating a topological superconductor by using an externally applied (and therefore tunable) magnetic field. The remainder of the thesis will be dedicated to using externally applied electromagnetic radiation to create and manipulate the properties of a topological insulating state.</dc:abstract><dc:abstract>Les travaux de cette thèse sont consacrés à la création et la manipulation des états topologiques de la matière dans les systémes de matiére condensée par l'utilisation de champs extérieurs. En particulier, la recherche dans cette thèse se concentre sur les supraconducteurs topologiques et les isolants topologiques. Ces  états de la matiére sont d'intérêt en raison de leurs ètats de bord uniques qui peuvent être utiles pour des applications technologiques. Dans un supraconducteur topologique, les  ètats de bord sont des modes de Majorana et ont des applications potentielles dans le calcul quantique. Par ailleurs, dans un isolant topologique, les  ètats de bord sont des canaux hèlicoïdaux qui propagent dans le sens inverse avec des propriètès photovoltaïques et de transports intèressants. Les  ètats topologiques de la matiére sont  ègalement intèressants pour des raisons plus fondamentales. En effet, ils d èvient  ènorm èment de notre comprèhension standard des  ètats de la matiére. La capacité de manipuler un  état topologique de la matière est importante pour isoler ces  ètats dans un laboratoire et pour utiliser les propriètès de ces ètats dans des applications physiques. Ce document commence en dècrivant la crèation d'un supraconducteur topologique en utilisant un champ magnètique appliquè. Le reste de la thése sera consacrè à l'utilisation du rayonnement  èlectromagnètique pour crèer et manipuler les propriètès d'un ètat isolant topologique.</dc:abstract><ual:supervisor>Tamar Pereg-Barnea (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/x920g0315.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/rf55zb47n</ual:fedora3Handle><dc:subject>Physics</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Azk51vk556"><dcterms:title>Living with sacred lands: negotiating sustainable heritage management and livelihoods in the Marquesas islands</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Anthropology</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Donaldson, Emily</ual:dissertant><dc:abstract>Cette thèse examine comment les perceptions du passé influencent les interactions d'un groupe autochtone avec le pays et l'usage de ressources.  Il étudie la rencontre de ce qu'on reconnaît comme "l'environnement" avec l'histoire et la façon dont laquelle ce lien guide la durabilité de la culture et l'environnement des îles Marquises.  Malgré les pertes graves de la vie et des connaissances marquisiens à cause de la colonialisme, la guerre, le dépeuplement et la maladie, certaines vues et compétences locales ont survécu grâce à la transmission personnelle à travers les générations.  Au fil du temps ces pratiques situées sur le terrain ont permis les insulaires à résister et à répondre à la puissance territoriale répandu par l'administration coloniale, la religion et le marché.  La nature de cette rélation de pouvoir et ses effets se manifeste dans les connexions ambivalentes, spirituelles et affectives entre les insulaires et les paysages ancestrales où ils travaillent tous les jours.  Les significations sacrées dans le pays jouent un rôle essentiel dans la façon dont les marquisiens voient leur passé et leur patrimoine, mais ils ne sont jamais reconnues par des institutions établies comme le gouvernement, l'Eglise Catholique, les organisations culturelles locales et les projets en cours pour le patrimoine et le développement durable.  En leur refus de reconnaître la puissance et l'importance spirituelle des lieux ancestraux, les processus de reconnaissance du patrimoine autochtone deviennent ironiquement un vecteur pour la perpétuation de modèles de l'autorité coloniale qui menacent à la fois la vision du monde marquisien et des ressources historiques locales.  Les tensions qui en résultent illustrent la créativité durable des insulaires de voir et agir sur leur patrimoine.  Surtout ils suggèrent, également, d'autres stratégies pour aborder la préservation des ressources historiques dans les communautés autochtones et post-coloniales dans le monde entier.</dc:abstract><dc:abstract>This thesis investigates how perceptions of the past influence one indigenous group's interactions with, and uses of, the land.  It looks at the confluence of what we generally know as "environment" with history and how this nexus guides both cultural and environmental sustainability in the Marquesas Islands.  Despite terrible historic losses of Marquesan life and knowledge due to colonialism, warfare, depopulation and disease, certain local understandings and expertise have survived through personal transmission across generations.  Over time these emplaced practices on the land have allowed islanders to resist and respond to the extension of territorial power through colonial administration, religion and the market.  Islanders' ambivalent, spiritual and embodied connections to the ancestral landscapes where they work each day are one example of this power dynamic and its effects.  Sacred meanings in the land play a crucial role in how Marquesans view their past and their heritage, yet they remain unrecognized by such established institutions as the government, the Catholic Church, local cultural organizations and ongoing initiatives for heritage and sustainable development.  By failing to acknowledge the spiritual importance and power of ancestral places, processes of indigenous heritage recognition ironically become a vehicle for the perpetuation of colonial patterns of authority that threaten both the Marquesan world-view and local historic resources.  The resulting tensions illustrate enduring creativity in the way that islanders view and act upon their heritage.  They also suggest alternative strategies for approaching the preservation of historic resources in indigenous and post-colonial communities around the globe.</dc:abstract><ual:supervisor>Colin H Scott (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/v405sd11s.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/zk51vk556</ual:fedora3Handle><dc:subject>Anthropology</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ajh343v65z"><dcterms:title>Food security and nutritional health of school-aged children in two Caribbean countries</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>School of Dietetics and Human Nutrition</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Mumena, Walaa</ual:dissertant><dc:abstract>L'insécurité alimentaire a été liée au régime alimentaire des enfants, à la santé et à la croissance, mais le lien est moins clair dans les pays en voie de développement à revenu élevé. Cette étude tente de trouver le lien entre les indicateurs de la sécurité alimentaire et la santé nutritionnelle chez les enfants en âge scolaire dans deux pays des Caraïbes pour lesquels il y a un manque de données récentes en ce qui concerne la nutrition. Le problème croissant de l'obésité ainsi que l'anémie ont été abordés comme des éléments potentiels de l'insuffisance al imentaire. Une étude longitudinale a été menée sur 390 enfants âgés de 6 à 10 ans et de leurs aidants , les enfants ont été recrutés dans huit écoles au Trinidad et dans sept écoles à St. Kitts en 2012-2014. Les variables démographiques, la situation de la sécurité alimentaire (mesurée par le questionnaire normalisé relatif à la sécurité alimentaire de l'USDA), un apport alimentaire de 24-heures pour enfant, des mesures anthropométriques pour les enfants et les soignants, et le niveau de l'hémoglobine chez les enfants (mesuré avec un HemoCue) ont été relevés deux fois. La prévalence de l'insécurité alimentaire au niveau des ménages a été de 42% alors que l'insécurité alimentaire chez les enfants a été de 27%. L'incidence en surpoids 8.8% ou en obésité 8.1% sur 18 mois était très élevée et très peu d'enfants (1.6%) sont passés de l'état de surpoids ou d'obésité à un état de poids santé. La prévalence de l'anémie chez les enfants était de 30%. L'insécurité alimentaire est liée à des apports en protéine et en zinc plus faibles. Il n'y a aucun lien entre la sécurité alimentaire et toute mesure anthropométrique. L'apport alimentaire chez les enfants n'est pas lié à une augmentation de l'adiposité ou du niveau de l'hémoglobine. Les prédicteurs de l'augmentation de l'adiposité sur une période de 18 mois étaient plus âgés, les résultats du niveau de IMC et de HFA plus élevés. L'insécurité alimentaire et être d'origine africaine étaient liés à des niveaux d'hémoglobine plus faibles. L'insécurité alimentaire est un peu liée au régime alimentaire, mais pas aux indicateurs de croissance dans l'environnement des Caraïbes étudié. Elle a, cependant, un lien avec l'anémie. Vu la croissance rapide dans la prévalence du surpoids et de l'obésité en plus du problème de l'anémie, plus d'attention à la qualité des régimes alimentaires et des aliments doit être accordée. Améliorer les apports alimentaires chez les enfants à un jeune âge est très important pour limiter l'augmentation rapide dans la prévalence de l'obésité et remédier à l'anémie qui peut être due à une défaillance nutritive.</dc:abstract><dc:abstract>Background: Food insecurity has been linked to children's diet, health and growth, but the link is less clear in upper-income developing countries, including those in the Caribbean. This study aims to investigate the association between food insecurity and nutritional health among school-aged children in two Caribbean countries for which there is a dearth of recent nutritional data. The growing problem of obesity was also addressed as well as anemia as a potential marker of dietary insufficiency.  Methods: A longitudinal study was conducted of 390 children aged 6-10 years at baseline, recruited from eight schools in Trinidad and seven schools in St. Kitts, and their caregivers, in 2012-14. Demographic variables, food insecurity (measured by USDA's food security standardized questionnaires), one 24-hour dietary intake of children, anthropometric measures for children and caregivers, and children's hemoglobin level (measured by by HemoCue) were measured at two time points. Results: The prevalence of household food insecurity at the household level was 42%, while food insecurity at the child level was 27%. Household food insecurity was linked to lower intakes of protein and zinc. There was no association between food insecurity and any anthropometric measures. The incidence of becoming overweight (8.8%) or obese (8.1%) over 18 months was high and very few children (1.6%) moved from being overweight or obese to a healthier (lower) weight group. In regards to diet, a lower intake of fruit was reported among children who become overweight or obese as compared to those who remain in the same weight category. These was a lack of association between energy intake and children's weight status; however, under-reporting of energy intake was evident among overweight and obese children as compared to children who were not. Predictors of increasing adiposity over an 18 months period were older age, higher baseline BMI z-score and HFA z-score. The prevalence of anemia among children was 30%. Dietary intake of children was not linked to anemia. Food insecurity and being of African origin were associated with lower hemoglobin levels. Conclusion: Food insecurity is marginally associated with diet, but not with any growth indicators in the Caribbean settings studied. It is, however, associated with anemia. Given the rapid increase in the prevalence of overweight and obesity as well as the continuing problem of anemia, more attention to diet quality and nutrient adequacy are needed. Improving children's dietary intake at an early age is important in an attempt to limit the rapid increase in the prevalence of obesity and to address anemia, which may be due to nutrient deficiency.</dc:abstract><ual:supervisor>Katherine Gray-Donald (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/qv33s014g.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/jh343v65z</ual:fedora3Handle><dc:subject>Dietetics and Human Nutrition</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Agm80hz173"><dcterms:title>Pathfinding in dynamically changing stealth games with distractions</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>School of Computer Science</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Borodovski, Alexander</ual:dissertant><dc:abstract>Les jeux d'infiltration sont un genre de jeux vidéo dans lesquels le joueur a besoin d'éviter les ennemis et arriver à un lieu de but. Créer des niveau pour un jeu d'infiltration est difficile, parce-que les chemins dans lesquels le jouer peut tromper la vigilance des gardes dépend sur plusieurs facteurs de l'éspace, les mouvement des gardes, et comment ils se réagissent.  Un de ces facteurs qui fait le création des niveaus beacoup plus compliqué, mais aussie les fait beaucoup plus intéressants est les distractions. Ils sont des actions de le joueur qui changent les mouvement des ennemis. Quand on a des mouvements des guards qui peuvent changer dynamiquement, il y a beaucoup plus de solutions pour les niveau. L'éspace de recherche est aussi plus grand, et donc, il est plus difficile de trouver des bons solutions.Ici, nous créeons notre propre version d'une algorithme de recherche probabiliste pour analyser des niveaus et trouver des solutions d'infiltration dans la présence des distractions. Nous le créeons  dans un façon qui permet la variation dans la conçu des niveaus et mouvement des ennemis, et aussi permet beacoup de variation dans les types et quantités de distractions qui sont disponible pour le jouer d'utiliser. Après, nous introduissons des optimisations qui améliorent la vitesse et le taux de succès de notre algorithme et créeons une forme compositionnelle pour les niveaus plus grand et compliqués. C'est tout intégré dans Unity 3D, qui permet la création et exploration des différents niveau, et la exploration de comment tout ces facteur, comme les emplacement et types de distraction peuvent agir sur la potential de l'infiltration des joueurs. Nous avons aussi créer des modèles des vrais niveau pour démontrer la applicabilité de notre algorithme.</dc:abstract><dc:abstract>Stealth games are genre of games that require the player to sneak past guards to reach a goal location. Designing a level for a stealth game is difficult, however, as the stealth paths in a level depend on a complex interplay of the physical space, the movements of enemies, and other factors. One such factor that makes the creation of good levels much more complicated, but also makes the levels much more interesting is distractions. They are player actions that change the movements of the enemies. By having dynamically changing guard movements, the realm of possible solutions increases greatly. The search space is thus also much larger, and hence finding good solutions becomes that much harder.Here, we create our own version of a probabilistic search algorithm to analyze a level and find stealth paths in the presence of distractions. This is done in a way that naturally allows variation in level design and enemy movements, while also allowing for a large variation in types and numbers of distractions that are present in the level for the player to use. We then introduce a series of optimizations that dramatically increase the success rate of the search while greatly decreasing its runtime, and create a compositional form of the search to solve larger, more complicated levels that are similar to real game levels.This design is integrated into the Unity 3D game development framework, which allows the creation and exploration of different levels, and exploration of how all of these factors including the placement and types of distractions affect the potential for stealth movement by players. We also model some levels from existing games to show the applicability of this design.</dc:abstract><ual:supervisor>Clark Verbrugge (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/3r074x82b.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/gm80hz173</ual:fedora3Handle><dc:subject>Computer Science</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ah128nh407"><dcterms:title>Mindless driving: linking trait absentmindedness to risky driving behaviour</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Psychiatry</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Albert, Derek</ual:dissertant><dc:abstract>Risky driving is an important factor associated with road traffic crashes, which is the leading cause of death among young people. An internal form of distraction, known as mind wandering (i.e., shifting attention from the immediate environment and ongoing tasks to unrelated thoughts and feelings), is associated with a reduction in driver visual attention, impairments in driving performance, and increased likelihood of being responsible for a crash. Individuals who show a propensity for mind wandering (i.e., trait absentmindedness) also experience more routine task errors, but whether trait absentmindedness also predicts risky driving behaviour is unknown. Moreover, mind wandering interferes with sensory information processing, but whether driver visual attention mediates the relationship between trait absentmindedness and risky driving has yet to be determined. Finally, executive control (i.e., the system responsible for deliberate and effortful goal-oriented cognition) is thought to facilitate and regulate mind wandering. It is currently unclear, however, whether it moderates the association between trait absentmindedness and behaviour. The present study examines the relationships between trait absentmindedness, executive control capacity, driver visual attention, and risky driving behaviour in young male drivers. We hypothesized that: H1) greater trait absentmindedness is associated with higher risky driving behaviour; H2) greater trait absentmindedness is associated with less driver visual attention; H3) visual attention mediates the relationship between trait absentmindedness and risky driving; and H4) executive control capacity moderates the relationship between trait absentmindedness and risky driving behaviour. A sample (N = 30) of young male drivers aged 18-21 years was administered the Sustained Attention to Response Task, the Daydreaming Frequency Scale, and the Dundee Stress State Questionnaire to measure trait absentmindedness, as well as the Color-Word Interference Test for executive control capacity. Mean driving speed in a simulator was used to measure risky driving, and eye tracking was used to quantify visual attention. Results showed that greater trait absentmindedness is significantly associated with higher risky driving, with trait absentmindedness explaining 32% of the variance in mean driving speed (i.e., H1). Greater executive control capacity was significantly associated with higher risky driving as a function of trait absentmindedness, with executive control explaining an additional 16% of the variance in mean driving speed (i.e., H4). The expected association between trait absentmindedness and driver visual attention (i.e., H2 and H3) was not detected. Exploratory analyses hinted that explicit awareness of mind wandering may be associated with reduced risky driving, and that greater trait absentmindedness may be associated with higher mean vertical gaze position. Trait absentmindedness is a significant marker of risky driving among young male drivers in a simulator. Moreover, executive control moderates this relationship, while meta-awareness may lessen the impact of mind wandering on driving. These preliminary findings suggest avenues for the development of detection and intervention programs designed to mitigate risky driving behaviour linked to trait absentmindedness.</dc:abstract><dc:abstract>La conduite à risque est un facteur important associé aux collisions routières qui représentent la première cause de décès chez les jeunes. La pensée errante est une forme de distraction interne qui consiste à déplacer son attention de l'environnement immédiat et d'une tâche courante vers des pensées et des émotions non liées à la tâche. Elle est associée à une réduction de l'attention visuelle du conducteur, une diminution de la performance de conduite et à une augmentation de la probabilité d'être reconnu responsable d'une collision. Les individus qui présentent une propension à la pensée errante (appelée ici le trait d'inattention) commettent aussi plus d'erreurs lors de l'exécution de tâches routinières. Toutefois, aucune étude ne s'est penchée sur la relation entre le trait d'inattention et la conduite à risque. De plus, la pensée errante interfère avec le traitement sensoriel de l'information, mais l'influence de l'attention visuelle du conducteur sur le lien entre le trait d'inattention et la conduite à risque n'a pas été étudiée. Enfin, le contrôle exécutif (c.-à-d., le système responsable de l'activité mentale délibérée et orientée vers un but) semble faciliter et réguler la pensée errante. Cependant, l'influence du contrôle exécutif sur l'association entre le trait d'inattention et le comportement reste à déterminer. La présente étude examine les liens entre le trait d'inattention, la capacité de contrôle exécutif, l'attention visuelle du conducteur et la conduite à risque chez les jeunes conducteurs masculins. Les hypothèses suivantes sont proposées : H1) un trait d'inattention plus élevé est associé à une plus grande manifestation de conduite à risque; H2) un trait d'inattention plus élevé est associé à une moins grande attention visuelle chez le conducteur; H3) l'attention visuelle influence le lien entre le trait d'inattention et la conduite à risque; et H4) la capacité de contrôle exécutif modère le lien entre le trait d'inattention et la conduite à risque. Un échantillon (N = 30) de jeunes conducteurs masculins âgés de 18 à 21 ans ont complété plusieurs tâches et questionnaires : une tâche d'attention soutenue à une réponse (Sustained Attention to Response Task); une échelle de fréquence de la rêverie (Daydreaming Frequency Scale); un questionnaire sur le trait d'inattention (Dundee Stress State Questionnaire) et un questionnaire pour mesurer la capacité de contrôle exécutif (Color-Word Interference Test). La conduite à risque est mesurée par la vitesse moyenne de conduite dans un simulateur et l'attention visuelle est calculée à l'aide d'un système de suivi oculaire. Les résultats indiquent qu'un trait d'inattention plus élevé est significativement associé à une vitesse plus élevée ; le trait d'inattention expliquant 32 % de la variance de la vitesse moyenne (c.-à-d., H1). De plus, une capacité de contrôle exécutif plus importante est significativement liée à une vitesse moyenne plus élevée en fonction du trait d'inattention ; la capacité de contrôle exécutif expliquant 16 % additionnel de la variance de la vitesse moyenne (c.-à-d., H4). Aucun lien significatif n'a été démontré entre le trait d'inattention et l'attention visuelle (c.-à-d., H2 et H3). Des analyses exploratoires suggèrent que la prise de conscience de la pensée errante pourrait être associée à une diminution de la conduite à risque et qu'un trait d'inattention plus élevé est significativement associé à une variation plus importante de la position verticale du regard. Le trait d'inattention est significativement associé à la conduite à risque chez les jeunes conducteurs masculins dans une situation de simulation. De plus, le contrôle exécutif modère ce lien, alors que la méta-conscience pourrait réduire l'impact de la pensée errante sur la conduite. Ces résultats préliminaires suggèrent des pistes pour le développement de programmes de détection et d'intervention visant à atténuer la conduite à risque liée au trait d'inattention.</dc:abstract><ual:supervisor>Marie-Claude Ouimet (Internal/Cosupervisor2)</ual:supervisor><ual:supervisor>Thomas Gordon Brown (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/zg64tp54p.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/h128nh407</ual:fedora3Handle><dc:subject>Psychiatry</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A2n49t473h"><dcterms:title>Dried broccoli «Brassica oleracea L. var. italica» stalk through application of osmotic dehydration and microwave-assisted hot air drying</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Bioresource Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Md Salim, Nora Salina</ual:dissertant><dc:abstract>This thesis focuses on the valorization of broccoli stalk as dried food product rather being discarded in the field. There are various drying technologies in food processing and recent advent of hybrid system such as microwave-assisted hot air drying is very promising. A study was conducted to compare the drying performance of broccoli stalk slices dried under hot air drying and microwave-assisted hot air drying. The results indicated that the microwave-assisted hot air drying was more efficient since it allowed faster moisture removal. Different treatments of preconditioning drying are suggested to improve the quality of dried product. Osmotic dehydration is a method of removing water from a product with minimum input of thermal energy. In this part of the study, we sought to optimize the conditions of osmotic dehydration process on broccoli stalk slices to maximize the water loss while minimizing the solute gain. The first series of tests were conducted in a water bath without agitation. The best results were obtained with a solution containing 56% sucrose (w/v) maintained at 42 °C and immersion time of four hours. Under these conditions, broccoli stalk slices showed nearly 61.5% of water loss with a solute gain of 6.7%. Thereafter, drying characteristics of osmotically dehydrated broccoli stalk slices under microwave-assisted hot air drying were investigated. The results demonstrated that the osmotic dehydration pre-treatment remarkably reduced the drying time while maintaining the dried product's color and shape as that of the untreated dried broccoli samples. During the osmotic dehydration with no agitation, the mass transfers were low resulting in long processing times. Therefore, a dewatering apparatus equipped with a pump for controlling the speed of the solution was designed and constructed. The device was used to study the effects of the flow velocity on the performance of osmotic dehydration process. The results showed that the flow velocity helps in faster rate of water removal while reducing the amount of sucrose gain. The optimum operating conditions were found to be at a temperature of 30 °C with a sucrose concentration of 54 °Brix and it was moving at a speed of 3.5 mm/s. Under these conditions, it only took 120 minutes to remove 65% of the water from the broccoli stalk slices, and sucrose gain was 3.9%. Osmotic dehydration results in loss of water and sucrose gain in the broccoli stalk slices. These compositional changes alter the dielectric properties of the product and its ability to convert the electromagnetic energy of the microwaves into heat. In this study, it was found that the dielectric properties of broccoli stalk were dependent on the osmotic dehydration processing parameters. Further study was conducted to evaluate the effects of osmotic dehydration and microwave-assisted hot air drying on the quality of the dried broccoli stalk slices. It has been demonstrated that when compared to that of the fresh sample, osmotic dehydration pre-treatment resulted in a significant decrease in vitamin C content, chlorophyll content, and total phenolic content. In addition, the osmotically dehydrated product has led to minimal color change and softer texture. When compared to varying drying temperatures, a drying temperature of 40 °C resulted in arriving at the best quality of the finished product. The last part of the study focused on the economic aspects of the production process of dried broccoli stalk slices. The economic analysis indicated that the proposed production process had a return on investment of 34.3% with a two-year payback period. Considering the positive results of the analysis and environmental benefits, the production of dried broccoli stalk slices seems to be viable on a commercial scale. Furthermore, this concept of osmotic dehydration followed by microwave-assisted hot air drying could eventually be used to process other biological materials that have the potential at the marketplace.</dc:abstract><dc:abstract>Cette thèse porte sur la valorisation de brocoli tige en tant que produit alimentaire séché plutôt d'être jeté sur le terrain. Il existe différentes technologies de séchage dans la transformation des aliments et récente apparition des systèmes hybride tels que le séchage à air chaud assisté par micro-ondes sont très prometteurs. Les résultats indiquent que le séchage à air chaud assisté par micro-ondes est plus efficace car il a permis l'élimination rapide de l'humidité. Différents traitements de séchage de préconditionnement sont proposées pour améliorer la qualité des produits séchés. La déshydratation osmotique est un procédé qui permet de retirer l'eau d'un produit en minimisant l'apport d'énergie thermique. Dans cette partie de l'étude, nous avons cherché à optimiser les conditions du procédé de déshydratation osmotique sur des tranches de tiges de brocoli afin de maximiser la perte en eau tout en minimisant le gain en soluté (sucre). Les meilleurs résultats ont été obtenus avec une solution contenant 56% de saccharose (w/v) maintenue à 42°C et un temps de trempage de quatre heures. Sous ces conditions, les tranches de tiges de brocoli ont perdues près de 61.5% de leur eau avec un gain en saccharose de 6.7%. Par la suite, les caractéristiques de séchage de osmotique déshydratées tranches brocoli tige a été étudiée sous séchage à air chaud assisté par micro-ondes. Les résultats ont démontré que la déshydratation osmotique du prétraitement réduit notablement le temps de séchage tout en maintenant la couleur des produits séchés et la forme par rapport à des échantillons de brocoli séchées non traitées. Pendant la déshydratation osmotique sans agitation, les transferts de masse sont bas ce qui résulte en des temps de traitement longs. Par conséquence, un appareil de déshydratation équipée d'une pompe permettant de contrôler la vitesse de la solution a été conçue et construite. Les résultats ont montré que la vitesse d'écoulement contribue à la vitesse plus rapide d'élimination de l'eau, tout en réduisant la quantité de saccharose absorbée. La déshydratation osmotique résulte en une perte d'eau et un gain en saccharose dans les brocolis traquent les tranches. Ces changements de la composition modifient les propriétés diélectriques du produit et son habilité à convertir l'énergie électromagnétique des micro-ondes en chaleur. Dans cette étude, on a constaté que propriétés diélectriques de brocoli tige était dépendante des paramètres osmotiques de traitement de déshydratation. Une étude plus poussée a été menée pour évaluer les effets de la déshydratation osmotique et séchage à air chaud assisté par micro-ondes sur la qualité des tiges séchées de brocoli tranches. Il a été démontré que lorsque comparer au brocoli frais, la déshydratation osmotique, utilisée en prétraitement, entraînait une diminution significative de la teneur en vitamine C, la teneur en chlorophylle et la teneur en composés phénoliques totaux. En outre, le produit osmotique déshydraté a conduit à un changement de couleur minimale et une texture plus douce. Lorsqu'on les compare à des températures variant de séchage, une température de séchage de 40°C a donné lieu à arriver à la meilleure qualité du produit fini. La dernière partie de l'étude a porté sur les aspects économiques du procédé de production de tranches de tiges de brocoli séchés fais à partir de résidus de brocoli. L'analyse économique a indiqué que le procédé de production proposé avait un retour sur investissement de l'ordre de 34.3% avec une période de récupération de deux ans. Ce concept de déshydratation osmotique suivie d'un séchage à air chaud assisté par micro-ondes pourrait éventuellement être utilisé pour traiter d'autres matières biologiques qui ont le potentiel du marché.</dc:abstract><ual:supervisor>G S Vijaya Raghavan (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/2r36v111r.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/2n49t473h</ual:fedora3Handle><dc:subject>Bioresource Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Afq977x56f"><dcterms:title>The role of horizontal gene transfer in mycobacterial pathogenesis</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Microbiology and Immunology</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Wang, Joyce</ual:dissertant><dc:abstract>Mycobacterium tuberculosis and Mycobacterium avium subsp. paratuberculosis (MAP) are important human and animal pathogens, respectively. Previous studies indicate that these two host-adapted pathogenic species have emerged from closely-related environmental strains that rarely cause disease. Through comparative genomic studies, our research group has observed a common, biphasic pattern of evolution that independently gave rise to these pathogenic species, characterized by gene acquisition via horizontal gene transfer (HGT), followed by gene deletion. As HGT is an important mechanism for bacteria to integrate novel genetic material into their genomes, yet was considered until recently to not occur in mycobacteria, we are particularly interested in its evolutionary significance in this genus. Our hypothesis is that the acquisition of virulence factors via HGT contributed to the emergence of these two professional pathogens. In this thesis, I aim to identify and characterize genomic differences between these two host-adapted mycobacterial pathogens and their genetically-closest environmental counterparts, using both a genome-wide discovery approach and targeted investigation of a candidate locus identified through genomic studies. In the example of MAP, use of transposon (Tn) mutagenesis mediated genome-wide screen showed MAP-specific genes are under-represented in genes required for growth in vitro, but over-represented for in vivo survival. One of the MAP-specific genes, MAP3776c, is required for full fitness in vivo. MAP3776c belongs to a 5-gene MAP-specific genomic island, LSPP15 (MAP3776-2c) that we experimentally showed codes for an iron acquisition system. As MAP has long been recognized as a siderophore auxotroph, our genomic analysis reveals that the acquisition of LSPP15 provides MAP with an alternative machinery for MAP to acquire metals such as iron in vivo. Applying this paradigm to the study of M. tuberculosis, we showed that many currently-accepted virulence factors of this organism are shared with M. kansasii, an environmental mycobacterium incapable of human-to-human transmission.  This observation prompted us to pursue functional characterization of a M. tuberculosis-specific gene pair, akin to our MAP LSPP15 study.  The introduction of the M. tuberculosis genes, Rv3377c-78c, into M. kansasii, resulted in the production in M. kansasii of tuberculosinol-adenosine, providing proof-of-principle that one can model in the laboratory discrete steps in the emergence of M. tuberculosis from an environmental ancestor.  Overall these findings provide independent lines of evidence that HGT events have contributed to the parallel emergence of these important pathogenic mycobacteria. This work is expected to stimulate further investigations that characterize the unique virulence attributes that define pathogenic mycobacteria of medical and veterinary relevance. </dc:abstract><dc:abstract>Mycobacterium tuberculosis et Mycobacterium avium subsp. paratuberculosis (MAP) sont, respectivement, des agents pathogènes humains et animaux importants. Des études précédentes indiquent que ces deux espèces adaptées à l'hôte sont apparues à partir de souches environnementales étroitement apparentées qui ne présentent pas de réels risques sanitaire. Grâce à des études génomiques comparatives, notre groupe de recherche a observé un modèle commun biphasique de l'évolution, qui a donné lieu indépendamment à ces espèces pathogènes, caractérisé par l'acquisition de gènes par transfert horizontal de gènes (THG), suivie par la délétion du gène. Le THG est un mécanisme important permettant aux bactéries d'intégrer un nouveau matériel génétique dans leurs génomes. Récemment, plusieurs études ont montré que le THG pouvait également se produire chez les mycobactéries et nous nous sommes particulièrement intéressés à sa signification évolutive chez les mycobactéries. Notre hypothèse est que l'acquisition de facteurs de virulence via THG a contribuée à l'émergence de ces deux agents pathogènes professionnels. Dans cette thèse, je vise à identifier et à caractériser les différences génomiques entre ces deux pathogènes mycobactériens adaptés à l'hôte et leurs homologues environnementaux les plus étroitement liés génétiquement, en utilisant à la fois une approche de découverte du génome entier et d'étude spécifique d'un locus candidat identifié par des études génomiques. Dans l'exemple de MAP, le screening du génome par mutagénèse médiée par les transposons (Tn) a montré que les gènes spécifiques de MAP sont sous-représentés dans les gènes nécessaires à la croissance in vitro, mais sur-représentés pour la survie in vivo. Un des gènes spécifiques à MAP, MAP3776c, nécessaire pour une croissance optimale in vivo, appartient à un îlot génomique spécifique à MAP contenant 5 gènes, LSPP15 (MAP3776-2c). Nous avons expérimentalement démontré que cet ilôt génomique code pour un système d'acquisition du fer. Comme MAP a longtemps été reconnu comme un auxotrophe à siderophore, notre analyse génomique révèle que l'acquisition de LSPP15 fournit à MAP un mécanisme alternatif permettant d'acquérir des métaux tels que le fer in vivo. En appliquant ce paradigme à l'étude de M. tuberculosis, nous avons montré que de nombreux facteurs de virulence reconnus de cet organisme sont partagés avec M. kansasii, une mycobactérie environnementale incapable de se transmettre d'humain à humain. Cette observation nous a incité à poursuivre la caractérisation fonctionnelle d'une paire de gènes spécifique à M. tuberculosis, semblable à notre étude sur MAP LSPP15. L'introduction du gène de M. tuberculosis, Rv3377c-78c, dans M. kansasii, a abouti à la production de 1-tuberculosinyladenosine, fournissant une preuve de principe qu'il est possible de modéliser les étapes distinctes menant à l'émergence de M. tuberculosis à partir d'un ancêtre environnemental. Globalement, ces résultats fournissent plusieurs preuves indépendantes que les événements de TGH ont contribués à l'émergence parallèle de ces importantes mycobactéries pathogènes. Ce travail devrait stimuler de nouvelles études caractérisant les attributs de virulence uniques qui définissent les mycobactéries pathogènes de pertinence médicale et vétérinaire.</dc:abstract><ual:supervisor>Marcel A Behr (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/zg64tp55z.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/fq977x56f</ual:fedora3Handle><dc:subject>Microbiology &amp; Immunology</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Aqv33s015r"><dcterms:title>Interaction between silver nanoparticles and model cell membranes</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Chemical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Kavianipour, Mona</ual:dissertant><dc:abstract>L'utilisation des nanoparticules (NPs) dans le domaine de la recherche et de la technologie s'est rapidement répandue ; Nps font partie  intégrante de notre vie quotidienne que ce soit en médecine, en cosmétique ou en alimentation. Dès lors que, l'exposition des cellules, à certaines NPs biofonctionnelles, peut être fatale si ces NPs sont toxiques. L'application des Nps avec une cytotoxicité minimale devrait alors être considérée.Dans cette recherche, nous avons étudié l'effet des NPs  Ag sur un modèle de membrane cellulaire, à savoir, des vésicules unilamellaire en suspension (SUVs) avec l'utilisation d'une sonde fluorescente, 1-N-phenylnaphthylamine(NPN) qui émet une fluorescence dans un environnement hydrophobique tel que  la région interne de la bicouche lipidique. Un lecteur de plaques multi-puits a été utilisé pour enregistrer les spectres de fluorescence des vésicules DMPC et DMPC/PS exposées aux différentes concentrations des Nps; dans cette technique, une perte de l'intensité de la fluorescence correspond à la rupture de ce modèle de membranaire cellulaire. Pour donner un aperçu sur l'état final et l'impact des Nps Ag sur la perméabilité des membranes cellulaires, l'interaction des Nps Ag et ions Ag (AgNO3) avec deux composantes de modèles de membranes (des SUVs de charge négative et neutre) a été analysées. Nous avons observé une réduction de 83% de l'intensité de fluorescence des vésicules chargées négativements interagissant avec 40 mM ions Ag. Un faible niveau de perturbation membranaire (50% de réduction de l'intensité fluorescente) a été observé pour les SUVs de charge neutre. Cela nous indique que les interactions électrostatiques jouent un rôle important.Etant donné que le comportement de phase des bicouches phospholipidiques influence les propriétés des vésicules, l'effet de la température a été aussi examiné. De plus, nous avons étudié l'effet de recouvrement de surface de NP sur l'interaction des vésicules-NP. Comme les propriétés des NPs peuvent altérées de façon significative leur surface, nous avons donc observés différent comportement pour le PVP- et citrate-coated silver NPs.Le rôle de type de NP sur l'interaction des vésicules-NP a été examiné en utilisant 50-nm-PVP-revêtu de Nps d'or et d'argent. Une diffusion dynamique de la  lumière a été utilisé pour déterminer la distribution de la taille, la surface potentielle  des vésicules lipidiques et la probabilité d'aggrégration au fil du temps.Les mesures ont révélés que l'aggrégration des vésicules augmente en élevant la concentration d'ion Ag et est plus présente pour les vésicules chargées négativement que neutre. L'analyse de suivi des nanoparticules a été utilisée pour déterminer la taille des vésicules lipidiques. La quantité d'argent dissous a été déterminée pour le PVP et le recouvrement de nanoparticules citrate en se servant d'un spectromètre de masse à couplage plasma inductif  en mode particule unique.  De manière générale, cette recherche démontre une nouvelle approche d'étudier la rupture du modèle de la membrane cellulaire par ions métalliques et les Nps.</dc:abstract><dc:abstract>The use of nanoparticles (NPs) in research and technology is rapidly expanding; NPs have become part of our daily life in medical, cosmetic, or food products. Since exposure of cells to some biofunctional NPs might be fatal if the NPs are toxic, applying NPs with minimal cytotoxicity should be considered. In this study, we investigated the effect of Ag NPs on model cell membranes, namely, suspended unilamellar vesicles (SUVs) using the fluorescent probe, 1-N-phenylnaphthylamine (NPN) that fluoresces in a hydrophobic environment such as the internal region of the lipid bilayer. A multi-well plate reader was used to record fluorescence spectra of neutral, and negatively charged vesicles exposed to different concentrations of NPs; in this technique, a loss in fluorescence intensity corresponds to disruption of the model cell membrane. To provide insight into the fate of Ag NPs and their impact on cell membrane permeability, the interaction of Ag NPs and Ag ions (AgNO3) with two component model membranes (neutral and negatively-charged SUVs) was analyzed. We observed an 83% reduction in the fluorescence intensity of negatively-charged vesicles interacting with 40 mM Ag ions. A lower level of membrane disruption (50% reduction in fluorescence intensity) was observed for the neutrally charged SUVs indicating that electrostatic interactions play an important role. Since the phase behavior of a phospholipid bilayer influences vesicle properties, the effect of temperature was also examined. Furthermore, we investigated the effect of NP surface coating on NP-vesicle interaction as the properties of the NPs can be significantly altered through their surface modification, and we observed different behavior for PVP- and citrate-coated silver NPs. The role of NP type on NP-vesicle interaction was examined using 50-nm-PVP coated gold and silver NPs. Dynamic light scattering was used to measure the size distribution, surface potential of the SUVs, and the likelihood of aggregation over time. The measurements revealed that by increasing the Ag ion concentration, the aggregation of vesicles increased. More SUV aggregation was observed for negatively charged vesicles in comparison to neutral ones. Nanoparticle tracking analysis was also utilized to determine the lipid vesicle size. The amount of dissolved silver was determined for both PVP- and citrate-coated NPs using inductively couple plasma mass spectrometry in a single particle mode. Overall, this study demonstrates a novel approach to study the disruption of model cell membranes by metal ions and NPs. </dc:abstract><ual:supervisor>Nathalie Tufenkji (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/h415pd23t.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/qv33s015r</ual:fedora3Handle><dc:subject>Chemical Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3At148fk70v"><dcterms:title>III-nitride nanowire photoelectrodes: design, epitaxial growth, and solar-to-fuels production</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Fan, Shizhao</ual:dissertant><dc:abstract>The photoelectrochemical (PEC) approach of converting solar energy into fuels holds significant potential to establish a sustainable energy system. Tremendous effort has been devoted to metal oxide based PEC systems. However, it remains elusive to reach the calibre for application in terms of efficiency, stability and scalability, due to the intrinsic limits of metal oxide light absorbers. Herein, we demonstrate the versatility of indium gallium nitride (InGaN) alloys grown by plasma-assisted molecular beam epitaxy (PA-MBE) for the purpose of water splitting under sunlight. Using tunnel junction nanowires, we realize a monolithically integrated InGaN-nanowire/Si tandem photocathode with dramatically improved efficiency and stability compared to other Si-based photocathodes. Besides, we establish a growth window to produce high quality InGaN alloy nanowires with indium content as high as 50%, which unprecedentedly extends the absorption edge to ~700 nm and leads to the highest photocurrent of InGaN photoelectrodes under AM1.5G one sun illumination. Based on such InGaN nanowires, we further construct an InGaN-nanowire/Si tandem photoanode with an energy bandgap configuration approaching the ideal values of 1.75 eV (top cell) and 1.13 eV (bottom cell) for tandem photovoltaic devices. Such an innovation brings us one step closer to unassisted PEC water splitting with a solar-to-hydrogen (STH) efficiency above 20%. We have successfully coupled the tandem photoanode with NiFeOx water oxidation co-catalyst, reaching a peak STH of 1.3% for water splitting in strong base electrolyte. In addition, we explore the photocatalytic properties of GaN nanowires for the formation and cleavage of C-H bond. Under UV illumination, photocatalytic CO2 reduction towards CO and CH4 is observed on GaN nanowires with Pt nanoparticles as co-catalyst. The difficulty of C-H bond formation on GaN nanowires inspires us to study the cleavage of C-H bond on the surface of GaN nanowires under UV illumination, which leads to the photocatalytic conversion of CH4 to benzene.</dc:abstract><dc:abstract>L'approche photoélectrochimique (PEC) de convertir l'énergie solaire en carburants détient un potentiel important d'établir un système d'énergie durable. De considérables efforts ont été consacrés à des systèmes PEC à base d'oxydes de métaux. Toutefois, il reste difficile d'atteindre un niveau de performance suffisant pour une application efficace, stable et grandissante, en raison des limites intrinsèques des absorbeurs de lumière en oxydes de métaux. Ici, nous démontrons la polyvalence des alliages en nitrure d'indium et de gallium (InGaN) formés par épitaxie par jets moléculaires (MBE) assistée par plasma à des fins de craquage de l'eau sous la lumière du soleil. Avec l'utilisation de jonctions tunnel de nanofils, nous réalisons une photocathode qui combine les nanofils en InGaN intégrés de façon monolithique au Si, avec une amélioration considérable de l'efficacité et la stabilité par rapport à d'autres photocathodes à base de Si. En outre, nous établissons les paramètres pour produire des nanofils en alliages d'InGaN de haute qualité avec un contenu d'indium aussi élevé que 50%, ce qui étend sans précédent la limite d'absorption à ~ 700 nm et mène au courant photoélectrique le plus élevé des photoélectrodes à base d'InGaN sous AM1.5G d'éclairage solaire. En nous basant sur ces nanofils d'InGaN, nous formons par la suite une photoanode en nanofils d'InGaN combinés au Si avec une configuration de la bande d'énergie interdite approchant les valeurs idéales de 1,7 eV (cellule supérieure) et 1,0 eV (cellulaire inférieure) pour les appareils photovoltaïques combinés. Une telle innovation nous rapproche au craquage de l'eau par PEC sans biais avec une efficacité solaire en hydrogène (SEH) au-delà de 20%. Nous avons couplé avec succès cette photoanode avec un cocatalyseur d'oxydation de l'eau en NiFeOx, pour atteindre une efficacité SEH de 1,3% pour le craquage de l'eau dans un électrolyte de base forte. De plus, nous explorons les propriétés photocatalytiques de nanofils en GaN pour la formation et le clivage de liaisons C-H. Sous une illumination UV, la réduction photocatalytique de CO2 en CO et CH4 est observée sur les nanofils en GaN avec des nanoparticules de platine en tant que cocatalyseur. La difficulté de la formation de liaisons C-H sur les nanofils en GaN nous incite à étudier la rupture de liaisons C-H sur la surface de nanofils en GaN sous une illumination UV, ce qui conduit à la conversion photocatalytique de CH4 au benzène.</dc:abstract><ual:supervisor>Zetian Mi (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/fj2364885.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/t148fk70v</ual:fedora3Handle><dc:subject>Electrical and Computer Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A8s45qc392"><dcterms:title>Essays on the size and sources of gender and sexual minority wage gaps in Canada</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Sociology</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Waite, Sean</ual:dissertant><dc:abstract>Gender is a primary source of differentiation in the labour market. On average, women earn less than men even when they have the similar  education, work full-time and in similar occupations. The availability of new data has also allowed researchers to explore whether labour markets are stratified by sexual orientation. This literature has found a hierarchy of earnings where heterosexual men earn the most, followed by gay men, lesbians and, lastly, heterosexual women. In other words, all men do better than all women but gay men are disadvantaged and lesbians are advantaged, relative to their heterosexual counterparts. To date, only a handful of studies have explored how sexual orientation shapes labour market outcomes in Canada. This is quite different from the large body of literature interested in the size and sources of the gender wage gap. The literature that has accumulated has tended to explore gender wage gaps at the aggregate level. For all the value of this research, wage gaps estimated at the aggregate level may conceal significant variation in the size and sources of wage disadvantage by age, education, field of study or occupation. The main objective of this dissertation is to disaggregate gender and sexual minority wage gaps to provide a more nuanced exploration of the size and sources of labour market stratification in Canada. In doing so, this dissertation will give greater meaning to residual or unexplained wage gaps estimated at the aggregate level and shed light on the mechanisms contributing to wage disadvantage. Two of the chapters in this dissertation also explore whether the size and sources of wage disadvantage have changed over time. </dc:abstract><dc:abstract>Le genre d'une personne est à la base de la différentiation dans le marché du travail. En moyenne, les femmes gagnent moins que les hommes même quand elles possèdent la même éducation, travaillent à temps plein et dans des domaines similaires. La parution de nouvelles formes de données a permis aux chercheurs d'explorer la stratification du marché de travail. Cette littérature a permis de découvrir qu'il existe une hiérarchie de gains où les hommes hétérosexuels gagnent le plus, suivi par les gais, les lesbiennes et, en dernier, les femmes hétérosexuelles. C'est à dire que tous les hommes gagnent plus que toutes les femmes, mais les hommes gais sont désavantagés, et les lesbiennes avantagées, comparés à leurs homologues hétérosexuels. À ce jour, peu d'études ont exploré la façon dont l'orientation sexuelle détermine les gains sur le marché du travail, contrairement à la grande disponibilité de littérature qui examine l'ampleur et la source des écarts salariaux selon le genre. Cette littérature tente d'explorer les écarts salariaux pour l'ensemble des femmes, toutes occupations confondues. Ces études sont tout à fait valides; par contre, des écarts salariaux estimés à partir de données agrégées peuvent dissimuler des variations significatives quant à l'importance et la source des désavantages selon l'âge, l'éducation, le domaine d'étude, ou la profession. L'objectif premier de cette thèse est de désagréger les écarts salariaux selon le genre et les minorités sexuelles afin d'offrir une explication plus nuancée quant à l'importance et la source de la stratification du marché du travail au Canada. Ainsi, cette thèse permettra de mieux saisir la signification des écarts salariaux résiduels ou non expliqués estimés à partir de données agrégées et jettera de la lumière sur les mécanismes à la base des désavantages salariaux. Deux des chapitres de cette thèse examinent si l'ampleur et les sources des écarts salariaux ont varié dans le temps.  </dc:abstract><ual:supervisor>Michael R Smith (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/9k41zh11g.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/8s45qc392</ual:fedora3Handle><dc:subject>Sociology</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A3t945t60h"><dcterms:title>Investigation of the mechanisms that control the pro-longevity response to mitochondrial reactive oxygen species</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Biology</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Yee, Callista</ual:dissertant><dc:abstract>In Caenorhabditis elegans, two mutations that affect mitochondrial electron transport chain subunits (isp-1 and nuo-6) result in increased mitochondrial reactive oxygen species (mtROS). These mutations cause a significant increase in lifespan relative to the wild type. Treatment with the pro-oxidant paraquat (PQ) can also significantly increase wild type lifespan, but is not additive to the lifespan of the two mutants. Using gene arrays, we determined a large overlap of differentially expressed genes between isp-1, nuo-6 and PQ treatment. These and other results are contrary the Free Radical Theory of aging and suggest that increased levels of mtROS act as a signal to extend lifespan in C. elegans. We wanted to understand how mtROS signaling is sensed and transduced in order to elicit these changes in gene expression. Many processes require components of the intrinsic apoptotic pathway to perform tasks that do not result in apoptosis (a type of cell death), for example, aspects of cell cycle regulation. Activation of the pathway by an elevation of mtROS does not affect apoptosis but protects from the consequences of mitochondrial dysfunction by triggering a unique pattern of gene expression that modulates stress sensitivity and promotes survival. In vertebrates, mtROS induce apoptosis through the intrinsic pathway to protect from severely damaged cells. Our observations in nematodes demonstrate that sensing of mtROS by the apoptotic pathway can, independently of apoptosis, elicit protective mechanisms that keep the organism alive under stressful conditions. This results in extended longevity when mtROS generation is inappropriately elevated. These findings clarify the relationships between mitochondria, ROS, apoptosis, and aging.</dc:abstract><dc:abstract>Chez Caenorhabditis elegans, des mutations affectant deux des sous-unités de la chaîne respiratoire (isp-1 et nuo-6) résultent en une augmentation du stress oxydatif mitochondrial. Ces mutations provoquent une augmentation significative de la durée de vie de ces organismes comparée a celle des organismes de type sauvage. L'exposition des vers de type sauvage à une substance pro-oxydante, le paraquat (PQ), cause une augmentation de la durée de vie, mais cet effet est non-additif à celui causé par ces deux mutations. Avec l'aide du « Gene array », nous avons pu observer que, suite à une exposition au PQ, un grand nombre de gènes réagissent de la même façon chez les mutants isp-1 et nuo-6. Ces résultats ainsi que d'autres suggèrent que les niveaux élevés d'espèces réactives oxygénées (RONS) agissent comme un signal afin de prolonger la vie chez C. elegans. Le but de cette étude était de découvrir comment la signalisation par les RONS mitochondriales est détectée et transduite afin de produire ces changements dans l'expression des gènes. Plusieurs processus, telle que la regulation du cycle cellulaire, utilisent des composants de la chaîne de signalisation apoptotique, mais ne résultent pas en apoptose (mort cellulaire programmée). Nous avons découvert que des composants de cette voie de signalisation sont requis pour l'augmentation de la durée de vie des mutants isp-1, nuo-6 et pour les organismes traités au PQ. De plus, la perte de cette voie de signalisation inverse une grande proportion des changements qui étaient observés dans l'expression des gènes. Nous avons démontré que pour induire un effet sur la longévité, la voie de signalisation n'est pas stimulée par EGL-1, comme pour l'apoptose, mais plutôt par CED-13, une protéine « BH3-seulement » alternative. L'activation de la voie de signalisation par les RONS n'affectent pas l'apoptose, mais agit comme un mécanisme de défense contre les dysfonctions mitochondriales en induisant des changements dans l'expression des gènes qui promouvoient la survie et modulent la sensibilité au stress.</dc:abstract><ual:supervisor>Siegfried Hekimi (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/1n79h709t.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/3t945t60h</ual:fedora3Handle><dc:subject>Biology</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A9019s516j"><dcterms:title>The bowed string and its playability: theory, simulation and analysis</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Schulich School of Music</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Mansour, Hossein</ual:dissertant><dc:abstract>Cette thèse décrit le développement et l'utilisation d'un modèle physique très raffiné de corde frottée qui permet l'étude de plusieurs aspects de la corde frottée, en particulier de sa jouabilité. On a remplacé les éléments d'un modèle précédemment décrit par des solutions plus précises et de nouveaux éléments ont été ajoutés pour rendre le modèle plus réaliste. On décrit tout d'abord des simulations de corde pincée puis les améliorations permettant d'inclure l'archet et le processus d'excitation par l'archet. Plusieurs propriétés de la réponse simulée de la corde pincée sont comparées aux valeurs désignées et expérimentales, ce qui confirme la précision du modèle et de ses paramètres. Une première application du modèle se concentre sur la force minimum fournie par l'archet au-dessus de laquelle le mouvement de Helmholtz est stable. Le mouvement de Helmholtz est associé au son "parlé" d'une corde frottée, en opposition avec son "sifflé" ou "craquant". On reprend une relation théorique précédemment établie pour la force minimum de fournie par l'archet, avec pour point de départ une hypothèse plus robuste de mouvement idéal au point de contact entre la corde et l'archet plutôt que l'hypothèse d'une excitation parfaitement en dents de scie au niveau du chevalet. Les simulations sont utilisées pour évaluer et valider les améliorations apportées par la nouvelle formulation en matière de précision. La relation révisée permet de faire des prédictions fondamentalement différentes, qui sont validées par les simulations. Parmi ces prédictions on trouve une augmentation des fréquences des pics dans le graphique de la force minimum fournie par l'archet par rapport aux fréquences des modes de corps responsables de ces pics. On montre que l'ampleur de l'augmentation fréquentielle est fonction de la distance entre le chevalet et le point de contact corde/archet, ce qui a d'importantes conséquencessur la jouabilité d'un instrument au voisinage de la "note du loup". En élargissant notre analyse et en restant conscient qu'il reste des améliorations à apporter pour que notre modèle puisse faire des prédictions quantitatives en accord avec les mesures, on a utilisé avec précautions le modèle pour prédire des tendances et les l'ampleur relative des résultats lorsqu'on ajoute ou retire du modèle certains détails physiques. On étudie la force minimum et la force maximum de l'archet, l'augmentation du rapport entre glissement et adhérence comparée à sa valeur théorique, le centre de gravité spectral, l'abaissement de la hauteur de jeu et le taux d'occurrences de deux régimes spéciaux de vibration appelés "les notes ALF" et le "mouvement-S". Les transitoires d'attaque sont également analysés dans le plan force de l'archet / accélération de l'archet (diagramme de Guettler).</dc:abstract><dc:abstract>This thesis describes the development of a highly refined physics-based model of a bowed string and its subsequent use to investigate several aspects of a bowed string, particularly its playability. Different components of a previously reported model are replaced by more accurate solutions, and several new features are added to make the model more realistic. Plucked-string simulations are described first, followed by enhancements to include the bow and the bowing process. Several properties of the simulated plucked response are compared to their designed values and to their experimental counterparts, which confirms the accuracy of the model and its parameters. An initial application of the model is focused on the minimum bow force above which the Helmholtz motion is sustainable. The Helmholtz motion is associated with the "speaking" sound of a bowed string, as opposed to its "whistling" or "crunching" sounds. An earlier theoretical relation for the minimum bow force is re-derived starting from a more robust assumption of an ideal stick-slip at the bowing point rather than a perfect sawtooth-shaped excitation force at the bridge. Simulations are used to evaluate and validate the improved accuracy of the new formulation. The revised relation makes some fundamentally different predictions that are confirmed by the simulations. Among those predictions is an upward shift in the frequency of the peaks in the minimum bow force plot with respect to the frequency of the body modes causing those peaks. The extent of that shift is shown to be a function of the bow-bridge distance which has important implications for the playability of an instrument close to its "wolf note". Extending the scope of our analysis and acknowledging the fact that our model is still a few steps away from making predictions in quantitative agreement with measurements, it has been cautiously used to predict the trend and the relative strength of outcome when different physical details are included or excluded from the model. The features that are investigated are the minimum and the maximum bow force, the increase in the slip-to-stick ratio compared to its theoretical value, the spectral centroid, the pitch flattening, and the rate of occurrence for two special vibration regimes called the "ALF notes" and the "S-motion". The initial transients of the bowed string are also analyzed in the bow force versus bow acceleration plane (a.k.a. the Guettler diagram).</dc:abstract><ual:supervisor>Gary Scavone (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/q811kn41m.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/9019s516j</ual:fedora3Handle><dc:subject>Music</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A4q77fv184"><dcterms:title>Energy full counting statistics in return-to-equilibrium</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Mathematics and Statistics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Panangaden, Jane</ual:dissertant><dc:abstract>On propose dans ce travail d'étudier un système quantique S de dimension finie couplé à un réservoir de chaleur quantique R infiniement étendu et en équilibre à tem- pérature β−1. Le couplage est causé par une perturbation bornée de la dynamique et l'intensité du couplage est contrôlée par un paramètre λ. Supposons que le système S + R manifeste la propriété de retour à l'équilibre, c'est-à-dire que, après longtemps, le système combiné évolue vers un état d'équilibre à temperature β−1. Dans ce contexte, on démontre un raffinement du premier principe de la thermodynamique, qui affirme que l'énérgie totale du systéme est conservée. Plus précisément, on définit deux mesures qui contiennent les informations complètes des fluctuations de l'énérgie du système et du réservoir lorsque des expériences sont effectuées aux temps 0 et t. Ces mesures s'appellent les statistiques « full counting » (FCS). On démontre la convergence faible des FCS du système et du rèservoir dans la limite t → ∞ et λ → 0.La difficulté technique se produit du fait que le réservoir est infiniement étendu. Pour définir son FCS, il faut réécrire le FCS de dimension finie en utilisant un opéra- teur modulaire: un objet qui survit la limite thermodynamique. Ensuite, on fait appel aux outils de la théorie modulaire de Tomita-Takesaki pour démontrer le théorème.</dc:abstract><dc:abstract>We consider a finite dimensional quantum system S in an arbitrary initial state coupled to an infinitely extended quantum thermal reservoir R in equilibrium at inverse temperature β. The coupling is given by a bounded perturbation of the dynamics and the coupling strength is controlled by a parameter λ. We assume the system S + R has the property of return to equilibrium, which means that after sufficiently long time, the joint system will have reached equilibrium at inverse temperature β. In this context, we prove a refinement to the first law of thermodynamics, which states that the total energy of the system and reservoir is conserved. Specifically, we define two measures which encode all the information about the fluctuations of the system and reservoir energy when two measurements are made at time 0 and time t. These measures are called the full counting statistics (FCS). We prove weak convergence of the system and reservoir FCS in the double limit t → ∞ and λ → 0.The technical difficulty comes from the fact that the reservoir is infinitely extended. In order to define the reservoir FCS, we write the finite dimensional FCS in terms of a relative modular operator: an object which survives the thermodynamic limit. We then draw on tools from Tomita-Takesaki modular theory to prove the result.</dc:abstract><ual:supervisor>Annalisa Panati (Internal/Cosupervisor2)</ual:supervisor><ual:supervisor>Vojkan Jaksic (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/1j92g9955.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/4q77fv184</ual:fedora3Handle><dc:subject>Mathematics and Statistics</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Afb494b96c"><dcterms:title>Child marriage in sub-saharan Africa: trends, effects on health, and efforts to limit the practice</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Epidemiology and Biostatistics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Koski, Alissa</ual:dissertant><dc:abstract>The marriage of any person below the age of eighteen, often referred to as child marriage, is widely considered a violation of human rights. Over the past decade the practice has garnered attention as a potential threat to women's health. Despite increasing discourse, estimates of trends in the prevalence of child marriage are dated and methodological challenges plague published studies of the relationship between child marriage and health. My thesis provides an updated examination of trends in sub-Saharan Africa, where rates of child marriage are highest, and aims to address some of the difficulties inherent in estimating the effects of child marriage on women's health. The first manuscript in this thesis describes changes in the prevalence of child marriage in twenty-nine sub-Saharan African countries over a twenty-year period. I used a novel estimation technique to avoid biases that may have affected earlier studies. My results indicate that the prevalence of child marriage has declined over time but the rate of decline has stagnated in some countries. Estimating the effects of child marriage on health is challenging for many reasons. The exposure is difficult to define and measure. Women married as children differ in many ways from their peers who married later in life, leading to concerns regarding confounding. I provide a critical evaluation of child marriage as a treatment within the potential outcomes framework and describe the challenge of approximating a causal contrast using observational data. The second manuscript included in this thesis makes the assumptions required for effect estimation more transparent through the use of matching techniques to estimate the effect of child marriage on the risk of domestic violence. Improving educational opportunities for girls is a promising mechanism for delaying marriage. Since the 1990s many sub-Saharan African countries have adopted legislation that prohibits public primary schools from charging tuition fees. Reducing financial barriers to schooling may result in greater educational attainment, particularly for girls. The third manuscript describes my evaluation of the effect of these legislative changes on the timing of reproductive events among girls in sixteen countries. Child marriage remains a pervasive violation of human rights that disproportionately affects girls throughout the developing world. Upholding these rights requires knowledge of the geographic distribution of child marriage and the effectiveness of policies that aim to end the practice. This thesis represents my contribution to this effort.</dc:abstract><dc:abstract>Le mariage de toute personne de moins de 18 ans, souvent appelé le mariage d'enfants, est largement considéré comme une violation des droits de la personne. Dans la dernière décennie, cette pratique a retenu l'attention, car elle représenterait une menace pour la santé des femmes. Malgré une réflexion grandissante, les estimations des tendances de la prévalence du mariage d'enfants sont anciennes, et des difficultés méthodologiques omniprésentes compromettent les publications portant sur la relation entre le mariage d'enfants et la santé des femmes. Ma thèse fournit un examen actualisé des tendances en Afrique subsaharienne où les taux de mariage d'enfants sont les plus élevés. Elle vise également à aborder certaines des difficultés inhérentes à l'estimation des effets du mariage d'enfants sur la santé des femmes. Le premier manuscrit de cette thèse décrit les variations observées de la prévalence du mariage d'enfants dans vingt-neuf pays d'Afrique subsaharienne sur une période de vingt ans. J'utilise une nouvelle approche afin d'éviter les biais ayant probablement affecté les estimations des études precedents. Mes résultats indiquent que la prévalence du mariage d'enfants décline avec le temps, mais que le taux de déclin stagne dans certains pays. L'estimation des effets du mariage d'enfants sur la santé est difficile pour plusieurs raisons. Cette exposition est complexe à définir et à mesurer. Les femmes mariées pendant l'enfance se distinguent de maintes façons des femmes qui se marient plus tard, ce qui entraîne des biais de confusion. J'établis une évaluation critique du mariage d'enfants en tant que variable de traitement dans le cadre théorique « des résultats potentiels » (potential outcomes framework) et je décris la difficulté que constitue l'approximation d'un contraste causal à partir de données observationnelles dans ce cadre. Le deuxième manuscrit de cette thèse clarifie les hypothèses nécessaires pour estimer l'effet du mariage d'enfants sur le risque de violence domestique grâce à l'utilisation de techniques d'appariement. L'amélioration des possibilités éducationnelles pour les filles est un mécanisme prometteur de retardement du mariage. Depuis les années 90, de nombreux pays subsahariens ont voté des lois interdisant aux écoles primaires publiques de facturer des frais de scolarité. La réduction des contraintes financières en éducation peut entraîner un meilleur niveau éducationnel, particulièrement chez les filles. Le troisième manuscrit décrit mon évaluation de l'effet de ces changements législatifs sur le calendrier des événements reproductifs des filles dans seize pays. Le mariage d'enfants reste une violation persistante des droits de la personne affectant disproportionnément les filles des pays en développement. Le respect de ces droits nécessite une connaissance de la distribution géographique du mariage d'enfants et l'efficacité de politiques visant à éradiquer cette pratique. Cette thèse représente ma contribution à cet effort.</dc:abstract><ual:supervisor>Arijit Nandi (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/x920g032f.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/fb494b96c</ual:fedora3Handle><dc:subject>Epidemiology and Biostatistics</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Acv43p085p"><dcterms:title>Spontaneous mutation rates and spectra with and without the influence of natural selection in Daphnia pulex</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Biology</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Flynn, Jullien</ual:dissertant><dc:abstract>Les mutations spontanées sont la source ultime de toute la diversité génétique et fournissent de potentielles modifications phénotypiques, sur laquelle la sélection naturelle peut agir. La compréhension des taux, des types de mutations et de leurs effets sur la valeur sélective est essentielle pour beaucoup des domaines de la biologie. Ainsi, quelques études ont cherché à faire la lumière sur ce phénomène fondamental au cours des dernières années. Cependant, les connaissances sont limitées au sujet des taux de mutations chez la plupart des organismes, et la façon dont la sélection naturelle se comporte sur de nouvelles mutations dans une population. Ma thèse tente de combler ces insuffisances en analysant les génomes de lignées de mutation accumulation (MA) de Daphnia pulex qui étaient maintenues dans des conditions avec un minimum de sélection, et de plus des individus d'une population qui était fondée par le même ancêtre et maintenue en laboratoire avec sélection pendant la duration de l'expérimente. Ce protocole expérimental permet de comparer les taux, types et distribution des mutations accumulées dans des conditions sans sélection, par rapport aux conditions avec sélection. Les daphnies ont été élevées pour qu'elles se reproduisent de manière asexuée, ce qui a permis la détection des nouvelles mutations étant hétérozygote et également des mutations à grande échelle qui causent une perte d'hétérozygotie (PDH). En faisant la séquençage de 24 lignées MA,  j'ai découvert 477 mutations ponctuelles et établi que le taux de mutations des daphnies ressemble à cela des autres métazoaires. Une lignée MA a subi un nombre énorme de PDH d'un chromosome complet (3 % du génome). En plus, j'ai séquencé six individus de la population et découvert moins de mutations que prévu, ce qui démontre que la sélection purificatrice était forte afin d'éliminer des mutations nuisibles qui diminuent la valeur sélective. Cependant, étonnamment, la population a maintenu un niveau élevé de diversité génétique, avec quatre lignées indépendantes entre six individus. Cela a probablement été provoqué par la sélection diversificatrice. Les conclusions de cette thèse contestent l'hypothèse que la sélection naturelle est inefficace dans les populations asexuées, fournissent un cas du maintien de la diversité, et fournissent un aperçu de la diversité et des conséquences des mutations chez la daphnie.</dc:abstract><dc:abstract>Spontaneous mutations are the ultimate source of genetic variation, which can generate phenotypic variation upon which natural selection can act. Understanding the rates, patterns, and fitness effects of mutation is essential to many fields of biology, thus several studies have attempted to investigate this fundamental phenomenon over the years. However, knowledge is still limited regarding the mutation rates in most organisms as well as the way selection acts on new mutations in a population. My thesis seeks to increase the understanding of the evolutionary phenomena of mutation and selection by analysing the genomes of mutation accumulation (MA) lines of Daphnia pulex maintained under selection-minimized conditions for many generations as well as isolates from a laboratory population that was founded with the same asexual progenitor and was maintained with selection acting throughout the course of the experiment. This unique experimental setup allows comparison of the rates, types, and patterns of mutations accumulated in conditions with and without selection. The Daphnia were propagated asexually, which allowed the detection of new mutations in a heterozygous state as well as large-scale mutations that result in loss of heterozygosity (LOH). Whole genome sequencing of 24 MA lines facilitated the detection of 477 single nucleotide mutations, and I found that the overall mutation rate in Daphnia is similar to that of other metazoans. One MA line experienced a massive LOH event that caused complete homozygosity across an entire chromosome (3% of the genome), resulting from a large gene conversion event. I also sequenced six isolates from the laboratory population and found fewer mutations than expected, demonstrating that purifying selection was acting strongly in order to purge harmful mutations that decrease fitness. Surprisingly though, the population maintained a high level of genetic diversity, with four distinct lineages from only six individuals. This observed pattern of high diversity was likely driven by balancing selection. My work challenges the assumption that selection is inefficient in asexual populations, provides an example of high diversity maintenance, and provides insight into the entire spectrum and implications of mutation in Daphnia.</dc:abstract><ual:supervisor>Elena Cristescu (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/xg94hs34j.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/cv43p085p</ual:fedora3Handle><dc:subject>Biology</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Akd17cw74j"><dcterms:title>Tuning in or out? Understanding the consequences of body-focused attention during exercise</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Psychology</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Ivanova, Elena</ual:dissertant><dc:abstract>La conscience de sensations corporelles est inévitable lorsqu'on s'entraine à un niveau d'intensité élevée. À une intensité basse à moyenne, la personne qui s'entraine peut se distraire des sensations corporelles ou peut porter attention volontairement à ses sensations corporelles. Cette thèse soulève deux questions de recherche: Premièrement, est-ce que porter attention volontairement aux sensations corporelles en s'entrainant physiquement empêche ou facilite l'acte de l'entrainement physique au fil du temps? Deuxièmement, est-ce qu'une intervention psychologique peut aider les personnes s'entrainant physiquement à faire face aux sensations corporelles liées à l'exercice à haute intensité? L'Étude 1 présente les propriétés psychométriques d'une échelle nouvellement créée: Porter Attention aux Sensations Corporelles durant l'Activité Physique (PASC-AP) (Ivanova et al., sous revisions). J'ai créé cette échelle pour mesurer le degré auquel les individus rapportent rétrospectivement une tendance à porter attention à leur sensations corporelles en s'entrainant. Les découvertes de l'Étude 1 apportent une évidence initiale pour la validité de l'échelle PASC-AP.  Les résultats démontrent que l'échelle PASC-AP peut être utilisée pour évaluer rétrospectivement la tendance à porter attention volontairement aux sensations corporelles en s'entrainant. L'Étude 2 a examiné si l'échelle PASC-AP prédit l'exercice fréquent au fil du temps parmi des individus avec des habitudes d'exercice physique différentes (Ivanova et al., sous révisions). Comme anticipé, PASC-AP était associée à un entrainement plus fréquent pour les individus s'entrainant d'une façon consistante. Contrairement, PASC-AP prédit un entrainement moins fréquent pour les individus s'entrainant d'une façon non-consistante. Étonnamment, PASC-AP n'était pas relié à la fréquence de l'entrainement pour les individus sans habitude d'entrainement. Déterminer si porter attention aux sensations corporelles durant l'entrainement est un crucial prédicteur d'habitude d'entrainement a des implications importantes: Des interventions cognitives, telle que celle présentée dans l'Étude 3, pourraient être conçus. L'Étude 3 était un essai randomisé contrôlé qui testait l'efficacité d'une intervention psychologique basée sur la thérapie d'acceptation et d'engagement qui a pour but de fournir des stratégies cognitives pour aider les femmes faiblement actives à faire face aux sensations corporelles présentes durant un entrainement à haute intensité (Ivanova et al., 2015). Tel qu'anticipé, les stratégies cognitives aidaient les femmes faiblement actives à s'entrainer physiquement pour une période de temps prolongée tout en rapportant moins de fatigue et une augmentation de bien-être après la session d'entrainement.  Au total, en utilisant l'échelle APS -PA, j'ai découvert qu'il est au détriment des individus s'entrainant d'une façon non-consistante de porter attention à leurs sensations corporelles durant l'entrainement. Cette découverte est attestée par un comportement d'entrainement physique moins fréquent au fil du temps. Pour les individus s'entrainant d'une façon consistante, porter attention aux sensations corporelles durant l'entrainement prédisait un comportement d'entrainement physique plus fréquent. Dernièrement, l'Étude 3 présente les découvertes d'un essai randomisé contrôlé qui a démontré qu'une intervention cognitive visant à enseigner aux individus comment apprécier et accepter les sensations corporelles durant l'entrainement peut améliorer les résultats liés à l'entrainement physique incluant la durée de l'entrainement physique. Au total, cette thèse aide à expliquer l'importance de la conscience des sensations corporelles dans le contexte de l'entrainement physique, démontrant que porter attention volontairement au sensations corporelles ne prédit pas les comportements d'entrainement physique pour toute personne.</dc:abstract><dc:abstract>Awareness of physical sensations is inevitable while exercising at high exercise intensities. At lower-to-moderate intensities, exercisers can either distract from the body sensations or they can tune in voluntarily to their body. This dissertation addresses two research questions: First, does voluntarily paying attention to the body while exercising hinder or facilitate exercise behaviour over time? Second, can psychological interventions assist exercisers in coping with the body sensations associated with exercising at high intensity? Study 1 presents the psychometric properties of a newly created Attention to Physical Sensations during Physical Activities (APS-PA) scale (Ivanova et al., under review). I created this scale to measure the degree to which individuals retrospectively report a tendency to tune in to their physical sensations while exercising. The findings of Study 1 provide initial evidence for the validity of the APS-PA. The results demonstrate that the APS-PA scale can be used to retrospectively assess the tendency to voluntarily pay attention to the body while exercising. Study 2 examined if the APS-PA predicts exercise frequency over time among individuals with different exercise patterns (Ivanova et al., under review). As expected, APS-PA was associated with increased exercise frequency over time for consistent exercisers. Conversely, APS-PA predicted decreased exercise frequency for inconsistent exercisers. Unexpectedly, APS-PA was not related to exercise frequency for individuals with no exercise pattern. Determining if APS-PA is a critical predictor of exercise behaviour has important implications: Cognitive interventions such as the one presented in Study 3 could be tailored to these individuals.Study 3 was a randomized controlled trial that tested the efficacy of a psychological intervention based on acceptance and commitment therapy that aimed to provide cognitive strategies for low active women to cope with the physical sensations when exercising at high intensities (Ivanova et al., 2015). As expected, the cognitive strategies assisted the low-active women to exercise for longer while reporting less exertion and increased post-exercise enjoyment. Altogether, using the APS-PA this scale, I found that it is detrimental for individuals who are irregular exercisers to tune in to their bodies during exercise, as evidenced by lower exercise behaviour over time. For individuals with consistent exercise patterns, tuning in to the physical sensations predicted increased exercise frequency. Lastly, Study 3 presents findings of a randomized controlled trial that showed that a cognitive intervention aimed to teach individuals how to appraise body sensations during exercise with acceptance can improve exercise-related outcomes including exercise duration times. Altogether, this dissertation shed light on the importance of body awareness in the context of exercise, indicating that voluntarily tuning in does not universally predict exercise behaviour.</dc:abstract><ual:supervisor>Baerbel Agnes Knaeuper (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/4t64gq958.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/kd17cw74j</ual:fedora3Handle><dc:subject>Psychology</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Afn1071696"><dcterms:title>Towards a better understanding of episodic memory deficits in schizophrenia: insights from neuroimaging and cognitive training</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Psychology</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Guimond, Synthia</ual:dissertant><dc:abstract>Episodic memory allows us to remember different events as well as their context, and therefore plays a critical role in our daily life. On average, schizophrenia patients display poorer episodic memory in comparison to healthy individuals, which can negatively affect their community functioning and outcome. Episodic memory deficits in schizophrenia remain an unmet therapeutic need, in part due to our lack of understanding of their underlying mechanisms and neural correlates. The primary objectives of this thesis were: 1) to better understand episodic memory impairments in schizophrenia, and 2) to develop a method to ultimately help patients in improving this cognitive capacity. First, we investigated the neural correlates of episodic memory deficits in patients with enduring schizophrenia, which remain poorly understood. To this end, we initially explored the relationship between verbal episodic memory deficits and cortical thickness. Thinner cortex in the left dorsolateral prefrontal cortex was found solely in patients with severe verbal episodic memory impairments. These results support the implication of this brain structure in episodic memory deficits in schizophrenia. Moreover, it has been suggested that episodic memory performance in patients is related to their difficulties to initiate effective encoding strategies. Using functional magnetic resonance imaging (fMRI), we investigated brain activity associated with impaired self-initiation of semantic encoding strategies. We identified that reduced activity in the left dorsolateral prefrontal cortex plays a key role underlying the difficulties in patients to self-initiate these strategies.Second, based on the above findings, we developed a novel and brief memory training, which aimed to increase the use of effective semantic encoding strategies in schizophrenia patients. We investigated the impact of this novel training paradigm on episodic memory performance and on brain functioning using fMRI. Results showed that the training improved the self-initiation of encoding strategies and was related to an increase in brain activity in the left dorsolateral prefrontal cortex. In conclusion, the results from this thesis enhance our understanding of the role of the prefrontal cortex in memory deficits in schizophrenia. Our findings suggest that the left dorsolateral prefrontal cortex is a critical structure related to episodic memory impairments in schizophrenia. Importantly, current results also support that prefrontal cortical functions are restorative in schizophrenia. Therefore, future treatments targeting this brain region, such as pharmacotherapy, cognitive training, or brain stimulation, should be encouraged. Improvement of episodic memory and underlying prefrontal function holds promise for ameliorating clinical outcome and general functioning in schizophrenia patients.</dc:abstract><dc:abstract>La mémoire épisodique nous permet de nous souvenir des événements et de leur contexte.  Elle est donc essentielle au bon déroulement de notre vie quotidienne. En général, les patients atteints de schizophrénie ont une mémoire épisodique inférieure à la moyenne de la population, ce qui peut affecter négativement leur fonctionnement dans la communauté, ainsi que l'issue de leur maladie. Les difficultés de mémoire épisodique dans la schizophrénie représentent un besoin thérapeutique non comblé, en partie en raison du manque de connaissance sur les mécanismes qui y sont sous-jacents, tel que les corrélats neuronaux.Les objectifs généraux de cette thèse étaient : 1) de mieux comprendre les difficultés  au niveau de la mémoire épisodique qui accompagnent la schizophrénie, et 2) de développer une méthode pour aider les patients à améliorer cette capacité cognitive.En premier lieu, nous avons étudié les corrélats neuronaux des troubles de la mémoire épisodique chez les patients atteints de schizophrénie chronique qui restaient peu étudiés à ce jour. Nous avons donc tout d'abord investigué la relation entre les déficits de la mémoire épisodique verbale des patients et l'épaisseur corticale de diverses régions cérébrales importantes pour mémoriser l'information. Nous avons observé un cortex plus mince au niveau du cortex préfrontal dorsolatéral gauche uniquement chez les patients présentant d'importants troubles de la mémoire verbale épisodique. Ces résultats suggèrent donc que cette région corticale est impliquée dans les déficits de mémoire épisodique associée à la schizophrénie. De plus, les faibles performances en mémoire épisodique des patients ont souvent été associées à leur difficulté d'initier des stratégies d'encodage sémantiques. En utilisant l'imagerie par résonance magnétique fonctionnelle (IRMf), nous avons étudié l'activité cérébrale associée au déficit d'auto-initiation de ces stratégies chez des patients ayant la schizophrénie. Nous avons été en mesure de constater qu'une réduction de l'activité cérébrale au niveau du cortex préfrontal dorsolatéral gauche est associée aux difficultés à auto-initier des stratégies d'encodage sémantiques chez les patients.En deuxième lieu, en s'appuyant sur les résultats présentés ci-haut, nous avons développé un nouvel entrainement cognitif bref et spécifique qui visait à accroître l'utilisation des stratégies efficaces d'encodage sémantiques. Nous avons aussi évalué l'impact de ce module d'entraînement sur la performance en mémoire épisodique des patients, ainsi que sur le fonctionnement de leur cerveau via l'IRMf. Nos résultats ont démontré que cet entrainement permet d'améliorer l'auto-initiation de ces stratégies et d'accroitre l'activité cérébrale du cortex préfrontal dorsolatéral gauche des patients. En conclusion, ces résultats permettent de mieux comprendre le rôle du cortex préfrontal dans la schizophrénie, en particulier dans le contexte de leurs difficultés mnésiques. Nos résultats suggèrent que le cortex préfrontal dorsolatéral gauche est une structure critique impliquée dans les difficultés de mémoire épisodique des patients. De plus, nos données confirment que les fonctions corticales préfrontales peuvent être restaurées en schizophrénie. Par conséquent, les traitements ciblant cette région du cerveau, que ce soit par le moyen de la médication, l'entraînement cognitif, ou la stimulation cérébrale, devraient être encouragés dans le futur. L'amélioration de la mémoire épisodique ainsi que des fonctions cérébrales sous-jacentes est prometteuse et donne espoir qu'un jour on puisse arriver à accroitre le fonctionnement général des patients qui vivent avec la schizophrénie. </dc:abstract><ual:supervisor>Martin Lepage (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/j098zd899.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/fn1071696</ual:fedora3Handle><dc:subject>Psychology</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A3484zk36g"><dcterms:title>Role of CUX1 DNA repair function in the resistance of cancer cells to ionizing radiation</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Biochemistry</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Donovan, Caroline</ual:dissertant><dc:abstract>More than 50% of cancer patients are treated with radiotherapy. Unfortunately, cancer cells driven by a RAS oncogene exhibit resistance to radiotherapy. Previous studies established that CUX1 knockdown is synthetic lethal to cancer cells carrying a RAS oncogene. The decrease in viability following CUX1 knockdown was associated with an increase in oxidative DNA damage. Mechanistically, the Cut repeat domains within p200 CUX1 were found to stimulate the enzymatic activities of the 8-oxoguanine DNA glycosylase 1 (OGG1) and the apurinic/apyrimidinic endonuclease 1 (APE1), two enzymes of the base excision repair (BER) pathway involved in the repair of oxidized bases and apurinic/apyrimidinic (AP) sites, respectively. In agreement with these results, repair of oxidative DNA damage is accelerated following ectopic p200 CUX1 expression and delayed after CUX1 knockdown. Since oxidized bases and apurinic/apyrimidinic (AP) sites are produced by ionizing radiation, we hypothesized that CUX1 may contribute to the resistance of cancer cells to ionizing radiation through its function as an accessory factor for OGG1 and APE1. In turn, inhibition of CUX1 DNA repair activity would sensitize cancer cells to ionizing radiation. To validate CUX1 as a therapeutic target, we initiated a series of experiments to test the effect of CUX1 knockdown and overexpression on the resistance of cancer cells to ionizing radiation. The goal of my project was to choose and optimize the assays that would enable us to perform these experiments. In parallel, I performed preliminary experiments to investigate the effects of CUX1 knockdown and overexpression on the resistance of cancer cells to ionizing radiation and other treatments that increase oxidative DNA damage. After optimizing the methyl-14C thymidine incorporation assay and the single-cell gel electrophoresis (comet) assay, I observed across a panel of tumour cell lines that CUX1 knockdown sensitizes cancer cells to radiations and to an agent causing oxidative DNA damage (TH588c), whereas CUX1 overexpression confers radio-resistance. Importantly, a recombinant CUX1 protein containing only two Cut repeats (CR1CR2) is devoid of transcriptional activity, but is still able to stimulate DNA repair and confer radio-resistance. Similarly, OGG1 overexpression confers radio-resistance to DLD-1 colorectal cells, but not to "normal" retinal pigment epithelial cells (RPE1), whereas OGG1 knockdown sensitizes both DLD-1 and U251 glioblastoma cells to radiations. My work will help establish the proof-of-principle that Cut repeat domains represent a valuable therapeutic target in sensitizing tumor cells to radiotherapy.</dc:abstract><dc:abstract>Plus de 50% des patients atteints de cancer sont traités par radiothérapie. Malheureusement les cellules cancéreuses stimulées par un oncogène RAS montrent une plus grande résistance à la radiothérapie. Des études antérieures ont établi que l'inhibition de l'expression du gène CUX1 cause la létalité pour les cellules cancéreuses porteuses d'un oncogène RAS, mais pas pour les cellules normales, un phénomène appelé "létalité synthétique". On a de plus montré que la létalité dans les cellules cancéreuses était associée à une augmentation des lésions oxydatives dans l'ADN. Précisément, on a trouvé que les domaines CUT (aussi appelés répétitions Cut) de l'isoforme CUX1 p200  stimulaient les activités enzymatiques de la 8-oxoguanine glycosylase 1 (OGG1) et de l'endonucléase spécifique aux sites apurinique/apyrimidinique, APE1. Ces deux enzymes exécutent les premières réactions enzymatiques de la voie de réparation des bases (BER pour Base excision repair en anglais). OGG1 a une activité glycosylique qui enlève la base oxydée, et une activité AP/lyase qui introduit une coupure simple brin. APE1 est une endonucléase qui reconnaît les sites abasiques et introduit une coupure simple brin. En accord avec ces résultats, la réparation des lésions oxydatives de l'ADN est accélérée suite à l'expression ectopique de CUX1 p200, mais retardée suite à l'inhibition de l'expression de CUX1. Puisque les bases nucléiques oxydées et les sites apuriniques/ apyrimidiniques représentent une large proportion des lésions produites par radiations ionisantes, nous avons émis l'hypothèse que CUX1 pouvait contribuer à la résistance des cellules cancéreuses aux radiations ionisantes par le biais de son rôle de facteur accessoire de OGG1 et APE1. À l'inverse, l'inhibition de l'activité réparatrice de CUX1 pourrait sensibiliser les cellules cancéreuses aux radiations ionisantes. La confirmation de cette hypothèse permettrait de valider CUX1 comme cible thérapeutique.  Nous avons donc entrepris une série d'expériences pour tester l'effet de l'inhibition de l'expression de CUX1, ou l'effet de sa surexpression, sur la résistance des cellules cancéreuses aux radiations ionisantes. Le but de mon projet était dans un premier temps de sélectionner et d'optimiser les tests pertinents à ces expériences, et dans un deuxième temps d'effectuer  des expériences préliminaires pour examiner le rôle de CUX1 dans la résistance des cellules cancéreuses aux radiations ionisantes ainsi qu'à d'autres traitements qui augmentent les lésions oxydatives dans l'ADN. Après optimisation des tests de mesure de l'incorporation de la thymidine marquée au 14C et l'électrophorèse de cellules isolées (aussi appelé test de comète), j'ai pu observer dans plusieurs lignées de cellules cancéreuses que l'inhibition de l'expression de CUX1 rend les cellules cancéreuses plus sensibles aux radiations ionisantes ainsi qu'à un agent qui produit des lésions oxydatives dans l'ADN, le TH588c. Au contraire, la surexpression de CUX1 rend les cellules cancéreuses plus résistantes à ces traitements. Plus encore, une protéine recombinante qui contient seulement deux répétitions Cut (CR1CR2) est dépourvue d'activité transcriptionnelle, mais est quand même capable de stimuler la réparation de l'ADN et de conférer la résistance aux radiations. De la même façon, la surexpression d'OGG1 confère la résistance aux radiations aux cellules colorectales DLD-1 et aux cellules de glioblastome U251. En conclusion, mes résultats contribuent à valider CUX1 comme cible thérapeutique dont l'inhibition permettrait de sensibiliser les cellules cancéreuses aux traitements de radiothérapie sans toutefois causer des effets néfastes aux cellules normales qui ne sont pas irradiées.</dc:abstract><ual:supervisor>Alain Nepveu (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/s4655k21h.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/3484zk36g</ual:fedora3Handle><dc:subject>Biochemistry</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Azk51vk56g"><dcterms:title>Numerical modeling of SLD secondary droplet flows for in-flight icing</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Mechanical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Bilodeau, David</ual:dissertant><dc:abstract>Le givrage en vol représente un risque grave pour la sécurité aérienne pouvant causer des pertes de performance conduisant à une perte de contrôle. Le phénomène est la cause de nombreux incidents et accidents. La majorité des gouttelettes surfondues rencontrées en vol sont de petite taille et adhérent rapidement aux surfaces qu'elles impactent. Elles gèlent soit immédiatement ou s'écoulent le long de la surface, portées par les forces aérodynamiques. Lorsque des gouttelettes plus grosses, dites SLD, impactent la surface, elles peuvent être soit coller à la surface, s'étendre, se fragmenter et éclabousser, ou rebondir dans le courant d'air. De telles gouttelettes qui rebondissent, lorsqu'elles se réintègrent au flux d'air, peuvent impacter d'autres régions non-protégées, en aval sur l'avion. De plus, elles peuvent s'écouler jusqu'en en bordure de la surface et réintégrer le flux d'air. Une approche Eulérienne est présentée, tenant compte de l'écoulement secondaire de gouttelettes SLD causé par leur éclatement et rebondissement. Le coût de calcul est optimisé par une méthode de regroupement statistique. L'approche numérique découple les conditions pré- et post-impact en des domaines de calcul indépendants. Suite à ce processus, les solutions pré- et post-impact sont combinées en une solution finale conservant la masse totale du système. Dans cette méthodologie, chaque facette surfacique est en effet une simulation secondaire unique. Le temps et coûts de calcul de telles simulations supplémentaires étant très élevés, des approches statistiques sont utilisées. Des critères de partitionnement des gouttelettes secondaires sont testés sur une aile à éléments multiples en deux dimensions. La comparaison avec les données expérimentales démontre une amélioration par rapport à un simple post-traitement des données, ainsi qu'en comparaison aux approches non conservatrices. La méthodologie est acceptable par rapport à l'approche assez coûteuse sans partitionnement. L'approche est par la suite appliquée à une aile tridimensionnelle à rabat et latte étendus et les effets d'éclaboussure et rebondissement sont examinés après cinq minutes de cumul de glace. Par la suite, un modèle bidimensionnel est proposé pour déterminer la taille minimale de gouttelettes pouvant s'arracher à partir d'un coin géométrique. Le modèle manque toutefois de validation et, lorsqu'il est étendu à trois dimensions, l'hypothèse d'un couplage à sens unique avec le flux d'air est jugée inappropriée. Un modèle tridimensionnel est alors proposé et validé sur une plaque plane. Le modèle se compare bien avec les données expérimentales et est appliqué à une aile, démontrant un effet minime sur l'impact global. Finalement, le modèle est appliqué à un problème de turbomachines où la teneur plus élevée en eau liquide et la plus courte longueur de corde sont présumés augmenter l'effet des gouttelettes secondaires sur les composantes en aval. Un effet minimal est à nouveau observé. Enfin, l'approche est appliquée à un rotor d'hélicoptère en vol stationnaire pour évaluer l'effet potentiel de gouttelettes secondaires, et, à nouveau, l'effet se montre minimal.</dc:abstract><dc:abstract>In-flight ice accretion poses a serious risk to the safety of air travel as it may cause performance degradation and loss of control. It is reported as being the cause of many incidents and accidents. Most of the supercooled droplets encountered during flight conditions are small in nature and, as such, adhere quickly to the surface where they impinge and either freeze where they first impact the surface or runback along the surface due to aerodynamic forces acting on the droplets during the freezing process. On the contrary, when supercooled large droplets (SLD) impinge on a surface, they may stick, fragment and splash, or bounce back into the airstream surrounding the surface. These rebounded droplets may impinge at an unprotected location on an aircraft. Additionally, the larger droplets may runback along the surface with a longer freezing time, arriving at a trailing edge and be entrained again in the airflow. An Eulerian approach to account for the secondary droplet flow resulting from splashing and bouncing of supercooled large droplets on aircraft surfaces is presented and optimized to reduce computational cost via statistical clustering approaches. The numerical approach presented decouples pre- and post-impact conditions into separate computational domains. After computing the post-impact computational simulations to account for splashed and bounced droplets, the pre- and post-impact solutions are combined for a final solution, having conserved mass in the system. In the proposed approach, each surface facet could be a unique secondary simulation. As the computation of an additional simulation for each surface facet is quite high, statistical approaches are used to combine the secondary solutions to provide a lower cost approach to estimate the effect of splashing and bouncing on aircraft surfaces. Criteria are proposed for grouping predicted secondary droplets, and are tested on a multi-element two-dimensional airfoil. Comparison with experiment shows improvement over simple post-processing, non-conservative approaches, with an acceptable level of error compared to a costly, straightforward non-clustered approach. The approach is then applied to a three-dimensional multi-element wing with flap and slat extended and the effect of the splashing and bouncing on a five-minute ice accretion is examined.A two-dimensional model to determine the minimum size of liquid droplets detaching from a geometric corner is proposed first. The model lacks validation and when extended to three-dimensions, the assumption of one-way coupling with the airflow is deemed inappropriate. A three-dimensional model to predict the detaching of droplets from a geometric corner is then proposed and validated against the limited experimental data available for detachment from a flat plate. This is accomplished by assuming that the angle subtending the corner approaches 180°. The model compares well with the limited experimental data for detaching droplet sizes. Subsequently, the model is applied to a three-dimensional wing with minimal observed effect on the ice accreted in time. Additionally, the model is applied to turbomachinery problems where the higher liquid water content and shorter chord length is presumed to increase the effect of the secondary droplets on the downstream components. Minimal effect was again observed of the detaching mass from the trailing edge of a turbofan blade. Finally, the splashing and bouncing approach along with the detachment model are applied to a three-dimensional rotor in hover to assess the potential effect of secondary droplets on a helicopter in flight, which, again, proves minimal.</dc:abstract><ual:supervisor>Wagdi George Habashi (Supervisor1)</ual:supervisor><ual:supervisor>Marco Fossati (Supervisor2)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/pk02cd56c.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/zk51vk56g</ual:fedora3Handle><dc:subject>Mechanical Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A8g84mq109"><dcterms:title>The role of microbial dissimilatory iron reduction in the formation of Proterozoic molar tooth structures</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Earth and Planetary Sciences</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Hodgskiss, Malcolm</ual:dissertant><dc:abstract>Les structures de "dents molaires" sont des structures carbonatées énigmatiques qui surviennent lorsque de la calcite microcristalline se retrouve sous forme de filaments et de masses au sein de carbonates argileux. Les observations de terrain indiquent que les structures de "dents molaires" se forment dans la partie supérieure de la colonne sédimentaire, et ce avant la lithification de la roche mère. Ces structures se retrouvent dans de nombreux bassins du Protérozoïque à travers le monde, et sont observées dans le registre sédimentaire entre approximativement 2600-720 Ma. Malgré leur présence répandue, les raisons de leur formation et de leur disparition au sein du registre sédimentaire demeurent peu comprises. De plus, même si les structures de "dents molaires" sont presqu'exclusivement présentes dans des sédiments carbonatés riches en argile, aucune étude géochemique explorant cette relation n'a été réalisée jusqu'à maintenant. Ici, nous présentons des analyses isotopiques du carbone, de l'oxygène, et du fer, en plus des concentrations des éléments majeurs et mineurs, pour 77 échantillons de structures de "dents molaires". Ces échantillons proviennent de huit bassins différents, et couvrent une période d'environ 700 Ma. Nous testons ici l'hypothèse que la réduction dissimilatrice du fer est à l'origine de la formation des structures de "dents molaires", c'est-à-dire que la réduction microbienne du Fe(III) en Fe(II) prend en présence des oxydes et smectites riches en fer. Cette réduction entraine le rétrécissement et la défloculation des minéraux argileux, créant ainsi des vides ou pores dans lesquels la formation des structures de "dents molaires" peut prendre place, tout en augmentant localement l'alcalinité de l'eau interstitielle jusqu'à atteindre le seuil auquel la calcite microcristalline peut précipiter. Les mesures du δ56Fe soutiennent l'hypothèse selon laquelle la réduction dissimilatrice du fer serait à l'origine de la formation des structures de "dents molaires". En effet, ces structures sont typiquement appauvries en δ56Fe par rapport aux minéraux carbonatés et siliclastiques présents dans la roche mère. Les mesures de δ13C des structures de "dents molaires" et de la matrice carbonatée sont indifférenciables. Les résultats de cette étude montrent donc que l'apparition et la disparition des structures de "dents molarires" sont loin d'être des évènements négligeables, et reflètent plutôt une Terre en transition.</dc:abstract><dc:abstract>Molar tooth structures are enigmatic carbonate structures that occur as microcrystalline calcite ribbons and blobs within argillaceous carbonates. Field observations indicate that they formed in the uppermost sediment column, prior to lithification of the host rock. Molar tooth structures have been found in numerous Proterozoic basins throughout the world, and are observed in the sedimentary record between approximately 2600-720 Ma. Despite their widespread occurrence, both their cause of formation and disappearance from the sedimentary record remain poorly understood. Although molar tooth structure occurrence is near-exclusive to clay-rich carbonate sediments, to date there has been no geochemical study exploring this relationship. Here, we present carbon, oxygen, and iron isotope analyses, in addition to major/minor element concentrations, for 77 molar tooth structure samples from eight different basins spanning approximately 700 Ma. We test a dissimilatory iron reduction hypothesis for the origin of molar tooth structures, in which microbial reduction of Fe(III) to Fe(II) occurs in Fe-rich smectites and oxides. The resulting shrinkage and deflocculation of clay minerals would create the void spaces in which molar tooth structures form, while locally increasing pore water alkalinity beyond a threshold at which microcrystalline calcite begins to precipitate. Measurements of δ56Fe are supportive of a dissimilatory iron reduction mechanism for molar tooth structure formation, with molar tooth structures typically depleted in δ56Fe relative to both the carbonate minerals and siliciclastic minerals in the host sediment. δ13C measurements of the molar tooth structures and matrix carbonate are indistinguishable. The findings of this study show that the appearance and disappearance of molar tooth structures are not insignificant events, but rather are reflective of an Earth in transition.</dc:abstract><ual:supervisor>Galen Halverson (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/9k41zh12r.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/8g84mq109</ual:fedora3Handle><dc:subject>Earth and Planetary Sciences</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Agt54kq773"><dcterms:title>Le français dans un espace non-francophone et plurilingue: le cas du Nigéria</dcterms:title><ual:graduationDate>2016</ual:graduationDate><dcterms:language>fre</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of French Language and Literature</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Akinpelu, Michael</ual:dissertant><dc:abstract>Pourquoi le français ne remplit-il pas encore des fonctions formelles au Nigéria, alors que la langue jouit du statut de langue officielle depuis maintenant deux décennies ? Cela serait-il dû au manque de volonté politique ou à la complexité de la situation linguistique du pays ? Comment expliquer ce phénomène, puisque le gouvernement Abacha semblait très enthousiaste et déterminé lors de sa décision d'adopter la langue ? Ces questions fondamentales, qui ont mené à la présente recherche, ont révélé plusieurs lacunes entourant l'activité d'aménagement de la langue. Parce que trop subite, la promotion du français au statut de langue officielle a été faite sans qu'on tienne compte des réalités sociales et des besoins réels de la situation linguistique jugée lacunaire, puisqu'aucune enquête formelle n'a précédé l'annonce. En outre, il n'existe pas de plan d'action qui étaye concrètement les activités qui favoriseraient la réussite de l'implantation de la langue. Cette négligence des enjeux sociopolitiques a engendré de sérieux problèmes (le manque de financement adéquat et d'enseignants qualifiés, par exemple) liés à la mise en œuvre de la nouvelle politique ; ce qui manifestement met non seulement en péril le projet de francisation, mais également l'avenir de la seconde langue officielle au Nigéria. Cette thèse postule donc une révision du programme de francisation qui est jugé trop ambitieux et propose une stratégie d'implantation mieux adaptée au contexte sociopolitique du pays.</dc:abstract><dc:abstract>Why is the French language still not occupying formal functions in Nigeria, whereas it has been enjoying the status of official language for two decades? Could it be due to a lack of political will or the complexity of the linguistic situation of the country? How can we explain this phenomenon, since the Abacha Government seemed very enthusiastic and determined in its decision to adopt the language? These fundamental questions, which led to this research, revealed many weaknesses related to the language planning activity. Because the decision to promote the language was too sudden, no formal study of the linguistic setting concerned was conducted prior to the announcement, in order to determine the social realities and real needs, and take them into consideration in the implementation of the policy. In addition, there is no concrete action plan which outlines activities to be carried out to promote the successful realization of the project. This negligence of socio-political issues has created serious problems (such as lack of adequate funding and qualified teachers) related to the implementation of the new policy; which obviously endangers the francization project and the future of the second official language in Nigeria. This thesis thus argues a revision of the project which is considered too ambitious and proposes an implementation strategy best suited to the country's socio-political context. </dc:abstract><ual:supervisor>Chantal Bouchard (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/hq37vr19t.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/gt54kq773</ual:fedora3Handle><dc:subject>French Language and Literature</dc:subject></rdf:Description></rdf:RDF>