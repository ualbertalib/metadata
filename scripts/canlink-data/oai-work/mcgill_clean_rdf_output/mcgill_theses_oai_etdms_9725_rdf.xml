<?xml version="1.0" encoding="UTF-8"?><rdf:RDF xmlns:oai="http://www.openarchives.org/OAI/2.0/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:ual="http://terms.library.ualberta.ca/" xmlns:bibo="http://purl.org/ontology/bibo/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:schema="https://schema.org/" xmlns:etdms="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Agx41mm915"><dcterms:title>Simulation and optimization of electric and hybrid vehicles with two-speed transmissions</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Mechanical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Humphries, Kieran</ual:dissertant><dc:abstract>Les véhicules électriques et hybrides deviennent des options de plus en plus intéressantespour les flottes de véhicules des entreprises et des gouvernements afin deréduire les couts d'opération et les émissions de gaz à effet de serre. Il existe plusieursconfigurations possibles pour ces véhicules avancés; des véhicules complètement électriques,des hybrides de type série, des hybrides de type parallèle, et des hybrides mixtes.Cette recherche se penche sur les véhicules complètement électriques et les hybridesde type série. Ces deux types de véhicules utilisent souvent un engrenage fixe pourréduire la vitesse du moteur avant de transférer le mouvement aux roues. Cependant,la performance pourrait être améliorée avec une transmission à deux rapports. Avecl'utilisation des simulations, ce projet vise à déterminer la configuration optimale d'unvéhicule de livraison de classe 4. Un camion actuellement en service, le Balance Hybridde Azure Dynamics, a été testé pour obtenir des résultats de base pour la performanceet le rendement énergétique. Ces résultats ont été analysés et utilisés pour raffiner lesspécifications des véhicules simulées. Les modèles numériques des véhicules ont étécréés avec des logiciels commerciaux et les composantes ont été dimensionnées. Enfin,les véhicules ont été optimisés avec les algorithmes DIRECT et génétique. Les résultatsdémontrent que les systèmes à transmission direct et à deux rapports possèdent un avantageen efficacité par rapport aux systèmes avec réduction fixe.</dc:abstract><dc:abstract>Electrification and hybridization of fleet vehicles is of interest to businessesand governments due to the potential for cost savings and reduction of harmfulemissions. There are many possible configurations for such vehicles, from full batteryelectric vehicles, to series, parallel and power-split hybrids. Electric vehicles andseries hybrid vehicles are the focus of this research. Both these types of vehicletypically use a single speed gear reduction to allow for high speed motors. Howeverperformance and efficiency gains may be possible using a two-speed transmissionsystem. Through simulation, this project aims to determine optimized configurationsfor Class 4 delivery vehicles using a two-speed transmission. An in-service hybriddelivery truck, an Azure Dynamics Balance Hybrid, was tested to obtain baselineperformance and fuel economy results. These results were analyzed and used to refineparameter specifications and operating maps for the simulation vehicles. Simulationsof the different architectures were created using commercial software and preliminarycomponent sizing was completed using various methodologies. Two-speed transmissionswere added and all systems were optimized using the DIRECT and geneticoptimization algorithms with respect to both component sizing and hybrid systemcontrol, leading to improved vehicle performance. The advantages of a two-speed ordirect-drive system over a single-speed gearbox were significant. Future cost analysisis recommended to determine which system will be best for production applications.</dc:abstract><ual:supervisor>Peter Henry Radziszewski (Internal/Supervisor)</ual:supervisor><ual:supervisor>Benoit Boulet (Internal/Cosupervisor2)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/bg257h927.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/gx41mm915</ual:fedora3Handle><dc:subject>Engineering - Mechanical </dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A3197xp73c"><dcterms:title>Stochastic long-term production scheduling of the LabMag iron ore deposit in Labrador, Canada</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Mining and Materials</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Spleit, Michael</ual:dissertant><dc:abstract>In long-term production scheduling, which is of vital importance to a project's success and profitability, the goal is to determine a feasible extraction sequence that maximizes the discounted cash flows of a mine while also ensuring the target ore quantities and qualities are met. There is risk of the actual production deviating from what is planned due to geological variability, which is not considered by conventional mine designs and production schedules that are based on a single estimated ore body model. In order to address this issue, multiple simulations of an orebody can be created to represent its geological variability and allow for quantifying expected bounds, instead of single estimates, for grades, tonnages, and financial results. Beyond simply quantifying the geological uncertainty, a mine production schedule can be optimized while directly considering simulations in order to manage the geological risk.In this study, a set of geological simulations of the LabMag iron ore deposit in Labrador, Canada is generated in order to quantify the geological variability in an existing mining schedule and assess the schedule's performance. The ‘DBMAFSIM' algorithm is used to provide joint geostatistical simulation of spatially correlated variables of interest. First, a novel application of the method is used to jointly simulate the thicknesses of seven lithological layers, and then four correlated grades within each lithology are jointly simulated. The variability in an existing production schedule, designed based on a single deterministic geological model, is then evaluated using the simulations. This evaluation quantifies the potential deviations from expected production target grades and tonnages as well as the associated financial impact of these deviations. Subsequently, a production schedule optimization based on stochastic integer programming (SIP) is presented that aims to improve mine profitability while simultaneously managing the risk of production tonnage and quality deviations. In addition, the formulation has components for equipment and waste material management: the truck fleet requirements are minimized while ensuring that the number of required trucks is an increasing function to avoid unnecessary peaks; and the evolution of the pit is controlled so that space within the mined out pit is continuously provided to allow for tailings and waste rock to be replaced, thus minimizing the project's environmental footprint.</dc:abstract><dc:abstract>L'établissement du calendrier de production minière à long terme est d'importance vitale pour le succès et la rentabilité d'un projet. Son but est de déterminer une séquence d'extraction réalisable qui maximise les flux de trésorerie actualisés d'une mine tout en assurant les quantités et qualités visées de minerai. La production réelle risque de s'écarter des prévisions à cause de la variabilité géologique, qui n'est considérée ni dans les conceptions de mine ni dans les calendriers de production conventionnels car ils sont basés sur un modèle d'évaluation unique du corps minéralisé. Pour y remédier, de multiples simulations peuvent être créées plutôt qu'une évaluation unique pour représenter la variabilité géologique d'un corps minéralisé et permettre de mesurer les limites escomptées pour les teneurs, tonnages et résultats financiers. Au-delà de la simple mesure d'incertitude géologique, un calendrier de production minière peut être optimisé en tenant compte directement des simulations pour gérer le risque géologique.Cette étude comporte un ensemble de simulations géologiques du gisement de minerai de fer LabMag au Labrador, Canada, générées afin de mesurer la variabilité géologique d'un calendrier de production minière existant et d'évaluer la valeur de celui-ci. L'algorithme «DBMAFSIM» est utilisé en géostatistique pour simuler conjointement des  variables qui sont spatialement corrélées. D'abord, la méthode est appliquée d'une nouvelle façon pour simuler conjointement les épaisseurs de sept couches lithologiques. Ensuite, quatre teneurs corrélées sont simulées conjointement dans chaque lithologie. La variabilité d'un calendrier existant de production conçu sur base d'un modèle géologique déterministe unique est ensuite évaluée en fonction des simulations. Cette évaluation mesure les écarts possibles avec les teneurs et tonnages initialement visés dans les prévisions de production, de même que l'impact financier associé à ces écarts.Une optimisation du calendrier de production basée sur la programmation stochastique en nombres entiers («SIP») est ensuite présentée. Elle a pour but d'améliorer la rentabilité de la mine tout en gérant le risque d'écarts pour le tonnage et la qualité de production. De plus, la formulation contient des éléments de gestion d'équipements et de déchets miniers. Ainsi, les besoins de la flotte de camions sont réduits au minimum tout en maintenant une fonction croissante pour calculer le nombre de camions nécessaires et éviter les pics inutiles. De même, l'évolution de la mine à ciel ouvert est contrôlée afin que la mine épuisée procure toujours l'espace nécessaire pour replacer les résidus et stériles miniers, réduisant ainsi l'empreinte environnementale du projet.</dc:abstract><ual:supervisor>Roussos G Dimitrakopoulos (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/6682x6823.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/3197xp73c</ual:fedora3Handle><dc:subject>Engineering - Mining</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A6395wb54w"><dcterms:title>A phase ll trial assessing the safety and efficacy of sorafenib in combination with yttrium90 radioembolization in patients with advanced hepatocellular carcinoma</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Surgery</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Bouteaud, Jeanne</ual:dissertant><dc:abstract>Dans cette étude de phase II, la sécurité, la tolerabilité et l'efficacité de sorafenib combiné avec la radioembolization yttrium90 sont investiguées. 26 patients avec un carcinome hépatocellulaire avancé ont été recrutés et ont reçu sorafenib en continue ainsi que la radioembolization ytrium90 entre 6 à 8 semaines après le de but du sorafenib.Les effets secondaires les plus fréquents sont des symptômes systémiques tels que la fatigue (23.1%), la perte de poids (23.1%), le syndrome pieds‐main (19.2%) ainsi que la douleur abdominale (23.1%). La diarrhée (11.5%), le syndrome pieds‐mains (15.4%) et la douleur abdominale sont les effets secondaires de grade 3 ou 4 les plusfréquents (15.4%). De manière générale, le type et la fréquence des effets secondaires observés dans cette étude ne diffèrent pas grandement de ceux obtenus avec un traitement par sorafenib ou radioembolization seul. La survie médiane est de 395 jours (12.97 mois) et le taux de survie à 1 an est de 65.4%. La cirrhose d'origine alcoolique, l'absence d'invasion vasculaire macroscopique ainsi que la baisse de l'AFP avec sorafenib sont associés avec une prolongation de la survie. Le régime de traitement proposé dans cette étude est associé avec une augmentation de la survie de 21%.</dc:abstract><dc:abstract>In a phase II trial we investigated the safety, tolerability and efficacy of sorafenib in combination with ytrium90 radioembolization in advanced hepatocellular carcinoma (HCC). 26 patients with advanced HCC were recruited and were treated with sorafenib continuously and ytrium90 radioembolization 6 to 8 weeks after the beginning of sorafenib. The most common adverse events were constitutional symptoms such as fatigue (23.1%), and weight loss (23.1%) as well hand‐foot skin reaction (19.2%), and abdominal pain (23.1%). When looking at grade 3 and 4 events, diarrhea (11.5%), hand‐foot skin reaction (15.4%) and abdominal pain (15.4%) were the most frequent. Overall, the type and rate of adverse events observed in our study did not differ widely from those seen with sorafenib or Y90 radioembolization alone.Overall median survival was 395 days (12.97 months) and survival rate at 1 years was 65.4%. Alcoholic cirrhosis, the absence of macroscopic vascular invasion or extrahepatic disease, and decrease in AFP with sorafenib were associated with prolonged survival.The proposed regimen was associated with a 21% increase in survival when compared to sorafenib alone and may also confer a survival advantage when compared to yttrium90 radioembolization.</dc:abstract><ual:supervisor>Prosanto Chaudhury (Internal/Supervisor)</ual:supervisor><ual:supervisor>Peter Metrakos (Internal/Cosupervisor2)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/76537403f.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/6395wb54w</ual:fedora3Handle><dc:subject>Health Sciences - Medicine and Surgery </dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A9p290d581"><dcterms:title>Role of calcium-independent phospholipase A2 gamma (iPLA2y) in glomerular epithelial cell injury</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Medicine</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Elimam, Hanan Attia</ual:dissertant><dc:abstract>In experimental membranous nephropathy, complement C5b-9-induces glomerular epithelial cell (GEC)/podocyte injury and proteinuria. The effects of C5b-9 are mediated via signaling pathways, including calcium-independent phospholipase A2γ (iPLA2γ), and mitogen-activated protein kinases (MAPKs) such as extracellular signal-regulated kinase (ERK), c-Jun N-terminal kinase (JNK), and p38. The iPLA2γ pathway is cytoprotective. First, we studied the mechanisms of iPLA2γ activation and cytoprotection. iPLA2γ activitation was monitored by quantifying prostaglandin E2 (PGE2) production. In GECs, iPLA2γ localized at the endoplasmic reticulum and mitochondria, which was dependent on the N-terminal region of iPLA2γ. Complement-mediated production of PGE2 was amplified in GECs that overexpress iPLA2γ, compared with control cells, and was blocked by the iPLA2γ inhibitor bromoenol lactone in both iPLA2γ-overexpressing and control GECs. Complement-induced activation of iPLA2γ was mediated via ERK and p38 pathways, but not JNK pathway. In COS-1 cells that overexpress iPLA2γ and cyclooxygenase-1, PGE2 production was induced by co-expression of constitutively active MEK1 or MAPK interacting kinase 1 (MNK1) as well as by stimulation with epidermal growth factor (EGF) + ionomycin. Complement- and EGF + ionomycin-stimulated iPLA2γ activity was attenuated by the S511A/S515A double mutation. Moreover, complement and EGF + ionomycin enhanced phosphorylation of Ser-511. Thus, stimulation of iPLA2γ was dependent on an increase in cytosolic Ca2+ concentration and phosphorylation of Ser-511 and/or Ser-515 via MNK1. Phosphorylation of Ser-511 and/or Ser-515 plays a key role in the catalytic activity and signaling of iPLA2γ. Next, we addressed the cytoprotective function of iPLA2γ by examining if iPLA2γ is involved in the adaptive unfolded protein response (UPR). In GECs, iPLA2γ amplified tunicamycin-induced activating transcription factor-6 (ATF6) activation and upregulated the ER chaperones, grp94 and grp78, which are downstream of ATF6 and enhance protein-folding capacity of the ER. These effects were dependent on iPLA2γ catalytic activity, but not on prostanoids. Furthermore, ATF6 amplification occurred only when the full length iPLA2γ was expressed, but not an N-terminally truncated mutant, which does not associate with the membrane of the ER. Induction of the ATF6 pathway of the UPR and its amplification by iPLA2γ limited tunicamycin-induced GEC injury. Finally, to better understand the role of iPLA2γ in normal podocyte function and in podocyte injury in vivo, we employed iPLA2γ knockout (KO) mice. Deletion of iPLA2γ caused neither albuminuria nor morphological changes in the glomerulus. However, after induction of anti-glomerular basement membrane nephritis, iPLA2γ KO mice exhibited significantly increased levels of albuminuria, compared to wild type (WT) mice. Furthermore, in contrast to WT mice, iPLA2γ KO mice exhibited a marked loss of podocytes, implying that iPLA2γ has a protective role in glomerulonephritis. Collectively, this work characterizes the mechanism of iPLA2γ activation in complement-mediated GEC injury, shows that the cytoprotective effect of iPLA2γ involves the unfolded protein response, ATF6, and that iPLA2γ has a protective role in glomerulonephritis. Defining the role of iPLA2γ provides opportunities for development of novel therapeutic approaches to GEC injury and proteinuria.</dc:abstract><dc:abstract>Dans la néphropathie membraneuse expérimentale, le complément C5b-9 induit des dommages aux cellules épithéliales glomérulaires (CGE)/podocytes et cause la protéinurie. Les effets du C5b-9 sont médiés par des voies de signalisation, y compris la phospholipase A2γ indépendante du calcium (iPLA2γ), et des protéines kinases activées par les mitogènes (MAPK) telles que ERK, JNK et p38. La voie iPLA2γ est cytoprotectrice. Tout d'abord, nous avons étudié les mécanismes d'activation de et de cytoprotection de iPLA2γ. L'activation de iPLA2γ a été suivie par la quantification de la production de prostaglandine E2 (PGE2). Dans les CGE, iPLA2γ est localisée au réticulum endoplasmique (RE) et aux mitochondries. Cette localisation était dépendante de la région N-terminale de iPLA2γ. La production de la PGE2 induite par le complément était amplifiée dans les CGE qui surexpriment iPLA2γ, par rapport aux cellules de contrôle. Cette amplification était bloquée par un inhibiteur de iPLA2γ (bromoenol lactone) à la fois dans les CGE surexprimant iPLA2γ et les CGE de contrôle. L'activation du iPLA2γ induite par le complément était médiée par des voies de signalisation ERK et p38, mais pas par JNK. Dans les cellules COS-1 qui surexpriment iPLA2γ et la cyclo-oxygénase-1, la production de PGE2 était induite par la co-expression de la kinase constitutivement active MEK1 ou de MNK1 ainsi que par la stimulation par le facteur de croissance épidermique (EGF) + ionomycine. L'activité iPLA2γ stimulé par le complément, EGF et ionomycine, était atténuée par la double mutation, S511A/S515A. En outre, la stimulation par le complément et par la combinaison EGF + ionomycine augmentait la phosphorylation de Ser-511. Ainsi, la stimulation de iPLA2γ était dépendant d'une augmentation de la concentration de calcium cytosolique et de la phosphorylation de Ser-511 et/ou Ser-515 par l'intermédiaire de MNK1. La phosphorylation de Ser-511 et/ou Ser-515 joue un rôle clé dans l'activité catalytique et la signalisation de iPLA2γ.Ensuite, nous avons examiné la fonction cytoprotectrice de iPLA2γ en examinant si iPLA2γ est impliqué dans la ‘‘unfolded protein response'' ou UPR. Dans les CGE, iPLA2γ amplifiait l'activation transcription factor 6 (ATF6) induite par la tunicamycine et a augmentait l'expression des chaperons du RE grp94 et grp78, qui sont en aval du ATF6 et améliorent la capacité de pliage des protéines dans ce compartiment. Ces effets étaient dépendants de l'activité catalytique de iPLA2γ, mais pas des prostanoïdes. En plus, l'amplification de ATF6 se produisait seulement en présence d'une forme intacte de iPLA2γ, mais pas en présence d'un mutant portant une troncation N-terminale et incapable de s'associer avec la membrane du RE. L'induction de la voie de ATF6 de l'UPR et son amplification par iPLA2γ limitait les dommages induits par la tunicamycine dans les CGE.Enfin, pour mieux comprendre le rôle de iPLA2γ dans la fonction normale des podocytes et dans les dommages aux podocytes in vivo, nous avons utilisé des souris knock-out iPLA2γ (KO). La déplétion de iPLA2γ ne cause pas d'albuminurie, ni de changements morphologiques dans le glomérule. Cependant, après l'induction de néphrite par anticorps anti-membrane glomérulaire basale, les souris KO iPLA2γ démontraient une albuminurie augmentée par rapport aux souris de type sauvage (WT). De plus, contrairement aux souris WT, les souris KO iPLA2γ présentaient une diminution marquée des podocytes, ce qui implique que iPLA2γ a un rôle protecteur dans la glomérulonéphrite.Mis ensemble, ces travaux caractérisent le mécanisme d'activation des iPLA2γ dans le dommage aux CGE induit par le complément. Ils montrent que l'effet cytoprotecteur de iPLA2γ implique l'UPR, ATF6, et que iPLA2γ a un rôle protecteur dans la glomérulonéphrite. Définir le rôle de iPLA2γ offre des possibilités pour le développement de nouvelles approches thérapeutiques pour les dommages aux CGE et pour la protéinurie.</dc:abstract><ual:supervisor>Tomoko Takano (Supervisor2)</ual:supervisor><ual:supervisor>Andrey V E Cybulsky (Supervisor1)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/ff3658221.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/9p290d581</ual:fedora3Handle><dc:subject>Health Sciences - General</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ab2773z659"><dcterms:title>What I learned about learning in the museum from visitors and from exhibit design research -2003 to 2013</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of Integrated Studies in Education</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Birker, Ingrid</ual:dissertant><dc:abstract>Cette étude examine l'influence de deux expositions de musée sur la compréhension et l'apprentissage d'étudiants universitaires en comparant deux études de recherche réalisées dans le même musée universitaire à deux périodes de temps différentes. Chaque étude a exploré l'apprentissage associé à une exposition de musée sur un sujet particulier: soit «les fossiles de schiste de Burgess» en 2003 et «la conservation et l'usage de l'eau» en 2013. Les participants à la première étude étaient des étudiants dont le programme de cours 2003 – 2004 incluait  la visite du musée. Les personnes ayant participé à la deuxième études étaient des visiteurs anonymes du musée pendant la période 2012 à 2013. L'objectif de chacune des deux études était de mesurer le niveau d'apprentissage, sachant que l‘apprentissage a été  acquis différemment dans les deux expositions. Le but de l'exposition BURGESS, conçue en 2001, était de promouvoir l'apprentissage de l'évolution biologique chez les étudiants universitaires et l'objectif principal de l'exposition de L'EAU ET LA VIE, organisée dix ans plus tard, était de promouvoir la compréhension et la prise de conscience chez les visiteurs des ressources hydriques et de leur conservation. Ces deux expositions sont comparées sur la base de la présentation de l'exposition, de l'objectif et de l'impact prévu, du processus de planification; du support pour le financement et du type de recherche effectuée pendant chaque période de temps pour évaluer l'impact de chaque exposition. La comparaison démontre comment les différences d'apprentissage théorique intrinsèques à chaque exposition se sont manifestées dans chacun des aspects précédents. L'auteur réfléchit aussi à comment les changements concernant l'apprentissage et le rôle éducationnel des musées trace un parallèle à son propre développement et évolution en tant qu'éducatrice de musée pendant les 10 ans qu'ont durées les deux expositions.</dc:abstract><dc:abstract>This study investigates the influence of two museum exhibits on university students' understanding and learning by comparing two research studies conducted at the same university museum at two different times. Each study explored the learning associated with a museum exhibit about one topic: in 2003, the topic was the Burgess Shale fossils, and in 2013, the topic was water conservation and use. The participants in the first study were students visiting the museum as part of their course curriculum in 2003 and 2004. The participants in the second study were anonymous visitors to the museum during 2012 and 2013.  The goal for each of the two studies was to measure learning, but learning was conceptualized differently in the two exhibits. The BURGESS exhibit, designed in 2001, was intended to promote the learning of biological evolution by university students, and the primary goal of the WATER IS LIFE exhibit, developed about ten years later, was to promote visitor understanding and awareness about water resources and conservation. These two exhibits are compared on the basis of the appearance of the exhibits; intended goals or impacts; planning process; funding support; and type of research carried out during each time period to assess the impact of each exhibit. The comparison shows how differences in the learning theory underlying each exhibit were manifested in each of the preceding aspects. The author also reflects on how changes in thinking about learning and the educational role of museums parallels her own growth as a museum educator during the 10 years spanning the two exhibits.</dc:abstract><ual:supervisor>Gale Seiler (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/1j92gb29s.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/b2773z659</ual:fedora3Handle><dc:subject>Education - Sciences</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Atb09j846s"><dcterms:title>Scenarios and implications of land use and climate change on water quality in mesoscale agricultural watersheds</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Geography</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Mehdi, Bano B</ual:dissertant><dc:abstract>A comparative study in two mesoscale, agricultural watersheds located in mid-latitude, developed regions (Altmühl River, Germany and in Pike River, Canada) investigated potential future land use change and climate change impacts on surface water quality. The two watersheds provided a unique opportunity to compare potential impacts of change in similar physical and climatological regions, yet under different political settings related to agricultural policies as well as water quality management and protection. The objectives of the research were to develop agricultural land use scenarios to apply to a hydrological model simultaneously with climate change simulations. This modelling framework allowed quantifying these combined impacts on streamflow, sediment loads, nitrate-nitrogen loads and concentrations, as well as total phosphorus loads and concentrations to the 2050 time horizon. The impacts of climate change were evaluated alone and then with land use change. Overall, the quality of surface water simulated in both watersheds will be deteriorated according to environmental standards set by the ministries by 2050 due to higher mean annual nutrient loads transported into the rivers. Climate change impacts were greater than land use change impacts; however land use change can have an important influence on water quality, depending on the magnitude of crop changes taking place. Field-level adaptation strategies in the Pike River were simulated to determine the extent of reducing the combined impacts of land use and climate change. The strategies were able to mitigate the combined impacts, and also to improve the quality of surface water compared to the in-stream nutrient concentrations in the reference simulation.In both watersheds, it was determined that the combined interaction between climate change and land use change in the hydrological model are non-linear. Examining the combined impacts are necessary to determine potential alterations in water quality in a basin since the direction and the magnitude are not predictable from the individual changes alone.</dc:abstract><dc:abstract>Une étude comparative de deux basins versants de mésoéchelle situés dans les latitudes moyennes, dans des régions développées (la rivière Altmühl en Allemagne, et le Rivière-aux-Brochets (Pike River) au Canada) a examiné les impacts des changements d'utilisation des terres future ainsi que les changements climatiques futurs sur la qualité des eaux de surface. Les deux bassins ont fourni une occasion unique de comparer les impacts potentiels des changements dans les régions physiquement et climatologiquement similaires, mais dans différents contextes politiques liés à l'agriculture et à la gestion et à la protection de la qualité de l'eau. Les objectifs de la recherche étaient de développer des scénarios d'utilisation des terres agricoles pour appliquer à un modèle hydrologique, simultanément avec des simulations climatiques futures. Ce cadre de modélisation a permis de quantifier à l'horizon 2050 les effets combinés sur : le débit, les charges de sédiments, les charges et les concentrations d'azote-nitrate, ainsi que les charges et les concentrations de phosphore total. Les impacts du changement climatique ont été évalués seuls, et ensuite avec les scenarios d'utilisation des terres agricoles. Dans l'ensemble, la qualité de l'eau de surface simulée dans les deux bassins versants se détériorera en 2050 en raison de charges moyennes annuelles élevés d'éléments nutritifs transportées vers la rivière. Les impacts du changement climatique étaient plus grands que les effets de l'utilisation des terres; cependant l'utilisation des terres agricoles peut avoir une influence importante sur la qualité de l'eau, en fonction de l'ampleur des changements des cultures. Des stratégies d'adaptation au niveau des champs ont été simulées pour bassin versant de la Rivière-aux-Brochets afin de déterminer l'ampleur de la réduction des effets combinés de l'utilisation des terres agricoles et des changements climatiques. Les stratégies d'adaptation ont été en mesure d'atténuer les effets combinés, et aussi d'améliorer la qualité des eaux de surface par rapport aux concentrations de nutriments dans la rivière dans la simulation de référence. Dans les deux bassins versants, l'interaction des simulations du changement climatique combinée avec des scénarios de changement d'utilisation des terres agricoles dans le modèle hydrologique était unique et non-linéaire. Donc, examiner les effets combinés est primordial pour déterminer les modifications éventuelles à la qualité de l'eau dans un bassin puisque la direction et l'ampleur du changement ne sont pas prévisibles à partir des changements individuels.</dc:abstract><ual:supervisor>Bernhard Lehner (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/6d570067w.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/tb09j846s</ual:fedora3Handle><dc:subject>Earth Sciences - Hydrology</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Am900nx65x"><dcterms:title>Pharmaceutically active compounds in the environment: risks, trade-offs and sewer epidemiology</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Civil Engineering and Applied Mechanics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Khan, Usman</ual:dissertant><dc:abstract>Dans cette étude, le rejet et la présence des PhACs dans l'environnement sont considérés depuis deux perspectives différentes. D'abord, une perspective amont depuis laquelle la concentration des PhACs dans l'environnement est estimée grâce à leur degré d'utilisation ou d'excrétion. Cela permet d'évaluer les inquiétudes liées à l'éco-toxicologie et/ou la santé humaine. Quatre évaluations uniques en leur genre ont été menées depuis cette perspective. La première évaluation a débouché sur le développement d'un modèle informatique du rejet endogène d'androgènes, d'hormones thyroïdiennes et leurs métabolites in vivo dans l'environnement. Le modèle a été utilisé pour évaluer la pertinence de tels polluants d'un point de vue éco-toxicologique; ainsi, il a été mis en évidence que le rejet endogène d'androstènedione comporte un risque d'impacts mesurables sur les poissons dans le cadre d'un scénario de forte exposition. La deuxième évaluation a conduit au développement d'une approche pour l'évaluation des risques liés à la santé humaine et à l'éco-toxicologie posés par les PhACs présents dans l'urine épandue sur les terres agricoles. Cette approche a été appliquée pour évaluer au travers de six voies d'exposition 25 PhACs abondamment utilisés. De ces 25 PhACs, 14 pourraient poser des risques d'éco-toxicologie ou pour la santé humaine. La troisième évaluation portait sur l'analyse des sources et la pertinence en termes de risques pour la santé humaine du rejet aquatique de 335 PhACs dans l'environnement au Canada. L'évaluation suggère qu'un maximum de sept sources distinctes peut mener au rejet dans l'eau d'un PhAC donné, avec l'importance de chaque source variant de manière significative d'un cas à l'autre. Les PhACs sont principalement rejetés dans l'environnement à travers leur utilisation au sein des populations; mais parfois, les hôpitaux entre autres sources peuvent aussi être d'importants contributeurs. L'évaluation de la pertinence de l'analyse de la présence potentielle de ces 335 PhACs dans les eaux potables montre que 323 de ces PhACs devraient poser un risque négligeable pour la santé humaine. Cependant, 14 PhACs méritent de plus amples recherches selon les résultats. De plus, il a été démontré que la surveillance environnementale des PhACs est actuellement insuffisante pour évaluer de façon correcte leurs impacts éco-toxicologiques et sur la santé humaine. Dans la quatrième évaluation, une approche a été développée pour mieux comprendre et évaluer les relations et compromis nécessaires entre les choix de contraception d'une population et la concentration en estrogènes stéroïdiens dans l'environnement. De façon contre-intuitive, l'analyse a suggéré que quelle que soit l'option de contraception utilisée, qu'elle soit à base d'estrogènes ou purement un instrument physique, des rejets d'estrogènes stéroïdiens dans l'environnement sont évités. Les femmes qui utilisent des contraceptifs oraux à base d'éthinylestradiol produisent une moindre concentration en estrogènes dans l'environnement que celles qui abandonnent l'utilisation d'une telle option. La seconde perspective adoptée dans cette étude utilisait la concentration en aval de résidus de drogues dans les eaux usées pour obtenir des informations sur le comportement d'une population en amont. Une étude spécifique a été conduite à l'aide d'une approche basée sur l'épidémiologie des eaux d'égout afin de déterminer comment mieux lier les concentrations de résidus de certaines drogues dans les eaux usées aux niveaux d'utilisation de ces drogues dans les populations en amont. Afin d'y parvenir, des bilans de masse ont été développés pour un ensemble de drogues illicites d'usage courant. Ainsi, les facteurs d'extrapolation utilisés dans la littérature liant les mesures de résidus de drogues dans les eaux usées à l'utilisation de drogues dans une population nécessitent d'être affinés de manière significative pour améliorer leur fiabilité et leur applicabilité.</dc:abstract><dc:abstract>In  this  research,  the  release  and,  hence,  the  environmental  presence  of  PhACs  are  viewed  from  two distinct perspectives. The first is from an upstream perspective in which the degree of use or excretion of PhACs is used to estimate the environmental load  of contaminants  which,  in turn,  allows one to assess eco-toxicological  and/or  human-health  concerns.  Four  unique  evaluations  were  performed  by  adopting this perspective. The first evaluation resulted in the development of a model for the endogenous release of androgens, thyroids and their in vivo metabolites to the environment. The model was used to assess the eco-toxicological relevance of such contaminants and, from this, it was found that the endogenous release of  androstenedione  carries  the  potential  to  yield  impacts  on  fish  under  a  high  exposure  scenario.  The second  evaluation led  to the  development  of  an  approach  for  the  assessment  of  human-health  and  eco- toxicological risks posed by PhACs in urine that is applied to agricultural land. This approach was applied to evaluate 25 widely-used PhACs through six routes of exposure. Of the 25 PhACs evaluated, 14 were found to pose possible eco-toxicological or human-health risks. The third evaluation explored the sources and the human-health relevance regarding the aquatic release of 335 PhACs to the Canadian environment. The  evaluation  suggested  that  up  to  seven  distinct  sources  can  lead  to  the  aquatic  release  of  a  given PhAC, with the importance of a given source term varying significantly from one case to another. PhACs appear to be predominantly released to the environment through their use in the general population but, in certain cases, their use in hospitals and their release through other sources (e.g., endogenous production, use  of  clinical  precursors  and  illicit  drugs)  can  also  be  important.  When  the  human-health  relevance regarding the potential presence of the 335 PhACs in drinking waters was evaluated, it was established that  323  of  the  PhACs  are  expected  to  pose  a  negligible  risk  to  human-health.  However,  the  results indicated that 14 PhACs warrant further study. Furthermore, it was demonstrated that environmental monitoring of PhACs is currently insufficient to properly assess their human-health impacts. In the fourth evaluation, an approach  was  developed  to  better  understand  and  evaluate  the  relationships  and  trade-offs  involved between  a  population's  contraceptive  choices  and  their  respective  load  of  steroidal  estrogens  to  the environment.  Counterintuitively,  the  analysis  suggested  that  use  of  each  contraceptive  option,  be  it estrogen based or purely physical, prevents the release of steroidal estrogens to the environment. It was also shown that those who use ethinylestradiol-based oral contraceptives produce a lower estrogenic load on the environment than those who discontinue the use of such an option. The  second  perspective  adopted  in  this  research  was  to  use  the  downstream  load  of  drug  residues  in wastewaters to gain information about the behaviour of an upstream population. Specifically research was conducted  to  use  a  sewer epidemiology  approach  to determine  how best to translate  measured  loads of selected  drug  residues  in  wastewaters  to  the  levels  with  which  the  parent  illicit  drugs  are  used  in  their respective  upstream  populations.  To  accomplish  this,  mass  balances  were  developed  for  a  number  of illicit  drugs  in  common  use.  Through  the  development  of  these  mass  balances,  it  was  established  that  the extrapolation factors used in the literature that relate drug residue measurements in wastewaters to drug use in a population required significant refinement to improve their reliability and applicability.</dc:abstract><ual:supervisor>Jim A Nicell (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/00000313p.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/m900nx65x</ual:fedora3Handle><dc:subject>Health And Environmental Sciences - Environmental Sciences</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Aws859j609"><dcterms:title>Media discourse and paradigm shifts in Canadian refugee and child policy frameworks</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Integrated Studies in Education</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Bober, Lara</ual:dissertant><dc:abstract>This study draws on sociological theories of education and the methodological frameworks of Critical Discourse Analysis and Frames Theory and Analysis in order to examine print media representations of new immigrant, refugee, and precarious status children in the three Canadian newspapers, the Globe &amp; Mail, National Post, and Toronto Star in the historical period of 1989-2009. The objective of this study is to analyze the ways in which media discourse provides ideological legitimacy to exclusionary immigration and refugee policies and the denial of social rights, and to identify media support for immigration justice campaigns. The historical period provides a context for the case study of the Toronto District School Board adopting a Don't Ask Don't Tell Policy in 2007 so that children without immigration status would be able to access schooling without the fear of being reported to immigration authorities. The educational experiences of new immigrant and refugee children have been considered from the lens of social justice research paradigms in terms of the opportunities and outcomes of schooling. This study contributes new knowledge that can be useful for children, educators, policy-makers, and social activists, about the ways in which Canadian media discourses frame children's access to social rights and their experiences of education and migration. This knowledge contributes to the sociology of education, childhood studies, studies in social justice, and refugee and migration studies. Additionally, this study explores opportunities to disrupt conventional explanations for the social and material exclusion of children, in order to advance campaigns for immigration and educational justice.Keywords: Children; Education; Immigration; Media; Migrant Justice; Neoliberalism</dc:abstract><dc:abstract>Cette étude s'appuie sur les théories sociologiques de l'éducation et les cadres méthodologiques de l'analyse critique du discours et de la théorie et de l'analyse Cadres pour examiner les réclamations de la presse écrite de nouveaux immigrants, les réfugiés et les enfants précaires d'état dans les trois journaux canadiens: Globe &amp; Mail, National Post, et Toronto Star dans la période historique de 1989-2009. Cette période historique fournit un cadre pour l'étude de cas de la Commission scolaire du district de Toronto l'adoption d'un politique “ne demandent pas ne disent pas" en 2007 afin que les enfants sans statut d'immigration seraient en mesure d'accéder à l'école sans la crainte d'être dénoncé aux autorités de l'immigration. Les expériences éducatives des nouveaux enfants immigrants et réfugiés ont été pris en considération de l'objectif de paradigmes de recherche de la justice sociale en termes de possibilités et les résultats d'études. L'objectif de cette étude est d'analyser la manière dont le discours médiatique donne une légitimité idéologique à l'immigration d'exclusion et politiques relatives aux réfugiés et le déni des droits sociaux, et d'identifier le soutien des médias pour les campagnes de la justice en matière d'immigration. Cette étude apporte des connaissances sur la façon dont les discours médiatiques canadiennes encadrent l'accès des enfants aux droits sociaux et de leurs expériences de l'éducation et de la migration. Cette connaissance peut être utile pour les enfants, les éducateurs, les décideurs et les activistes sociaux. En outre, cette étude explore les possibilités de defies explications classiques de l'exclusion sociale et matérielle des enfants, afin de faire progresser les campagnes pour l'immigration et de la justice de l'éducation.Mots-clés: enfants; l'éducation; immigration; médias; la justice sociale; le néolibéralisme</dc:abstract><ual:supervisor>Claudia A Mitchell (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/9306t230m.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/ws859j609</ual:fedora3Handle><dc:subject>Education - Sociology of</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ajm214s26q"><dcterms:title>Multiscale modeling of heat and mass transfer phenomena in nanofluids</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Chemical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Aristizabal, Felipe</ual:dissertant><dc:abstract>Heat and mass transfer phenomena in nanofluids are studied using numerical experiments. The main focus of this study is to determine the contribution of nanoparticle Brownian motion-induced micro-convection currents on the effective thermal conductivity and effective mass diffusivity.The mathematical model developed is based on the fluctuating lattice Boltzmann method (fLBM) to simulate nanoparticle Brownian motion, the multiple relaxation time lattice Boltzmann method (MRT-LBM) to provide a description of micro-convection currents, and the finite volume method (FVM) to calculate the evolution of a scalar field (mass or temperature) subject to the effect micro-convection currents. Finally, two averaging methods to calculate effective thermal conductivity and effective mass diffusion coefficient are presented and validated.The results from numerical experiments on heat transfer show that nanoparticle Brownian motion-induced micro-convection currents are not significant enough to justify any notable enhancements in thermal conductivity above the values estimated using classical models for composite materials.In the case of mass transfer, the numerical experiments show that nanoparticle Brownian motion-induced micro-convection currents cause significant enhancements of the effective mass diffusion coefficient. This result is in general agreement with the conclusion drawn by Veilleux and Coulombe (2010, J. Appl. Phys.) using scaling arguments based on the heat and mass transfer Peclet numbers, that Brownian motion has a much larger effect on the mass diffusivity than on the heat diffusivity.The numerical experiments on mass transfer are summarized by a simplified model based on dispersion. The parameters considered in the numerical experiments are: particle size, particle density, fluid viscosity, fluid density and temperature. The simplified model adds two important terms to Maxwell's model: a new dimensionless number N_BM (defined as the ratio of the nanoparticles Brownian self-diffusion coefficient over the molecular diffusion coefficient) and a particle interaction term.Although the simplified model fails to predict the order of magnitude increase in mass diffusivity for Rhodamine 6G in 10 nm Al2O3-water nanofluids (D_eff/D_m = 1.2 compared to the experimental value of 10), the form of the simplified model is used to provide possible explanations for the effective mass diffusivity increase/decrease with nanoparticle volume fraction observed experimentally.This thesis concludes by extending the current analysis to polydisperse nanoparticle suspensions. Numerical experiments on bidisperse suspensions highlight the importance of the interaction term in the simplified model.</dc:abstract><dc:abstract>Les phénomènes de transfert de chaleur et de masse dans les nanofluides sont étudiés à l'aide d'expérimentations numériques. L'intérêt principal de cette étude est de déterminer la contribution des courants de micro-convection induits par mouvement Brownien de nanoparticules sur la conductivité thermique et le coefficient de diffusion massique effectifs.Le modèle mathématique développé est fondé sur la méthode de lattice Boltzmann fluctuante (fLBM) pour simuler le mouvement Brownien des nanoparticules, sur la méthode de lattice Boltzmann à temps de relaxation multiple (MRT-LBM) pour fournir une description des courants de micro-convection et sur la méthode de volume fini (FVM) pour calculer l'évolution d'un champ scalaire (masse ou température) sujet à l'effet des courants de micro-convection. Finalement, deux méthodes d'établissement de la moyenne pour calculer les coefficients de conductivité thermique et de diffusion massique effectifs sont présentés et validés.Les résultats d'expérimentations numériques sur le transfert thermique démontrent que les courants de micro-convection induits par mouvement Brownien de nanoparticules ne sont pas suffisamment significatifs pour justifier l'amélioration de la conductivité thermique jusqu'à des valeurs dépassant celles obtenues avec les modèles classiques pour les matériaux composites.Dans le cas du transfert de masse, les expérimentations numériques démontrent que les courants de micro-convection induits par mouvement Brownien de nanoparticules provoquent une amélioration du coefficient de diffusion massique effectif. Ce résultat concorde avec la conclusion obtenue par Veilleux et Coulombe (2010, J. Appl. Phys.) à partir d'analyse dimensionnelle basée sur le nombre de Péclet pour les transferts de masse et de chaleur; le mouvement Brownien a un bien plus grand effet sur la diffusion massique que sur la conductivité thermique.Les expérimentations numériques sur le transfert de masse sont synthétisées par un model simplifié basé sur la dispersion. Les paramètres considérés dans les expérimentations numériques sont : la taille des particules, la densité des particules, la viscosité du fluide, la densité du fluide et la température. Le modèle simplifié ajoute deux termes importants au modèle de Maxwell : un nouveau nombre sans dimension N_BM (défini comme étant le rapport du coefficient d'auto-diffusion Brownien des nanoparticulessur le coefficient de diffusion moléculaire) et le terme représentant l'interaction entreles particules.Bien que le modèle simplifié échoue à prédire l'ordre de grandeur de l'augmentation du coefficient de diffusion massique pour la Rhodamine 6G dans un nanofluide comportant des nanoparticules de 10 nm de Al2O3 en suspension dans l'eau (D_eff /D_m = 1.2, comparé à une valeur expérimentale de 10), il est utilisé pour fournir des explications possibles à l'augmentation et la baisse du coefficient de diffusion massique effectif par rapport à la fraction de particules.Cette thèse se conclut avec l'approfondissement de l'analyse actuelle des suspensions polydispersées dans les nanofluides. Les expérimentations numériques portant sur des suspensions bidispersées soulignent l'importance du terme représentant l'interaction entre les particules dans le modèle simplifié.</dc:abstract><ual:supervisor>Sylvain Coulombe (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/jw827f698.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/jm214s26q</ual:fedora3Handle><dc:subject>Engineering - Chemical</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Awh246v945"><dcterms:title>Greenhouse gas emissions from international aviation: legal and policy challenges</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Civil Law</schema:inSupportOf><dc:contributor>Institute of Air and Space Law</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Piera Valdes, Alejandro Jose</ual:dissertant><dc:abstract>ABSTRACTInternational aviation grows at a rate of roughly 5 percent per year. Its greenhouse gas (GHG) emissions are forecasted to increase annually by 3-4 percent. Currently, international aviation's contribution to global GHG emissions is approximately 2 percent and is expected to increase considerably as more people utilize air travel. While the aviation sector has introduced a number of technological and operational measures to curb emissions, these measures will not offset the emissions expected from its projected growth. For instance, there is no indication that alternative fuels will be available in sufficient quantities and at reasonable prices to engender meaningful reductions in GHG emissions.  This thesis examines aspects of the legal framework underlying the international aviation and climate change discourse with a view to providing some recommendations that may facilitate the adoption, implementation and, ultimately, compliance with the International Civil Aviation Organization's (ICAO) global market-based measure (MBM) scheme to limit GHG emissions from international aviation. In other words, it seeks to analyze certain issues that have directly or indirectly influenced discussions on aviation and climate change and that have played or will play a significant role in ICAO's global MBM scheme. I deal with five broad areas. First, the thesis examines ICAO's relationship with the climate change regime, the implicit mandate provided by the Kyoto Protocol and the interplay between the core principles of the United Nations Framework Convention on Climate Change (UNFCCC) regime and those of the international aviation regime. I utilize the theory of fragmentation of international law as an analytical framework for the resolution of normative conflict. Second, the thesis explores ICAO's institutional setting and its suitability for addressing climate change. Third, the thesis comprehensively analyzes the European Union Emission Trading Scheme (EU ETS), its influence on the climate change discourse, as well as the legal issues associated with it. Fourth, by applying the theory of norm entrepreneurship, the thesis assesses the role of the major players involved in climate change discourse. Fifth, the thesis highlights some issues that should be carefully considered during the design of ICAO's global MBM. This should not necessarily be construed as an attempt to develop a comprehensive global MBM scheme for international aviation. Such an endeavor would require substantial qualitative and quantitative data that fall outside the scope and reach of this exercise. I end by identifying necessary factors to consider in proposals that seek to regulate GHG emissions from international aviation.</dc:abstract><dc:abstract>RÉSUMÉ Le trafic aérien croît à un rythme annuel d'environ 5%. Les émissions de gaz à effets de serre (GES) qu'il génère devraient augmenter de 3 ou 4% par an. Actuellement, la contribution de l'aviation internationale à l'augmentation globale des GES est d'approximativement 2%, et devrait considérablement augmenter, compte tenu de la multiplication du nombre de voyageurs aériens dans toutes les régions du monde. Bien que le secteur de l'aviation ait introduit de nombreuses technologies et mesures opérationnelles permettant de contrôler les émissions, ces avancées ne permettront pas de compenser les émissions résultant de la croissance projetée. Ainsi, il n'existe aucune certitude que des carburants alternatifs seront disponibles en quantité suffisante et à des prix raisonnables, pour engendrer une réduction significative des GES.Cette thèse examine différents aspects juridiques des débats relatifs à l'aviation et au changement climatique, afin de proposer des solutions qui puissent faciliter l'adoption, la mise en place et in fine le respect de la mesure basée sur le marché (MBM) initiée par l'Organisation de l'Aviation Civile Internationale (OACI) et destinée à limiter les émissions de GES du transport aérien international. En d'autres termes, l'objectif est d'analyser certains problèmes, qui ont, directement ou indirectement, influencé les discussions afférentes au plan d'action mondial relatif aux GES de l'OACI, et qui y ont joué ou y joueront un rôle significatif. Nous abordons cinq grands thèmes. En premier lieu, cette thèse examine le lien entre l'OACI et les accords sur les changements climatiques, le mandat implicite octroyé à cette organisation par le Protocole de Kyoto, et l'interaction entre les principes fondamentaux du régime de la Convention-Cadre des Nations Unies sur les Changements Climatiques (CCNUCC) et ceux du régime de l'aviation internationale. Nous avons utilisé la théorie de la fragmentation du droit international comme outil d'analyse pour la résolution des conflits normatifs. En second lieu, cette thèse explore le cadre institutionnel de l'OACI et sa capacité à traiter les problèmes liés aux changements climatiques. Dans un troisième temps, nous analysons de manière compréhensive le système communautaire d'échange de quotas d'émission (SCEQE), son influence sur les débats sur le changement climatique, ainsi que les problèmes juridiques qui s'y rattachent. Dans un quatrième temps, par le biais de la théorie de l'entreprenariat des standards, cette thèse évalue le rôle des acteurs majeurs impliqués dans les discussions sur le changement climatique. Dans une cinquième partie, elle met en lumière certains problèmes qui devraient être soigneusement examinés lors de l'élaboration de la MBM par l'OACI. Cela ne doit pas nécessairement être interprété comme une tentative de présenter un plan exhaustif relatif à la MBM pour l'aviation internationale. Une telle tâche requerrait des données quantitatives et qualitatives substantielles, qui vont au delà de la portée et des buts de cet exercice. Nous concluons en identifiant les facteurs essentiels à prendre en compte, dans les propositions de régulation des émissions de GES dues au trafic aérien international.</dc:abstract><ual:supervisor>Paul Stephen Dempsey (Supervisor2)</ual:supervisor><ual:supervisor>Jaye Dana Ellis (Supervisor1)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/bg257h93h.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/wh246v945</ual:fedora3Handle><dc:subject>Social Sciences - Law</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Azg64tp94n"><dcterms:title>The muted city: New York, noise control and the reconfiguration of urban space</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Art History and Communication Studies</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Radovac, Lilian</ual:dissertant><dc:abstract>The Muted City examines the problematization of noise in New York City from 1930 to 1989, focusing on the periods surrounding the city's adoption of its first comprehensive noise ordinance in 1936 and the law's first major revision in 1972.  The dissertation situates noise in this specific urban context, moving between the scales of local history and microhistory in order to present an account of the ordinances and some of their broader social and cultural effects.  To accomplish this, I use archival sources, newspaper and trade reports, and advertising and popular science materials to construct a narrative of the civic processes that led to the ordinances' adoption as well as the larger urban issues that shaped them, including urban renewal, gentrification, and (post)liberalization. These, in turn, foster analyses of how noise "bleeds" into the management of public space, where it intersects with race, class, ethnicity and gender to form criminalized categories of sound that are subject to police intervention as well as technological mediation.  The dissertation concludes with a discussion of how these issues continue to resonate in the present moment, and an example of how New Yorkers have recently resisted the acoustic control of their city.</dc:abstract><dc:abstract>La ville en sourdine examine la problématisation du bruit dans la ville de New York entre 1930 et 1989 avec une emphase particulière sur les périodes entourant l'adoption de la première ordonnance générale sur le bruit en 1936 et sa première révision majeure en 1972. La dissertation situe le bruit dans ce contexte urbain spécifique, alternant entre l'histoire locale et la micro histoire pour rendre compte des ordonnances et de quelques-uns de leurs effets sociaux et culturels. Pour ce faire, j'utilise des sources archivistiques, des rapports journalistiques et sur le commerce, en plus de matériaux publicitaires et de science populaire pour construire une narration des processus civiques qui ont mené à l'adoption des ordonnances et des problèmes urbains plus généraux qui les ont façonnées, incluant le renouveau urbain, la gentrification et la (néo)libéralisation. Ces considérations, à leur tour, amènent à analyser la manière dont le bruit s'infiltre dans la gestion des espaces publics, où il interagit avec la race, la classe, l'ethnicité et le genre pour former des catégories criminalisées de bruit, sujettes à intervention policière et à médiation technologique. La dissertation se conclut sur une discussion qui fait résonner ces problèmes dans le présent et sur un exemple récent de la manière dont les new-yorkais ont opposé résistance au contrôle acoustique de leur ville.</dc:abstract><ual:supervisor>Jonathan Sterne (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/ht24wn388.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/zg64tp94n</ual:fedora3Handle><dc:subject>Communications And The Arts - Mass Communications</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Az603r166w"><dcterms:title>Participants' experience of the Trinidad and Tobago educational leadership project (TTELP): a case study</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Educational and Counselling Psychology</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Williams, Margaret</ual:dissertant><dc:abstract>RésuméCette étude de cas portrait sur les perceptions des participants de l'impact sur leurs vies professionnelles de leur participation à un programme de développement de leadership d'une durée de trois ans. Le projet en Leadership Éducationnel  de Trinidad et Tobago (TTELP) était une initiative internationalement subventionnée et dirigée par un consortium de l'Université McGill et de l'Université de Montréal et offerte à Trinidad  par une équipe d'experts des deux universités canadiennes. Les objectifs du TTELP étaient d'équiper le groupe des directeurs d'école, des directeurs adjoints et d'administrateurs intermédiaires du Ministère de l'Éducation avec les habiletés pour gérer le programme du gouvernement de restructuration et de décentralisation du système secondaire d'éducation. Le cadre théorique de cette étude était celui des communautés de pratique de Lave et Wenger (1991). Cette approche socioconstructiviste est cohérente avec le nouveau paradigme du leadership, qui la considère comme étant non hiérarchique  dont le développement est un processus en cours, systémique et impératif. Les données de cette étude ont été colligées par des sondages en ligne et par des entrevues en profondeur par téléphone avec neuf participants. Les questions de l'entrevue semi-structurée permettaient aux participants de discuter du développement de leurs activités antérieures de leadership, de leurs attentes et de leur expérience actuelle du TTELP et de l'application du nouveau savoir et des habiletés qu'ils avaient acquises. Les questions de recherche qui encadraient étaient : «Quels sont le nouveau savoir et les habiletés que les participants pensent qu'ils ont acquis?» Et «Jusqu'à quel point ont-ils été capables de les appliquer dans leurs écoles?» Les données des sondages et des entrevues avec les participants du TTELP ont été triangulées avec les données des entrevues avec les deux directeurs du projet, un National Lead Scholar et trois enseignants travaillants sous un des directeurs d'écoles participants.  Les résultats de cette recherche montrent que les participants ont senti que  leur savoir de base en leadership avait augmenté et que leurs habiletés en leadership avaient été augmentées par le TTELP. Ils ont exprimé un haut degré de satisfaction avec le programme, spécialement avec les instructeurs. Les deux aspects du programme qui ont reçu la plus forte critique furent le manque de temps pour faire tout ce qu'ils avaient besoin de faire durant le programme et l'absence de certification à sa fin. Les principales composantes du TTELP furent évaluées en utilisant les six points du modèle de Leskiw et Singh (2007) d'évaluation des programmes de développement du leadership. Les résultats de cette recherche confirment l'utilité de ces programmes de développement de leadership dans la préparation des leaders éducationnels et la construction de capacité de leadership. Les résultats soulignent aussi le potentiel pour les relations problématiques et les résultats insatisfaisants dans les programmes internationaux à moins que les développeurs de programmes soient capables de former des partenariats collaboratifs avec leurs contreparties locales et que l'élaboration des programmes soit remarquablement sensible aux besoins du contexte international. Cette étude contribue au savoir de base sur le développement du leadership  en l'appliquant aux pays en développement à travers une analyse du «Trinidad and  Tobago Educational Leadership Project».  Mots clefs : Leadership, développement de leadership, partenariats internationaux, communautés de pratique</dc:abstract><dc:abstract>AbstractThis qualitative case study investigated participants' perceptions of the impact of a three-year leadership development programme on their professional lives. The Trinidad and Tobago Educational Leadership Project (TTELP) was an internationally funded leadership development initiative directed by a McGill University-Université de Montréal consortium and delivered in Trinidad by a team of experts from the two Canadian universities. The objectives of TTELP were to equip the group of school principals, vice-principals and mid-level managers from the Ministry of Education with the skills to manage the government's programme of restructuring and decentralization of the secondary education system. The theoretical framework used in this study was Lave and Wenger's (1991) communities of practice. This social-constructivist framework is consistent with the new paradigm in leadership which views it as non-hierarchical and its development as an ongoing, systemic imperative. Data for this study were collected from an online survey followed by in-depth telephone interviews with nine participants. The semi-structured interview questions allowed participants to discuss their previous leadership development activities, their expectations and actual experience of TTELP and the implementation of the new knowledge and skills that they had acquired. The research questions that framed this study were: "What new knowledge and skills did the participants feel they had acquired?" and "To what extent have they been able to apply them in their schools?" Data from the survey and interviews with TTELP participants were triangulated with data from interviews with the two directors of the project, a National Lead Scholar and three teachers working under one of the participating principals. Findings from this study showed that participants felt that their knowledge base in leadership had improved significantly and their leadership skills had been enhanced by TTELP. They reported a strong degree of satisfaction with the programme, especially with the instructors. The two aspects of the programme for which there were the strongest criticisms were the lack of time to do all that they needed to do during the programme and the absence of certification at the end of it. Key components of TTELP were evaluated using Leskiw and Singh's (2007) six-point model for evaluating leadership development programmes. Findings confirm the usefulness of these programmes in preparing educational leaders and building leadership capacity. The results also highlight the potential for problematic relationships and unsatisfactory outcomes in international programmes unless programme developers are able to forge collaborative partnerships with local counterparts and design programmes that are conspicuously sensitive to the needs of the international context. This study contributes to the existing knowledge base in leadership development by extending it to the developing world through an analysis of the Trinidad and Tobago Educational Leadership Project.Keywords: Leadership, leadership development, international partnerships, communities of practice.</dc:abstract><ual:supervisor>Michael L Hoover (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/b8515r47v.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/z603r166w</ual:fedora3Handle><dc:subject>Education - Psychology </dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Aj6731698w"><dcterms:title>Utility of neuraminidase inhibitor dispensing data as a tool for influenza surveillance</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Epidemiology and Biostatistics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Papenburg, Jesse</ual:dissertant><dc:abstract>Surveillance performed using routinely collected electronic data offers advantages that include a short reporting delay and a low acquisition cost. Monitoring of neuraminidase inhibitor (NI) dispensing in community pharmacies has emerged as a possible automated information source for influenza surveillance. However, little is known about the utility of these data for monitoring influenza activity. Therefore, we aimed to evaluate the timeliness, correlation, and predictive accuracy of community pharmacy NI dispensing in relation to laboratory-confirmed influenza activity in Quebec, Canada, during 2010-2013. Our secondary objective was to compare the characteristics of NI dispensing to those of visits for influenza-like illness (ILI) in emergency departments (ED), a commonly used source of surveillance data.Provincial weekly counts of positive influenza laboratory tests were used as a reference measure for the level of influenza circulation. We applied ARIMA models to account for seasonality and computed cross-correlation functions to measure the strengths of association and lead-lag-relationships of NI dispensing and ILI ED visits to our reference indicator. Finally, using an ARIMA model, we evaluated the ability of NI dispensing and ILI ED visits to predict laboratory–confirmed influenza. NI dispensing was significantly correlated (R=0.68) with influenza activity with no lag; the earliest statistically significant correlation occurred with a lead-time of 1 week. The maximal correlation of ILI ED visits was not as strong (R=0.50), but occurred with a lead-time of 1 week. Both NI dispensing and ILI ED visits were significant predictors of laboratory-confirmed influenza in a multivariable model; the predictive potential was greatest when NI counts were lagged to precede laboratory surveillance by two weeks.We conclude that NI dispensing data can provide timely and valuable information for the surveillance of influenza at the provincial level.</dc:abstract><dc:abstract>La surveillance qui s'appuie sur des données électroniques recueillies et enregistrées en routine offre des avantages tels qu'un court retard de déclaration ainsi qu'un faible coût d'acquisition. La surveillance des ventes au détail de médicaments sur prescription contre l'influenza, les l'inhibiteurs de la neuraminidase (NI), a émergé comme une source possible d'information automatisée pour la vigie sanitaire de la grippe. Toutefois, les caractéristiques de la performance de ces données comme objet de surveillance ne sont pas bien connues. Dès lors, nous avons cherché à évaluer les données de distribution des NI dans les pharmacies communautaires comme un nouvel outil de surveillance de l'influenza, de par leur relation d'ordre temporelle (décalage), de leur corrélation et de leur capacité prédictive, en comparaison à l'activité grippale confirmée en laboratoire, au Québec, Canada, de 2010 à 2013. Notre objectif secondaire était de comparer ces caractéristiques à celles de la surveillance des visites pour syndrome d'allure grippal (SAG) inscrites aux d'urgences.Les données hebdomadaires provinciaux du nombre de tests de laboratoire positifs pour l'influenza ont été utilisées comme mesure de référence pour le niveau d'activité grippale. Nous avons appliqué la méthodologie de modélisation ARIMA pour tenir compte de la saisonnalité et de l'autocorrélation. Nous avons ensuite calculé les fonctions de contre-corrélation pour mesurer les forces d'association et explorer les relations temporelles entre la distribution des NI et les visites SAG avec notre mesure de référence. Enfin, nous avons évalué la valeur prédictive de la distribution des NI et des visites SAG dans le montage d'un modèle ARIMA pour les comptes d'influenza confirmés en laboratoire.La distribution des NI était significativement corrélée (R = 0,68) avec l'activité grippale au temps de latence zéro; la première corrélation statistiquement significative a eu lieu avec un décalage anticipatoire d'une semaine. La corrélation maximale des visites SAG n'était pas aussi forte (R = 0,50), mais a culminé une semaine plus tôt que les distributions NI. Tant la distribution des NI et les visites SAG à l'urgence étaient des variables prédictives significatives dans un modèle multivarié de cas confirmés en laboratoire; le potentiel prédictif du modèle était maximal lorsque les distributions NI ont été décalées pour précéder la surveillance en laboratoire de deux semaines.Ainsi, nous concluons que les données de distribution NI peuvent fournir des informations utiles et en temps opportun pour la surveillance de la grippe à l'échelle provinciale.</dc:abstract><ual:supervisor>David Buckeridge (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/7m01bp705.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/j6731698w</ual:fedora3Handle><dc:subject>Health Sciences - Epidemiology</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Avq27zr59j"><dcterms:title>Assessing stakeholder participation in Northern scientific research</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Natural Resource Sciences</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Brunet, Nicolas</ual:dissertant><dc:abstract>Plusieurs experts dans le domaine de la recherche nordique clament qu'un nouveau paradigme émerge, un paradigme caractérisé par une participation communautaire accrue en science. Cette affirmation d'un nouveau paradigme de recherche en science nordique a été exprimée dans de nombreux autres domaines, notamment dans le cadre théorique du mode 2. Comme il n'y avait pas de preuves empiriques d'un changement de paradigme, notre premier objectif était de tester cette affirmation. En utilisant le cadre mode 2, nous avons trouvé que les changements vers les approches de recherche mode 2 au fil du temps ont été modestes et progressifs et que le mode 1 continue de prédominer la science dans l'Arctique. La participation locale dans la recherche varie systématiquement entre les disciplines, les organisations et les régions. Nous avons également déterminé que la recherche sur les changements environnementaux contribue faiblement à l'émergence des approches mode 2. Ces revendications d'un nouveau paradigme de recherche ont été couplées avec une insatisfaction croissante par rapport aux activités de recherche, en particulier au sein des communautés autochtones de l'Arctique. Nous avons donc tenté de découvrir les facteurs qui permettent et limitent le développement de partenariats de recherche ainsi que les bénéfices associés. Une étude de cas approfondie d'un programme de recherche survenant dans une collectivité de l'Arctique a révélé que certains aspects contextuels et de la procédure de partenariats de recherche sont associés à des résultats bénéfiques. Ces aspects procéduraux inclus un engagement précoce des partenaires locaux dans le processus scientifique, de la conception de la recherche ou même, du processus de  proposition de recherche. Ceci fut associé avec un sentiment de contrôle local et de partage du pouvoir. Les éléments contextuels inclus le capital social entre les chercheurs et les partenaires communautaires, associé à l'histoire de recherche locale, les processus décisionnels locaux ainsi que les formes locales de réciprocité et de développement de confiance. Notre sondage de parties prenantes en recherche nordique a en outre confirmé ces résultats. Cependant, nous avons trouvé que des éléments contextuels étaient plus importants que les considérations de procédure. Nous avons constaté que, finalement, le succès des partenariats est associé au niveau de capital social des partenaires, souvent exprimé en termes de confiance. Sur la base de ces résultats et inspiré par la littérature sur la recherche pour le développement, nous avons décidé d'utiliser les cinq capitaux (humain, social, naturel, physique, financier) afin de conceptualiser et d'évaluer les partenariats. Le succès serait évalué relatif aux changements de ces cinq capitaux. Nous avons utilisé un sondage auprès d'intervenants de recherche nordique pour tester le potentiel de cette approche afin de conceptualiser et  devenir un outil pour l'évaluation de la réussite d'un partenariat de recherche. Nous avons constaté qu'en effet, la nature contextuelle des partenariats a permis à cette approche de fournir un indicateur important du changement des niveaux de capitaux, et donc, pourrait devenir un indicateur de réussite.</dc:abstract><dc:abstract>Many researchers have claimed that Northern science has experienced a paradigm shift which includes an increased emphasis on local community engagement. However, very few studies have empirically examined this claim. This thesis seeks to better understand and explore stakeholder participation in Northern science to inform research policy and practice, primarily in Canada. The shift towards a greater emphasis on local community engagement in Northern science fits within a broader transition that has been observed in international research policy, described by Gibbons et al. (1994) as a shift from Mode 1 (traditional forms of scientific discovery) to Mode 2 (knowledge generated in the context of application) approaches to knowledge production. Using this framework to analyze research articles published between 1960 and 2010 in four prominent Arctic and polar-focused journals, we identify that shifts toward Mode 2 research approaches over time have been modest and gradual, and that Mode 1 forms of knowledge production continue to dominate Northern science. Local involvement in research appears to vary systematically among disciplines, organizations and regions, raising important questions for research and policy. Recognizing that claims of a new Northern research paradigm have been coupled with growing levels of dissatisfaction with research activities within many Northern indigenous communities, there is a need to better understand the factors that enable and limit research partnership development as well as the associated outcomes. Using a single in-depth case study analysis of a successful research partnership of an International Polar Year program in a remote northern Yukon community, it was revealed that certain contextual and procedural aspects were associated with positive outcomes. The procedural aspects included early engagement in the research design or even proposal-writing process which was associated with decentralized control and power sharing. Important contextual elements included local research history and local decision making processes as well as local forms of reciprocity and trust, all identified as critical to building bridging social capital between researchers and communities. Building on these findings, a national survey of Northern research stakeholders revealed that contextual elements were generally considered more important than procedural considerations. More specifically, respondents indicated that research partnership success was more often depended on how and to what extent the social capital of stakeholders was bridged, often expressed as trust.   Acknowledging the importance of the research context and inspired by the literature on research for development, a capital assets approach to conceptualizing and assessing partnership outcomes is proposed. Based on survey data, the potential for such a capital assets approach to improve our understanding of the transformative effects of scientific research partnerships on communities and researchers is discussed.</dc:abstract><ual:supervisor>Gordon Hickey (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/ws859j61k.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/vq27zr59j</ual:fedora3Handle><dc:subject>Social Sciences - Geography </dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Asf2688275"><dcterms:title>Macroscopic anisotropy tissue modelling for three dimensional finite element analysis of internal myocardium defibrillation</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Golshayan, Maryam</ual:dissertant><dc:abstract>L'objectif de cette contribution est d'évaluer la faisabilité, les avantages potentiels et les coûts associés à la généralisation et l'amélioration des formulations d'éléments fini utilisé afin de modéliser, d'analyser et de simuler le fonctionnement théorique et pratique et l'efficacité des systèmes internes de défibrillation du myocarde.Le premier objectif de cette contribution est de développer un modèle anatomiquement précis d'élément fini du myocarde pour l'analyse et la simulation computationnelle de la fonction cardiaque. Ce travail permet de clarifier les caractéristiques essentielles requises pour produire des modèles computationnels précis, fiables et facilement adaptables pour le cœur humain. Cela fournira une base de données fonctionnelle pour l'analyse et la simulation biomédicales computationnelles de nouvelle génération afin de déterminer la santé cardiaque propre du patient. Plus important encore, cela permettra la détection précoce et non invasive des maladies de coeur avec le prototypage simulé et l'évaluation des traitements thérapeutiques et des interventions chirurgicales proposés. Afin d'atteindre cet objectif ultime, les composants clés fournis par ce travail sont de deux ordres : la génération d'un modèle d'élément fini pour le ventricule gauche, seul, basée sur des méthodes de mappage de transformation de forme structurée ainsi que le modèle d'élément fini multicouche propre au patient basé sur des données brutes extraites d'imagerie médicale. Cette dernière méthode est considérablement avancée par rapport à la méthode de pointe actuelle; elle est construite sur la base d'un ensemble autocohérent de sous-structures de domaines modulaires isoparamétriques de second ordre, ce qui facilite à la fois les capacités de la modélisation compatible du tissu anisotrope tout en préservant l'intégrité de l'adaptabilité du modèle.Le principal objectif de cette contribution est d'étudier et d'évaluer l'impact de la modélisation des aspects directionnels des propriétés de la conductivité électrique anisotrope des tissus du myocarde, du sang et des régions environnantes immédiates dans les formulations computationnelles utilisées pour modéliser, analyser et prédire l'efficacité globale de défibrillation du myocarde interne. Le tout est calculé en fonction du positionnement des électrodes, de la taille, et des profils de tension appliquée pour, à la fois, des cœurs sains et des cœurs ayant subi un infarctus. Des formulations complètes du tenseur d'anisotropie représentant une variété de modèles de plus en plus détaillés de conductivité pour représenter les couches de tissu du myocarde et les faisceaux de fibres sont examinées et évaluées par rapport à des modèles plus simples. Pour intégrer les propriétés d'anisotropie du myocarde dans les modèles computationnels, la technique de mappage basée l'algorithme Iterative Closest Point (ICP) a été utilisé pour ajuster les fibres du myocarde et la feuille de données brutes disponibles pour les modèles computationnels. Des test computationnels confirment qu'en incluant la nature anisotrope du myocarde, cela peut jouer un rôle important dans le calcul des excitations requises pour les électrodes de défibrillation internes. Il est indiqué que les modèles de tissus isotropes peuvent surestimer l'efficacité de la défibrillation. En outre, les résultats indiquent la sensibilité potentielle du seuil de défibrillation prédite (defibrillation threshold or DFT) par rapport au positionnement des électrodes, quel que soit le modèle utilisé. Il est à noter que dans certains cas les prévisions du modèle anisotrope peuvent être très similaires à celles du modèle isotrope correspondant. Les résultats montrent que de petits changements dans le positionnement et la taille de l'électrode du défibrillateur cardioverteur implantable (DCI) ainsi que la composition de modèle peuvent entraîner des variations importantes dans le seuil de défibrillation prédite (DFT).</dc:abstract><dc:abstract>The purpose of this contribution is to evaluate the feasibility, potential benefits and costs associated with generalizing and improving finite element formulations used to model, analyze and simulate the theoretical and practical operation and efficacy of internal myocardium defibrillation systems. The first goal of this contribution is to develop an anatomically accurate finite element model of the myocardium for the computational analysis and simulation of cardiac function. This work clarifies the critical characteristics required to produce accurate, reliable, and easily adaptable computational models for the human heart.  This will provide a functional database for next generation biomedical computational analysis and simulation, for patient-specific determination of human heart health.  More importantly, it will allow for the early and non-invasive detection of heart disease, along with the simulated prototyping and evaluation of proposed therapeutic treatments and surgical interventions.  Towards this ultimate objective, the key components provided by this work are twofold: the generation of a finite element model for the left ventricle alone based on structured shape transformation mapping methods, and the patient-specific multilayered finite element model based on extracted raw data from medical images. The latter method is significantly advanced over the current state-of-the-art; it is constructed based on a self-consistent set of modular isoparametric second-order sub-domain structures, which facilitate both compatible anisotropic tissue modelling capabilities and integrity-preserving model adaptability. The main objective of this contribution is to investigate and evaluate the impact of modelling the directional aspects of the anisotropic electrical conductivity properties of the myocardium tissues, blood, and the immediate surrounding regions within the computational formulations used to model, analyze and predict the overall efficacy of internal myocardium defibrillation, in terms of electrode placement, size, and applied voltage profiles for both isolated healthy and infarcted hearts. Full tensor anisotropy formulations representing a variety of increasingly detailed conductivity models for representing the myocardium tissue layers and fiber bundles are considered and evaluated against simpler models. To incorporate the myocardial anisotropy properties into the computational models, the mapping technique based on the iterative closest point algorithm was used to fit the available myocardial fiber and sheet raw data for the computational model. Computational tests confirm that including the anisotropic nature of the myocardium can play a significant role in computing the excitations required for the internal defibrillation electrodes. It is shown that isotropic tissue models can overestimate defibrillation efficacy. In addition, results indicate the potential sensitivity of the predicated Defibrillation Threshold (DFT) results with respect to the electrode placement, regardless of the model used. It is noteworthy that in certain instances the anisotropic model predictions can be very similar to corresponding isotropic ones. Results show that small changes in Implanted Cardioverter-defibrillator (ICD) electrode placement and size, as well as model composition, can result in significant variations in the predicted DFT. The computational results confirm that predicted ICD stimulation levels and their resulting current distributions can depend significantly on the tissues immediately surrounding the heart, regardless of the electrode placement; however, while the impact of including the conductivity of the blood varies with placement of electrodes, in some instances very little impact was seen.</dc:abstract><ual:supervisor>Milica Popovich (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/3j333539p.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/sf2688275</ual:fedora3Handle><dc:subject>Engineering - Electronics and Electrical</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A2b88qg252"><dcterms:title>Black matters: young Ethiopian Jews and race in Israel</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Anthropology</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Djerrahian, Gabriella</ual:dissertant><dc:abstract>Cette thèse vise à élucider les multiples articulations du concept de race et de «blackness» en Israël parmi deux groupes d'âges de juifs éthiopiens (les adolescents et les jeunes adultes). Je propose une double approche à l'analyse du stigma attaché au «blackness» juif éthiopien. D'une part, racialement parlant ce groupe fait face aux doutes persistants quant à leur «pureté» généalogique. Je décris en détail l'histoire des juifs éthiopiens, tout en explorant l'influence qu'ont eues leurs rencontres avec les juifs occidentaux sur la formation du groupe en tant que Noirs vivant en Israël. D'autre part, le stigma racial de «blackness» constitue une référence somatique superficielle renvoyant à la couleur de la peau. Ces deux logiques raciales s'affrontent et se contredisent à mesure que les juifs éthiopiens luttent pour se tailler une place au sein de la société juive israélienne. Tel que je le démontre, leur identité raciale en tant que juifs est la plateforme par laquelle le «blackness» des Éthiopiens gagne du terrain. Or, malgré leur marginalisation, leur position en tant qu'un «Autres» à l'intérieur du monde juif en Israël ne peut être dissociée des implications légales et structurales plus larges de leur inclusion raciale dans la méta-famille juive. Les relations raciales et ethniques entre juifs en Israël sont également mises de l'avant pour décrire le contexte dans lequel se constitue le «blackness» juif éthiopien et mettent en perspective les accusations de racisme portées par ces derniers contre l'État d'Israël.  En ce qui concerne la méthodologie, j'ai utilisé principalement l'enquête ethnographique, comprenant des observations participantes, des entrevues formelles, et des discussion informelles. Le travail de terrain en Israël a duré 12 mois entre 2007 et 2009. J'ai également analysé les reportages médiatiques diffusés localement en Israël ainsi qu'au niveau international qui parlaient du thème de la race et/ou du racisme et de l'intégration en rapport aux juifs éthiopiens.</dc:abstract><dc:abstract>This dissertation sheds light on the multiple articulations of race and blackness in Israel amongst two age groups of Ethiopian Jews (teenagers and young adults). My analysis of the stigma of Ethiopian Jewish blackness relies on a two-thronged approach. Racially speaking, on the one hand this group copes with lingering doubts as to the authenticity and "purity" in regards to their bloodline and genealogy. On the other hand, blackness as a racial stigma is located on the level of the epidermis and is, somatically speaking, skin deep. Both racial logics clash and contradict one another as Ethiopian Jews struggle to find their place in Jewish Israeli society. I describe in detail the historical period that formed the group that came to be known as Ethiopian Jews and recount the impact encounters with Western Jews had on their formation as black Jews living in Israel. I argue that their identity as Jews racially speaking is the platform on which Ethiopians' blackness gains traction. As such, however marginalized, their position as "internal Others" cannot be disassociated from the larger legal and structural implications of their racial inclusion into the body of the Jewish meta-family. Race and ethnic relations amongst Jews are also explored as a way to provide the backdrop against which Ethiopian Jewish blackness and claims of racism emerged.Methodologically, I used ethnographic inquiry by way of participant observation, formal interviews, and informal discussions. Fieldwork consisted of a total of 12 months between 2007-2009. I equally analyzed the media, locally in Israel and internationally as well, that addressed the topic of race and/or racism and the integration of Ethiopian Jews.</dc:abstract><ual:supervisor>Setrag Manoukian (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/v405sd51r.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/2b88qg252</ual:fedora3Handle><dc:subject>Anthropology - Cultural</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Adn39x438p"><dcterms:title>The detention of migrant children and families in Canada: advocacy, policy and lived experience</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Psychiatry</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Kronick, Rachel Cardon</ual:dissertant><dc:abstract>Children and parents who come to Canada seeking asylum and protection are regularly detained in Canada. International literature suggests that the detention of children is associated with significant morbidity, and that the wellbeing and best interests of children are often not taken into consideration. Despite this knowledge, the detention of children continues to be debated in Canadian parliament, and little is known about the experiences of families who are held in detention in Canada. This thesis examines the practice of detaining migrant children in Canada through the lenses of advocacy, legislation and lived experiences' of detainees. The need for advocacy on behalf of asylum seeking children is addressed, followed by an analysis of discursive strategies used in the Canadian House of Commons in the context of debate on immigration detention. Finally, we examine the conditions of detention and lived experiences of migrant children and families who have been detained in Canada.</dc:abstract><dc:abstract>Les enfants et les parents qui viennent au Canada en tant que requérants au statut de réfugié sont fréquemment détenus dans ce pays dont ils demandent pourtant la protection. La littérature internationale suggère que la détention des enfants est associée à une morbidité significative et que le bien-être et le meilleur intérêt de l'enfant ne sont souvent pas considérés. En dépit de ces constats, la question de la détention des enfants continue d'être débattue au parlement Canadien et l'expérience des enfants et des familles détenus, reste encore méconnue. Cette thèse examine la détention des enfants réfugiés au Canada d'un point de vue moral, légal et clinique, à partir de l'expérience vécue des enfants et des familles détenus. La nécessité d'une action concertée de la part des professionnels de la santé pour protéger ces enfants est présentée, ainsi qu'une analyse des stratégies discursives utilisées au parlement dans le contexte du débat sur la détention des demandes d'asile.Finalement, les conditions de détention et l'expérience des enfants et des familles qui ont été détenus au Canada sont examinées.</dc:abstract><ual:supervisor>Cecile Rousseau (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/41687m278.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/dn39x438p</ual:fedora3Handle><dc:subject>Anthropology - Medical and Forensic</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ab5644v77b"><dcterms:title>The functions of the transmembrane proteins Ihog and Boi in the hedgehog pathway</dcterms:title><ual:graduationDate>2014</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Medicine</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Camp, Darius</ual:dissertant><dc:abstract>Les protéines Hedgehog (Hh) sont des molécules sécrétées à l'origine de signalisations intracellulaire vitale lors du développement des vertébrés et des invertébrés. Le dérèglement de la voie de signalisation Hh est responsable de nombreux cancers et malformations congénitales. Malgré les progrès récents dans l'exploration des mécanismes moléculaires et cellulaires qui définissent la voie Hh, notre compréhension de cette voie reste loin d'être complète. Dans cette thèse, j'ai poursuivis une approche génétique pour comprendre les mécanismes impliqués dans la réception initiale et la transduction du signal Hh, en utilisant la Drosophile comme système modèle. La réception de Hh à la surface de cellule a longtemps été pensé comme étant médiée par Ptc, une protéine transmembranaire 12-pass, qui inhibe normalement la voie lorsque Hh est absent. La fixation de Hh à Ptc est censée inhiber Ptc et ainsi initier la transduction de la voie. L'interaction entre Hh et Ptc est également soupçonnée d'être essentiel pour séquestrer Hh et ainsi limiter son expression spatiale. Ma recherche a caractérisée des facteurs supplémentaires appelé Ihog et Boi impliqué dans la voie Hh. Des études préliminaires ont identifié ces molécules comme étant des protéines transmembranaires de type 1 de la superfamille des immunoglobulines capables de se lier à la fois à Hh et Ptc. Mes études ont démontré que ces molécules sont fonctionnellement redondantes, génétiquement en amont de Ptc et absolument requises à l'activation de la voie Hh. De plus, mes résultats démontrent que Ihog et Boi, contrairement à Ptc, ne sont pas requis pour la liaison et la séquestration de Hh. En outre, mes résultats démontrent que l'expression de Ptc dans des cellules est suffisantes pour lier et séquestrer Hh en l'absence de Ihog et Boi ce qui implique Ptc comme ayant un rôle central pour la fixation de Hh in vivo. En conséquence je propose qu'Ihog et Boi sont indispensables pour l'activation de la voie due à leurs rôles dans la présentation correct de Hh à Ptc menant à une conformation qui permette l'inhibition de Ptc et ainsi l'activation de la voie. Ces résultats fournissent un nouvel aperçu des mécanismes de régulation contrôlant la transduction de Hh et la formation de son gradient.</dc:abstract><dc:abstract>Hedgehog (Hh) proteins are secreted molecules that elicit intracellular signaling vital for tissue development in both vertebrates and invertebrates. Misregulation of the Hh signaling pathway is responsible for many human congenital defects and cancers. Despite recent advances in exploring the molecular and cellular mechanisms that define the Hh pathway, our understanding of the pathway is still far from complete. In this thesis research, I have taken a genetic approach to understand the mechanisms involved in the initial reception and transduction of the Hh signal, using the Drosophila developing wing as a model system. Reception of Hh at the cell surface has long been understood to be mediated by Ptc, a 12-pass transmembrane protein, which ordinarily inhibits the pathway when Hh is absent. Binding of Hh to Ptc is thought to inhibit Ptc and thereby initiate transduction of the pathway. The interaction between Hh and Ptc is also believed to be essential to sequester Hh and thus limit its spatial range of influence. My research characterizes additional Hh modulating factors at the cell surface called Ihog and Boi. Initial studies have identified them as type 1 transmembrane proteins of the immunoglobulin superfamily capable of binding both Hh and Ptc. My studies demonstrate that these molecules are functionally redundant, act upstream or at the level of Ptc, and are absolutely required for Hh pathway activation. Furthermore, my data show that Ihog and Boi, unlike Ptc, are dispensable for Hh binding and sequestration of Hh; Ptc-expressing cells can bind and sequester Hh in the absence of Ihog and Boi, consistent with a central role for Ptc in binding Hh in vivo. I therefore propose that Ihog and Boi are essential for activation of the pathway because they present Hh to Ptc in a manner that inhibits Ptc and thereby activates signal transduction. These findings provide novel insight into the regulatory mechanisms controlling Hh transduction and gradient.</dc:abstract><ual:supervisor>Frederic Charron (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/nk322h64d.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/b5644v77b</ual:fedora3Handle><dc:subject>Biology - Cell</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ac247dw302"><dcterms:title>Framing the web: cognitive modularity and the limits of belief revision</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Philosophy</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Stephens, Robert John</ual:dissertant><dc:abstract>Belief revision practices ought to respect the principles of coherence, according to standard norms of rationality. Yet numerous empirical studies suggest our belief revision practices fall hopelessly short of this goal.  Worse, a number of influential accounts in cognitive science note that there are hard computational limits involved in any sort of holistic, global belief revision. We are faced with what cognitive scientists call the frame problem, which alludes to the difficult question of where to stop considering evidence before committing to (or rejecting) any given belief, yet at the same time, trapped in what Cherniak (1986) refers to as the finitary predicament of having limited time and computational resources to engage in the process.   I argue that an effective way to escape this dilemma is to invoke a modular cognitive architecture, where belief revision practices are sub-served, mediated, and heavily circumscribed by informationally encapsulated cognitive mechanisms and heuristic processing.  A number of influential accounts have emerged in recent years arguing for such "massively modular" systems as a response to various aspects of the frame problem (Carruthers, 2006a; Jackendoff, 2007; Sperber, 2005; Barrett &amp; Kurzban, 2006).  I defend my own version of such an account, with a specific emphasis on the question of belief revision within such a modular framework. I begin by exploring the Fodor's (1983) thesis of perceptual modularity and then elaborate the idea, arguing that there is evidence for assembled modular structures, including integrative modular assemblies that can execute belief revision processes in a computationally tractable fashion, despite Fodor's well-known objections to this extension of his theory.I describe a modular, heuristically driven cognitive system that is plausibly capable of approximating the sort of global, holistic belief revision practices that rationality demands, while maintaining computational tractability. The price of such a system, however, is that it is error-prone—it will have systematic patterns of breakdown, where some beliefs will turn to out to be essentially unrevisable and some inconsistencies of belief will be irremediable.  I argue that this prediction of the account is confirmed by current research on memory distortion and delusion.  Finally, I demonstrate how my account may illuminate and help resolve some ongoing debates regarding the etiology, doxastic status, and potential treatment of certain monothematic delusions.</dc:abstract><dc:abstract>Les pratiques de révision des croyances doivent respecter les principes de cohérence, selon les normes de la rationalité.  Pourtant, de nombreuses études empiriques suggèrent que nos pratiques de révision des croyances ne respectent clairement pas cet objectif. Pire encore, un certain nombre de théories influentes dans les sciences cognitives notent qu'il y a des limites de calcul formidables impliqués dans toute sorte de révision holistique de croyance. Nous sommes confrontés au problème de cadre, qui renvoie à la question difficile de savoir où arrêter l'examen des preuves avant de s'engager à (ou de rejeter) une croyance, mais en même temps, pris au piège dans ce que Cherniak (1986) appelle la situation finie d'ayant peu de temps et de ressources de calcul à dédier à ce processus. Je soutiens qu'un moyen efficace d'échapper à ce dilemme est d'invoquer une architecture cognitive modulaire, où les pratiques de révision des croyances sont sous-desservies et fortement encadrées par des mécanismes cognitifs encapsulés ainsi que le traitement heuristique. De nombreuses théories influentes qui ont émergé au cours des dernières années défendent les systèmes "massivement modulaires" comme réponse à divers aspects du problème de cadre (Carruthers, 2006a; Jackendoff, 2007; Sperber, 2005; Barrett &amp; Kurzban, 2006). Je défends ma propre version d'une telle théorie, avec un accent particulier sur la question de la révision des croyances dans un cadre modulaire.  Je commence par explorer la thèse de la modularité de Jerry Fodor (1983), puis j'élabore l'idée, soutenant qu'il existe des preuves de structures modulaires assemblées, y compris les assemblages modulaires intégrées qui peuvent exécuter des processus de révision des croyances dans un mode de calcul tractable, malgré les objections de Fodor à cette extension de sa théorie. Je décris un système cognitif modulaire, entraîné par des processus heuristiques, qui est probablement capable de rapprocher les pratiques de révision de croyance holistique exigées par la rationalité, tout en conservant tractabilité informatique.  Toutefois, le prix d'un système de croyance est qu'il est une source d'erreurs et qu'il y aura des mouvements systématiques de rupture, où certaines croyances sont essentiellement non révisables et certaines incohérences seront irrémédiables.  Je soutiens que cette prédiction de la thèse est confirmée par de nombreuses études empiriques sur les distorsions de la mémoire et croyances délirantes. Finalement, je démontre comment ma thèse peut éclairer et aider à résoudre certains débats en cours sur l'étiologie, l'état doxastique et le traitement potentiel de certains délires monothématiques.</dc:abstract><ual:supervisor>Ian Jeffrey Gold (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/mp48sg681.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/c247dw302</ual:fedora3Handle><dc:subject>Philosophy, Religion And Theology - Philosophy</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Agq67jv26k"><dcterms:title>The emancipatory justice claim</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Civil Law</schema:inSupportOf><dc:contributor>Faculty of Law</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Lehun, Richard</ual:dissertant><dc:abstract>Laws supply us with guidelines and solutions. But what if our survival were to depend on normative transformations that the law is structurally disabled from recognizing? How do we deal with a contradiction between the persistence of law, and the need to enable outcomes that negate the law, as it currently exists? If one asks this question, one begins to make a counter- factual justice claim, an emancipatory claim. This thesis argues that the evolution of collective otherregarding norms cannot be visualized using the existingframe of reference of legal legitimacy.The first chapter introduces key concepts relating to the emancipatory justice claim. They include: (i) a justice matrix: the differentiation and contextualization of often structurally contradictory justice claims; (ii) an economy of affirmation: epistemological constraints that limit justice expectations; (iii) justice resources: the allocations made towards justice outcomes; (iv) antinomical burdening: the challenge posed by parallel and mutually exclusive justice outcomes to which an economy of affirmation responds; (v) legacy subjectivity: an existing horizon of individualexpectations for justice; and (vi) emancipatorydisappointment: the characteristic of emancipatory moments that makes them inadequate to render the justice claims they assert.The second chapter analyzes contemporary understandings of the legal, as manifested in legal positivist and natural law theories. The goal is to show how both assert emancipatory justice claims and close them off, thus creating a threshold of inadequacy within the law. In the third chapter, I examine the shifting emancipatory potential of equity through its Jewish, Classical Greek, Roman, and English iterations. Law has throughout history struggled with its own emancipatory inadequacy by acknowledging an otherness within it.The fourth chapter offers a theory of how to confront the law's continuous inadequacy in light of such emancipatory claims. Here I contextualize Adorno's critique of epistemology and trace the interdependence of critical epistemology and critique of justice.The fifth and last chapter looks at the expansion of other-regarding fiduciary duties and their potential relevance to macro-normative challenges. I close with a critique of two Supreme Court of Canada cases in order to illustrate the shortcomings of existing fiduciary theories and jurisprudence in light of the theory elaborated here.</dc:abstract><dc:abstract>Les catégories juridiques nous fournissent des di-rectives et des solutions. Mais que faisons-nous si notre survie dépend maintenant d'une transformation normative que la loi est structurellement incapable de permettre? Comment pouvons-nous faire face à la con-tradiction entre la persistance du juridique, et le besoin de permettre des résultats qui déconstruisent la nature du juridique actuel? Si l'on pose cette question, on commence à faire une revendication de justice émancipatrice. Cette thèse énonce que l'évolu-tion vers une constellation de normes collectives orientées vers l'autrui – les normes fiduciaires – ne peut pas être visualisées en utilisant le cadre exis-tant pour déterminer la légitimité juridique. La thèse examine comment la transformation sociale peut être envisagée à travers une nouvelle compréhension de la durabilité normative.Le premier chapitre introduit les concepts clés pour la contextualisation d'une revendication de jus-tice émancipatrice. Elles sont: (i) une matrice de justice : la différenciation et la contextualisation des revendications de la justice souvent contradic-toires; (ii) une économie de l'affirmation : les con-traintes épistémologiques qui limitent ce qui est at-tendu de la justice; (iii) les ressources de la jus-tice : ce qui est alloué pour rendre justice; (iv) les surcharges antinomiques : le défi lancé par des résul-tats de la justice parallèles et mutuellement exclu-sives auxquels une économie de l'affirmation répond; (v) le patrimoine de la subjectivité : l'horizon ac-tuel des attentes individuelles en matière de justice; et (vi) la déception de l'émancipation : la caracté-ristique des moments de l'émancipation qui les laisse inadéquats pour rendre la justice qu'ils affirment.Le deuxième chapitre analyse les interprétations du juridique offertes par les écoles de positivisme et jus naturalisme. L'objectif est de montrer comment les deux écoles affirment les revendications de justice émancipatrice tout en les restreindre à outrance, créant ainsi un seuil d'insuffisance dans le concept de droit. Dans le troisième chapitre, nous examinons l'évolution du potentiel émancipateur de l'«équité» à travers ses itérations dans la tradition Talmudique, grecque antique, romaine, et anglaise. Tout au long de l'histoire, le juridique a lutté avec sa propre insuf-fisance émancipatrice en reconnaissant une altérité intérieure au droit.Le quatrième chapitre théorise comment le droit pourrait acquérir une capacité de confronter sa propre insuffisance perpétuelle. Je contextualise la critique d'Adornienne de l'épistémologie et trace l'interdépendance entre l'épistémologie critique et la justice. Le cinquième et dernier chapitre se penche sur l'expansion des obligations fiduciaires envers l'autrui et leur pertinence potentielle pour les défis macro-normatifs. Je termine par une critique de deux arrêts de la Cour suprême du Canada afin d'illustrer les lacunes des conceptualisations fiduciaires exis-tantes à la lumière de la théorie développée ici. </dc:abstract><ual:supervisor>Richard Janda (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/fn1072110.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/gq67jv26k</ual:fedora3Handle><dc:subject>Social Sciences - Law</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ax920g0803"><dcterms:title>Cartographic empire: production and circulation of maps and mapmaking knowledge in the Song dynasty (960-1279)</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Art History and Communication Studies</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Lin, Fan</ual:dissertant><dc:abstract>Ma dissertation est une étude sur les significations sociales des cartes et des différentes formes de connaissances géospatiales dans la Chine des Song (960-1279). Je soutiens que les connaissances géographiques étaient produites, reproduites et transformées par la cartographie et par la circulation, dans des contextes de culture d''imprimé, d'examens impériaux et de réformes politiques. Je divise les cartes et autres représentations graphiques que j'examine en trois catégories selon leurs thèmes et fonctions sociales : (1) cartes et diagrammes impériaux commandés par la cour des Song ayant une utilité administrative et militaire; (2) cartes, tableaux et graphiques faits par des élites lettrées en construisant la géographie d'un passé canonique basé sur le «Tribut de Yu»; et (3) des cartes de répertoires principalement faites par des élites locales dans des circonstances où la conscience de la localité et ses liens avec l'État étaient tous les deux formulés et négociés. Les cartes de ces trois catégories, vues comme des objets dans le contexte de relations sociales, étaient produites et commandées par divers échelons de l'élite sociale. Je conclus que les identités sociales des lettrés Song et la compréhension de l'empire étaient tous les deux formés par l'interaction et les échanges de connaissances géographiques et cartographiques.</dc:abstract><dc:abstract>My dissertation is a study of the social meanings of maps and various forms of geospatial knowledge in Song China (960-1279). I argue that geographical knowledge was produced, reproduced and transformed through mapmaking and circulation within the contexts of print culture, civil service examinations, and political reforms. I divide the maps and other graphic representations I examine into three categories according to their subject matter and social functions: (1) imperial maps and diagrams commissioned by the Song court serving administrative and military purposes; (2) maps, tables and charts made by literati scholars in constructing the geography of a canonical past based on the "Tribute of Yu"; and (3) gazetteer maps made primarily by local scholars as a venue in which both the consciousness of the "local" and its bond with the state were formulated and negotiated. Maps in these three categories, viewed as objects within the context of social relations, were produced and commissioned by various echelons of the social elite. I conclude that both the Song literati's social identities and understanding of the empire were shaped by the interactions and exchanges of geospatial and cartographic knowledge.</dc:abstract><ual:supervisor>Robin Yates (Supervisor2)</ual:supervisor><ual:supervisor>Jeffrey Moser (Supervisor1)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/fb494c339.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/x920g0803</ual:fedora3Handle><dc:subject>Communications And The Arts - Art History</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A8910jx57g"><dcterms:title>Adsorption and bacterial adhesion characteristics of proteins, microbial growth media and milk on abiotic surfaces under static and laminar flow conditions</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Food Science and Agricultural Chemistry</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Hiremath, Nikhil</ual:dissertant><dc:abstract>Comprendre l'adhérence des substances biologiques comme des macromolécules et des micro-organismes sur des surfaces abiotiques a des effets délétères pour l'environnement de l'industrie alimentaire à cause des problèmes de sécurité ou détérioration alimentaire. Dans cette étude, deux surfaces abiotiques ont été conditionnés avec des protéines, des milieux de croissance microbienne, le lait  dans des conditions statiques et sous flux. L'étendue de la protéine adsorbée sur des surfaces a été quantifiée en utilisant le teste micro-BCA. Les surfaces de contact alimentaire (mica et polystyrène), conditionnés et non conditionnés, ont été caractérisés par des mesures d'angle de contact pour obtenir des propriétés thermodynamiques pour les deux surfaces. Les solutions de conditionnement ont également été caractérisées par diffraction dynamique de la lumière et des mesures de potentiel zêta. L'énergie libre totale d'interaction a été calculé en utilisant les modèles thermodynamique et XDLVO. L'effet du pré-conditionnement sur l'adhérence des bactéries aux deux surfaces ont été étudiés. Sous condition statique, les résultats ont montré que la quantité de protéine adsorbée sur le mica était beaucoup plus élevée que les surfaces de polystyrène, attribué a son propriétés hydrophiles. La quantité de protéines à partir de solutions à base de caséinate de sodium adsorbé sur les deux surfaces (mica et polystyrène) était le plus élevé par rapport à d'autres solutions de conditionnement. Les propriétés thermodynamiques des surfaces conditionné ont montré qu'ils étaient les donneurs d'électrons ou tenir le rôle d'un base Lewis, qui sont les propriétés typiques pour des rotéines hydratés. Les mesures de potentiel DLS et Zeta ont indiqué que les protéines étaient dans des états agrégés dans les solutions et avait une charge de surface négative. La pré-conditionnement des surfaces (mica et polystyrène) modifié leurs propriétés thermodynamiques, en particulier, les constituent donneur et accepteur d'électrons de l'énergie libre de surface, qu'avaient  un impact significatif sur l'hydrophobie des surfaces pré-conditionnés par rapport à les surfaces non-conditionnée. L'énergie libre d'interaction, calculé avec les deux modèles, ont démontré une adhérence favorable de solutions de conditionnement (dans la plupart des cas) sur les deux surfaces, mais n'a pas réussi à prédire avec précision l'étendue de l'adsorption des protéines sur les surfaces. Dans des conditions de flux laminaire la quantité de protéines adsorbées sur le mica et le polystyrène surface était environ deux fois plus élevés que ceux obtenus dans des conditions statiques. Les mesures DLS des solutions de conditionnement ont montré que les tailles de particules des solutions de conditionnement ont été plus diffusées que dans des conditions statiques. État de flux a également modifié les propriétés thermodynamiques des surfaces (mica et polystyrène) par rapport à des conditions statiques. L'analyse par AFM des deux surfaces statiques et conditionnés flux a démontré que le film de conditionnement formé n'était pas un film continu, mais un dépôt hétérogène et fixé sous la forme d'agrégats. L'adhésion de Listeria innocua aux surfaces pré-conditionnée avec BSA, TSB ou CAS sous flux a montré des valeurs d'adhérence plus faibles par rapport aux surfaces qui ont été pré-conditionnés par méthode statique. Par contre, les surfaces pré-conditionnées par lait (entier et écrémé) sous flux ont démontré des valeurs d'adhérence plus élevées de L. innocua par rapport aux conditions statiques, indiquant des variations dépendantes de la source. En plus, il a été observé que le nombre de cellules de L. innocua adhéré sur des surfaces de mica et de polystyrène pré-conditionnés dans des conditions statiques avec CAS, WML et SML était inférieur à Listeria monocytogenes sur les surfaces qui ont été pré-conditionnés aux mêmes conditions, indiquant des variations dépendant de la souche microbienne.</dc:abstract><dc:abstract>Understanding the adhesion of bio-molecules and microorganisms to abiotic surfaces is an important consideration in food industry. The formation of these biofilms can have deleterious effects leading to contamination of food or materials coming into contact with them, causing spoilage &amp;/or safety concerns. Among the biomolecules proteins are known to adhere to the surface very rapidly, followed by other biomolecules and microorganisms. In this study the two abiotic model surfaces, were conditioned with proteins [bovine serum albumin, sodium caseinate], microbial growth media [tryptic soya broth] and milk [whole milk, skim milk] under static and dynamic flow processing conditions. The extent of protein adsorbed to surfaces was quantified using the micro BCA protein assay. The food contact surfaces conditioned or without conditioning, were characterized using contact angle measurements to obtain various surfaces thermodynamic properties. The conditioning solutions were also characterized by dynamic light scattering and zeta potential measurements. The total free energy of interaction was calculated using the thermodynamic and the extended XDLVO models, and the adhesive potential of the biofilms was evaluated. The effect of preconditioning on the adhesion of bacteria to mica and polystyrene were studied. In addition the distribution of conditioning solutions and bacteria on the surface was evaluated using atomic force microscopy. The results under static conditions showed that the amount of proteins adsorbed on mica was much higher than polystyrene surfaces which may be because mica is more hydrophilic and polystyrene more hydrophobic. Sodium caseinate had the highest adsorption on both mica and polystyrene when compared to other conditioning solutions. The thermodynamic properties of conditioned surfaces showed that they favored electron-donating or Lewis base properties which are typical for proteins in hydrated states. DLS and Zeta potential results indicated that proteins were in aggregated states in solutions and had a negative surface charge. Preconditioning of mica and polystyrene surfaces altered their surface thermodynamic properties, especially, the electron donor and acceptor components of the surface free energy. This had a significant impact on the resulting hydrophobicity of the preconditioned surfaces as compared to the surfaces which were not conditioned. The computed free energy of interaction using the two models indicated the adhesion potential of conditioning solutions (in most cases) on both surfaces, but failed to accurately predict the extent of protein adsorption on surfaces. Under laminar flow conditions the amount of protein adsorbed onto mica and polystyrene surface was approximately two times higher than those obtained under static conditions. The DLS measurements of conditioning solutions showed that particle sizes of the conditioning solutions were more polydisperse than under static conditions. Dynamic flow condition also altered the surface thermodynamic properties of mica and polystyrene as observed with static conditions. The AFM analysis of both static and flow conditioned surfaces revealed that the conditioning film formed was not a continuous film but a heterogeneous deposit and attached in the form of aggregates. The adhesion of Listeria innocua to mica and polystyrene surfaces that were preconditioned with BSA, TSB and CAS under laminar flow showed lower adhesion values in comparison with those under static settings. However, with whole milk and skim milk, higher adhesion values of L. innocua were observed under flow conditions as compared with static conditions indicating bio-film source dependent variations. It was also observed that L. innocua cell adhesion on mica and polystyrene surfaces preconditioned with CAS WML and SML under static conditions were lower than Listeria monocytogenes under similar conditions, indicating strain dependent variations.</dc:abstract><ual:supervisor>Hosahalli Ramaswamy (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/70795b83w.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/8910jx57g</ual:fedora3Handle><dc:subject>Agriculture - Food Science and Technology</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Akh04ds638"><dcterms:title>An architecture for multibit log-domain delta-sigma modulators and low-power CMOS implementation targeting 10-12 bit resolution</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Shaheen, Mohamed</ual:dissertant><dc:abstract>Les interfaces sensorielles biopotentielles en dispositifs biomédicaux ont besoin de convertisseursanalogique-numérique (CAN) à haute résolution fonctionnant à faibles moyennes vitesses. En outre, les exigences de faible puissance et de basse tension d'alimentation de ces systèmes sont essentielles et sont de plus en plus strictes. Le fonctionnement à faible puissance est nécessaire pour augmenter la durée de vie des batteries des dispositifs implantables. L'abaissement de la tension d'alimentation est entraîné par l'utilisation croissante de traitement numérique dans les dispositifs implantables à calculs extensives et les dispositifs biomédicaux portables; que les tensions d'alimentation sont abaissés, la consommation électrique numérique est réduite. De plus, pour prolonger la vie des batteries, ces dispositifs doivent être capables de fonctionner à des tensions d'alimentation allant de la tension nominale VDD jusqu'à la tension de fin de vie (EOL) de la batterie.Cette thèse explore de nouvelles techniques pour la conception de CAN à faible puissance, à basse tension, et à haute résolution pour l'acquisition des signaux biomédicaux dans les dispositifs portables. Des techniques de conception de circuits infraliminaires, et en particulier les techniques de circuits en domaine log (log-domain) dans les modulateurs DS, sont utilisés pour réaliser ces objectifs de conception. Plus précisément, ce travail explore ce qui suit:1. Les modulateurs DS multibit en domaine log (log-domain): Les modulateurs DS en domaine log précédemment rapportés ont été limitées à une quantification d'1-bit et, par conséquent, ne pouvaient pas bénéficier des avantages liés à la quantification multibit (à savoir, la réduction de bruit de quantification intra bande, et l'augmentation de stabilité du modulateur). Cette thèse explore les défis de la quantification multibit et de la conversion numérique-analogique en domaine log, et présente un nouveau modulateur DS multibit en domaine log qui est pratique pour la realisation CMOS. Il démontre l'équivalence du système conu pour les modulateurs classiques intérieurement linéaires. De plus, des modèles Simulink pour les circuits du modulateur DS en domaine log sont proposés, et les effets des non-idéalités divers de circuit sur la performance de l'architecture du modulateur DS multibit en domaine log sont étudiées.2. La réalisation du circuit du filtre de boucle à faible distorsion et à faible bruit: La réalisation des modulateurs DS en domaine log ciblant des applications à haute résolution nécessite la minimisation de la distorsion et du bruit dans le filtre de boucle en domaine log. Dans ce travail, des blocs de circuits en domaine log à faible distorsion sont presentés. En outre, les tendances de conception de circuits log-domain sont examinées et une méthode d'optimisation du bruit est proposée pour répondre à l'objectif de rendement à haute résolution tout en conservant fonctionnement à faible puissance. La nécessité des circuits log-domain à faible distorsion et les compromis de conception sont validés par des simulations au niveau du circuit. En outre, un convertisseur numérique-analogique (CNA) de sortie à courant ayant faible bruit est proposé pour le modulateur DS en log-domain. Un prototype du modulateur DS multibit de classe AB en domaine log a été conu et fabriqué en 0,13 μm technologie CMOS. Dans la simulation, le modulateur proposée atteint 10.47-bit de rapport signal-sur-bruit-et-distorsion (SNDR) sur une largeur de bande de 10 kHz avec un signal d'entrée différentiel de 0,84 Vpp, tout en fonctionnant à partir d'une alimentation de 0,8 V et en consommant une puissance totale de 46.7 μW. Les résultats du prototype fabriqué indiquent l'instabilité du biais dc dans les sorties des intégrateurs du modulateur DS, et, au moyen des tests des composants individuels, valident le fonctionnement des différents circuits à l'intérieur du modulateur.</dc:abstract><dc:abstract>Biopotential sensory interfaces in biomedical devices require high-resolution analog-to-digital converters (ADCs) operating at low-to-medium speeds. Additionally, the low-power and low-supply voltage requirements of such systems are critical and are increasingly stringent. Low-power operation is necessary in order to increase the battery life of implantable devices. Lowering of supply voltages is driven by the increasing reliance on digital processing in computationally-extensive implantable and portable biomedical devices; as supply voltages are lowered, digital power consumption is reduced. Moreover, to extend the battery life, these devices must be capable of operating from supply voltagesranging from the nominal VDD down to the end-of-life (EOL) battery voltage.This thesis explores new techniques for the design of low-power low-voltage ADCs for high-resolution biomedical signal acquisition in portable devices. Subthreshold circuit design techniques, and in particular log-domain circuit techniques in Delta Sigma modulators, are utilized to realize these design objectives. Specifically, this work investigates the following:1. Multibit Log-Domain Delta-Sigma Modulators: Previously reported log-domain Delta-Sigma modulators were limited to 1-bit quantization and hence could not benefit from the advantages associated with multibit quantization (namely, reduced in-band quantization noise, and increased modulator stability). This thesis explores the challenges of multibit quantization and digital-to-analog conversion in the log-domain, and presents a novel multibit log-domain Delta-Sigma modulator, practical for CMOS implementation. It demonstrates the equivalence of the designed system to classical, internally-linear modulators. Furthermore, SIMULINK models of log-domain Delta-Sigma modulator circuits are proposed, and the effects of various circuit non-idealities on the performance of the proposed multibit log-domain Delta-Sigma modulator architecture are investigated.2. Low-Distortion Low-Noise Loop-Filter Circuit Implementation: The realization of log-domain Delta-Sigma modulators targeting high-resolution applications necessitates a minimization of distortion and noise in the log-domain loop-filter. In this work, low-distortion log-domain circuit blocks are presented. Furthermore, the design trends of log-domain circuits are investigated and a noise-optimization method is proposed to meet the targeted high-resolution performance while maintaining low-power operation. The necessity of the low-distortion log-domain circuits and the design tradeoffs are validated through circuit-level simulations. Additionally, a low-noise current output DAC is proposed for the log-domain Delta-Sigma modulator. A class AB multibit log-domain Delta-Sigma modulator prototype was designed and fabricated in 0.13 μm CMOS technology. In simulation, the proposed modulator achieves 10.47-bit signal-to-noise-and-distortion-ratio (SNDR) over a 10 kHzbandwidth with a 0.84 Vpp differential signal input, while operating from a 0.8 V supply and consuming a total power of 46.7 μW. Results of the fabricated prototype indicate dc-bias instability within the Delta-Sigma modulator's integrator outputs and, through testing of individual components, validates the operation of various circuits within the modulator.By proposing a novel multibit log-domain Delta-Sigma modulator architecture and low-distortion log-domain circuits, and by presenting the first class AB implementation of log-domain Delta-Sigma modulators, the presented modulator achieves low-power high-resolution operation at aggressivelylow supply voltages and with one of the largest reported input-signal-swing to supply-voltage ratios. Furthermore, by presenting an optimization procedure for the various design parameters involved, this work aims at easing the incorporation of log-domain circuit techniques in Delta-Sigma modulator applications.</dc:abstract><ual:supervisor>Yvon Savaria (Supervisor2)</ual:supervisor><ual:supervisor>Fabrice Labeau (Supervisor1)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/t435gg924.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/kh04ds638</ual:fedora3Handle><dc:subject>Engineering - Electronics and Electrical</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Aqz20sw872"><dcterms:title>Biodeterioration of concrete sewer pipes: a practical analytical model</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Civil Engineering and Applied Mechanics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Hudon, Emilie</ual:dissertant><dc:abstract>La durabilité des infrastructures enfouies est souvent hors de l'esprit du public. Au Canada seulement, selon une étude de la Fédération canadienne de la municipalité datant de 2007, un investissement de plus de 40 milliards de dollars serait nécessaire pour assurer un niveau de service acceptable pour toutes les infrastructures d'eau. Contrairement à différents types de dégradation due aux contaminants locaux dans le sol, dans les matériaux de construction, ou dues aux conditions météorologiques, toutes les municipalités peuvent faire face à la biodégradation dans leurs systèmes de transport et de traitement des eaux usées. La biodeterioration d'égouts en béton se produit sur le béton non-immergées lorsque des micro-organismes vivant  en biofilm excrètent de l'acide sulfurique, substance délétère pour le béton due à la présence d'acidité (ions H+) et de sulfates. Ce programme de recherche combine différents domaines du génie civil et du génie de l'environnement en y intégrant des notions de chimie et de biologie. Plus précisément, le programme de recherche propose deux outils d'analyse applicables à la prévision des réactions qui se produisent pendant la biodégradation des égouts en béton. Premièrement, une nouvelle approche de modélisation du pH est proposée. Dans cette nouvelle approche, les variations au pH sont calculées directement dans chaque processus par le coefficient stœchiométrique (̶ ΔH+ / β), où ΔH+ est la production ou la consommation de protons et β est le pouvoir tampon. L'approche tient compte également des effets de la force ionique. La nouvelle approche peut prédire les changements au pH dus à l'addition ou à la production biologique d'acides et de bases et dus à l'équilibre avec les gaz et les minéraux. Elle est plus simple que les approches existantes tout en maintenant le même niveau de précision. Ensuite, l'approche a été appliquée à la modélisation des réactions se produisant durant la biodétérioration des égouts : la production biologique d'acide sulfurique (diminution du pH), et la dissolution de la pâte de ciment hydraté (augmentation du pH). La dissolution de la pâte de ciment hydraté fut modélisée par une réaction en surface, où l'hydroxyde de calcium se dissout de manière préférentielle. La diminution du pH due à la production d'acide sulfurique à partir de thiosulfate a pu être modélisée par une réaction de dismutation. Afin de mieux représenter les conditions de détérioration dans les égouts, les mêmes réactions ont été étudiées mais avec la biomasse formant des biofilms. Alors que les effets délétères de l'acide sulfurique sur la pâte de ciment hydratée et le béton sont bien connus, l'impact du rapport eau/ciment (e/c) sur cette dégradation n'est pas aussi évident. La cinétique de dissolution du calcium à partir de la pâte de ciment hydraté dans une solution acide a donc été paramétrée. Les caractéristiques de l'échantillon (rapport e/c et carbonatation) ont été testés mais n'ont pas eu d'impact statistiquement significatif, mais le type d'acide et la concentration de l'acide l'étaient. Ce paramétrage est appliqué à la prédiction de la perte de masse de disques en béton soumis à l'acide sulfurique et à différents régimes de brossage. Le brossage du béton crée des forces de cisaillement représentant l'effet de l'écoulement des eaux usées à la ligne d'eau dans les égouts et  augmentant significativement la dégradation. Cette thèse propose une revue multidisciplinaire de la biodétérioration des égouts en béton, développe une  nouvelle approche pour la modélisation du pH applicables dans les modèles de traitement des eaux (et des biosolides) existants, et  présente plus d'information sur la durabilité de la pâte de ciment hydraté et du béton face aux attaques acide. La validation de la nouvelle approche de modélisation du pH pour son utilisation dans les modèles de procédés existants ainsi que l'interaction entre le béton et les biofilms devraient être explorés en plus de détails.</dc:abstract><dc:abstract>Durability of buried infrastructure is often "out-of-sight and out-of-mind". In Canada alone, according to a Federation of Canadian Municipality study from 2007, upgrading and building new water infrastructure to an acceptable level of service requires an expenditure of more than $40 billion. Unlike different types of degradation due to local soil contaminants, construction materials, or weather conditions, biodeterioration in sewage transportation and treatment systems is generally faced by all municipalities worldwide. Biodeterioration of concrete sewers occurs when microorganisms living in biofilm formation on unsubmerged sections of concrete excrete sulfuric acid, which is deleterious to the concrete because it contains acidity (H+ ions) and sulfates. This research program combines different areas of civil and environmental engineering by integrating important biological and chemical concepts. More specifically, the research program proposes two analytical models applicable to predicting reactions occurring during biodeterioration of concrete sewers.   First, a new modeling approach for pH changes is proposed. In this new proposed pH approach, pH changes are calculated in each process definition by the stoichiometric coefficient (–∆H+/β), where ∆H+ is the production or consumption of protons and β is the buffering capacity. The method also includes the effects of the ionic strength. The method can predict pH changes due to the input or biological production of acids and bases, or equilibrium with gases and minerals. It is found to be simpler than the existing methods, while maintaining the same level of accuracy. The approach was then applied to reactions where pH changes kinetically. Two reactions occurring during the biodeterioration of concrete sewers were studied: the continuous production of sulfuric acid by sulfur-oxidizing biomass (decrease in pH), and dissolution of hydrated cement paste (increase in pH). In batch-reactors, the dissolution of hydrated cement paste was modeled by a surface reaction where calcium hydroxide dissolves preferentially.  The decrease in pH due to the production of sulfuric acid from thiosulfate could be accurately modeled by a disproportionation reaction where the biomass stores part of the thiosulfate as sulfur granules and oxidizes the rest as sulfates and protons. The same reactions occurring in biofilm formation were also studied to represent the sewer conditions more closely. While the deleterious effects of sulfuric acid to hydrated cement paste and concrete are well known, the impact of the w/c ratio on the extent of degradation is not as clear. To help alleviate this situation, the dissolution kinetics of calcium from hydrated cement paste in acidic solution was parameterized. Sample characteristics (w/c ratio and carbonation) were tested but were not found to have a statistically significant impact on the dissolution parameters. However, acid type and concentration were found to significantly affect the same parameters. The parameterization was applied to predict the mass loss of concrete discs subjected to sulfuric acid and different brushing regimes. Brushing of the concrete surface creates shearing forces representing the effect of sewerage flow at the water line in sewers. These forces were found to cause a significant increase in deterioration. The part of mass loss due to diffusion was determined from the previous calcium solubilisation experiment on hydrated cement paste prism. Overall, this thesis offers a multi-disciplinary review of the biodeterioration of concrete sewers, proposes a new modeling approach to pH changes in process models, and develops some insights on the impact of acidic solutions on hydrated cement paste and concrete durability. Further research on this topic should focus on validating the buffering capacity approach to existing wastewater and biosolides treatment models, and modeling the interactions between concrete and biofilms.</dc:abstract><ual:supervisor>Dominic Frigon (Supervisor2)</ual:supervisor><ual:supervisor>M Saeed Mirza (Supervisor1)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/rx913s840.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/qz20sw872</ual:fedora3Handle><dc:subject>Engineering - Civil</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Akh04ds64j"><dcterms:title>Assessing the effectiveness of adding gliclazide or pioglitazone in patients with type 2 diabetes using post-market observational data</dcterms:title><ual:graduationDate>2015</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Epidemiology and Biostatistics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Wang, Ting-Yu</ual:dissertant><dc:abstract>Contexte: Plusieurs études ont démontré une différence entre l'efficacité obtenue pré et post marché, ce qui démontre la nécessité d'évaluer l'efficacité post marché. Par contre, la comparaison entre l'efficacité pré et post marché est difficile à cause des mesures non-systématiques de l'hémoglobine glyquée (HbA1c).Objectifs: Déterminer l'efficacité d'ajouter la pioglitazone ou gliclazide au metformin dans une population avec le diabète de type 2 utilisant une nouvelle méthode pour estimer le contrôle de la glycémie et comparer à l'efficacité obtenue dans un essai randomisé contrôlé (ERC). Notre deuxième but est de déterminer l'efficacité dans un sous-groupe exclus de l'ERC, mais qui reçoive encore le médicament : patients âgés plus que 75 ans. Méthodes: Une cohorte rétrospective était déterminée utilisant un grand réseau de données du Royaume Uni (Clinical Practice Research Datalink) pour examiner l'efficacité de pioglitazone et metformin comparant à celui du gliclazide et metformin. La population était sélectionnée pour ressembler aux critères d'inclusion et d'exclusion d'un ERC publié. La différence d'hémoglobine glyquée entre les semaines 0 et 52, estimée utilisant les résultats de chaque patient durant la période de suivi par analyse en composantes principales, est comparée aux résultats de l'ERC. Subséquemment, une analyse était faite pour les patients avec un dosage médicamenteux et adhérence similaire à celui de l'ERC. La même méthode était utilisée pour évaluer l'efficacité dans une population supérieure à l'âge de 75 ans qui étaient exclus de l'ERC.Résultats: L'ajout de la pioglitazone ou gliclazide ont un changement similaire de HbA1c (pioglitazone -0.53%, IC 95% -0.69, -0.37 comparée à gliclazide -0.46%, IC 95% -0.55, -0.36; différence entre ces groupes -0.08, IC 95% - 0.27, 0.10), ce qui est moindre que le changement observé dans le ERC  (-0.99% and -1.01% respectivement). Par contre, quand l'analyse était restreinte au sous-groupe ayant un dosage médicamenteux et adhérence similaire à celui de l'ERC, nos résultats rapprochent ceux de l'ERC : -1.11% (IC 95% -1.52, -0.69,) and -0.69% (IC 95% -0.97, -0.41) respectivement. Pour les patients plus vieux que 75 ans, l'addition du pioglitazone est associée à un changement de HbA1c de 0.62% (IC 95% -1.30, 0.07) comparé au gliclazide -0.19% (IC 95% -0.39, 0.00); différence entre ces groupes -0.24% (95%CI -0.73, 0.25).Conclusion: L'ajout de la pioglitazone ou gliclazide à metformin mène à une réduction de HbA1c de 0.5%, et celui-ci rapproche les résultats obtenus par l'ERC quand l'analyse est restreinte aux patients ayant une adhérence et dosage médicamenteux similaire. Les résultats sont similaires pour les patients âgés plus que 75 ans, mais pas de conclusion définie peut être établie étant donné du petit nombre de patients.</dc:abstract><dc:abstract>Background: Both observational and experimental studies have shown substantial differences between pre-market evidence of efficacy and post-market evaluation of effectiveness, which highlights the need to evaluate both efficacy and effectiveness of new therapies. However, in diabetes, the direct comparison between effectiveness and efficacy on glycemic control is challenging given the non-systematic timing of the measurement of glycated hemoglobin (HbA1c) in real-life practice Objectives: To estimate the effectiveness and efficacy of adding pioglitazone or gliclazide to metformin in an adult population with type 2 diabetes using novel methods to estimate glycemic control and compare it to results obtained in an efficacy randomized controlled trial (RCT). The secondary aim is to examine the effectiveness of these medications in a subgroup of population who are usually excluded from efficacy trials, but in whom the medication is still prescribed: patients older than 75 years old. Methods: A retrospective cohort study was conducted using a large UK anonymised primary care research database, the Clinical Practice Research Datalink, to examine the effectiveness of pioglitazone and metformin compared with gliclazide and metformin. The population was selected to match the inclusion and exclusion criteria from a published RCT. HbA1c change between week 0 and 52, estimated using each patient's values during the follow-up by functional principal component analysis, was compared to the RCT results. Sensitivity analyses were conducted to assess the impact of limiting the analysis to patients whose medication dosage and adherence were similar to that achieved in the RCT. The same method was used to evaluate the comparative effectiveness in those over 75 years old who were excluded from the RCT.Results: The pioglitazone or gliclazide groups had a similar HbA1c change (pioglitazone -0.53%, 95%CI -0.69, -0.37 compared to gliclazide -0.46%, 95%CI -0.55, -0.36; difference between groups -0.08, 95% CI - 0.27, 0.10), which was less than the change observed in the RCT (-0.99% and -1.01% respectively). However, when limited to the subgroup of patients with equivalent medication dosage and adherence to that achieved in the RCT, our results approached those from the RCT: -1.11% (95%CI -1.52, -0.69,) and -0.69% (95%CI -0.97, -0.41) respectively. For patients over the age of 75, the addition of pioglitazone led to a change in HbA1c of -0.62% (95%CI -1.30, 0.07) compared to gliclazide -0.19% (95%CI -0.39, 0.00); difference between groups -0.24% (95%CI -0.73, 0.25).Conclusion:  The addition of either pioglitazone or gliclazide to metformin resulted in similar reduction in the HbA1c by 0.5%, and approached results obtained in the RCT when restricted to patients with comparable adherence and medication dosage. Similar results were obtained for those over the age of 75, but were non-conclusive given the small sample size.</dc:abstract><ual:supervisor>William Dixon (Internal/Cosupervisor2)</ual:supervisor><ual:supervisor>Robyn Tamblyn (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/hh63t0010.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/kh04ds64j</ual:fedora3Handle><dc:subject>Health Sciences - Pharmacy</dc:subject></rdf:Description></rdf:RDF>