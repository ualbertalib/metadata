<?xml version="1.0" encoding="UTF-8"?><rdf:RDF xmlns:oai="http://www.openarchives.org/OAI/2.0/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:ual="http://terms.library.ualberta.ca/" xmlns:bibo="http://purl.org/ontology/bibo/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:schema="https://schema.org/" xmlns:etdms="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Adv13zw919"><dcterms:title>Biophysics of nano-vaccines in relation to autoimmunity</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Mathematics and Statistics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Pineros-Rodriguez, Manuela</ual:dissertant><dc:abstract>Le diabète de type 1 est une maladie auto-immune dans laquelle des cellules T auto-réactives sont activées pour reconnaître et détruire les cellules beta pancréatiques, responsables de produire l'insuline. Des thérapies à base de nano-particules (NP) sont considérées comme une possibilité de traitement pour cette maladie. Ces NP, couvertes de peptides spécifiques aux cellules beta attachés à des complexes majeurs de histocompatibilité (pCMH), promeuvent la prolifération d'une lignée de cellules T à avidité réduite, qui restreignent la réponse auto-immune. Pour déterminer l'efficacité de telles thérapies, il est nécessaire de comprendre les interactions entre les NP et les récepteurs de cellules T (RCT), responsables de lier les pCMH sur les NP. De plus, les RCT sont présentés sur la surface de la cellule sous forme de nano-grappes (RCTng), dont la structure contribue à l'activation de cellules T. Analyser l'effet de contraintes geómétriques sur les intéractions entre récepteurs et ligands peut donner un aperçu du système CMH/RCT lui-même.Ainsi, étudier l'effet de propriétés géométriques sur l'activation de cellules T peut élucider comment optimiser la structure des NP pour maximiser l'activation. De plus, cela peut aider à identifier les propriétés régissant les intéractions entre CMH et RCT. Ce système est donc analysé mathématiquement, grâce à des méthodes numériques. On développe des modèles de type chaîne de Markov pour les différentes échelles des intéractions de ce système, puis on présente la méthode utilisée pour relier ces différents modèles. Deux possibilités sont considérées: le modèle à avidité, qui associe l'activation de cellules T au temps d'interaction entre ligand (pCMH) et récepteur (RCT), et le modèle d'engagement en série, qui l'attribue à l'engagement de plusieurs récepteurs par un même ligand. Les modèles développés sont étudiés analytique et numériquement, et comparés à des données expérimentales grâce à des méthodes de chaînes de Markov de Monte Carlo (MCMC). Étant donnée leur généralité, ils peuvent être utilisés en tant que modèles génériques pour des interactions polyvalentes entre ligands et récepteurs soumises à des contraintes spatiales.Nos résultats montrent que le nombre de RCT couverts/attachés par des NP, pour chaque RCTng suit une distribution gamma, et que le modèle d'engagement en série a plus de chances de représenter l'activation de cellules T. On trouve aussi que les contraintes géométriques peuvent expliquer certains aspects de l'attachement de NP aux cellules T, incluant la saturation de l'affinité de l'attachement en fonction de la valence des NP. Certains aspects ne sont cependant pas capturés par nos  modèles. En particulier, des données expérimentales montrent une importante sensibilité des cellules T la densité de pCMH sur les NP, que même le modèle d'engagement en série ne peut capturer qu'en partie. De plus, notre analyse suggère que les différents niveaux d'activation achevés pour des NP, selon leurs propriétés géométriques, dépend de l'engagement en série de CMH. On conclut en proposant des nouvelles approches pouvant expliquer certains aspects de l'activation de cellules T que les modèles ci-dessous ne réussissent à capturer.</dc:abstract><dc:abstract>Type 1 Diabetes (T1D) is an autoimmune disease in which autoreactive T cells are activated to recognize and deplete the population of insulin-producing pancreatic beta-cells. Nano-particle (NP)-based therapies have been proposed as a possible method to treat this disease. When coated with beta-cell specific peptides bound to major histocompatibility complexes (pMHC), these NP expand a protective, low-avidity T-cell population, which restrains the autoimmune response. Determining the efficiency of such therapies requires an understanding of the dynamics between pMHC-coated NP and T-cell receptors (TCR) that bind to pMHC. In addition, TCR are presented in tightly packed nano-clusters (TCRnc), whose structure has been shown to contribute to T cell activation. The system is thus simultaneously subject to the confinement of TCR to the TCRnc, and of pMHC on the NP. Analysis of the effect that geometrical constraints have on ligand-receptor interactions may provide some insights onto how this polyvalent binding system manifests itself.Studying the effect of geometry on T-cell activation can elucidate both how the design of the NP can be optimized to maximize T-cell response, and what the underlying dynamics of the pMHC/TCR interaction are. We perform such a study using mathematical analysis and computational methods. We develop multi-scale Markov chain type models of this system, and present the method used to link these models to one another. Two possibilities are considered: the avidity model, which associates T cell activation to the interaction time between ligand (pMHC) and receptor (TCR), and the serial engagement model, which attributes activation to the sequential binding of multiple receptors by the same ligand. The developed models are then studied analytically and numerically, and tested against experimental data through Markov Chain Monte Carlo (MCMC) techniques. Given their generality, they can be used as generic models for polyvalent, spatially constrained ligand/receptor systems.Our results reveal that the number of covered/bound TCR by NP per TCRnc follows a gamma distribution and that the serial engagement model is more likely to account for T-cell activation. We also find that geometrical constraints can account for few important aspects of NP binding to T cells, including the saturation of binding affinity with respect to NP valency, but not all when considered alone. More specifically, experimental data shows T-cells to be very sensitive to pMHC density on the surface of NP, and only the serial engagement model can capture this effect partially. In fact, our analysis suggests that serial engagement of TCR may be required to explain the various levels of activation achieved by NP with different geometrical properties. We conclude by proposing new directions on how to account for certain aspects of T-cell activation that models presented here missed.</dc:abstract><ual:supervisor>Anmar Khadra (Internal/Supervisor)</ual:supervisor><ual:supervisor>Michael C Mackey (Internal/Cosupervisor2)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/1g05ff34f.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/dv13zw919</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A73666718t"><dcterms:title>Theorizing cosmic environmental law</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Laws</schema:inSupportOf><dc:contributor>Institute of Air and Space Law</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Goswami, Bayar</ual:dissertant><dc:abstract>La recherche et la planification, notamment en ce qui concerne l'exploitation minière des ressources de l'espace, la terraformation et la colonisation des corps célestes est activement recherché pour réaliser le et axés sur les avantages sociaux, conduisant à une course à l'espace entre les Etats-nations. La durée actuellement dans l'ère de l'espace est assez semblable à l'humanité où s'élevait autrefois dans l'histoire - où les masses terrestres devaient être réclamé et ouverts, la course pour les ressources ont conduit à la colonisation suivie de la révolution industrielle puis par la mondialisation. Aujourd'hui, par conséquent, l'humanité se trouve dans une époque de l'anthropocène, où des êtres humains ont collectivement devenir une force géologique modifier négativement l'écosystème naturel de la seule planète habitable en créant un climat mondial et l'impact sur l’environnement.L'évaluation de la course à l'espace et l'évolution de l'ère spatiale, il semble que l'histoire est sur le point de se répéter, maintenant dans le domaine de l'espace, et un rythme alarmant des surfaces question de savoir si l'humanité pourrait devenir une force cosmique, portant sur lui-même ou un dommage à l'environnement cosmique l'espace équivalent d’anthropocène.Dans ce contexte, cette thèse tente de théoriser les lois de l'environnement cosmique basé sur la compréhension que l'espace extra-atmosphérique, tout comme la Terre, est un système naturel d'interdépendance avec l'ordre cosmique qui prévaut, la perturbation de ce qui pourrait représenter un danger pour le naturel dans des conditions in situ de l'espace extra-atmosphérique et également à l'habitabilité étroitement liés sur et de la planète Terre. En outre, cette thèse conteste la valeur anthropocentrique dominante de la civilisation humaine, qui est seul responsable de l'apparition de l'anthropocène et fait un plaidoyer convaincant pour un changement de paradigme pour cosmocentrism pour une véritable coexistence de l'humanité avec la nature, le cosmos.En conséquence, l'établissement de la notion d'ordre cosmique, plaidant pour l'adoption d'cosmocentrism, cette thèse critiques d'un cosmocentric point de vue, les principes établis dans le droit international de l'environnement, d'autant plus que dans le droit international de l'espace, vers la théorisation cosmique de lois sur l'environnement.</dc:abstract><dc:abstract>Research and planning, inter alia, with regard to space resource mining, terraforming and colonization of celestial bodies is actively being pursued to realize the human-centric benefits, leading to a space race amongst nation-states. The current duration in the space age is quite akin to where the humanity once stood in the history – where land masses were to be claimed and appropriated, the race for resources led to colonization followed by industrial revolution and then by globalization. Today, consequently, humanity stands in an epoch of Anthropocene, where human beings have collectively become a geological force adversely altering the natural ecosystem of the only habitable planet by creating a global climate and environmental impact. Assessing the space race and the trends in the space age, it appears that the history is about to repeat itself, now in the domain of outer space, and an alarming question surfaces as to whether humanity could possibly become a cosmic force, bringing upon itself cosmic environmental harm or an outer space equivalent of Anthropocene. Against this backdrop, this thesis attempts to theorize cosmic environmental laws based on an understanding that the outer space, much like the Earth, is an interdependent natural system with prevailing cosmic order, disruption of which could possibly pose significant threats to the natural in situ conditions of the outer space and also to the closely linked habitability on and of the planet Earth. Further, this thesis challenges the prevailing anthropocentric value system of the human civilization, which is solely responsible for the onset of Anthropocene and makes a persuasive plea for a paradigm shift to cosmocentrism for a true coexistence of humanity with the nature, the cosmos. Accordingly, establishing the notion of cosmic order, arguing for the adoption of cosmocentrism, this thesis critiques from a cosmocentric perspective, the principles established in the international environmental law, particularly as in the international space law, towards the theorization of cosmic environmental laws.</dc:abstract><ual:supervisor>Ram S Jakhu (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/9593tx541.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/73666718t</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ax346d6736"><dcterms:title>Charge state dynamics during excitation and depletion of the nitrogen vacancy center in Diamond</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Physics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Hacquebard, Luke</ual:dissertant><dc:abstract>The nitrogen-vacancy (NV) defect center in diamond shows great promise for many applications in quantum information processing and precision sensing. The NV center naturally occurs in two different charge states (NV0 and NV-), which have very different optical and spin properties. Understanding laser-induced switching between these charge states is essential for taking advantage of the NV center's properties in many contexts. Reducing the amount of optically-induced ionization is often important for increasing SNR and spin-coherence times. On the other hand charge state switching can be taken advantage of through spin-to-charge conversion techniques, enhancing optical spin-state readout of the NV center [1].A method for charge state initialization and readout using yellow (594 nm) laser illumination was used to investigate the ionization and recombination processes from other laser sources. The commonly used CW green (532 nm) laser was found to follow a simple two-level process at low powers while deviation occurred at higher powers, resulting in an unexpected peak in NV- population. This unexpected behaviour was found to be associated with an unknown process relaxing in the dark with a lifetime of 8.8 ± 0.6 µs. A spin-dependence in ionization was also observed due to the reduced ionization rate out of the metastable singlet state in NV- at this wavelength.Pulsed green (531 nm) and red (766 nm) illumination were used to study the charge state dynamics during excitation and depletion processes. Red illumination is known to cause depletion of NV- fluorescence, but it was initially unclear how much of this reduction is due to stimulated emission and how much is from charge state ionization, as both are non-radiative processes. By simultaneously modeling the measured excitation, fluorescence depletion, and charge state switching of the pulsed lasers, we were able to quantitatively extract the relative rates of excitation, ionization, and stimulated emission for the two colors of pulsed laser. The models developed through these measurements were used to calculate the amount of expected spin-polarization after a single excitation then depletion pulse sequence. These results have implications for stimulated emission depletion (STED) microscopy [2], laser threshold magnetometry [3] and spin to charge conversion [1,4].</dc:abstract><dc:abstract>Le centre azote-lacune (ou centre NV) du diamant démontre un potentiel élevé pour un grand nombre d'applications en traitement d'information quantique ainsi que pour la détection haute-précision. Le centre NV se présente naturellement sous deux états de charge distincts (NV0 et NV-) possédant des propriétés optiques et de spin trés différentes. Dans de nombreux contextes, il est essentiel de comprendre le passage d'un état de charge à l'autre induit par illumination laser pour mettre à profit les propriétés du centre NV. Réduire l'ionisation photoinduite est souvent important pour l'augmentation du rapport signal sur bruit ainsi que pour le maintien de la cohérence du spin. De manière alternative, la commutation de niveau de charge peut être exploitée par des techniques de conversion spin/charge, améliorant la mesure optique de l'état de spin du centre NV [1].Une méthode d'initialisation et de mesure du niveau de charge utilisant une illumination par laser jaune (594 nm) a été utilisée pour investiguer les processus d'ionisation et de recombinaison provenant d'autres sources laser. Il a été constaté que le laser vert (532 nm) à ondes continues, couramment utilisé, suit un processus simple à deux paliers à faibles puissances tandis qu'une déviation se produit pour des puissances plus importantes, provoquant un pic inattendu dans la population de NV-. Ce comportement imprévu a été associé à un processus inconnu relaxant dans l'absence d'illumination avec une durée de vie de 8.8 ± 0.6 µs. Une dépendance de l'ionisation par rapport à l'état de spin a aussi été observée dû à un taux d'ionisation réduit de l'état singulet métastable du NV- à cette longueur d'onde.L'illumination en mode pulsé de lasers vert (531 nm) et rouge (766 nm) a été utilisée pour étudier la dynamique des niveaux de charge durant les processus d'excitation et de déplétion. L'illumination rouge peut causer la déplétion de la fluorescence NV- mais il était initialement peu clair à quel point cette réduction était dû à l'émission stimulée ou à l'ionisation du niveau de charge, puisque tous les deux sont des processus non-radiatifs. En modélisant simultanément l'excitation mesurée, la déplétion de la fluorescence et la commutation du niveau de charge induites par les lasers pulsés, il a été possible d'extraire de faç con quantitative les taux relatifs d'excitation, d'ionisation ainsi que d'émission stimulée pour chacune des deux couleurs de laser pulsé. Les modèles développés ainsi ont été utilisés pour calculer la polarisation prévue du spin suite à une excitation simple suivie d'une séquence pulsée de déplétion. Ces résultats ont des implications pour la microscopie à déplétion par émission stimulée (STED) [2], la magnétométrie à seuil d'émission stimulée [3], et la conversion spin/charge [1,4].</dc:abstract><ual:supervisor>Lilian Childress (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/hh63sz434.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/x346d6736</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ak0698994z"><dcterms:title>Estimating treatment importance in multidrug-resistant tuberculosis using Targeted Learning: an observational individual patient data network meta-analysis</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Epidemiology and Biostatistics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Wang, Guanbo</ual:dissertant><dc:abstract>La tuberculose multirésistante est une souche de la tuberculose qui ne répond pas au moins aux deux médicaments les plus puissants contre cette dernière. La tuberculose multirésistante continue de se propager de nos jours, et par conséquent, il est important de savoir évaluer avec précision l'importance des traitements pour cette souche. La tuberculose multirésistante est souvent traitée par de multiples antibiotiques de première et de seconde ligne.Notre base de données se compose des données individuelles des patients provenant de 31 études observationnelles et contient des caractéristiques démographiques, l’historique médical, les médicaments utilisés et les issues thérapeutiques. Dans cette étude, nous définissons une métrique mesurant l’importance d’une variable afin de comparer la contribution apparente de chaque médicament au taux de récupération global parmi les patients qui ne sont pas connus pour être résistant à l'antibiotique donné.Bien que les études individuelles puissent évaluer les associations spécifiques entre le traitement et les résultats dans la sous-population, notre méta-analyse sur les données individuelles des patients permet une perspective globale de l'importance moyenne des médicaments dans le traitement de la tuberculose multirésistante.Pour ce faire, nous avons développé des critères d'identification et appliqué l'estimation par maximum de vraisemblance ciblée (TMLE) pour estimer le taux moyen de récupération ajusté pour chaque traitement chez les patients qui ne sont pas connus pour être résistants au traitement. TMLE est une méthode semi-paramétrique et doublement robuste. Au cours de l'analyse, la transportabilité est utilisée pour transférer l'estimation des études où un traitement a été observé aux études où ce traitement n'a pas été observé. Enfin, nous avons adopté un estimateur sandwich dérivé de la fonction d'influence efficiente pour estimer leur variance associée.Des études de simulation sont menées pour prouver la validité de notre estimateur et vérifier la double robustesse de notre estimateur. En outre, ils montrent également que notre méthode d'estimation de la variance est appropriée avec un taux de couverture adéquat.Les résultats montrent que la ciprofloxacine a la plus grande importance au traitement, suivie de l'amikacine et des quinolones à haute génération. Ils montrent également que les médicaments à base d'acide para-aminosalicylique, de pyrazinamide et de groupe 5 sont les moins importants.</dc:abstract><dc:abstract>Multi-drug-resistant tuberculosis (MDR-TB) is defined as strains of tuberculosis (TB) that do not respond to at least the two most powerful anti-TB drugs. Nowadays, MDR-TB continues to emerge and thus accurate assessment of the importance of treatments for MDR-TB is a critical issue. MDR-TB is often treated with multiple first and second line antibiotics.Our data consists of individual patient data from 31 international observational studies which measured patient demographic information, medical history, medications used and therapeutic outcomes. In this study, we defined an adjusted variable importance metric to compare the apparent contribution of each medication to the overall recovery rate among patients who are not known to be resistant to the given antibiotic. While individual studies are able to evaluate subpopulation-specific associations between treatment and outcome, our individual patient data network meta-analysis (IPD-NMA) allows for a global perspective on average medication importance in the treatment of MDR-TB.To these ends, we develop identifiability criteria and apply targeted maximum likelihood estimation (TMLE) to estimate the adjusted recovery rate means for each treatment amongst patients who were not known to be resistant to the treatment. TMLE is a semi-parametric and double robust method. Throughout the analysis, transportability is utilized to translate the estimation from studies where a given antibiotic was used to studies where it wasn't. Finally, we adopted a clustered sandwich estimator derived from the efficient influence function to compute variance estimates.Simulation studies were conducted to assess the performance of our estimator and verify the theoretical double robustness property. These simulations were also used to evaluate the validity of the sandwich estimator for variance estimation and the coverage rate of the derived Wald-type confidence intervals.The results show that Ciprofloxacin has the greatest treatment importance, followed by Amikacin and High-generation Quinolones. They also show that Para-aminosalicylic acid, Pyrazinamide, and Group 5 level drugs are the least important.</dc:abstract><ual:supervisor>Andrea Benedetti (Internal/Supervisor)</ual:supervisor><ual:supervisor>Mireille Schnitzer (Internal/Cosupervisor2)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/kw52jb38x.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/k0698994z</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Afq977x38h"><dcterms:title>Searching for Lalla in between the vowels</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Music</schema:inSupportOf><dc:contributor>Schulich School of Music</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Haran, Noa</ual:dissertant><dc:abstract>Dans Searching for Lalla in between the vowels, la figure et la poésie de Lalla, une femme mystique et sacrée qui vécu dans le Kashmir du 14ième siècle, est explorée. Six poèmes, traduits par Coleman Barks, servent à la base d'une composition pour un ensemble de quatre chanteurs, orgue, percussions et trompette. Étant inspirée par la tradition orale qui permis la transmission de ces poèmes, la pièce utilise les sons du language (voyelles et consonnes) comme matériel principal ainsi que comme matériel purement musical (sons à hauteurs déterminées). Le corpus explore les transitions entre différentes techniques vocales, comme la voix parlée vis à vis celle chantée, ainsi qu'entre différents champs harmoniques distants. En flouant les distinctions entre des éléments a priori contrastants, la pièce transmet  l'expérience de la ''non-dualité'', concept qui est au centre de la poésie de Lalla.</dc:abstract><dc:abstract>In Searching for Lalla in between the vowels, the figure and poetry of Lalla, a mystic and holy woman who lived in 14th century Kashmir, are explored. Six poems, in translation by Coleman Barks, serve as the basis of a composition for an ensemble of four singers, organ, percussion, and trumpet. Drawing inspiration from the oral tradition which allowed the transmission of these poems, the piece uses speech sound (vowels and consonants) as primary material as well as purely musical (pitched) materials. The body of the work explores transitions between different vocal techniques, such as speech versus singing, and different, distant harmonic fields. By blurring the distinctions between seemingly contrasting elements, the piece transmits the experience of “non-duality” which is at the heart of Lalla’s poetry.</dc:abstract><ual:supervisor>Jean Lesage (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/5999n579f.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/fq977x38h</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A1831cn34p"><dcterms:title>Sparse representations of audio signals with asymmetric atoms</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Schulich School of Music</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Neri, Julian</ual:dissertant><dc:abstract>Sparse representations of audio is a mature field that has evolved from decades of research that established its utility in a variety of applications, for example, audio coding, source-separation, and transformation. However, the performance of sparse approximation algorithms still depend highly on signal length, which is problematic for audio signals with durations of more than a few seconds. Furthermore, there is a need for elementary waveforms, atoms, that can effectively adapt to represent temporally asymmetric features. Atoms with temporally asymmetric amplitude evolutions have already shown promise in sparse representation applications, namely the gammatone and formant-wave-function, however, due to their origins from outside the sparse realm, they either cannot adapt to model a wide range of audio features or their mathematical definition reduces the speed of the approximation process.This thesis addresses these crucial aspects of sparse audio representations. We establish desirable atom properties, for example, mathematical properties that enable efficient parameter estimations and an analytic inner product formula, then compare existing atoms using our criteria to highlight their relative strengths and weaknesses. We establish a new asymmetric atom, ramped exponentially damped sinusoid (REDS), that can model salient audio signal features, especially transients and decaying oscillations, and has all the properties we desire. Results from an experiment show that it can more sparsely represent audio than existing atoms and mathematical proofs show how we can tune the parameters of a REDS such that it approximately equals either existing asymmetric atom.We introduce a new sparse approximation system, Partial Trajectory Matching Pursuit (PTMP), that employs sinusoidal partial tracking to locate long duration atoms and, in parallel, a small-scale sub-dictionary pursuit that locates short duration atoms. PTMP effectively locates arbitrarily long duration atoms, something that previous algorithms have not addressed, and, since these atoms match closely with the audio signal, they increase the sparsity of representation. We establish several estimation methods that work within PTMP to refine the REDS parameter set, which increase representation sparsity even further. Results from a series of experiments that gauge PTMP's performance show that PTMP is a powerful sparse approximation system that manages to avoid pre-echo and produce state-of-the-art sparsity levels by decomposing audio onto REDS atoms at high-speed.</dc:abstract><dc:abstract>La représentation parcimonieuse des signaux sonores est un thème de recherche bien établi ayant bénéficié de plusieurs décennies de travaux qui ont consacrés son usage dans de nombreuses applications, comme par example le codage audio, la séparation de sources, et les transformations sonores. Cependant, la performance des algorithmes d'approximations parcimonieuses dépend encore fortement de la longueur du signal, ce qui est problématique dans le cas des signaux sonores dont la durée est souvent supérieure à quelques secondes. De plus, il y a un besoin de nouvelles formes d'onde élémentaires, ou atomes, qui puissent représenter et s'ajuster aux caractéristiques temporelles asymétriques des signaux sonores. L'utilisation, dans le cadre d'applications de décompositions parcimonieuses, d'atomes à évolution temporelle d'amplitude asymétrique tels que les gammatones ou bien les fonctions d'onde formantiques, a déjà donné lieu à des résultats prometteurs. Cependant, comme ils proviennent de domaines d'étude extérieurs à celui des décompositions parcimonieuses, ils ne peuvent pas s'ajuster pour modéliser une large classe de caractéristiques sonores ou bien leur expression mathématique ne permet pas de mettre en place un processus d'approximation rapide.Dans cette thèse, nous nous sommes donc intéressés à ces aspects cruciaux des représent-ations parcimonieuses des signaux audio. Nous avons dressé une liste des propriétés souhaitables des atomes, comme par example les propriétés mathématiques  facilitant une estimation efficace des paramètres, et  celles menant à une expression analytique du produit scalaire entre atomes; nous avons ensuite comparé les types d'atomes existants selon les critères précédemment établis afin de mettre en lumière leurs avantages et leurs défauts. Nous proposons un nouveau type d'atomes asymétriques, que nous appelons REDS, apte à modéliser les caractéristiques pertinentes des signaux audio, plus spécialement les transitoires et les oscillations amorties, tout en possédant  les propriétés de la liste que nous avons établie. Nos résultats expérimentaux montrent que l'utilisation des atomes REDS mène à des modélisations plus parcimonieuses que celles reposant sur les atomes asymétriques pré-existants; de plus nous établissons le lien mathématique montrant comment ajuster les paramètres des atomes REDS afin d'approximer voire même égaler les  atomes symétriques pré-existants. Par ailleurs, nous proposons un nouveau système d'approximation parcimonieuse, que nous appelons Partial Trajectory Matching Pursuit (PTMP), reposant sur l'extraction de trajets de partiels sinusoïdaux afin de localiser les atomes de longue durée, tout en menant simultanément une poursuite sur un sous-dictionnaire d'atomes à petite échelle afin de localiser des atomes de courte durée. PTMP localise effectivement des atomes de durée arbitrairement longue, ce que les algorithmes existants ne détectent pas; et puisque ces longs atomes sont en bonne adéquation avec le signal audio, leur utilisation accroît la parcimonie de la représentation.  Nous avons établi et mis en place plusieurs méthodes d'estimation qui affinent le jeux des paramètres REDS au sein de l'algorithme PTMP  ce qui accroît encore la parcimonie.  Enfin lors d'une série d'expériences destinées à mettre l'algorithme PTMP à l'épreuve, les résultats obtenus montrent que PTMP est un système d'approximation parcimonieuse puissant qui prévient l'apparition de pré-echos et produit une décomposition parcimonieuse comparable à l'état de l'art des autres méthodes tout en assurant une décomposition rapide des signaux audio sur les atomes REDS.</dc:abstract><ual:supervisor>Philippe Depalle (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/cf95jd70t.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/1831cn34p</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Av692t876m"><dcterms:title>Computational and experimental analysis of early reflections in concert spaces</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Schulich School of Music</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Xiao, Wen</ual:dissertant><dc:abstract>A study on the acoustic simulations of early reflections in three-dimensional rooms is presented. Measurements of four real rooms in Schulich School of Music and computational simulations in Matlab are compared to verify the results.The four real rooms are modeled with two methods commonly used in modern geometric acoustic modeling, the image source method and the ray-tracing method. Then the simulation results are compared with the measurement in impulse responses and echo densities. Discussions about the differences between measurements and modeling results are based on geometrical models and acoustic properties. Factors influencing the accuracy of the simulations include the geometric shapes of rooms, the directivity patterns of the speakers and microphones in the measurement and acoustic coefficients such as wall absorption coefficients and air absorption coefficients. The results indicate that rooms commonly used for music performance have very diffuse scattering characteristics, which has important implications for modeling techniques based on assumptions of specular reflections. As well, this may have some consequences on our understanding of sound localization, which assumes specular early reflections. Suggestions for further improvements of models and measurement techniques are given. </dc:abstract><dc:abstract>Une étude sur les simulations acoustiques des réflexions précoces dans les salles tridimensionnelles est présentée. Les mesures de quatre salles dans l'École de musique Schulich et les simulations calculées par Matlab sont comparées pour vérifier les résultats.Les quatre salles existantes sont modelées avec deux méthodes couramment utilisées dans la modélisation acoustique géométrique moderne, la méthode source d'image et la méthode de lançcage de rayons. Les résultats des mesures de réponses impulsionnelles et des densités d'échos de la simulation sont comparés. Les discussions sur les différences entre les mesures et les résultats de la modélisation sont basées sur des modèles géométriques et des propriétés acoustiques. Les facteurs influençant la précision des simulations incluent les formes géométriques des salles, les modèles de directivité des haut-parleurs et des microphones mesurés et les coefficients acoustiques tels que les coefficients d'absorption des parois et de l'air. Les résultats indiquent que les salles couramment utilisées pour les performances musicaux ont des caractéristiques de diffusion d'ondes trés diffuses, ce qui a des implications importantes pour les techniques de modélisation basées sur des hypothèses de réflexions spéculaires. Cela peut avoir des conséquences sur notre compréhension de la localisation du son, qui suppose une spécification de réflexions préliminaires. Des suggestions pour d'autres améliorations des modéles et des techniques de mesure sont données.</dc:abstract><ual:supervisor>Gary Scavone (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/h702q8707.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/v692t876m</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A0z709026b"><dcterms:title>G-estimation of dynamic treatment regimes in the presence of shared parameters</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Epidemiology and Biostatistics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Wang, Shouao</ual:dissertant><dc:abstract>La médecine personnalisée attire l’attention comme une avenue prometteuse pour l’amélioration dessoins de santé et a suscité un intérêt croissant pour la recherche dans de nombreux domaines. A régime detraitement dynamique (DTR) est une approche de la médecine personnalisée, qui a comme base les règlesde décision séquentielles (en termes de niveaux de traitement) basées sur l’histoire médicale personnelleet évolutive d’un patient. Dans ce travail, je me concentre sur l’estimation G, une approche basée sur larégression pour estimer les paramètres d’une DTR, dans le cadre spécifique où les paramètres de la règlede décision de traitement peuvent être partagés entre différents stades de la séquence de traitement.Dans cette thèse, une nouvelle méthode de calcul est introduite pour effectuer une estimation Gpartagée. La nouvelle méthode partage des propriétés théoriques similaires avec l’estimation séquentielleinitiale "non partagée": La nouvelle méthode conserve la propriété double robustesse, ce qui garantit uneestimation constante aussi longtemps que l’un des (i) le modèle de résultat sans traitement attendu ou(ii) le modèle de traitement est correctement spécifié. Des études de simulation sont menées pour testerla validité et la performance de l’estimation G partagée. En outre, les comparaisons entre l’apprentissageQ non partagé et partagé, l’estimation G séquentielle non partagée et l’estimation G partagée sont faitesen termes de biais et de variance. La méthode d’estimation G du paramètre partagé est appliquée auxdonnées provenant de l’essai randomisé STAR*D (NIMH Sequenced Treatment Alternatives to RelieveDepression) pour estimer le DTR optimal des paramètres partagés visant à réduire les symptômes de ladépression.</dc:abstract><dc:abstract>Personalized medicine is gaining attention as a promising avenue for improved healthcare, and hasreceived increased research interest in many domains. A dynamic treatment regime (DTR) is oneapproach to personalized medicine, which has as its basis sequential (in terms of treatment stages)decision rules that are based on a patient’s personal, and evolving, medical history. In this work, I focuson G-estimation, a regression-based approach to estimating the parameters of a DTR, in the specificsetting where treatment decision rule parameters may be shared across different stages of the treatmentsequence.In this thesis, a new computational method is introduced to perform shared-parameter G-estimation.The new method shares similar theoretical properties with the original, “unshared” sequential G-estimation:the new approach retains the double-robustness property, which ensures consistent estimation as longas one of (i) the expected treatment-free outcome model or (ii) the treatment model is correctly specified.Simulation studies are conducted to test the validity and performance of the shared G-estimation.In addition, comparisons between unshared and shared Q-learning, unshared sequential G-estimation,and shared-parameter G-estimation are made in terms of bias and variance. The shared parameterG-estimation method is applied to the data from the the STAR*D (NIMH Sequenced Treatment Alternativesto Relieve Depression) randomized trial to estimate the optimal shared-parameter DTR aimedat reducing symptoms of depression.</dc:abstract><ual:supervisor>David Stephens (Internal/Cosupervisor2)</ual:supervisor><ual:supervisor>Erica Moodie (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/f1881p46c.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/0z709026b</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Afj2364621"><dcterms:title>Detecting fragile comments</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>School of Computer Science</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Ratol, Inderjot Kaur</ual:dissertant><dc:abstract>The development lifecycle of a software system demands incessant improvements in the sourcecode of a system to maintain its high quality with improved performance and code readability.Refactoring is a common software development practice that reshapes the internal structure andnon-functional properties of a system without modifying its core functionality. Many simple refactoringslike renaming code elements, extracting a snippet from large method to form new methodetc. can be performed with the help of automatic tools. Renaming code elements like classes,interfaces or methods is a widely used refactoring activity. With tool support, rename refactoringscan rely on the program structure to ensure correctness of the code transformation. Unfortunately,the textual references to the renamed identifier present in unstructured comment text cannot beformally detected through the syntax of the programming language. These textual references tothe previous version of a renamed identifier pose threats to the consistency between code and comments,which leads to poor program comprehensibility. The comments containing such textualreferences become fragile with respect to the renamed program element and are referred to as fragilecomments.This thesis proposes a new rule-based approach to detect and fix the fragile comments thatresult from renaming the identifiers. We implemented this approach for the Java programminglanguage in the form of an Eclipse plug-in called Fraco. Fraco takes into account the type of anidentifier, its morphology i.e. the part-of-speech tag and its inflectional form, its scope that definesits visibility in the source code and the location of comments in the source code with respect to theidentifier.We evaluated the performance of our technique, as implemented for Java in Fraco, by comparingits precision and recall against hand-annotated benchmarks created for both developmentand test sets each containing six target Java systems, and also compared the results against theperformance of Eclipse’s automated in-comment identifier replacement feature. Fraco performedwith an average of 99% precision and recall on most components of both development and testdatasets, and generally outperformed the baseline Eclipse feature. An average percentage of 25%of the total identifiers of category type and method in the data sets had fragile comments afterrenaming, which further motivates the need for research on automatic comment refactoring.</dc:abstract><dc:abstract>Le cycle de développement d’un système logiciel exige des améliorations incessantes dans lecode source d’un système afin de maintenir élevée sa qualité en termes de performance et de lisi-bilité du code. Le réusinage de code est une pratique courante dans le développement logiciel quiremodèle la structure interne et les propriétés non fonctionnelles d’un système sans modifier sesfonctionnalités principales. Plusieurs transformations simples peuvent être effectuées à l’aide d’ou-tils automatiques. Renommer des éléments du code comme une classe, une interface, une méthode,etc. est une tâche qui revient souvent lors d’un réusinage. Avec le support d’outils, le renommagepeut se baser sur la structure d’un programme pour s’assurer de l’exactitude de la transformationdu code. Malheureusement, les références textuelles aux identifiants renommés présentes dans lescommentaires non-structurés ne peuvent être détectées formellement à travers la syntaxe du lan-gage. Ces références textuelles aux identifiants renommés sont des obstacles à la synchronisationentre le code et les commentaires, ce qui détériore la compréhensibilité du programme. Les com-mentaires incohérents peuvent donc devenir une source d’introduction de bogue ou induire enerreur les développeurs.Cette thèse propose une idée nouvelle combinant le renommage à la détection des commen-taires fragiles en introduisant une nouvelle approche basée sur un ensemble de règles pour détecteret corriger les commentaires fragiles produits par un renommage d’identifiant, implémentée sousforme d’une extension de la plateforme Eclipse. L’outil, nommé Fraco, considère le type d’iden-tifiant, sa morphologie, c’est-à-dire l’étiquette partielle et sa forme inflexionnelle, sa portée quidéfinit sa visibilité dans le code source et le lieu des commentaires par rapport à l’identifiant.La précision et le rappel de l’outil proposé sont évalués à l’aide de systèmes de référenceiiiannotés manuellement pour les ensembles de développement et d’évaluation, chaque ensemblecontenant six systèmes en Java. Les résultats sont comparés à la performance de la fonctionnalitéde remplacement d’identifiants à l’intérieur de commentaires intégrée à Eclipse. Fraco a performéune précision moyenne de 99% et un rappel presque optimaux sur la plupart des composantes desensembles de développement et d’évaluation et performe en général mieux que la fonctionnalitéde base d’Eclipse. Un pourcentage moyen de 25 % des identifiants totaux de catégorie type etméthode dans les ensembles de données présentait des commentaires fragiles après le changementde nom, ce qui motive davantage la recherche sur le refactoring automatique des commentaires.</dc:abstract><ual:supervisor>Martin Robillard (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/g732dc31w.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/fj2364621</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Amk61rk609"><dcterms:title>Dome, arch, barrel, void for 8 instruments (Volume 1 of 2: Analysis)</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Music</schema:inSupportOf><dc:contributor>Schulich School of Music</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Toraman, Zeynep</ual:dissertant><dc:abstract>Dome, arch, barrel, void est une composition musicale originale écrite pour huit instruments d'une durée de douze minutes. Une analyse technique de la composition, présentée dans le 1er volume de cette thèse, illustre les méthodes de composition développés au cours du processus de composition de cette pièce. La partition est présentée dans le 2e volume. La pièce vise à étudier la construction d'une forme à grande échelle en utilisant l'échelle de complexité de Gérard Grisey pour le temps musical. Le processus de pré-composition a impliqué la création d'un catalogue des modes de jeu qui a servi pour composer des matériaux musicaux utilisés dans la composition dome, arch, barrel, void.</dc:abstract><dc:abstract>Dome, arch, barrel, void is an original music composition scored for eight instruments with a duration of twelve minutes. The analytical paper presented in Volume 1 of this thesis, illustrates the compositional tools and methods developed during the composition process. The musical score is presented in Volume 2. The piece aims to investigate the construction of a large scale form by utilizing Gérard Grisey’s scale of complexity for musical time. The pre-compositional process involved the creation of a catalogue of playing techniques, and the musical materials used in the piece were derived from this catalogue.</dc:abstract><ual:supervisor>Philippe Leroux (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/bv73c3053.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/mk61rk609</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Afx719p74n"><dcterms:title>Higher capacity cold-formed steel sheathed and framed shear walls for mid-rise buildings: part 1</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Civil Engineering and Applied Mechanics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Santos, Veronica</ual:dissertant><dc:abstract>The use of cold-formed steel (CFS) for seismic force-resisting systems (SFRS), including shear walls, has increased throughout the years. However, the design provisions for CFS sheathed and framed shear walls available in the North American CFS standards (AISI S400 and AISI S240) are limited by the shear walls’ sheathing and framing thicknesses. Design guidelines for CFS sheathed and framed shear walls for the purpose of mid-rise construction (up to 5 storeys) are still absent from the standards. The main objective of this research program was to develop a design procedure for CFS sheathed and framed shear walls to achieve higher capacity and ductility to resist the higher forces experienced in mid-rise construction. The developed design procedure is proposed to be included in the provisions of the AISI S240 Standard and AISI S400 Standard.The design procedure was developed by determining the shear strength of full-scale shear wall specimens built and tested at McGill University under monotonic and cyclic loading protocols. A total of 31 specimens, with varying building parameters, were constructed using thicker sheathing and framing members than what is currently available for design. The specimens were built using two new shear wall configurations (double-sheathed and centre-sheathed) to address out-of-plane forces experienced by shear walls tested in previous research programs.The centre-sheathed shear wall configuration, with a confined and concentrically placed sheathing panel, reached a shear resistance four times higher than the design values tabulated in the current standards. The ductility of these CFS shear walls was also significantly improved. A preliminary equation-based nominal shear strength prediction method has been developed for the centre-sheathed shear walls; the method reflects the shear wall’s different configuration and superior behaviour. Following the test data analysis, preliminary design parameters for Limit States Design (LSD) used in Canada and for Load and Resistance Factor Design (LRFD) used in the USA and Mexico were determined, including the load resistance factor,  and the factor of safety. In addition, capacity based design parameters were determined for seismic design in Canada. These parameters included the “test-based” seismic performance factors, Rd and Ro, which were found to be 2.8 and 1.5 respectively. The superior performance of the centre-sheathed configuration showed its promising potential as a new design option for higher capacity CFS shear walls. However, before a potential implementation into mid-rise construction, further research is needed in order for a complete design procedure to be developed. </dc:abstract><dc:abstract>L’utilisation de l’acier formé à froid pour les systèmes résistants aux efforts sismiques, desquels font partie les murs de refend, a augmenté au fur et à mesure des années. Cependant, les mesures de conceptions pour les murs de refend utilisant un cadre et un parement en acier formé à froid disponibles dans les normes Nord-Américaines pour l’acier formé à froid (AISI S400 et AISI S240) sont limitées par les épaisseurs du parement et du cadre de ces murs. Les recommandations de conception pour une utilisation dans les constructions de mi-hauteur (jusque 5 étages) de ce type de mur de refend en acier formé à froid ne sont toujours pas proposées dans les normes actuelles.L’objectif principal de ce programme de recherche était de développer une procédure de dimensionnement pour les murs de refend présentant un cadre et un parement en acier formé à froid afin d’obtenir une résistance et une ductilité augmentées leur permettant de résister aux efforts plus importants présents dans les constructions de mi-hauteur. La procédure de dimensionnement sera proposée à l’inclusion dans les normes AISI S400 et AISI S240.La procédure de dimensionnement a été développée en déterminant la résistance au cisaillement de murs de refend construits à l’échelle 1:1 et testés dans le Laboratoire de Structures Jamieson à l’université McGill, en utilisant des protocoles de chargement monotoniques et cycliques. Au total, 31 spécimens ont été construits en utilisant des matériaux plus épais que ceux proposés pour leur dimensionnement dans les normes actuelles. Ils ont été construits selon deux nouvelles configurations (parement double et parement central) pour éliminer les efforts s’exerçant hors plan subis par les murs de refend testés lors des programmes de recherche précédents.La configuration utilisant un parement central confiné au sein même des membres du cadre du mur de refend a atteint une résistance au cisaillement quatre fois plus élevée que les valeurs de conception tabulées dans les normes actuelles. La ductilité de ces murs de refend en acier formé à froid fut aussi améliorée de manière significative.Une méthode préliminaire de prédiction de la résistance nominale à l’effort tranchant a été développée pour la configuration utilisant un parement central ; cette méthode prend en compte la nouvelle configuration de construction du mur de refend ainsi que son meilleur comportement. A la suite de l’analyse des résultats, les paramètres de conception préliminaires pour le calcul aux états limites utilisé au Canada (LSD) et aux Etats-Unis et au Mexique (LRFD) ont été déterminés, notamment le facteur de résistance, , et le facteur de sécurité. De plus, les facteurs de performance sismique pour le Canada, Rd et Ro, ont été déterminés en se basant sur les résultats expérimentaux, obtenant les valeurs de 2.8 et 1.5 respectivement.Le niveau de performance supérieur de la configuration utilisant un parement central a mis en lumière le potentiel que celle-ci présente en tant que nouvelle option pour la conception de murs de refend en acier formé à froid de plus haute résistance. Cependant, une recherche plus approfondie est nécessaire avant de pouvoir envisager une utilisation de ce type de mur de refend au sein de constructions de mi-hauteur ; cela permettra de développer une procédure de conception complète et plus spécifique à cette nouvelle configuration.</dc:abstract><ual:supervisor>Colin Andrew Rogers (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/z890rw912.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/fx719p74n</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ac247dv667"><dcterms:title>« Le désir d’être soi » : fragmentation et identités dans Kuessipan de Naomi Fontaine suivi du texte de création sois qui peux</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>fre</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of French Language and Literature</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Baker, Rachel</ual:dissertant><dc:abstract>Critical EssayInnu author Naomi Fontaine’s novel Kuessipan depicts the Innu community on the Uashat reserve by way of fragments. Through an examination of the healing aspects of Indigenous literature, this analysis posits that Kuessipan is an example of curative literature and that the fragmented form paradoxically provides coherence to an experience fragmented by colonialism. Fontaine’s text also seems to contribute to the collective process of healing and restoring Innu identity by evoking Indigenous kinship and survivance.Creative WritingHow to evoke gender ambiguity in writing without confusing the reader? This short story reflects on the way in which identity is constructed with hints and snapshots transmitted through one’s immediate entourage as well as society, and sometimes in response to these perceived images. Using a fragmented narrative form, the text characterizes the main character’s identity by pointing to the fact that life, perceived as continuous, is made up of intermittent moments and discrete experiences; the organization of the fragments ensures the coherence of the composition. As French is a highly gender-marked language, writing around the grammatical indications of the masculine and feminine is essential. Rather than a mere formal exercise, this constraint provides an ethical framework for the representation of the character by constantly reminding me of my own position as a cis-gender writer. </dc:abstract><dc:abstract>Volet critiqueKuessipan, de l’auteure innue Naomi Fontaine, évoque la communauté innue de la réserve d’Uashat au moyen de fragments. Cette analyse, en examinant les aspects réparateurs de la littérature autochtone, postule que Kuessipan en est un exemple et que la forme fragmentée du texte contribue paradoxalement à donner de la cohérence à une expérience morcelée par le colonialisme. Le texte de Fontaine semble contribuer en outre au processus collectif de réparation identitaire en évoquant les « liens de parentalité » (kinship) et la « survivance » autochtones. Volet créationComment évoquer un personnage de genre ambigu à la lecture, sans perdre le lecteur ? Ce texte s’interroge sur la manière dont l’identité se construit à partir de clichés et d’instantanés renvoyés par l’entourage immédiat et la société, et parfois comme réplique à ces images. « Sois qui peux » est une nouvelle sous forme de microrécits qui cerne l’identité du personnage central en rappelant que la vie, apparemment continue, est faite de moments suspendus et d’expériences discrètes ; la manière dont ces fragments seront agencés assure la cohérence de la composition. Le français étant une langue très marquée par le genre, une partie du travail d’écriture est consacrée à contourner les indications du masculin et du féminin. Il ne s’agit pas seulement d’un exercice formel ; cette contrainte sert aussi de cadre éthique à la représentation de ce personnage en me rappelant constamment mon positionnement d’auteure cisgenre.</dc:abstract><ual:supervisor>Jane Everett (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/6h440w181.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/c247dv667</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A6395w991t"><dcterms:title>Durable bistable auxetics made of rigid solids</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Mechanical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Shang, Xiao</ual:dissertant><dc:abstract>Les matériaux auxétiques ont tendance à augmenter de taille dans le plan normal à la déformation appliquée, affichant ainsi un coefficient de Poisson négatif. Si une déformation élastique est appliquée à un élastomère monolithique auxétique puis retirée, le matériau revient à sa forme et sa taille originales. Pour un Bistable Auxetic Metamaterial (BAM) constitué d'une architecture d’élastomère monolithique à charnières par points, il existe un deuxième état d'équilibre du matériau qui conserve sa position même lorsque la déformation élastique est enlevée. Cet état de bi-stabilité dans le BAM permet un changement répétable entre deux états stables. Cependant, si le BAM était construit avec un polymère ou un métal rigide, le matériau entrerait inévitablement en rupture au premier cycle de chargement. Dans ce travail, l'architecture originale du BAM est développée pour permettre à des matériaux monolithiques rigides, comme ceux avec une relation constitutive élastique parfaitement plastique, de présenter une bi-stabilité et un auxétisme simultanés. Les charnières par points sont remplacées par des ligaments minces à profil optimisé, permettant ainsi de réduire les concentrations de contrainte et de retarder la défaillance en fatigue. Une combinaison de simulations et d'expériences est utilisée pour évaluer la performance du BAM avec des résultats qui illustrent une résistance la défaillance supérieure à 10 000 cycles. L'état de bi-stabilité et la défaillance sont caractérisés à travers le domaine de design, ce qui permet d’élucider le rôle joué par la géométrie du ligament par rapport à celle des charnières par point. En généralisant l'architecture du BAM, il est possible de designer une plus grande variété de matériaux, y compris les polymères rigides et les métaux pour une utilisation durable du BAM, ce qui pourrait rendre possible l'utilisation de la céramique, du verre et d'autres matériaux fragiles.</dc:abstract><dc:abstract>Auxetics materials tend to increase in size in the plane normal to an applied stretch, thus exhibiting a negative Poisson’s ratio. If an elastic strain is applied to a monolithic elastomer auxetic and then removed, the material returns to its original shape and size. In contrast, for a Bistable Auxetic Metamaterial (BAM) made of a monolithic elastomer cut with point-wise living hinges, there is a second state of equilibrium that the material can retain even when the elastic strain is removed. Introducing bistability in BAM allows repeated switch between stable states. If BAM, however, is realized with a rigid polymer or metal, the material would inevitably fail at the first loading cycle. In this work, the original architecture of BAM is extended to allow a rigid monolithic material, such as those with elastic-perfectly plastic constitutive relation, to feature concurrent bistability and auxeticity. Point-wise flexural hinges are here replaced by slender ligaments with optimized beam profile that can effectively reduce stress concentration and delay failure induced by repeated switches between stable states. A combination of simulations and experiments is used to assess BAM performance with results showing a resistance to failure above 10,000 cycles. Bistability condition and failure regime are both captured in design maps that elucidate the role played by ligament geometry relative to that of the rotating units. The generalized BAM architecture here introduced enables a larger palette of materials including rigid polymers and metals for durable use of BAM, thereby potentially unlocking the use of ceramic, glass and other brittle materials. </dc:abstract><ual:supervisor>Damiano Pasini (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/xk81jn941.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/6395w991t</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Afn107145m"><dcterms:title>Spatial operator algebra in modeling and properties of 3D inverted pendulae</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Navarro Heredia, Ana</ual:dissertant><dc:abstract>Ce mémoire emploie la méthode Complément Orthogonal Naturel (NOC), la méthode de corps articulé (AB) et la structure du Opérateur spacial algébrique (SOA) développée dans le laboratoire de Jet Propulsion à Caltech, Etats-Unis, pour concevoir des pendules inversés et étudier leur propriétés dynamiques.Une méthode de modélisation simplifiée est aussi présentée en utilisant les équations de Newton-Euler. L’approche de modélisation Lagrangienne n’est pas considérée comme pertinente pour les systèmes de ce niveau de complexité.Les attributs des méthodes de modélisation mentionnés sont analysés du point de vue de leur modularité et la flexibilité nécessaire pour la construction de stratégies de commande hybride pour la stabilisation de la pendule spatiale multi-bras à un équilibre instable et relatif.</dc:abstract><dc:abstract>This thesis employs the Natural Orthogonal Complement (NOC) method, the Articulated -Body (AB) method in the Spatial Operator Algebra (SOA) framework, developed in the Jet Propulsion Laboratory, CALTECH, USA, to model 3D inverted pendulae and investigates their dynamical properties.A simplified modeling approach is also presented using Newton-Euler equations. The Lagrangian modeling approach is not considered suitable for systems of this degree of complexity.The attributes of the mentioned modeling approaches are analyzed from the point of view of their modularity and flexibility as necessary for the construction of hybrid control strategies for stabilization of multi-link spatial pendulae to unstable and relative equilibria.</dc:abstract><ual:supervisor>Hannah Michalska (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/5m60qv38r.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/fn107145m</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Atm70mz01z"><dcterms:title>Automatic scoring up of mensural music using perfect mensurations, 1300-1550</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Schulich School of Music</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Thomae Elias, Martha</ual:dissertant><dc:abstract>La musique écrite en notation mensurelle — à savoir, la plupart des pièces polyphoniques écrites du milieu du treizième siècle jusqu’au seizième siècle — a été transcrite en parties séparées plutôt qu’en une seule partition. Afin d’étudier le contrepoint dans la musique mensurelle, il faut donc aligner les parties séparées dans une même partition, un processus appelé la « mise en partition » (scoring up). Ce processus implique la transcription de la notation originale et l’alignement exact sur la page des notes provenant des différentes parties. Il est donc nécessaire de connaître la durée de chaque note. La difficulté qui se présente dans la mise en partition de la notation mensurelle est que les durées des différentes notes (brève, semibrève, etc.) dans les mensurations ternaires (parfaites) ne sont pas absolues, mais dépendent du contexte. À cause de cela, à ce jour, il n’y a pas de méthode d’automatisation pour le processus de mise en partition. Dans cette thèse, nous allons présenter le premier processus automatique pour la mise en partition de la musique écrite entre les années 1300 et 1550.Dans la musique mensurelle, chaque note a une valeur de base donnée par la mensuration : la relation métrique entre la valeur d’une note et celle du prochain niveau métrique plus petit. Cette relation métrique peut soit être imparfaite (binaire) ou parfaite (ternaire). Dans le cas de la mensuration parfaite, la valeur de base d’une note peut changer selon le contexte (c’est-à-dire selon les notes qui précèdent et suivent). En nous basant sur les principes de l’imperfection et de l’altération exposés par Franco de Cologne dans son traité Ars cantus mensurabilis (vers 1280), nous avons implémenté un outil qui résout les principaux problèmes de la division ternaire : identifier si une note parfaite doit préserver sa valeur ou devenir une note imparfaite (c’est-à-dire raccourcie d’un tiers) ; discerner si une note doit préserver sa durée originale ou être altérée (c’est-à-dire doubler sa durée originale). De plus, l’outil accomplit les tâches suivantes : identifier la fonction des points, c’est-à-dire distinguer, malgré leur apparence identique, les points de division (les points qui séparent les notes en groupes parfaits) et les points d’augmentation (les points qui ajoutent à une note donnée la moitié de sa durée originale) ; prendre en compte la coloration des hémioles ; traiter la mensuration parfaite appliquée à des valeurs de notes variées (semibrève, brève et longue) dans plusieurs niveaux de notes simultanément. L’efficacité de l’outil de mise en partition est mesurée en utilisant une collection de pièces des quatorzième et quinzième siècles encodées en format MEI (Music Encoding Initiative), un format symbolique qui permet l’encodage de la notation mensurelle.</dc:abstract><dc:abstract>Music written in mensural notation—that is, most polyphonic music from the mid-thirteenth century to the sixteenth century—was written in separate parts rather than in score format. In order to study counterpoint in mensural music the parts must be aligned into a full score, a process referred to as “scoring up”. Scoring up involves transcribing the original notation and correctly aligning notes from different parts on the page, for which it is necessary to know the sounding duration of the notes. The difficulty mensural notation presents for scoring up is that the duration of individual note symbols (breve, semibreve, etc.) in perfect (triple) mensurations is not absolute, but rather context dependent. Because of this problem, it previously has not been possible to automate the process of scoring up parts. In this thesis, I present the first automatic scoring-up tool for music written in mensural notation between 1300 and 1550.In mensural notation, every note symbol has a default value given by the mensuration: the metrical relation between the value of one note and that of the next smaller metrical level. This metrical relation can be either imperfect (i.e., duple) or perfect (i.e., triple). In the case of perfect mensuration, the default value of a note can be changed by its context (i.e., by the notes preceding and following it). Based on the principles of imperfection and alteration outlined by Franco of Cologne in his treatise Ars cantus mensurabilis (ca. 1280), I implement a system that solves the main issues of triple meter: identifying when a perfect note should preserve its value or be imperfected (i.e., worth two thirds of its original value), and when a note should keep its original duration or be altered (i.e., be twice as long). Additionally, the tool is able to perform the following tasks: identify the functionality of dots—that is, distinguishing between dots of division (i.e., dots that separate notes in perfect groups) and dots of augmentation (i.e., dots that add to a given note one half of its value)—despite their identical appearance; deal with hemiola coloration; and handle perfect mensuration at different note-levels (semibreve, breve, and long) in more than one note-level at a time. The performance of the scoring-up tool is tested on a set of fourteenth- and fifteenth-century pieces encoded in MEI (Music Encoding Initiative), a symbolic format that supports the encoding of mensural notation.</dc:abstract><ual:supervisor>Julie Emelyn Cumming (Internal/Cosupervisor2)</ual:supervisor><ual:supervisor>Ichiro Fujinaga (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/n870zt010.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/tm70mz01z</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A6395w9923"><dcterms:title>Commissioning of an optically stimulated luminescence dosimetry (OSLD) system for in vivo dosimetry</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Medical Physics Unit</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Osunkwor, Offormata Emmanuel</ual:dissertant><dc:abstract>A commercial OSL dosimetry system was investigated for passive in vivo dosimetry in radiationtherapy. Al2O3:C OSLDs have been characterized by various authors and researchers,however an AAPM protocol for its clinical use is still in progress. In this work, a system ofnanoDots with the microStar reader (Landauer Inc.) was tested using typical radiotherapybeams in our clinic. The goal was to fully characterize the system and determine all thenecessary correction factors for accurate patient dose measurements. The results demonstratethat our OSLD system is a valid alternative to already established in vivo dosimetrymethods in our clinic.</dc:abstract><dc:abstract>Un systeme de dosimetrie OSL commercial a ete etudie pour la dosimetrie passive in vivodans le traitement de radiotherapie. Al2O3:C Les OSLD ont ete caracterises par diversauteurs et chercheurs, mais un protocole AAPM pour son utilisation clinique est toujours encours. Dans ce travail, un systeme de nanoDots avec le lecteur microStar (Landauer Inc.) aete teste en utilisant des faisceaux de radiotherapie typiques dans notre clinique. L'objectifetait de characteriser pleinement le systeme et de determiner tous les facteurs de correctionnecessaires pour des mesures precises de la dose du patient. Les resultats demontrent quenotre systeme OSLD est une alternative valable aux methodes de dosimetrie in vivo dejaetablies dans notre clinique.</dc:abstract><ual:supervisor>Stephen Douglas Davis (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/vd66w221s.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/6395w9923</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A3t945t355"><dcterms:title>Performing Québécois nationalism: the reception and revival of André Mathieu</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Schulich School of Music</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>van Vliet, Kiersten</ual:dissertant><dc:abstract>Over the past decade there has been an unexpected revival of Québécois composer André Mathieu’s works. Mathieu (1929–1968), who was allegedly touted by Rachmaninoff as the “Little Canadian Mozart,” died in poverty and obscurity. Post-World War Two, his music was unpopular for aesthetic and social reasons, and thus rarely performed until the mid-2000s. The shape Mathieu has taken in the recent mémoire collective of Quebec citizens is directly linked to the efforts of pianist-composer Alain Lefèvre. Discussion of Mathieu’s career and reputation is divided chronologically into three periods: his early life as a child prodigy (1929–1945); his adolescence and later career (1943–1968); and his ensuing reception (1964–2017). Drawing on musical analysis, biographical detail, and reception history, as well as larger networks of cultural and institutional history, sociology, and contemporaneous philosophical thought, I explore reasons for Mathieu’s discontinuous reception as well as his current prominence in the Québécois canon.</dc:abstract><dc:abstract>La dernière décennie fut témoin d’une étonnante redécouverte des œuvres du compositeur québécois André Mathieu (1929–1968). Celui que Rachmaninoff aurait surnommé le « petit Mozart canadien » mourut dans la misère et l’oubli. Après la Deuxième Guerre mondiale, pour des raisons esthétiques et sociales, sa musique était devenue impopulaire et fut donc rarement interprétée avant le milieu des années 2000. L’espace qu’occupe depuis peu le compositeur dans la mémoire collective québécoise est directement lié aux efforts du pianiste et compositeur Alain Lefèvre. Une analyse de la carrière et de la réputation d’André Mathieu est ici divisée chronologiquement en trois périodes : ses débuts en tant qu’enfant prodige (1929–1945); son adolescence et les dernières années de sa carrière (1943–1968); et la réception qui s’ensuivit (1964–2017). M’appuyant sur une analyse musicale, sur des détails biographiques et sur l’histoire de la réception, ainsi que sur des réseaux plus larges d’histoire de la culture et des institutions, de sociologie et de pensées philosophiques contemporaines aux événements analysés, j’explore les raisons de cette discontinuité de la réception de Mathieu, ainsi que sa notoriété actuelle dans le canon musical québécois.</dc:abstract><ual:supervisor>Lloyd Whitesell (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/ns064835h.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/3t945t355</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Arx913s31z"><dcterms:title>Studies of cosmic ray events in ATLAS sTGC muon chamber prototypes</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Physics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Léger, Félix</ual:dissertant><dc:abstract>Four years after its first long shutdown in 2015, the Large Hadron Collider (LHC) will be shut down once more for a luminosity upgrade. During that time, the ATLAS detector on the LHC ring will also follow an upgrade program, one upgrade being the replacement of the Small Muon Wheels New Small Muon Wheels containing small-strip Thin Gap Chambers (sTGCs). The sTGCs built in Canada will be tested at McGill University before their installation in ATLAS. A testing facility has been constructed and a 40 x 60 cm^2 sTGC prototype has been used to deliver preliminary measurements from cosmic rays. This thesis will present the development of a robust tracking algorithm which can handle extra clusters and multiple tracks in an sTGC detector. This algorithm also categorizes events based on their number of clusters and tracks. By modifying the trigger time window of the sTGC prototype, the evolution of the distribution of events over this categorization is shown.</dc:abstract><dc:abstract>Quatre ans après son premier arrêt en 2015, le Grand Collisionneur hadronique (LHC) sera mis en arrêt une fois de plus pour augmenter sa luminosité. Pendant ce temps, le détecteur ATLAS situé sur le cercle du LHC suivra lui aussi un programme visant son amélioration. Un des changements sera le remplacement des petites roues à muons pour de nouvelles petites roues contenant des Chambres Minces à petites bandes (sTGCs). Les sTGC seront construites au Canada et seront testées à l'université McGill avant d'être installées dans ATLAS. Un laboratoire de test a été construit à cette fin et un prototype sTGC de 40 x 60 cm^2 a été utilisé pour faire des mesures préliminaires de rayons cosmiques. Cette thèse présentera le développement d'un algorithme robuste permettant de reconstruire des événements contenant plusieurs points et traces dans un détecteur sTGC. Cet algorithme peut aussi catégoriser ces événements en se basant sur leur nombre de points et de traces. En modifiant le temps de déclencement d'acquisition de données du prototype sTGC, l'évolution de la distribution d'événements dans les différentes catégories est présentée.</dc:abstract><ual:supervisor>Andreas Warburton (Internal/Cosupervisor2)</ual:supervisor><ual:supervisor>Steven Robertson (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/1v53k0513.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/rx913s31z</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Axk81jn959"><dcterms:title>Waiting for a cognitive behavioural therapy (CBT): A randomized controlled trial evaluating the use of a computerized CBT program with outpatients on a waitlist in a university CBT unit</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Psychiatry</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Villemaire-Krajden, Rosanne</ual:dissertant><dc:abstract>L’emploi de programmes informatisés de thérapie cognitivo comportementale (TCCi) pourrait être un moyen de réduire les longues listes de personnes en attente d’une psychothérapie financée par le gouvernement. Toutefois, proposer un programme approprié à ces personnes pose un problème compte tenu de la diversité des troubles présentés et du fait que l’évaluation diagnostique est habituellement effectuée à la fin de la période d’attente. La présente étude avait pour objet de déterminer si le recours à un programme général de TCCi axé sur la dépression et l’anxiété permettrait de réduire les symptômes de patients externes en attente d’une TCC qui avaient été orientés vers nos services et dont les problèmes variaient grandement.Soixante sept patients externes dont les diagnostics variaient (anxiété, dépression, trouble obsessionnel compulsif, trouble bipolaire, trouble psychotique et autres troubles) ont participé à l’étude et ont été classés de façon aléatoire dans l’un de deux groupes : 1) le groupe de ceux qui allaient se servir du programme de TCCi Good Days Ahead, qui comportait une séance hebdomadaire d’orientation et de soutien; 2) le groupe témoin, dans lequel les patients allaient remplir en ligne, de manière autonome, un carnet de travail de TCC. Dans un premier temps (T1), soit au début de l’étude, les participants ont répondu au questionnaire de mesure systématique des résultats cliniques [The Clinical Outcomes in Routine Evaluations – Outcome Measure (CORE OM)], aux questionnaires de dépression et d’anxiété de Beck et à un questionnaire de mesure de la motivation autonome et de la motivation contrôlée à l’égard de la TCC, puis, dans un deuxième temps (T2), soit à la fin de la période d’attente, ils ont fait l’objet d’une évaluation en bonne et due forme dans le cadre d’une thérapie face à face.Les analyses de variance mixtes ont révélé qu’il n’y a eu aucun changement statistiquement significatif dans la mesure des symptômes au fil du temps, sauf pour ce qui est des sous échelles d’évaluation des problèmes ou symptômes et de bien-être du questionnaire de CORE OM. Le degré de motivation a changé de façon inattendue : la motivation autonome a diminué du T1 au T2, alors que la motivation contrôlée a augmenté. Les interactions statistiquement non significatives et l’ampleur modeste de l’effet indiquent que le groupe ayant utilisé le programme de TCCi n’a pas obtenu de meilleurs résultats que le groupe témoin. Fait intéressant, une majorité des participants au programme de TCCi ont indiqué que le programme leur avait été « très » ou « extrêmement » utile, tandis qu’une faible partie seulement du groupe témoin ont eu la même impression par rapport au carnet de travail. Le taux d’achèvement du programme informatisé est nettement supérieur au taux d’achèvement du travail effectué à l’aide du carnet.Il n’est peut être pas plus avantageux d’offrir aux patients en attente d’une TCC de participer à un programme général de TCCi que de les inviter à utiliser un carnet de travail. En fait, les résultats de notre étude indiquent que les changements dans le degré de gravité des symptômes et dans le niveau de bien-être étaient probablement plus attribuables au passage du temps qu’à notre intervention. La diminution de la motivation autonome à l’égard de la TCC pourrait en partie s’expliquer par la difficulté à mettre en pratique les connaissances acquises, particulièrement dans le cas des patients dont le problème principal ne faisait pas directement l’objet d’une démarche dans le programme ou dans le carnet de travail. Les résultats obtenus indiquent qu’il vaudrait sans doute mieux offrir aux patients un programme de TCCi précis ayant un rapport direct avec les problèmes dont ils se plaignent que de leur faire suivre un programme général de TCCi.</dc:abstract><dc:abstract>Computerized Cognitive-Behavioural Therapy (cCBT) programs are a potential solution to decrease waiting lists for publicly-funded psychotherapy. However, assigning an appropriate program to individuals on a waiting list can be a challenge, given the heterogeneity of disorders presented and the timing of diagnostic assessments, which usually occur at the end of the waiting period. This study aimed to determine if a general cCBT program for depression and anxiety could reduce symptoms in outpatients referred for a wide variety of problems, while on a waiting list for CBT.Sixty-seven outpatients with disparate diagnoses (anxiety, depression, obsessive compulsive disorders, bipolar disorders, psychotic disorders and others), were randomized to one of two conditions: 1) the cCBT program “Good Days Ahead”, which included weekly guidance and support, or 2) a control condition where patients were referred to an online self-help CBT workbook. The Clinical Outcomes in Routine Evaluations - Outcome Measure (CORE-OM), Beck Depression Inventory, Beck Anxiety Inventory, and an autonomous and controlled motivation for CBT scale were administered at start of study (T1), and at the end of the waiting period, when participants were formally assessed for face-to-face therapy (T2).Mixed-design analyses of variance revealed no statistically significant changes in symptom measures over time, with the exception of the problems/symptoms and well-being subscales of the CORE-OM. Motivation changed in unexpected ways, with autonomous motivation decreasing from T1 to T2, and controlled motivation increasing over time. Non-significant interactions and modest effect sizes between groups across time suggested that the cCBT group did not do better than the control group. Interestingly, the majority of cCBT participants reported that the program was “very” or “extremely useful”, while only a portion of the control group felt the same about the workbook. There were also notable differences in the completion rates of the two groups, in favour of the cCBT program.Offering a general cCBT program to waiting list patients may not confer an advantage over simply referring them to an online workbook. In fact, our results suggest that changes in symptom severity and well-being were likely due to the passage of time rather than to the effects of either intervention. The decline in autonomous motivation for CBT could be explained, in part, to difficulties translating knowledge into practice, especially if participants’ main problem was not directly addressed by the program or workbook. These findings suggest it might be more helpful to offer patients specific cCBT programs targeting their main complaints rather than assign them to a general cCBT program. </dc:abstract><ual:supervisor>Gail Myhr (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/5d86p275k.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/xk81jn959</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Adf65vb09g"><dcterms:title>Design of an anemometer to characterize the flow in the rotor rim ducts of a hydroelectric generator</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Mechanical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Venne, Kevin</ual:dissertant><dc:abstract>Due to its complex geometry, the airflow within hydroelectric generators is difficult to characterize. Although Computational Fluid Dynamics (CFD) can be a reliable engineering tool, its application to the field of hydroelectric generators is quite recent and has certain limitations, which are in part due to geometrical and flow complexities, including the coexistence of moving (rotor) and stationary (stator) components. For this reason, experimental measurements are required to validate CFD simulations of such complex flows. To this end, a 1:4 scale model of a hydroelectric generator was constructed at the Institut de recherche d’Hydro-Québec (Hydro Québec’s Research Institute - IREQ) and measurements using Particle Image Velocimetry (PIV) were performed to characterize the flow therein. However, this technique cannot be used in machines and thus, new flow sensors must be developed to measure the flow in the confined and harsh regions in these machines. The main region of interest is the flow within the rotor rim ducts, since it is directly responsible for cooling the poles (one of the most critical components). This rather complex task required the design of an anemometer that had to be accurate, durable, cost-effective, easy to install, and able to withstand the extreme conditions found in hydroelectric generators (temperatures of 45°C, centrifugal forces of 300 g, etc.). In this thesis, a thermal mass flow meter and a method for validating its performance, using hot-wire anemometry and a static model of a rotor rim, was developed. The sensor is equipped with two uniquely designed features: i) a heating element made of an array of Nichrome wires and ii) Resistance Temperature Detectors (RTDs) made of Balco wires. This design is capable of: i) measuring the mass flow rate in the rotor rim ducts with an accuracy of approximately 10%, ii) fitting inside small rectangular ducts (12.2 mm by 51 mm), iii) resisting forces up to 300 g, and iv) making measurements that are not altered by the magnetic fluxes found in the rotor poles.</dc:abstract><dc:abstract>La complexité géométrique des alternateurs rend la caractérisation de l’écoulement d’air dans ces machines très difficile à réaliser. En dépit de la fiabilité des outils de modélisation tels que la Computational Fluid Dynamics (CFD), leur utilisation dans le domaine des alternateurs est très récente et implique certaines limitations, qui sont dues en partie à la complexité de la géométrie et de l’écoulement, et à la coexistence de composantes rotative (rotor) et fixe (stator). En conséquence, des mesures expérimentales sont requises pour la validation de simulations numériques et pour ce faire, une maquette tournante d’alternateur (échelle 1:4) a été construite à l’Institut de recherche d’Hydro-Québec (IREQ). De plus, des mesures par Particle Image Velocimetry (PIV) ont été réalisées afin de caractériser l’écoulement au niveau du rotor et du stator. Cependant, cette technique ne peut pas être utilisée dans des alternateurs réels et il est donc nécessaire de développer de nouveaux capteurs pour mesurer l’écoulement dans des régions confinées de ces machines. Une région d’intérêt particulier se situe au niveau de la jante du rotor, car l’écoulement sortant des canaux a un impact majeur sur le refroidissement des pôles (une des composantes critiques). Cette tâche très complexe nécessite la conception d’un anémomètre fiable, durable, abordable, simple à installer et en mesure de résister aux conditions extrêmes normalement rencontrées dans les alternateurs (températures de 45ᵒC, forces centrifuges de 300 g, etc.). Dans cette thèse, un débitmètre massique de type thermique et une méthode permettant de valider sa performance, en utilisant un anémomètre à fil chaud et une maquette statique d’une jante de rotor, ont été développés. Ce capteur est équipé de deux design uniques : i) un élément chauffant fabriqué avec des fils de Nichrome et ii) des Resistance Temperature Detectors (RTDs) fabriqués avec des fils de Balco. Ce design peut : i) mesurer le débit massique dans les canaux de la jante du rotor avec une précision approximative de 10%, ii) être inséré dans de petits canaux rectangulaires (12.2 mm par 51 mm), iii) résister à des forces centrifuges de 300 g, et iv) prendre des mesures qui ne sont pas altérées par les flux magnétiques qui se retrouvent dans les pôles du rotor.</dc:abstract><ual:supervisor>Federico Torriano (Internal/Cosupervisor2)</ual:supervisor><ual:supervisor>Laurent B Mydlarski (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/db78tf48x.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/df65vb09g</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A4m90dx86j"><dcterms:title>Gimp Sue gets the girl: disability, desirability, and the twilight fanfiction</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of English</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Dreisinger, Olivia</ual:dissertant><dc:abstract>NA</dc:abstract><dc:abstract>This article brings a queer crip analysis to investigate the function of disabled Mary Sues in the online world of fan fiction. A Mary Sue is either a canon or original character (OC) written into a pre-existing universe, whose perfect set of traits seem entirely unbelievable. Mary Sues are often surrogates of the authors themselves, tactlessly implanted into universes to live out personal fantasies with fictional characters, in fictional situations. Because of their self-gratifying behaviour, Mary Sues are viewed as badfic (bad fiction) and as poorly developed original characters. I disagree with these critiques that pose Mary Sues as badfic. Instead I argue that Mary Sues, specifically disabled Mary Sues, are powerful disruptive agents that challenge and resist narratives of compulsory able-bodiedness and compulsory heterosexuality. By writing spaces for themselves in fandoms that canonically don’t consider their bodies, or threaten to erase them, disabled Mary Sues write a way for disabled characters and readers to have agency (and to sometimes have hot consensual sex too).  While many scholars have written about the Mary Sue through gender and sexuality, disability is often entirely overlooked.  I take up this gap in scholarship in the following sections, looking at the various intersections between disability and Twilight fanfiction. At the beginning of this article, I begin by conducting a review of Mary Sues in both scholarship and fandom, arguing that authoring a Sue troubles the intersections between critical distance and fannish attachment, repeatedly sending academic and fan spaces into crisis. In the second section, I give a brief overview of disability Twilight fics, broadly examining common tropes and problems found within the genre. Lastly, I look closely at two Disabled!Twilight fanfics written by disabled authors—LisbethsGirlfriend’s Forgive Me for Loving You and The Plasma’s Coping with Change.</dc:abstract><ual:supervisor>Mary Bunch (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/x633f374q.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/4m90dx86j</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A3n2041596"><dcterms:title>A neural network based nonlinear weighted finite automata</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>School of Computer Science</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Li, Tianyu</ual:dissertant><dc:abstract>Weighted finite automata (WFA) can expressively model functions defined over strings. However, a WFA is inherently a linear model, with the transition matrices being a linear function. Neural network, on the other hand, is a powerful nonlinear function approximator. In this paper, we propose a neural network based nonlinearWFA model along with a learning algorithm. Our learning algorithm is inspired by the classic spectral learning method for WFA. It turns out that learning the WFA canbe described as a two-stage process. The first one is to find a rank factorization for the so-called Hankel matrix and the step two is a regression problem based on thisfactorization. This two-stage procedure provides us with two places to apply non-linearity, thus with three different settings for learning the nonlinear WFA. Insteadof using linear rank factorization of the matrix, we will use nonlinear auto encoderdecoder to learn the factorization and we will use neural network to replace the linear regression for the second stage. We will show that all these three settings have the form of the defined nonlinear WFA. We also provide the method to use this nonlinear method to predict the likelihood for a string as well as the next letter after reading a prefix. We assessed the performance of the proposed model on the synthetic Dyck language data, and two metrics – Pautomac score and word error rate will be tested.</dc:abstract><dc:abstract>Les automates finis pondérés (WFA) peuvent modéliser de façon explicite des fonctions définies sur des chaînes. Cependant, un WFA est intrinsèquement un modèle linéaire, les matrices de transition étant une fonction linéaire. D'autre part, le réseau de neurones est un puissant approximateur de fonction non linéaire. Dans cet article, nous proposons un modèle basé sur un réseau neuronal non linéaire avec un algorithme d'apprentissage. Notre algorithme d'apprentissage est inspiré de la méthode d'apprentissage spectrale classique pour WFA. Il s'avère que l'apprentissage du WFA peut être décrit comme un processus en deux étapes. Le premier est de trouver une factorisation de rang pour la matrice dite de Hankel et la deuxième étape est un problème de régression basé sur cette factorisation. Cette procédure en deux étapes nous fournit deux endroits pour appliquer la non-linéarité, donc avec trois paramètres différents pour l'apprentissage du WFA non-linéaire. Au lieu d'utiliser la factorisation de rang linéaire de la matrice, nous utiliserons auto codeurdecoder non linéaire pour apprendre la factorisation et nous utiliserons le réseau de neurones pour remplacer la régression linéaire pour la deuxième étape. Nous montrerons que tous ces trois paramètres ont la forme du WFA non linéaire défini. Nous fournissons également la méthode pour utiliser cette méthode non linéaire pour prédire la probabilité d'une chaîne ainsi que la lettre suivante après avoir lu un préfixe. Nous avons évalué la performance du modèle proposé sur les données de langage synthétique Dyck, et deux mesures - le score de Pautomac et le taux d'erreur de mots seront testés.</dc:abstract><ual:supervisor>Doina Precup (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/xk81jn97v.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/3n2041596</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A5q47rr345"><dcterms:title>A near-field study of a shallow mixing layer between coflowing streams using 3D-PTV</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Civil Engineering and Applied Mechanics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Consuegra Martínez, Claudio</ual:dissertant><dc:abstract>Une compréhension plus approfondie du mélange turbulent en eaux peu profondes est pertinente pour mieux prédire la dispersion des contaminants/nutriments, le transport des sédiments et les processus d’érosion, même si le sujet a été étudié dans différentes recherches. Comprendre le comportement hydrodynamique et les caractéristiques des écoulements des eaux peu profondes demande un regard tridimensionnel de l’écoulement ainsi que de ses structures turbulentes. Cette recherche est une première étape d'étude des couches de mélange des eaux peu profondes dans une région proche de la convergence des courants parallèles en utilisant un cadre Lagrangien via l’utilisation de 3D Particle Tracking Velocimetry (3D-PTV). Cette recherche étudie un modèle simplifié de la confluence d’une rivière à travers l’écoulement des courants parallèles des différentes vitesses (U1 = 0.45 m/s, U2 = 0.31 m/s), entre lesquelles une couche de mélange en eaux peu profondes se développe. Un canal de laboratoire, 9 m x 1.5 m x 0.25 m, avec des paroirs et un fond en verre a été construit. Les expériences de laboratoire ont été conduites pour un Re moyen de 24,700, avec une profondeur d’eau de 6.5 cm et une pente nulle. Les mesures avec 3D-PTV ont été réalisées à partir de l’extrémité d’une planche de séparation jusqu’à 30 cm en aval. Pour faire les mesures, trois caméras CCD à haute vitesse (600 Hz) et à haute résolution (2016x2016) localisées en-dessous du canal ont été utilisées. Les images enregistrées ont été analysées en utilisant OpenPTV pour extraire l’information du champ d’écoulement. Des microsphères (Florabeads RBW) avec une densité relative à l’eau de ~ 1 à 25°C et une couleur naturelle, ont été semées pour tracer l’écoulement, illuminé par des lampes d’halogène. La calibration de 3D-PTV a été effectuée avec un objet 3D. Les données obtenues à partir de l’application de 3D-PTV ont permis l’acquisition du champ de vitesse. Les données de vitesse ont été analysées pour obtenir des séries temporelles de vitesse ainsi que des profils transversaux de vitesse moyenne longitudinale et d’intensité turbulente de la couche de mélange. En plus, des graphiques de contour instantanées ont été générés pour comprendre le processus de mélange à l’intérieur de l’écoulement à différentes positions en aval. Une couche de mélange d’eau en milieu peu profond formée à partir de la confluence des courants parallèles peut être divisées en deux régions en aval, une zone proche de la confluence où l’écoulement défini par la géométrie initiale évolue vers une couche de mélange, et une zone autosimilaire postérieure ou la couche de mélange d’eau en milieu peu profond a développé ces propriétés caractéristiques. Dans cette première étape de recherche le première 30 cm après la confluence ont été étudiés. Dans cette région les caractéristiques suivantes existent. Des couches limites se développent à côté la planche de séparation des courants, créant un déficit de vitesse propre d’un sillage (à la fin de la planche de séparation). Ce déficit de vitesse diminue en magnitude en aval mais il n’est pas complétement disparu après x = 30 cm. Le sillage a une zone de haute turbulence, grâce au gradient de vitesse entre les vitesses libres et le déficit de vitesse, zone de haute turbulence que diminue ainsi que le déficit de vitesse diminue dans la direction de l’écoulement. Le sillage formé empêche la formation et élargissement de la couche de mélange d’eau en milieu peu profond, ce qui occasionne que la largeur de la couche de mélange soit constante au long de la distance des mesures et qu’elle fasse un virage vers le courant lent causé par le transfert latéral du moment. En fin, le développement d’une circulation secondaire peut commencer à se former à la fin de la distance de mesure. Ce comportement est évident vue que des sections d’écoulement instantanées montrent qu’il y a un flux transversal vers le courant lent en surface et vers le courant rapide au fond du canal.</dc:abstract><dc:abstract>Shallow mixing layers have been the subject of many experimental studies, yet further understanding of the hydrodynamics of shallow flows is important to better predict their effect on the dispersion of pollutants/nutrients, sediment transport, and erosion processes. Understanding the hydrodynamics and the characteristics of shallow flows requires a fully three-dimensional (3D) observation of the flow and its turbulent structures. This thesis is a first attempt to study shallow mixing layers in the near-field of coflowing streams using a Lagrangian reference frame by applying 3D Particle Tracking Velocimetry (3D-PTV). The present study investigates a simplified laboratory model of a river confluence modelled by parallel coflowing streams with different velocities (U1 = 0.45 m/s, U2 = 0.31 m/s) between which a shallow mixing layer develops. A new shallow recirculating glass flume, with dimensions of 9 m x 1.5 m x 0.25 m, (glass walls and bed) was set up for experiments for one turbulent hydraulic condition (mean Re = 24,700), having a water depth of 6.5 cm and a bed slope of zero. 3D-PTV measurements were made from the end of a splitter plate to a distance of 30 cm in the downstream direction using three high speed (600 Hz) and high-resolution (2016x2016 pixels) CCD cameras positioned to record images from below the glass flume bed. Information on the flow field was extracted from the image sequences using OpenPTV. The flow was seeded with rice bran wax microspheres (Florabeads RBW) with a specific gravity ~ 1 at 25°C and natural color, illuminated with halogen lamps. The 3D-PTV system was calibrated using a solid 3D calibration object. The data from 3D-PTV was post-processed to obtain the velocity flow field, which was in turn analyzed to obtain velocity time-series and shallow mixing layer transverse profiles for mean streamwise velocity and turbulent intensity, as well as instantaneous velocity information at different downstream positions. A shallow mixing layer formed from coflowing streams can be divided into two regions in the downstream direction, a near-field zone in which the flow defined by the initial geometry evolves into a mixing layer and a self-similar region in which the mixing layer has developed its characteristic properties. In this first stage of investigation, the first 30 cm of the near-field were studied. In this region, the following flow characteristics were observed. Boundary layers, developing along the splitter plate dividing the parallel channels, result in a wake or velocity deficit at the streams confluence (at the end of the splitter plate). This velocity deficit decreases in magnitude in the downstream distance but has not fully decayed by x=30 cm.  The wake has a high turbulent intensity, as it is a shear layer forming due to the velocity gradient between the free streams and the velocity deficit, which decreases as the velocity deficit decreases in magnitude with downstream distance. The wake formed by the splitter plate is reducing, which limits establishment and growth of the mixing layer, causing the width of the shear layer to remain constant over the measurement distance and shifts towards the slower moving stream due to transverse momentum transfer. Lastly, the development of a secondary circulation is possibly appearing by the end of the measurement distance, as in instantaneous flow sections, transverse flow towards the slow stream appears at the surface and towards the fast stream at the bed. </dc:abstract><ual:supervisor>Susan J Gaskin (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/js956j36g.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/5q47rr345</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Azs25xb978"><dcterms:title>The use of ionic liquids as a platform for the sustainable development of high value materials from chitin waste</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Chemistry</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>King, Catherine</ual:dissertant><dc:abstract>Avec l’utilisation de plus en plus répandue de polymères basés sur les composés pétrochimiques la pollution environnementale s’est accrue. L’inquiétude sociétale pour les problèmes environnementaux de ces dernières années a entrainé un intérêt grandissant pour développer l’utilisation de matériaux durables. La chitine est le deuxième bio polymère le plus abondant dans la nature, et elle peut être récoltée parmi les « déchets » des zones de pêche et des fermes d’élevage de crevettes, elle possède également de nombreuses propriétés à forte valeur ajoutée telles que la biocompatibilité, la biodégradabilité et la bio activité. Bien que son utilisation fût historiquement entravée par son insolubilité dans les systèmes de solvant traditionnels, les liquides ioniques (LI) sont récemment apparus comme de nouveaux solvants. Les LI permettent l’extraction, la régénération et le traitement de la chitine pour la préparation de nouveaux matériaux. Dans cette thèse, les LI furent employés comme moyens de traitement de la chitine pour préparer de nouveaux matériaux. La thèse débute avec une nouvelle méthode de détermination de la pureté des échantillons de chitine. La chitine est mélangée avec des protéines et des minéraux dans la biomasse, mais il est important de connaître la pureté des bio polymères isolés pour la qualité des matériaux futurs. Ici (chapitre 3) la RMN du 13C à polarisation croisée multiple (multi-CP) du solide fût utilisée pour déterminer précisément, rapidement et de manière non destructive la teneur en chitine d’un échantillon chitineux. Les matériaux préparés pour cette thèse furent ensuite préparés en toute connaissance de la pureté de la chitine. Dans le chapitre 4, la préparation de films de chitine via traitement par LI fut optimisée, et les propriétés de ces films furent étudiés. Il a été constaté que les paramètres de préparation tels que le chargement de chitine dans le LI, la source de chitine ou la méthode de coulage ont un effet sur la performance du coulage de film. Pour démontrer une application potentielle en tant que membrane libérant des médicaments, de la caféine fut chargée puis relâchée depuis des films séchés par CO2 supercritique. Le chapitre suivant (Chapitre 5) est axé sur l’utilisation de la plate-forme de préparation de films de chitine composites fonctionnels, la méthode utilisant les LI permettant l’incorporation d’additifs dans la solution chitine/IL. En poursuivant sur le thème de l’utilisation de la chitine en tant que matériau polymérique plus durable, des films composites de chitine/graphène furent préparés et utilisés pour la construction d’un super condensateur fonctionnel. La dispersion du graphène dans la chitine fut étudiée, et des films composites ayant jusqu’à 80% en poids de graphène furent coulés. Les films composites de graphène/chitine (utilisés en tant qu’électrodes), ainsi que les films de chitine purs (utilisés en tant que séparateurs) furent assemblés en un super condensateur fonctionnel basé sur la chitine. Le travail effectué dans cette thèse vise à jeter les bases du développement de matériaux avancés, durables et à forte valeur ajoutée obtenus par le traitement de bio polymères par LI pour un monde ayant une meilleure durabilité.</dc:abstract><dc:abstract>As petrochemical based polymers have become prevalent, so too has the environmental pollution which results from their widespread use. In recent years, increasing societal concern for environmental issues has led to a growing focus on the use of more sustainable materials. Chitin is the second most abundant biopolymer, can be obtained from “waste” generated in fisheries and shrimp farms, and possess many high value properties such as biocompatibility, biodegradability, and bioactivity. Although its use has traditionally been hindered due to its insolubility in common solvent systems, ionic liquids (ILs) have recently emerged as a solvent. ILs allow for the extraction, regeneration, and solution processing of chitin for the preparation of new materials. In this thesis, the IL processing platform was utilized for the preparation of new functional materials from chitin. The thesis begins with a new method for the determination of purity of chitin samples. In biomass, chitin is mixed with proteins and minerals, but it is important for the quality of the resulting materials that the purity of the isolated biopolymer to be known. Here (Chapter 3), solid-state 13C multiCP NMR was used to determine chitin content in a chitinous sample accurately, quickly, and non-destructively. From here, with knowledge of the chitin purity in mind, materials were prepared. In Chapter 4, the preparation of chitin films via IL processing was optimized, and the properties of the resulting films studied. It was found that preparation parameters such as the loading of chitin in the IL, the chitin source, and the casting method influenced the ability to cast a film. Caffeine was loaded and released from supercritically CO2 dried films, demonstrating a potential application as a drug releasing membrane. The next chapter (Chapter 5) focused on using the platform for the preparation of functional composite chitin films, as the IL method allows for the incorporation of additives into the chitin/IL solution. Here, following the theme of using chitin for more sustainable polymeric materials, chitin/graphene composite films were prepared and used in the assembly of a functioning supercapacitor. Dispersion of graphene into the chitin/IL solution was studied, and composite films of up to 80 wt% graphene were cast. The graphene/chitin composite films (used as electrodes), along with neat chitin films (used as separators) were assembled into a working chitin-based supercapacitor. The work done in this thesis aims to pave the way for the development of high-value, sustainable advanced materials from IL-processed biopolymers for a more sustainable world. </dc:abstract><ual:supervisor>Mark P Andrews (Internal/Cosupervisor2)</ual:supervisor><ual:supervisor>Robin Rogers (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/cj82k9770.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/zs25xb978</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ap2676z26c"><dcterms:title>The distribution of narwhal «(Monodon monoceros)» males, females, and newborns in the Canadian Arctic Archipelago</dcterms:title><ual:graduationDate>2018</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Natural Resource Sciences</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Charry, Bertrand</ual:dissertant><dc:abstract>Le narval (Monodon monoceros) est un cétacé de taille moyenne vivant exclusivement dans les eaux arctiques. L'éloignement de leur environnement en conjonction avec la large diffusion de leur distribution pose de nombreux défis pour étudier cette espèce arctique au niveau de la population. Il existe peu de connaissance sur la structure de population et la distribution des différentes classes d’âge et sexes des narvals. Dans cette thèse, j'ai utilisé la photographie aérienne comme méthode non-invasive pour étudier la distribution des narvals de manière plus détaillée, en identifiant et localisant les mâles, les femelles et les nouveau-nés à travers l'archipel arctique canadien. En août 2013, Pêches et Océans Canada (MPO) a mené des survols aériens approfondie couvrant l’air de distribution connue des narvals durant l’été afin d’estimer l'abondance de la population de la baie de Baffin. J'ai utilisé les photographies géo-référencées recueillies au cours des survols à partir desquelles j’ai élaboré une clé dichotomique pour identifier les nouveau-nés. J’ai par la suite regardé la distribution des mâles, des femelles et des nouveau-nés. J'ai testé la fiabilité de la clé en effectuant un test Kappa de Cohen entre quatre observateurs. La performance globale de la clé était bonne. En 3393 photographies analysées, j'ai détecté 6315 individus différents, sexé 2804 individus et trouvé 141 nouveau-nés. Pour analyser la distribution des narvals, j'ai d'abord utilisé l'algorithme de cheminement de plus faible coût pour construire une matrice de distances de nage entre les individus. Ensuite, j'ai effectué un partitionnement autour de l'algorithme de medoids, une variante de l'algorithme k-means, pour diviser mes données en k ensembles en fonction des distances de nage. J'ai trouvé cinq groupes principaux en alignement avec les quatre zones de gestion des narvals actuellement définies par le MPO. Ces zones de gestion correspondent à différents stocks de narvals déterminés par la connaissance locale, les données de télémétrie et la génétique. Les narvals ont été répartis inégalement entre chaque groupe et j'ai trouvé différents ratios hommes:femmes variant de 0,71 à 1,4. Les nouveau-nés correspondaient à environ 10% du nombre de femelles présentes dans chaque groupe. Cette thèse est la première à décrire le comportement spatial des dyades mères-nouveaux-nés narvals ainsi que la distribution des sexes de la population de la Baie de Baffin dans l'Archipel de l’Arctique Canadien. </dc:abstract><dc:abstract>The narwhal (Monodon monoceros) is a medium-sized odontocete exclusively found in Arctic waters. The remoteness of their environment in conjunction with their widespreaddistribution poses numerous challenges to studying this Arctic species at a population level. The narwhal is a species with knowledge gaps regarding their population structure and the distribution of different sexes and age classes. This thesis provides a detailed description of narwhal distribution in the Canadian Arctic Archipelago using the non-invasive method of aerial photography to identify and geo-locate narwhal males, females, and newborns. In August 2013, Fisheries and Oceans Canada (DFO) conducted an extensive aerial survey of narwhal summer habitat to estimate the abundance of the Baffin Bay population. I used the georeferenced photographs collected during the surveys to develop a dichotomous key to identify newborns from photographs. The key was also used to describe the distribution of narwhal males, females, and newborns. I used a Cohen’s Kappa test, across four observers, to test the replicability of the key, with strong positive results.  Within the 3,393 photographs analyzed I detected 6,315 different individuals. I could identify the sex of 2,804 individuals and identified 141 newborns. To analyze the distribution of narwhals, I first used the least cost path algorithm to construct a matrix of swimming distances between individuals. Then, I performed a partitioning around the medoids algorithm, a variation of the k-means algorithm, to divide my dataset into k clusters based on the swimming distances. I found five main clusters of narwhals that align closely with four narwhal management zones currently defined by DFO. These four management zones correspond to different narwhal stocks determined through local knowledge, telemetry data, and genetics. Narwhals were unevenly distributed between each cluster and I found different male:female sex ratios varying from 0.71 to 1.4, newborns represented 10% of the number of females present in each cluster. This thesis is the first to shed light on narwhal newborn-mother spatial patterns and narwhal sex distribution of the Baffin Bay population in the Canadian Arctic Archipelago.</dc:abstract><ual:supervisor>Marianne Marcoux (Supervisor2)</ual:supervisor><ual:supervisor>Murray Mitchell Humphries (Supervisor1)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/4x51hm65s.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/p2676z26c</ual:fedora3Handle><dc:subject>UMIC code is not required - UMIC code is not required</dc:subject></rdf:Description></rdf:RDF>