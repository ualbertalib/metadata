<?xml version="1.0" encoding="UTF-8"?><rdf:RDF xmlns:oai="http://www.openarchives.org/OAI/2.0/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:ual="http://terms.library.ualberta.ca/" xmlns:bibo="http://purl.org/ontology/bibo/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:schema="https://schema.org/" xmlns:etdms="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Aww72bf003"><dcterms:title>Optimization of surgical technique by objective quantification and reconstruction of adipose tissue volume</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Surgery</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Azzi, Alain</ual:dissertant><dc:abstract>Introduction/hypothèse: Les spécialistes en chirurgie plastique et esthétique manipulent souvent le tissu adipeux. Les reconstructions par lambeaux libres, les greffes adipeuses ainsi que la liposuccion sont parmi les procédures les plus fréquentes. Il n'y a présentement aucun moyen objectif de mesurer le volume de tissu adipeux de la zone donneuse. Les chirurgiens se fient aux moyens subjectifs pour estimer le volume de tissu adipeux adéquat (e.g. test du pincement). L'imagerie par résonance magnétique et la tomodensitométrie peuvent mesurer le volume de tissu adipeux, cependant les limites d'accès (temps d'attentes) et les coûts associés à ces techniques d'imageries limitent leur applicabilité. De plus, ils ne peuvent pas mesurer le volume adipeux en temps réel durant la chirurgie. En utilisant l'échographie, nous aimerions développer un outil qui permet de mesurer le tissu graisseux en temps réel et le représenter en utilisant un modèle trois-dimensionnel. Notre objectif principal est d'améliorer les résultats des procédures reliées aux tissus graisseux, diminuer les complications, ainsi qu'améliorer la satisfaction des patients. Méthodes: La première partie de notre projet (thèse actuelle) est composée de trois revues de littérature. Les données ramassées étaient essentielles  au développement du logiciel protoype qui servira à mesurer le volume du tissu adipeux par échographie. La première revue de littérature a comme but de standardiser la mesure du tissue adipeux abdominal par échographie. Le but de la deuxième revue de littérature est de comparer les différentes méthodes décrites pour mesurer le tissu adipeux dans le domaine de la chirurgie reconstructive. Finalement, le but de la troisième revue de littérature est de comparer les différentes méthodes décrites pour mesurer le tissu adipeux durant la liposuccion. Dans la deuxième partie de notre projet (projet pilote en cours), notre laboratoire a développé un prototype pour la mesure du tissu adipeux avec le logiciel ''Rhinocerus 5.0 spatial reconstruction software (McNeel North America, Seattle, WA) ''. Résultats: Afin de développer une approche standardisée, les techniques d'échographie les plus fiables et communes ont été analysées dans la première revue de littérature. Les paramètres suivants ont été analysés : le type de mesure, la marque et le modèle de la machine, la fréquence du transducteur, les repères anatomiques externes et internes, la pression transmise par la sonde, les techniques spéciales (inspiration, position etc.) et la reproductibilité. Les diverses méthodes de quantification objective de lambeaux libres ont été analysées et résumées dans la deuxième revue de littérature. Le volume des lambeaux libres a été calculé à l'aide des méthodes suivantes : imagerie par résonance magnétique, tomodensitométrie, modélisation tridimensionnelle, modèles physiques, échographie, et diverses échelles. Les diverses méthodes de quantification objective de tissu graisseux suite à la liposuccion ont été analysées et résumées dans la troisième revue de littérature. L'information ci-haut a été essentielle pour le développement et la validation du prototype ayant comme but de quantifier le tissu adipeux de la liposuccion et des lambeaux libres.Conclusion : Les résultats préliminaires confirment que la modélisation tridimensionnelle et la quantification objective sont le futur de la chirurgie reconstructive et esthétique. Plus d'études sont nécessaires pour confirmer la pertinence clinique de la quantification objective et des mesures volumétriques automatisées. Les résultats de cette première phase de notre projet serviront comme point de référence afin de développer le premier outil pour mesurer le tissu adipeux par échographie et modélisation tridimensionnelle. </dc:abstract><dc:abstract>Background/hypothesis/objectives: Plastic and Reconstructive surgeons commonly manipulate adipose tissue for reconstructive and cosmetic purposes. When harvesting adipose tissue, there is no practical way of measuring fat volume. Surgeons currently estimate the required volume by tactile sensation (i.e. pinch test). Computed tomography scans and magnetic resonance imaging can potentially be used to measure adipose tissue volume; however, these modalities are both resource and time-consuming. Moreover, they cannot be used intra-operatively. We would like to develop a quick and inexpensive tool to measure patients' fat volume in order to improve procedures that manipulate adipose tissue. Using ultrasound, a readily available and inexpensive modality, the goal is to develop a software that facilitates pre-operative planning with three-dimensional graphic representation. Our main objective is to improve results and decrease complications by implementing intra-operative real-time guidance and immediate feedback. We hypothesize that objective measurement of adipose tissue will result in improved surgical outcomes, decreased donor-site morbidities, and higher patient satisfaction. Methods: The first phase of our project (current thesis) constitutes three extensive literature searches aimed at collecting data for the development of a software that accurately measures abdominal fat volume using ultrasound. The information presented in this thesis was essential for the technological development of the current and future prototypes. The first literature search aims to report techniques of subcutaneous adipose tissue measurement using ultrasound. The second systematic review aims to summarize the available techniques used to objectively measure flap volume in reconstructive surgery. Finally, the third systematic review aims to summarize the available techniques used to objectively measure adipose tissue during liposuction. In the second phase of our project (ongoing pilot project), a prototype was developed for validation of ultrasound quantification in both flap reconstruction and liposuction using the software Rhinocerus 5.0 spatial reconstruction software (McNeel North America, Seattle, WA). Results: To establish a standardized approach, the most consistent and reliable techniques are summarized in the first review. Literature findings related to the following parameters are summarized: type of measurement, ultrasound make/model, transducer frequency, external and internal landmarks, pressure applied on probe, special techniques and inter/intra-observer reliability. Reported methods of objective adipocutaneous flap quantification are summarized in the second review. Flap volume was calculated using the following techniques: magnetic resonance imaging, computed tomography, three-dimensional imaging and modeling, material templates, ultrasound, and weighing scales. Techniques and results of the included studies are summarized. Finally, the third review summarizes reported methods of fat quantification following liposuction. The details of the above reviews were crucial for the development and validation of a prototype for volumetric measurement of adipose tissue designed by our laboratory. Conclusion: The preliminary results are promising, and we believe that three-dimensional representation and objective quantification is the future of reconstructive and cosmetic surgery. More studies are needed to study the clinical relevancy and impact of the various imaging modalities reviewed as well as to develop automated volumetric measurement technology with improved accuracy, efficacy and reproducibility. Using the information gathered in the first phase of our project, we hope to contribute to our specialty by validating the first tool that objectively quantifies fat volume using ultrasound along with computer-assisted three-dimensional and volumetric representation.</dc:abstract><ual:supervisor>Thomas Hemmerling (Internal/Cosupervisor2)</ual:supervisor><ual:supervisor>Miroslav Sergio Gilardino (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/9019s473z.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/ww72bf003</ual:fedora3Handle><dc:subject>Surgery</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ajw827d86q"><dcterms:title>Circumventing static and moving pedestrians while walking in virtual and physical environments</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>School of Physical and Occupational Therapy</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Bühler, Marco</ual:dissertant><dc:abstract>Lorsqu'ils marchent dans la communauté, les individus doivent contourner des objets et autres piétons. Bien que cette habileté soit souvent compromise chez les populations de patients présentant une incapacité physique, son évaluation et son entraînement en milieu clinique ou en laboratoire demeurent difficiles. La réalité virtuelle (RV) est un outil qui permet de reproduire les conditions de la vie réelle tout en permettant aux personnes de se déplacer dans un environnement sécuritaire et contrôlé. Néanmoins, les évidences démontrant que la RV génère des comportements moteurs naturels sont rares et aucune étude n'a spécifiquement examiné le contournement de piétons dans un environnement virtuel (VE) versus physique (PE).Les objectifs du manuscrit 1 étaient d'estimer dans quelle mesure les stratégies d'évitement en réponse aux piétons en mouvement différaient dans un EV par rapport à l'EP et d'examiner l'effet de l'exposition répétée sur les stratégies de contournement. Les participants (n=12) ont été évalués lors du contournement de piétons dans un EP et un EV d'apparences et de dimensions similaires. Une cible bleue se trouvait dans l'espace lointain (8.5m) et trois piétonnes se tenaient à une distance de 6.25m de la position de départ du participant. Lorsque le participant marchait 0.5m vers l'avant, l'une des piétonnes s'approchait du participant soit par la gauche (-40°), le centre (0°) ou la droite (40°). Dans une quatrième condition, aucune des piétonnes n'était présente. Cinq blocs de 8 essais (2×4 conditions, ordre aléatoire) ont été enregistrés dans l'EP et l'EV, dans un ordre aléatoire. Les résultats montrent que les participants utilisent des distances minimales plus grandes (Δ=0.10m) et des vitesses de marche minimales, moyennes et maximales plus lentes (Δ=0.13-0.15m/s) pour contourner les piétons dans l'EV versus l'EP. Pendant toute la séance d'expérimentation, une exposition répétée a entraîné une augmentation de la vitesse moyenne de marche (0.09m/s) similaire entre les environnements.Les objectifs du manuscrit 2 étaient d'estimer dans quelle mesure le contournement d'un piéton statique différait dans l'EV et l'EP, et de comparer la variabilité inter-essai des résultats de contournement d'obstacles entre les environnements. Les participants (n=13) ont été évalués dans le même EV et EP que dans le manuscrit 1, tout en évitant une collaboratrice stationnaire qui se trouvait aléatoirement à 3m ou 3.5m de la position de départ du participant. Les essais avec une interférence stationnaire ont été entrecoupés d'essais contrôles où la collaboratrice se déplaçait sur le côté dès que le participant marchait 0.5m. Une augmentation de la distance minimale (Δ=0.10m), de la distance minimale du corps entier (Δ=0.10m) et de la déviation latérale maximale (Δ=0.12m), ainsi qu'une réduction de la vitesse minimale, moyenne et maximale (Δ=0.17m/s pour tous les résultats de vitesse) ont été observées dans l'EV en comparaison avec l'EP. De plus, la variabilité des résultats entre les essais mentionnés ci-dessus était similaire entre les deux environnements.Les résultats suggèrent que la RV favorise l'utilisation de stratégies de contournement «plus sécuritaires» par rapport à l'EP, qui se caractérisent par de plus grandes distances d'évitement et une marche plus lente. Le fait que l'exposition répétée à l'EV n'ait pas atténué les différences de stratégies de contournement entre l'EV et l'EP peut être expliqué par la familiarité des participants avec l'EP avant l'expérimentation, laquelle a pu permettre une recalibration de la perception de l'EV. Les résultats de cette thèse suggèrent que la RV a un grand potentiel en recherche et comme outil de réadaptation. La RV offre une alternative écologique, sécuritaire et contrôlée aux expériences menées dans le monde réel pour approfondir les mécanismes de contrôle locomoteur, ainsi que pour évaluer ou entraîner des tâches locomotrices complexes telles que le contournement de  piétons.</dc:abstract><dc:abstract>As they walk in the community, individuals are required to circumvent objects and other pedestrians. While obstacle circumvention is often compromised in patient populations with physical disability, its assessment and training in the clinical or laboratory setting remain challenging. Virtual reality (VR) is a tool which allows replicating real-life conditions while having the participants moving in a safe and controlled environment, and which could be used to assess or train obstacle circumvention. However, evidence supporting the assumption that VR generates natural motor behaviors is scarce and no studies have specifically examined the circumvention of moving pedestrians in a virtual (VE) vs. physical environment (PE).In Manuscript 1 of this thesis, objectives were to estimate the extent to which avoidance strategies in response to approaching pedestrians differed in a VE vs. PE and to examine the effects of repeated exposure to the obstacle circumvention task. Participants (n=12) were assessed on an obstacle circumvention task performed in a PE and a VE of similar appearance and dimension as they walked towards a blue target (8.5m). Three female collaborators, acting as interferers, stood in an arc fashion (6.25m). As the participant reached 0.5m of forward displacement, one of the interferers approached the participant from either the left (-40°), middle (0°) or right (40°), while the others moved away. In a fourth condition, all interferers went away. Five experimental blocks comprising of 8 trials (2×4 obstacle conditions) were recorded in each environment. The presentation order of environments and trials was randomized. In the VE, participants used larger minimum distances (∆=0.10m) and slower minimum, average and maximum walking speeds (∆=0.13–0.15 m/s) when circumventing the moving pedestrians. Over the entire session, repeated exposure resulted in an increment in average walking speed (0.09m/s) that was similar between the VE and PE.In Manuscript 2, objectives were to estimate the extent to which the circumvention of a static pedestrian differed in the VE vs. the PE and to compare inter-trial variability of obstacle circumvention outcomes. Participants (n=13) were assessed in the same VE and PE as in Manuscript 1 but while avoiding a stationary interferer that randomly stood at 3m or 3.5m from the participant. Trials with a stationary interferer were interspersed with catch trials where the interferer exited the volume to the side as soon as the participant reached 0.5m of forward displacement. An increase in minimum distance (∆=0.10m), full body minimum distance (∆=0.10m) and maximum lateral deviation (∆=0.12m) as well as a reduction in minimum, average and maximum walking speed (∆=0.17m/s) were observed in the VE. Furthermore, the inter-trial variability of above mentioned outcomes was similar between the two environments.Results suggest that VR elicit "safer" circumvention strategies, characterized by larger obstacle clearances and slower walking speeds. Repeated exposure to VE failed to alleviate the differences between the VE and PE and resulted in similar adaptations in both environments. The latter findings could be due to the participants being familiar with the PE prior to testing (that identically replicated the VE), which might have allowed for a perception recalibration in the VE. Collectively, results of this thesis suggest that VR has a great potential for research and as a rehabilitation tool, as it provides an ecologically-valid, safe and well-controlled alternative to real-world experiments and clinical tools to further investigate locomotor control mechanisms as well as to assess or train complex locomotor tasks such as pedestrian circumvention.</dc:abstract><ual:supervisor>Anouk Lamontagne (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/p8418q48p.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/jw827d86q</ual:fedora3Handle><dc:subject>Physical &amp; Occupational Therapy</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Acj82k949t"><dcterms:title>Impact of bile acid malabsorption on unfolded protein response status in the hearts of Fabp6-deficient mice fed the Western-style diet</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>School of Human Nutrition</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Salavi Tabar, Simindokht</ual:dissertant><dc:abstract>Contexte : La diète occidentale, communément appelé 'Western-style diet (WD)', augmente les risques de développer des maladies métaboliques telles que les maladies cardiovasculaires, les maladies du foie, l'obésité et le diabète en raison de sa teneur élevée en graisses saturées et sucre raffiné. En outre, l'acide palmitique, un acide gras saturé qui constitue une partie substantielle des gras saturés dans l'alimentation occidentale, est un inducteur puissant de stress causé par le réticulum endoplasmique (RE). Le RE est une organelle cellulaire clé impliquée dans de nombreuses fonctions cellulaires. La perte de l'énergie cellulaire et de l'homéostasie des nutriments perturbe la fonction du RE et entraîne, par la suite, un RE stressé. Un mécanisme d'adaptation au stress cellulaire, aussi appelé la réponse protéique dépliée (Unfolded Protein Response, UPR, en anglais), est activé pour rétablir l'homéostasie du RE. Cependant, l'activité prolongée de l'UPR est préjudiciable à la fonction métabolique cellulaire globale et provoque finalement, des maladies métaboliques acquises. La protéine de liaison aux acides gras 6 (Fabp6) est une protéine cytoplasmique présente dans les entérocytes de l'iléon et qui lie les acides biliaires étant nécessaires à l'absorption des graisses alimentaires. Les souris déficientes en Fabp6 et nourries par la diète occidentale démontrent une malabsorption des acides biliaire et dont l'excès de gras fourni par l'alimentation ne peut pas être efficacement absorbé.Objectifs: Le but de cette étude est d'étudier l'impact de la malabsorption des graisses suite à la malabsorption des acides biliaires sur le statut de l' UPR cardiaque chez des souris déficientes en Fabp6 nourries à la diète Western. Méthodes: Les souris Fabp6+/+ et Fabp6-/- (mâles et femelles, n = 3-5 chacune) appariées selon l'âge et le sexe recevaient soit le régime pauvre en graisses (LD) (13% de matières grasses) soit la WD (41% de matières grasses). Après dix semaines, les souris ont été évaluées7pour les lipides plasmatiques. Les marqueurs UPR (sXBP1, ATF4, CHOP, GRP78, PERK) ont été mesurés par PCR quantitative (qPCR) afin de déterminer l'état de la UPR cardiaque. Résultats: Les deux sexes de souris Fabp6-/- nourries avec la WD n'ont montré aucune différence dans la concentration de triacylglycérols comparativement aux LD. Les mâles déficients en Fabp6 sur WD ont montré une hypercholestérolémie, contrairement aux femelles du même génotype recevant la même diète, mais n'ayant montré aucune différence. L'abondance de l'ARNm de sXBP1, l'indicateur de l'activation de la voie IRE1, était élevée seulement chez les souris mâles de type sauvage nourries par WD, tandis que les marqueurs de la voie PERK (ATF4, CHOP) ont augmenté significativement chez les souris Fabp6-/- et Fabp6+/+ du même régime par rapport à la LD. Des augmentations significatives de l'ARNm ATF4, CHOP et PERK ont été observées entre les souris Fabp6-/- et Fabp6+/+ nourries avec WD chez les deux sexes. Indépendamment des génotypes et du sexe, les souris sur WD présentaient un l'ARNm de GRP78 élevé par rapport à LD. Conclusion: Cette étude montre que la malabsorption des graisses due à la malabsorption des acides biliaires ne protège pas les coeurs des souris Fabp6-/- contre les WD de l'activation de l'UPR. Une différence de sexe a été observée quant à la sensibilité de l'activation de l'UPR cardiaque, notamment la voie cardiaque UPR chez les femelles était plus sensible à WD que chez les mâles.</dc:abstract><dc:abstract>Background: Long-term Western-style diet (WD) consumption increases the chance of developing acquired metabolic diseases such as cardiovascular disease, liver disease, obesity and diabetes due to its high saturated fat and refined carbohydrate content. In addition, palmitic acid, a saturated fatty acid that makes up a substantial portion of saturated fats in the WD, is a potent inducer of endoplasmic reticulum (ER) stress. The ER is a key cell organelle involved in many cellular functions. Loss of cellular energy and/or nutrient homeostasis disturbs ER function and leads to ER stress. A cellular stress coping mechanism called the unfolded protein response (UPR) is activated to re-establish ER homeostasis. However, prolonged UPR activity is detrimental to overall cellular metabolic function and eventually causes acquired metabolic disease. The fatty acid binding protein 6 (Fabp6) is a cytoplasmic protein found in ileal enterocytes and binds bile acids. Fabp6 is needed for absorption of dietary fat. Fabp6-deficient mice exhibited bile acid malabsorption, and thus excess dietary fat provided by the WD may not be efficiently absorbed by Fabp6-deficient mice fed this diet. Objectives: The aim of this study is to investigate the impact of fat malabsorption due to bile acid malabsorption on cardiac UPR status in Fabp6-deficient mice fed the WD. Methods: Fabp6+/+ and Fabp6-/- mice (males and females, n=3-5 each) matched by age and sex were fed either the Low-fat diet (LD) (13 % fat) or the WD (41 % fat). After ten weeks, mice were assessed for plasma lipids. UPR markers (sXBP1, ATF4, CHOP, GRP78, PERK) were measured by quantitative PCR (qPCR) in order to determine cardiac UPR status. Results: Both sexes of Fabp6-/- mice receiving WD displayed no difference in triacylglycerol concentration compared to LD. Fabp6-deficient male mice, but not female, on WD showed hypercholesterolemia. sXBP1 mRNA abundance, the indicator of IRE1 pathway activation,5was elevated only in the hearts of wild-type male mice fed the WD, while markers of the PERK pathway (ATF4, CHOP) were higher in both Fabp6-/- and Fabp6+/+ mice on the same diet in comparison with LD. The WD induced significant increments in abundance of mRNA encoding ATF4, CHOP, and PERK in the hearts of Fabp6-/- mice compared to Fabp6+/+ mice of both sexes. Independent of genotype and sex, mice on WD exhibited high cardiac GRP78 mRNA relative to LD. Conclusion: This study shows that fat malabsorption due to bile acid malabsorption did not protect the hearts of Fabp6-/- mice on WD from UPR activation. There was a sex difference in sensitivity of cardiac UPR activation; cardiac UPR pathway in the female was more sensitive to WD than that in the male.</dc:abstract><ual:supervisor>Luis Agellon (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/bk128d22s.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/cj82k949t</ual:fedora3Handle><dc:subject>Human Nutrition</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ak643b333q"><dcterms:title>Assessment of the role of spinal mGluR5 and associated anchoring proteins in nociception</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Integrated Program in Neuroscience</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Gill, Nitasha</ual:dissertant><dc:abstract>Les patients souffrant de douleur neuropathique chronique ne bénéficient pas d'un soulagement adéquat de la douleur avec les options de traitement actuellement disponibles, et il y a donc un besoin considérable de mieux comprendre la signalisation nociceptive de la douleur neuropathique sous-jacente. Le récepteur 5 du glutamate métabolotrope (mGluR5) est un récepteur couplé à la protéine G dans la moelle épinière qui joue un rôle important dans la nociception. Des résultats récents ont révélé qu'il existe deux pools de mGluR5 fonctionnels - à la membrane plasmique et sur les membranes nucléaires. En fait, c'est la membrane nucléaire mGluR5 qui semble jouer un rôle plus important dans la douleur persistante. On a observé une augmentation significative du mGluR5 dans les fractions enrichies en énergie nucléaire des rats épargnés par des lésions nerveuses (SNI) par rapport aux shams. L'inhibition des récepteurs intracellulaires, et non des récepteurs de la membrane plasmique, a atténué les comportements douloureux induits par le glutamate, ou l'allodynie observée chez le rat SNI. Actuellement, l'augmentation du mGluR5 de la membrane nucléaire reste inexpliquée. Cependant, elle peut être due à l'action du trafic de protéines, à savoir la famille Homer 1. Homer 1b/c scaffold mGluR5 dans un complexe de signalisation pour faciliter la signalisation à médiation mGluR5, tandis que Homer 1a est régulé par la transcription et perturbe ce complexe, permettant à mGluR5 de diffuser à un autre endroit. Un peptide leurre synthétique court, Tat-mGluR5ct, imite les actions d'Homère 1a. Cette étude visait à déterminer si Homer 1a était responsable du trafic du mGluR5 vers les membranes nucléaires. Tout d'abord, nous avons examiné l'expression d'Homère 1b/c et Homère 1a 4 et 24 heures après le SNI et la chirurgie simulée, où nous n'avons trouvé aucun changement significatif. Deuxièmement, nous avons évalué les effets du Tat-mGluR5ct sur les comportements nociceptifs soutenus induits par le quisqualate et avons constaté une tendance pour le Tat-mGluR5ct à atténuer les comportements de douleur. Enfin, nous avons constaté que Tat-mGluR5ct n'a pas affecté l'expression de mGluR5 dans aucune fraction sous-cellulaire 30 minutes, 24 et 48 heures après l'administration spinale. Cependant, Tat-mGluR5ct a été capable d'atténuer significativement l'allodynie mécanique chez les rats SNI à 3 et 24 heures après l'administration spinale. Pris ensemble, ces résultats suggèrent que Homère 1a ne traite pas le mGluR5 in vivo, mais qu'il joue un rôle dans la modulation de la signalisation à médiation mGluR5. </dc:abstract><dc:abstract>Chronic neuropathic pain patients do not experience adequate pain relief with currently available treatment options, and so there is a considerable need to better understand nociceptive signaling underlying neuropathic pain. Metabotropic glutamate receptor 5 (mGluR5) is a G protein-coupled receptor (GPCR) in the spinal cord that is known to play a significant role in nociception. Recent studies revealed that there are two pools of functional mGluR5 – at the plasma membrane and on nuclear membranes. In fact, it is nuclear membrane mGluR5 that seem to play a more important role in persistent pain. There was a significant increase in mGluR5 in nuclear-enriched fractions of spared nerve injury (SNI) rats relative to shams. Inhibiting the intracellular receptors, and not the plasma membrane receptors, attenuated glutamate-induced pain behaviours, as well as allodynia in SNI rats. Currently, the increase in nuclear membrane mGluR5 remains unexplained. However, it may be due to the actions of trafficking proteins, namely the Homer 1 family. Homer 1b/c scaffolds mGluR5 in a signaling complex to facilitate mGluR5-mediated signaling, whereas Homer 1a is transcriptionally upregulated and disrupts this complex, allowing mGluR5 to diffuse to a different location. A short, synthetic decoy peptide, Tat-mGluR5ct, mimics the actions of Homer 1a. This study aimed to determine whether Homer 1a was responsible for mGluR5 trafficking to nuclear membranes. Firstly, we looked at Homer 1b/c and Homer 1a expression 4 and 24 hours after SNI and sham surgery, where we found no significant changes. Secondly, we assessed the effects of Tat-mGluR5ct on quisqualate-induced sustained nociceptive behaviours and found a trend for Tat-mGluR5ct to attenuate pain behaviours. Lastly, we found that Tat-mGluR5ct did not affect mGluR5 expression in any subcellular fraction 30 minutes, 24 and 48 hours after spinal administration. However, Tat-mGluR5ct was able to significantly attenuate mechanical allodynia in SNI rats at 2 to 24 hours after spinal administration. Taken together, these results suggest that Homer 1a does not traffic mGluR5 in vivo, but does play a role in modulating mGluR5-mediated signaling. </dc:abstract><ual:supervisor>Terence Coderre (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/sx61dp61b.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/k643b333q</ual:fedora3Handle><dc:subject>Neuroscience</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Arv042w186"><dcterms:title>Neural-based traffic risk assessment: a two-stream neural network approach using dynamic attention</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Corcoran, Gary</ual:dissertant><dc:abstract>The problem being addressed in this research is performing traffic risk assessment on visual scenes captured from outward-facing dashcam videos. To perform risk assessment, a two-stream dynamic-attention recurrent convolutional neural architecture is used to provide a risk level for every frame in a given input video sequence. The two-stream approach consists of a spatial stream, which analyses individual video frames and computes high-level appearance features and a temporal stream, which analyses optical flow between adjacent frames and computes high-level motion features. Both spatial and temporal streams are then fed into their respective recurrent neural networks (RNNs) that explicitly models the sequence of features in time. A dynamic-attention mechanism that allows the network to learn to focus on relevant objects in the visual scene is added. These objects are detected by a state-of-the-art object detector and correspond to vehicles, pedestrians, traffic signs, etc. The dynamic-attention mechanism not only improves classification performance, but it also provides a method to visualize what the network "sees" when predicting a risk level. This mechanism allows the network to implicitly learn to focus on hazardous objects in the visual scene. Additionally, this research introduces an offline and online model that differ slightly in their implementations. The offline model takes as input the complete video sequence and scores a classification accuracy of 84.89%. The online model can deal with an infinite stream of data and produces results in real-time; however, it suffers from a slight decrease in classification accuracy 79.90%.The input data consists of outward-facing dashcam videos in various driving situations. The dataset being used is a selection of 1750 dashcam videos collected by Chan et al. [6]. The dataset was previously annotated with positive and negative instances of vehicle accidents; however, this research proposes a new set of annotations. Each video sequence is densely annotated with a risk level corresponding to the amount of perceived risk in the visual scene. These videos were collectively annotated among a group of participants who annotated each individual frame. The average score across all participants was used as the final risk level. The four categories of risk are as follows: low risk, moderate risk, high risk, and critical risk.</dc:abstract><dc:abstract>La problématique abordée dans cette recherche est l'évaluation des risques de la circulation à partir de vidéos capturées par une caméra montée sur l'avant d'un véhicule (dashcam). Pour effectuer une évaluation des risques, un double flux d'attention dynamique basé sur un réseau neuronal de convolutions récurrentes est utilisé afin de fournir un niveau de risque pour chaque image dans une séquence vidéo donnée. L'approche à deux flux consiste d'abord en un flux spatial qui analyse les images vidéo prises individuellement et analyse les caractéristiques d'apparence à haut niveau et d'un flux temporel qui analyse les trames adjacentes et calcule les caractéristiques de mouvement à haut niveau. Les flux spatiaux et temporels sont ensuite introduits dans leurs réseaux neuronaux récurrents respectifs (RNN) qui modélisent explicitement la séquence des caractéristiques dans le temps. Un mécanisme d'attention dynamique est ajouté, ce qui permet au réseau d'apprendre à se concentrer sur les objets pertinents de la séquence vidéo. Ces objets sont détectés par un détecteur d'objets dernier cri et correspondent à des véhicules, des piétons, des panneaux de signalisation, etc. Le mécanisme d'attention dynamique améliore non seulement les performances de classification, mais permet aussi de visualiser ce que le réseau perçoit et ainsi prédire un niveau de risque. Ce mécanisme permet au réseau d'apprendre implicitement à se concentrer sur les objets dangereux dans la séquence vidéo. De plus, cette recherche introduit un modèle hors ligne ainsi qu'un modèle en ligne qui diffèrent légèrement dans leurs implémentations. Le modèle hors ligne prend en entrée la séquence vidéo complète et obtient ainsi une précision de classification de 84,89%. Le modèle en ligne peut traiter un flux infini de données et produit des résultats en temps réel, mais subit une légère baisse de performance 79,90%.Les données d'entrée consistent en des vidéos orientées vers l'avant du véhicule dans diverses situations de conduite. L'ensemble de données utilisé est une sélection de 1750 vidéos dashcam collectées par Chan et al. [6]. L'ensemble de données a déjà été annoté avec des exemples positifs et négatifs d'accidents de véhicules. Cette recherche propose cependant un nouvel ensemble d'annotations. Chaque séquence vidéo est densément annotée avec un niveau de risque correspondant à la quantité de risque dans la séquence vidéo. Chaque vidéo a été annotée trame par trame par les membres d'un groupe de participants. Le score moyen de dangerosité donné par l'ensemble des participants a été utilisé comme niveau de risque final. Les quatre catégories de risque sont: risque faible, risque modéré, risque élevé et risque critique.</dc:abstract><ual:supervisor>James J Clark (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/ht24wm46r.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/rv042w186</ual:fedora3Handle><dc:subject>Electrical and Computer Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ax633f359m"><dcterms:title>Towards a better implementation of accessibility indicators in land use and transport planning practice</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>School of Urban Planning</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Boisjoly, Genevieve</ual:dissertant><dc:abstract>In order to address the shortcomings of mobility-centered transport planning, planning for accessibility is increasingly considered as an essential complementary approach. This approach aims to provide reasonable access to destinations (employment centers, amenities, social and health services, etc.) to the entire population instead of prioritizing the optimization of travel times. Although a large body of literature has explored how to conceptualize and measure accessibility, research on how to incorporate accessibility in transport planning is scarce. Knowing that accessibility is currently marginalized in transport planning, the overarching goal of this dissertation is to contribute to the implementation of accessibility measures in land use and transport planning practice, by answering the following research question: How can accessibility measures be incorporated into current land use and transport planning practice in order to improve our understanding of the performance of land use and transport systems?To answer this question, the following objectives will be pursued: 1. To determine how accessibility is used in land use and transport planning practice; 2. To identify appropriate measures of accessibility to be used in land use and transport planning practice; 3. To generate measures of accessibility in a data-challenging context in collaboration with local transport planners. To reach these objectives, this dissertation follows a manuscript-based approach, with four studies building on one another. Collectively, these manuscripts address both the planning and research realms of transport planning through a multifaceted approach.Through an analysis of 32 metropolitan transport plans around the world, the first study reveals that, while the concept of accessibility is considered in most planning documents, it is rarely translated into goals and indicators that reflect the ease of reaching destinations. The findings of the first study are strengthened by a second study surveying 343 practitioners about accessibility. The results of the study demonstrate that most practitioners, although aware of the concept of accessibility, do not consider the ease of reaching destinations in their work. In addition, the results identify two main barriers to the implementation of accessibility indicators: lack of knowledge and lack of data. In light of the knowledge and data barriers, the third study assesses the usability of various accessibility measures from a planning perspective. Three measures of accessibility to jobs by public transport in the Greater Toronto and Hamilton Region are generated and assessed through a mode share regression model. The study concludes that the simplest measure – the number of jobs that can be reached within 45 minutes of travel at 8 am – is the most adequate to assess the performance of land use and transport systems at the regional level. Using the measure identified in the above study, the last study conducts an equity assessment of public transport services in four large metropolitan areas in Brazil. The study, led in a data-challenging context, proposes a methodology that can be easily applied by any transport agencies and illustrates the relevance of the accessibility indicators to inform planning processes. Conducted in collaboration with local transport planners, the study also contributes to an enhanced collaboration between research and planning. Overall, this dissertation presents a set of complementary studies to bridge the gap between research and practice and better understand how accessibility indicators can be incorporated into current land use and transport planning practice. This dissertation demonstrates the importance of carefully and critically thinking about how to include accessibility indicators in practice, be it with respect to how it is defined or how it is measured, and about how research can better contribute to the current challenges faced by professionals.</dc:abstract><dc:abstract>Afin de répondre aux lacunes d'une approche centrée sur la mobilité, la planification centrée sur l'accessibilité est de plus en plus considérée comme une approche essentielle à la planification des transports. Cette planification vise à s'assurer que l'ensemble de la population ait un accès raisonnable aux destinations urbaines, plutôt que de privilégier l'optimisation des temps de déplacements. Si de nombreuses études ont exploré comment conceptualiser et mesurer l'accessibilité, la littérature portant sur l'intégration de l'accessibilité dans la planification des transports se fait plus rare. Sachant que l'accessibilité est actuellement marginalisée dans la pratique, cette thèse vise à contribuer à la mise en œuvre des mesures d'accessibilité dans la planification des transports et de l'aménagement du territoire, en répondant à la question suivante : Comment les mesures d'accessibilité peuvent-elles être intégrée dans la planification des transports et de l'aménagement du territoire afin d'améliorer notre compréhension de la performance de ceux-ci ? Afin de répondre à cette question, les objectifs suivants sont mis de l'avant : 1. Déterminer de quelle façon l'accessibilité est considérée dans la planification des transports et de l'aménagement du territoire ; 2. Identifier des mesures appropriées d'accessibilité pour la planification des transports et de l'aménagement du territoire ; 3. Générer des mesures d'accessibilité en collaboration avec des professionnels en transport dans un contexte où les données sont limitées. Ces trois objectifs de recherche sont réalisés par le biais d'une série de quatre études qui s'appuient les unes sur les autres, considérant autant le domaine de la recherche que celui de la planification.La première étude analyse 32 plans de transport et démontre que, bien que le concept d'accessibilité soit présent dans la plupart des plans, celui-ci se traduit rarement par des indicateurs reflétant la facilité d'accéder aux destinations. Les résultats de cette première étude sont renforcés par une seconde étude ayant sondé 343 professionnels en transport à propos de l'accessibilité. Cette étude démontre que la plupart des professionnels, bien qu'ils soient familiers avec le concept d'accessibilité, ne considèrent pas la facilité d'accéder aux destinations dans leur travail. De plus, l'analyse des résultats révèlent deux barrières principales à l'utilisation d'indicateurs d'accessibilité : le manque de connaissances et le manque de données. À la lumière des barrières identifiées ci-dessus, la troisième étude compare l'utilité, pour la planification des transports, de différentes mesures d'accessibilité. L'étude conclut que la mesure la plus simple – le nombre d'emplois accessibles en moins de 45 minutes à 8h – est la mesure la plus adéquate pour évaluer la performance des systèmes de transport et d'aménagement du territoire au niveau métropolitain. À l'aide de cette mesure, la dernière étude réalise une analyse de l'équité des transports en commun dans quatre régions métropolitaines au Brésil, illustrant ainsi la pertinence des indicateurs d'accessibilité pour informer la planification des transports et de l'aménagement du. Cette étude contribue aussi à une meilleure collaboration entre chercheurs et professionnels, ayant été réalisée en collaboration avec des professionnels en transport.En conclusion, cette thèse propose une série d'études complémentaires visant à combler l'écart entre la recherche et la pratique afin de mieux comprendre comment les indicateurs d'accessibilité peuvent être intégrés dans la planification des transports et de l'aménagement du territoire. Elle démontre ainsi l'importance de se questionner sur comment inclure l'accessibilité dans la planification des transports, que ce soit par rapport à sa définition ou à son opérationnalisation en pratique, et de comment la recherche peut contribuer de façon plus significative aux enjeux auxquels les professionnels font face.</dc:abstract><ual:supervisor>Elgeneidy, Ahmed (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/5d86p256c.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/x633f359m</ual:fedora3Handle><dc:subject>Urban Planning</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Arn301364q"><dcterms:title>V1 neurons sense eye movements during smooth pursuit</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Integrated Program in Neuroscience</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Shao, Jie</ual:dissertant><dc:abstract>La fonction du cortex visuel primaire (V1) a été largement étudié grâce à des enregistrements électrophysiologiques pendant des conditions visuelles passives. Au cours des dernières années, l'importance d'étudier les fonctions de V1 durant la perception visuelle active a été reconnue. Notamment, les études électrophysiologiques chez le primate ont démontré que le traitement des stimuli visuels dans V1 était modulé lors des mouvements de saccade oculaire. Cependant, à ce jour, la réponse neuronale de V1 à d'autres classes de mouvements oculaires, tel que la poursuite, demeure mal compris. Dans cette thèse, une nouvelle méthodologie expérimentale a été utilisée pour étudier la réponse neurale de V1 lors d'un mouvement de poursuite avec un stimulus visuel (que se soit un mouvement des yeux seul ou une combinaison des yeux et de la tête). Un singe cynomolgus a été entrainé à faire des mouvements de poursuite horizontal génères par la fixation d'une cible ayant une trajectoire en saut de rampe (0, 20°/s, 40°/s, 60°/s). Simultanément, l'activité neuronale de V1 était enregistrée en réponse a un stimulus visuel représentant un grillage se déplaçant dans le champ réceptif du neurone. Dans le but d'éviter un décalage entre la vitesse des yeux et du stimulus visuel, la position de ce dernier était ajustée en ligne en fonction de la position des yeux et ce, avec un échantillonnage de 60Hz. De cette façon le stimulus restait stable a l'intérieur du champ réceptif du neurone. Les résultats ont démontré une suppression initiale de la réponse neurale autour de 100 à 200ms suivit d'une augmentation entre 200 et 350ms après le début du stimulus lorsque le singe exécutait une poursuite oculaire. La suppression initiale était atteinte plus tôt pour la vitesse de poursuite oculaire la plus rapide (i.e., 60°/s). Cependant, l'occurrence de l'augmentation de la réponse demeurait inchangée indépendamment des vitesses de poursuite. De plus, les résultats suggèrent que les neurones de V1 signalent l'initiation des mouvements de tête tel que démontré par la réponse neuronale lors des mouvements de poursuit requérant un mouvement coordonné des yeux et de la tête. Dans leur ensemble, ces résultats ont révélé que les mouvements de poursuite provoquent une modulation du traitement visuel de V1, ce qui suggère une combinaison des informations extra-rétiniennes des mouvements des yeux et de la tête dans le but de maintenir une perception du monde stable.</dc:abstract><dc:abstract>The function of the primary visual cortex (V1) has been extensively explored by electrophysiological recordings under passive viewing conditions. In recent years, the importance of exploring V1 function during active visual perception has been increasingly recognized. Notably, electrophysiological studies from awake behaving primates have demonstrated that visual stimulus processing in V1 is modulated by saccadic (rapid) eye movements. However, to date, we have a poor understanding of V1 neuronal responses in the context of other voluntary gaze movements, for instance, smooth pursuit gaze movements. In this thesis, a novel experimental design was used to investigate V1 neural response to a visual stimulus during smooth pursuit gaze movement (either by eye pursuit alone or by a combination of eye and head pursuit). A cynomolgus monkey was trained to actively perform horizontal smooth pursuit elicited by step-ramp target trajectories (0, 20°/s, 40°/s, 60°/s) of a fixation target, while single V1 neuronal responses were recorded in response to a drifting grating stimulus in the neuron's receptive field. To prevent a velocity mismatch between gaze pursuit and the visual stimulus, the position of the stimulus was adjusted online in a frame-based manner (60 Hz) according to the on-going gaze position, so as to keep the stimulus stabilized within the neuron's receptive field. The results revealed that, in conditions where the monkey generated smooth pursuit eye movements, neural responses exhibited an initial suppression around 100 – 200ms followed by an enhancement between 200 – 350ms, after stimulus onset. The initial suppression produced by smooth pursuit eye movement was reached earlier for the highest tracking velocity (i.e., 60°/s). In contrast, the timing of the subsequent enhancement did not change across pursuit velocities. Furthermore, the results also provide evidence that V1 neurons may signal the onset of head movement - V1 neurons demonstrated a response for the initiation of head motion during coordinated eye and head pursuit movement. Taken together, these results have revealed a clear modulatory effect on V1 visual processing from smooth pursuit gaze movement, suggesting that the visual system combines extra-retinal information about both eye and head movement to help maintain a perceptually stable world.</dc:abstract><ual:supervisor>Kathleen E Cullen (Supervisor1)</ual:supervisor><ual:supervisor>Curtis L Baker (Supervisor2)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/z029p692t.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/rn301364q</ual:fedora3Handle><dc:subject>Neuroscience</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A3x816p72b"><dcterms:title>Dynamic adaptation of peasant livelihoods to river capture in the Peruvian Amazon</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of Geography</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Wustenberg, Lauren</ual:dissertant><dc:abstract>Les moyens de subsistance des populations paysannes d'Amazonie réflètent fortement les caractéristiques uniques de l'environnement biophysique local.  Les études précédentes s'attardaient principalement à comprendre comment les moyens de subsistance des populations paysannes d'Amazonie s'adaptaient aux environnements en marge des cours d'eau (soit les terrasses bordant les rivières ou leur rivage inondable), que ces biotopes soient associés à des rivières riches en nutriments (rivières à « eaux blanches ») ou à celles aux eaux plus acides et pauvres en nutriments (rivières à « eaux noires »). L'adaptation des pratiques des résidents aux changements dynamiques dans l'environnement fluvial (tels les avulsions, captures ou migrations rapides des tracés) demeurait toutefois sous-étudiée. En 1989, la capture de la portion inférieure de la rivière Tahuayo (cours d'eau à « eaux noires ») par la rivière Amazone (cours d'eau à « eaux blanches ») nous a procuré la possibilité unique d'étudier l'adaptation des moyens de subsistance des paysans à un changement environnemental rapide et significatif. Avant la capture de la rivière, une enquête auprès des ménages avait permis de recueillir des données de nature démographique, ainsi que sur la production agricole, les pratiques de chasse et de pêche, la propriété foncière et la propriété d'actifs non fonciers. Après la capture de 1989, une enquête à l'échelle des ménages a été répétée à cinq reprises au cours de la période de 1989 à 2015, au sein de neuf communautés, procurant ainsi une base d'informations quantitatives très riche sur les pratiques de subsistance et leur adaptation aux changement biophysiques de l'environnement riverain. De plus, afin de mieux comprendre le contexte au sein duquel les moyens de subsistance changeaient, l'auteure de cette étude a passé une saison sur le terrain afin d'y mener des entretiens de groupe (n=11) et des entretiens individuels semi-dirigés (n=37) avec des résidents ayant habité la région depuis avant la capture de rivière de 1989. Une analyse descriptive et statistique des données qualitatives et quantitatives recueillies rend compte des risques et opportunités variés auxquels les résidents de ce paysage en mutation ont fait face. En identifiant les principaux facteurs qui distinguent les bilans de développement entre les communautés ainsi qu'entre les ménages au sein des communautés, nous pouvons mieux comprendre comment les populations paysannes d'Amazonie s'adaptent et bénéficient des changements à leur environnement biophysique, aux marchés régionaux et aux programmes sociopolitiques nationaux.  </dc:abstract><dc:abstract>The livelihoods of Amazonian peasants are often highly dependent on the unique characteristics of the local biophysical environment. Previous studies focus on understanding how Amazonian peasant livelihoods are adapted to upland or riverine environments, whether they be nutrient-rich whitewater rivers or nutrient-poor blackwater rivers. Less is known about how residents adapt practices following dynamic change in their biophysical environment. The 1989 river capture of the lower reach of the blackwater Tahuayo River by the whitewater Amazon River provides a unique opportunity to study livelihood adaptation to environmental change. Before river capture, a census-level household survey collected data on demographics, agricultural production, fishing and hunting practices, land ownership, and non-land household asset ownership. This household survey was repeated five times from 1989 – 2015, providing rich quantitative information on livelihood practices in nine communities over that period. To understand the context in which livelihoods changes, a field season was spent by the author hosting focus group discussions (n=11) and semi-structured interviews (n=37) with residents who had resided there since before the 1989 river capture. Descriptive and statistical analyses of the qualitative and quantitative data illuminate differential risks and opportunities facing residents of this changed and changing landscape. By identifying the main drivers that differentiate the development outcomes across communities, and across households within communities, we can better understand how Amazonian peasants adapt to and benefit from to changes in the biophysical environmental, markets, and sociopolitical programs. </dc:abstract><ual:supervisor>Oliver T Coomes (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/dn39x362j.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/3x816p72b</ual:fedora3Handle><dc:subject>Geography</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A3484zj902"><dcterms:title>A security-constrained unit commitment formulation using the flexibility envelope method</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Antoine, Hugo</ual:dissertant><dc:abstract>The traditional Economic Dispatch and Unit Commitment problem formulations are not able to handle any variability in the load and non-dispatchable generation like solar and wind power. Prior work developed an Economic Dispatch formulation using the concept of flexibility envelopes. The envelope, like the stochastic scenario-based approach, is an approach able to deal with the variability of the load and non-dispatchable generation at minimal computational cost. In this thesis, we first propose a Unit Commitment formulation using the flexibility envelope approach. This formulation takes into account the commitment, start-up and shut-down of dispachable generating units. The main innovation lies with the consideration of the line flows with flexibility envelopes. These line flows are checked in a computationally efficient way that does not require the creation of scenarios. This formulation is then implemented and tested on a small example network. The results show how the flexibility envelope approach can be generalized to the network-constrained case. It provides unit commitment robustness for low computational time.</dc:abstract><dc:abstract>Les formulations traditionnelles de dispatching économique et de programmation de l'arrêt-démarrage des groupes de production ne sont pas en mesure de gérer la variabilité de la charge et des ressources de production renouvelables fluctuantes telles que l'énergie solaire et éolienne. Des travaux récents ont développé une formulation du dispatching économique utilisant le concept des enveloppes de flexibilité. L'enveloppe, comme l'approche par scénarios générés de manière stochastique, est une approche capable de gérer la variabilité de la charge et des énergies fluctuantes. Dans cette thèse, nous proposerons tout d'abord une formulation du problème de programmation de l'arrêt-démarrage des groupes utilisant l'approche de l'enveloppe. Cette formulation prend en compte l'engagement, le démarrage et l'arrêt des unités de production, ainsi que les transits de puissance sur les lignes pour n'importe quel cas au sein de l'enveloppe. Ces flux de puissance sont vérifiés d'une façon qui ne nécessite pas la création de scénarios etéconomise du temps de calcul par rapport à des approches comparables en ce faisant. Cette formulation est ensuite implémentée dans une simulation test basée sur un réseau de trois nœuds. La méthode des enveloppes permet de rendre le réseau plus robuste que ne le ferait un Unit Commitment traditionnel, tout en maintenant des coûts d'opération bas et un temps de calcul raisonnable.</dc:abstract><ual:supervisor>François Bouffard (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/1c18dh90b.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/3484zj902</ual:fedora3Handle><dc:subject>Electrical and Computer Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Afb494b554"><dcterms:title>Réduction des émissions d'oxydes d'azote d'une turbine à gaz aérodérivée</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>fre</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Civil Engineering and Applied Mechanics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Samson, Michel</ual:dissertant><dc:abstract>Nowadays, aeroderivative gas turbines are commonly used for land-based applications such as electrical power generation and mechanical drive. As opposed to jet engines, they are subject to more stringent regulations regarding pollutant emissions. Hence, the original equipment manufacturers (OEM) are challenged to develop pollutant control strategies to deal with these unprecedentedly low emission limit values while trying to maintain, or even improve, current gas turbines performance. This work aimed to reduce the nitrogen oxides (NOx) emissions from an aeroderivative gas turbine developed by Siemens. Such a goal required the homogenization of the air and fuel mixture prior to its combustion which is achieved through optimization of the burner configuration. More specifically, the hole pattern of a perforated plate located in the combustion chamber had to be improved. Therefore, a simplified model of a section of the actual combustor was designed and built to accommodate for a measurement technique called planar laser-induced fluorescence (PLIF). The test rig was sized in function of theoretical calculations, computational fluid dynamics analysis and practical reasons. It has been decided to replace the air and fuel that compose the mixture of interest by water in order to perform nonreacting tests. Furthermore, to achieve optimal similarity between the experimental and real mixing conditions, the test rig must be operated at the engine velocity ratio and at Reynolds numbers above 10,000. A physical access to the interior of the prototype was needed to change the removable parts in between the different experiments. The construction techniques that were used to build the prototype and its support include machining, 3D printing, computer numerical control machining and welding. A hydraulic system was also designed and installed in the experimental facility to feed the test rig. Finally, theoretical recommendations based on a literature review of the topic were made concerning the optimal hole pattern of the perforated plate. It is suggested to use a perforated plate with a solidity of 35%, a thickness of 6 mm, and 41° tapered holes to provide the highest degree of turbulence intensity, and thus the most uniform mixture of air and fuel in terms of homogeneity.</dc:abstract><dc:abstract>De nos jours, les turbines à gaz dérivées des réacteurs d'avion sont couramment employées pour des applications au sol telles que la génération d'électricité et la transmission mécanique. Contrairement à leur prédécesseur, ce type de moteur est sujet à des normes environnementales beaucoup plus strictes en termes de rejets atmosphériques. Ainsi, les fabricants d'équipement d'origine (FEO) sont contraints de mettre au point des technologies permettant une réduction significative des émissions de polluants sans nuire à la performance actuelle des moteurs, voire même en l'améliorant. Ce travail visait à réduire les émissions d'oxydes d'azote (NOx) provenant d'une turbine à gaz aérodérivée qui a été développée par la compagnie Siemens. Cet objectif requérait l'homogénéisation du mélange entre l'air et le combustible avant qu'il ne brûle dans la chambre de combustion. Plus spécifiquement, la configuration des trous d'une plaque perforée qui est située dans le réseau de distribution d'air de cette chambre de combustion devait être optimisée. Un modèle simplifié d'une section du véritable moteur a donc été conçu et bâti pour permettre d'effectuer des expériences à l'aide d'une technique de fluorescence planaire induite par laser (FPIL). Le prototype a été dimensionné en fonction de calculs théoriques, de simulations numériques et de raisons pratiques. Il a été nécessaire d'apporter certaines modifications à sa géométrie pour satisfaire les nombreuses contraintes expérimentales. Le choix de remplacer l'air et le combustible composant le mélange à homogénéiser par de l'eau a été justifié sous conditions que les nombres de Reynolds de l'écoulement produit soient supérieurs à 10,000 et que le ratio de la vitesse des réactants soit respecté. Un accès physique à l'intérieur du prototype était requis pour changer les pièces amovibles entre les différents essais. En somme, les techniques employées pour construire le prototype expérimental et son support incluent l'usinage en atelier, l'impression 3D, l'utilisation d'une machine-outil à commande numérique et la soudure. Un système hydraulique a également été conçu et installé pour alimenter le prototype. Finalement, des recommandations théoriques basées sur une revue littéraire du sujet ont été proposées concernant la configuration optimale des trous de la plaque perforée. Elles suggèrent qu'une plaque perforée de 6 mm d'épaisseur dont la solidité correspond à 35% et comportant des trous de forme conique avec un angle intérieur de 41° offre la plus grande intensité de turbulence, et donc le mélange le plus homogène.</dc:abstract><ual:supervisor>Susan J Gaskin (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/st74cs76q.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/fb494b554</ual:fedora3Handle><dc:subject>Civil Engineering &amp; Applied Mechanics</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A6m311r62m"><dcterms:title>Types of practice and their effect on L2 development: A classroom study</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of Integrated Studies in Education</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Vergara Lavdas, Mélanie</ual:dissertant><dc:abstract>While most researchers agree on the need for practice to develop a skill, one of the most controversial issues that remains unsolved in the field of second language acquisition (SLA) is what constitutes optimal second language (L2) practice for L2 development (DeKeyser, 2017). By drawing on the basic tenets of skill acquisition theory, L2 learning has been understood by some researchers as a process in which learners first acquire declarative knowledge, or factual information of the target language (e.g., morphosyntactic and phonological rules) through instruction, and later develop procedural knowledge that allows learners to use these linguistic rules during production, through opportunities for L2 practice and feedback (DeKeyser &amp; Criado, 2012; Lyster, 2004a; Lyster &amp; Sato, 2013). Indeed, learners in foreign language (FL) contexts typically follow this sequence; first they acquire declarative knowledge and, by drawing on this declarative knowledge repeatedly and consistently, they develop procedural knowledge. However, limited instruction time added to overtly form-oriented, mechanical practice results in learners who struggle to use the target language accurately and fluently in authentic, communicative situations. To quickly access L2 knowledge and use it in spontaneous contexts, a skill that most L2 learners hope to develop, they need to proceduralize the declarative knowledge of target language structures through practice that promotes a communicative use of the L2. This sets two important needs to be addressed by SLA research; (a) to examine the development of procedural knowledge in a classroom setting and (b) to operationalize different types of L2 practice and test their effects on L2 development in the classroom. The present study aimed to contribute to the existing research that applies skill acquisition theory to SLA, by examining the effect of different types of practice on the development of declarative and procedural knowledge in a classroom setting. Three intact Grade 7 classes of EFL learners (N = 70) in Chile participated in this quasi-experimental study, and were assigned to different practice conditions that promoted the use of English third-person singular possessive determiners, his and her, during three stages of three 45-minute lessons each. The first practice condition, noticing-awareness practice, was designed to draw learners' attention to the structures through consciousness-raising tasks without explicitly teaching them any rules. The second practice type, guided practice, shifted learners' attention from meaning to linguistic form to develop accuracy through meaningful yet controlled activities. Finally, autonomous practice provided opportunities to use the linguistic structures in more meaningful, less constrained contexts. While Group A (n = 25) engaged in all three types of practice, Group B (n = 23) engaged only in noticing-awareness and guided practice. Group C (n = 22) engaged only in noticing-awareness practice. Measures of declarative and procedural L2 knowledge revealed that although all groups evidenced increased accuracy in the use of the target structure across time, there was an advantage for the group that received a combination of the three types of L2 practice operationalized in this study. The results suggest that (a) FL learners who engaged in the three types of L2 practice –noticing-awareness, guided, and autonomous practice—developed more declarative and procedural L2 knowledge than learners who only engaged in noticing-awareness practice, and (b) guided practice was the most effective type of practice for proceduralization of L2 knowledge. </dc:abstract><dc:abstract>Pendant que la plupart des chercheurs sont d'accord avec le besoin de pratique pour développer une compétence, un des sujets le plus controversé dans le domaine de l'acquisition d'une langue seconde (L2) relève des conditions de pratique optimales pour le développement d'une L2 (DeKeyser, 2017). En abordant les principes de la théorie de l'acquisition des compétences, l'apprentissage d'une L2 est conçu comme un processus par lequel les élèves acquièrent des connaissances déclaratives ou des informations factuelles de la langue objet, pour ensuite développer des connaissances procédurales permettant aux élèves d'utiliser ces règles linguistiques lors de la production, à travers des opportunités de pratique et de rétroaction corrective (DeKeyser et Criado, 2012, Lyster, 2004a, Lyster et Sato, 2013). Les élèves dans des contextes de langues étrangères suivent généralement cette séquence; ils acquièrent des connaissances déclaratives et, en se servant de ces connaissances de façon répétée, ils développent des connaissances procédurales. Le temps d'enseignement limité et la pratique orientée vers la forme a pour résultat des élèves qui ont de la difficulté à utiliser la langue objet avec précision dans des situations communicatives authentiques. Pour accéder à leurs connaissances en L2 et les utiliser dans des contextes spontanés, les élèves doivent procéduraliser leurs connaissances déclaratives des structures de la langue objet à travers la pratique qui favorise une utilisation communicative de la L2. Il importe donc que la recherche en acquisition de L2 aborde les deux lignes suivantes; (a) l'étude du développement des connaissances procédurales dans un contexte de salle de classe et (b) l'opérationnalisation de différents types de pratique L2 pour mettre à l'épreuve leurs effets sur le développement de la L2 dans un contexte de salle de classe. La présente étude vise à contribuer à la recherche qui applique la théorie de l'acquisition des compétences à l'acquisition de langues secondes, en examinant l'effet de différents types de pratique sur le développement des connaissances déclaratives et procédurales en salle de classe.Trois classes intactes d'apprenants d'anglais comme langue étrangère de 5ème (Secondaire 1) (N = 70) du Chili ont participé à cette étude quasi-expérimentale. Chaque classe a été assignée à différentes conditions de pratique favorisant l'utilisation des déterminants possessifs singuliers à la 3ème personne (en anglais, his and her), pendant trois étapes. La pratique de perception-conscientisation a été conçue pour attirer l'attention des apprenants vers les structures grammaticales à travers de tâches de sensibilisation, sans enseigner explicitement des règles. La pratique guidée a été conçue pour attirer l'attention vers la forme linguistique pour développer la précision à travers d'activités signifiantes mais contrôlées. Finalement, la pratique autonome donnait aux élèves des tâches où ils pouvaient utiliser les structures linguistiques dans des contextes plus signifiants et moins contraints. Alors que le groupe A s'engageait dans les trois types de pratique, le groupe B se consacrait uniquement à la pratique de perception-conscientisation et à la pratique guidée. Le groupe C s'est engagé uniquement à la pratique de perception-conscientisation.Les mesures des connaissances déclaratives et procédurales ont révélé que, même si tous les groupes ont démontré des gains au niveau de la précision dans l'utilisation de l'objectif linguistique, il y eu un avantage pour le groupe ayant reçu une combinaison des trois types de pratique. Les résultats suggèrent que (a) les apprenants L2 qui ont reçu les trois types de pratique L2 ont développé plus de connaissances déclaratives et procédurales que les apprenants qui se sont engagés uniquement dans la pratique de perception-conscientisation, et (b) la pratique guidée est le type de pratique le plus efficace pour la procéduralisation des connaissances en L2.</dc:abstract><ual:supervisor>Masatoshi Sato (Supervisor2)</ual:supervisor><ual:supervisor>Roy Lyster (Supervisor1)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/k643b3340.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/6m311r62m</ual:fedora3Handle><dc:subject>Integrated Studies in Education</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Agb19f8194"><dcterms:title>Combinatorial nanodot stripe assay to study cell haptotaxis</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Biological and Biomedical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Dlamini, Mcolisi</ual:dissertant><dc:abstract>Haptotaxis, a cellular migration response to surface-bound biochemical cues, is essential for life processes such as angiogenesis, tissue repair, and embryonic development. In vitro, haptotaxis signaling processes are typically studied using protein gradient patterns. However, while these gradients provide global cell distributions for haptotaxis results, they do not easily and clearly provide precise information about the choices that cells make locally on different protein surface densities that exist within the gradient. Herein, we introduce the nanodot stripe assay (NSA) in order to (i) easily examine cell migration choices to different protein surface densities and (ii) to investigate the effect of protein nanodot cluster sizes on cell migration behavior. Each NSA design consists of a pair of alternating nanodot arrays of discrete and non-continuous surface density of either 0, 1, 3, 10, 30, 44 or 100% coverage. The NSA configuration challenges cells with a binary choice of low versus high surface densities of all possible combinations at once. The cell-surface affinity of the reference surface (RS), the area between patterned cues was adjusted towards maximizing cell response to the nanopatterned guidance cue. The RS was backfilled with a mixture of polyethylene glycol (PEG) and poly-D-lysine (PDL) with a low and high cell-surface affinity, respectively, and three RS combinations of 100:0, 90:10 and 75:25 %PEG:%PDL were tested with the NSA. The 90:10 %PEG:%PDL RS resulted in optimal C2C12 myoblasts haptotaxis responses to patterned netrin-1 nanodots. To study the effect of nanodot size, netrin was patterned as 200 nm × 200 nm, 400 nm × 400 nm and 800 nm × 800 nm dots. The migration response was found to be indifferent to the nanodot size. The NSA revealed that the myoblasts preferentially migrated onto higher netrin-1 density stripes when challenged with nanodot stripes with a threefold and greater density difference. Finally, by comparing the cell migration on NSA and stepped gradients, a response consistent with directional persistence could be identified on the stepped gradients. The NSA provides a powerful haptotaxis platform to advance the understanding of contact-mediated migration and signaling of motile cells to surface-bound protein cues.</dc:abstract><dc:abstract>L'haptotaxie, une réponse de migration cellulaire a la biochimie des surfaces, est essentielle pour des processus vitaux tels que l'angiogenèse, la réparation tissulaire et le développement embryonnaire. In vitro, les processus de signalisation de l'haptotaxie sont généralement étudiés en utilisant des motifs de gradients de protéines sur des surfaces. Cependant, alors que ces gradients fournissent des distributions de cellules pour des résultats d'haptotaxie, ils ne fournissent pas facilement et clairement des informations précises sur les choix que font les cellules sujettes à des différences locales de densités de protéines sur la surface. Ici, nous introduisons le test de la bande de nanopoint (BNP) afin de (i) examiner facilement les choix de migration cellulaire à différentes densités de surface protéiques, et (ii) étudier l'effet de la taille des nanopoint de protéines sur la migration cellulaire. Chaque BNP consiste en une paire de matrice de nanopoint discret et alternant de façon discontinue entre des densités de soit 0, 1, 3, 10, 30, 44 ou 100%. La configuration du BNP présente ainsi les cellules avec un choix binaire de densités de surface faibles ou élevées couvrant toutes les combinaisons possibles. Pour étudier l'effet de la dimension des nanopoint de protéines, des nanopoint de 200 nm × 200 nm, 400 nm × 400 nm et 800 nm × 800 nm ont été testés. De plus, pour révéler la migration cellulaire, l'affinité de la surface cellulaire a la SR a été ajustée pour maximiser la réponse cellulaire au guidage du motif de nanopoint. Le SR a été remblayé avec un mélange de polyéthylène glycol (PEG) et de poly-D-lysine (PDL) avec une affinité faible et élevée à la surface des cellules, respectivement. Trois combinaisons de SR ont été testées; 100:0, 90:10 et 75:25 %PEG:%PDL. Le PEG 90%:10% PDL SR a résulté à des réponses optimales de l'haptotaxie des myoblastes C2C12 spécifiques aux nanopoints de netrin-1, et ont été conservés avec toutes les tailles de nanopoints. Les myoblastes ont migré préférentiellement vers les bandes de haute densité de nétrine-1 lorsque présentés avec des bandes de nanopoint avec une différence de densité de triple et plus. Par rapport aux résultats du test par gradient, les choix des cellules présentées au bande du BNP étaient exempts d'effet persistant de la migration cellulaire. Le BNP fournit une plate-forme d'haptotaxie puissante pour améliorer la compréhension de la migration et de la communication cellulaire face à des motifs de proteines sur les surfaces.</dc:abstract><ual:supervisor>David Juncker (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/12579v55z.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/gb19f8194</ual:fedora3Handle><dc:subject>Computer Science</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Az603r069h"><dcterms:title>A numerical study of frictional contact</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>School of Computer Science</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Datta, Sayantan</ual:dissertant><dc:abstract>La friction est un phénomène complexe résultant de déformations élastiques et plastiques couplées à une interaction moléculaire le long de la frontière de contact. Lorsque deux surfaces se touchent, leur rugosité et leur force normale déterminent la surface réelle en contact qui régit le processus de déformation et d'interaction moléculaire. Une interaction macroscopique typique peut impliquer des millions de contacts microscopiques, c'est l'agrégation de ces forces qui provoque le phénomène de friction. Dans cette thèse, notre objectif est de simuler le phénomène de frottement en supposant un contact non lubrifié ainsi qu'une déformation élastique aux aspérités de contact. Nous recueillons des données en faisant varier de nombreux paramètres qui affectent le frottement entre deux surfaces et construisons une approximation exploitant la corrélation des données. Un tel approximation est peu coûteux, polyvalent et plus précis que les tables de coefficients de frottement actuellement utilisées dans divers simulateurs physiques.</dc:abstract><dc:abstract>Friction is a complex phenomenon resulting from elastic and plastic deformations coupled with molecular interaction along the contact boundary. When two surfaces touch, their roughness, and normal force determines the actual area under contact, governing the process of deformation and molecular interaction. A typical macroscopic interaction may involve millions of microscopic contacts and the aggregate of these forces give rise to the phenomenon of friction. In this thesis, our goal is to simulate the phenomenon of friction assuming unlubricated contact and elastic deformation at the contact asperities. We collect data by varying many parameters that affect friction between two surfaces and build a function approximator exploiting the correlation in data. Such an approximator is a computationally inexpensive, versatile and more accurate substitute for friction coefficient tables currently in use with various physically based simulators.</dc:abstract><ual:supervisor>Derek Nowrouzezahrai (Internal/Cosupervisor2)</ual:supervisor><ual:supervisor>Paul Kry (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/vt150m28q.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/z603r069h</ual:fedora3Handle><dc:subject>Computer Science</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A6395w966g"><dcterms:title>The new crimes of rape and sexual slavery against child soldiers at the ICC: A feminist perspective of the expressivist potential</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Laws</schema:inSupportOf><dc:contributor>Faculty of Law</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Beaulieu Lussier, Mélissa</ual:dissertant><dc:abstract>This thesis explores the capacity of international criminal law (ICL) to express norms in the context of sex crimes prosecutions from a feminist perspective. Two key elements are considered: norm expression and the creation of a wartime narrative. Ultimately, this thesis seeks to analyze the expressive strengths and shortcomings of ICL in relation to the prosecution of the crimes of rape and sexual slavery against child soldiers. Those "new crimes" are currently prosecuted in the case of The Prosecutor v. Bosco Ntaganda at the International Criminal Court (ICC). The first chapter explores the feminist literature on this matter and how ICL has distorted the wartime narrative away from women's standpoint, expressed norms that have reinforced victimhood, and denied women's agency. Chapter 2 examines two case-studies, the ICC child soldiers case of Thomas Lubanga and the "bush wives" cases from the Special Court for Sierra Leone, that both share similarities with the "new crimes" of rape and sexual slavery against child soldiers. Specifically, I trace the expressive strengths and weaknesses in those cases and conclude that, while holding the perpetrator accountable might be a strength, reifying gendered stereotypes clearly shape our understanding of those crimes and the experiences of women. In the final chapter, I illustrate how the expressive function of international criminal law is likely to fall short of its purpose in the case of "new crimes" by creating a hierarchy of harms and reifying gendered stereotypes. In summary, although the expressive function of ICL have been considered the most persuasive justification of ICL, the norms and the wartime narrative expressed with the "new crimes" of rape and sexual slavery against child soldiers are expected to remain imperfect and limited.</dc:abstract><dc:abstract>Le présent mémoire explore la capacité du droit pénal international (DPI) d'exprimer des normes dans le contexte de procès pour violence sexuelle. Tout en adoptant une perspective féministe, ce mémoire reposera sur deux concepts clefs, soit l'expression de normes et la création d'un narratif de guerre. Plus particulièrement, il sera ici question d'exposer les forces et les lacunes de cette fonction expressive du DPI qui pourrait trouver écho dans la poursuite des « nouveaux crimes » de violences sexuelles à l'encontre d'enfant soldats dans le cadre de l'affaire Le Procureur c Bosco Ntaganda devant la Cour Pénale Internationale (CPI). Le premier Chapitre explore la littérature féministe concernant les poursuites de violences sexuelles, puis la manière par laquelle le DPI déforme le narratif de guerre dans une perspective de genre et exprime des normes qui renforcent la victimisation et suppriment l'agentivité des victimes. Le deuxième Chapitre examine deux cas d'espèce où l'on retrouve des éléments communs avec les « nouveaux crimes », soit l'affaire Thomas Lubanga au sujet d'enfant soldats devant la CPI, ainsi que les cas de mariage forcé débattus devant le Tribunal Spécial pour la Sierra Leone. Plus précisément, je retrace les lacunes expressives en lien avec ces cas et conclus qu'ils ont contribué à réifier des stéréotypes de genre qui ont clairement modelé notre compréhension des expériences des femmes survivantes. Le troisième Chapitre illustre comment la fonction expressive du DPI est susceptible de faillir à sa tâche dans le cas des « nouveaux crimes » en créant une hiérarchie des souffrances et en réifiant des stéréotypes de genre. Au final, malgré que la fonction expressive du DPI soit la justification la plus convaincante, les normes exprimées et le narratif de guerre que créeront les « nouveaux crimes » est susceptible de demeurer au mieux limités et à parfaire.</dc:abstract><ual:supervisor>Alana Klein (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/hx11xh079.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/6395w966g</ual:fedora3Handle><dc:subject>Law</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Av692t8628"><dcterms:title>Palladium-catalyzed carbonylative and decarbonylative transformations for the synthesis of reactive electrophiles and heterocycles</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Chemistry</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>De La Higuera Macias, Maximiliano</ual:dissertant><dc:abstract>The palladium catalyzed carbonylation of aryl halides can provide a useful method to synthesize carbonyl containing products. This thesis describes the development of two new variants of such reactions that offer efficient routes to generate either reactive electrophiles or heterocycles. These reactions can be performed using commercially available reagents, which include aryl iodides, imines, acid chlorides and carbon monoxide. Chapter 2 describes the development of a new method to utilize palladium catalysis to generate reactive acid chloride electrophiles. This transformation occurs via the metathesis of covalent σ-bonds between Ar-X fragments, and demonstrates the dynamic nature of palladium-based oxidative addition/reductive elimination. Overall, this opens a route to synthesize acid chlorides without the use of high energy corrosive or toxic reagents, and instead from exchange with other acid chlorides. Coupling the in-situ formation of acid chlorides with nucleophiles allows the efficient synthesis of a number of carbonyl containing compounds. Chapter 3 describes the development of a new palladium catalyzed multicomponent synthesis of spirocyclic-β-lactams. This reaction proceeds via two tandem catalytic carbonylation reactions, where a single palladium catalyst mediates the formation of acid chlorides, α-chloroamides and ketenes as intermediates. Subsequent trapping of the ketene by [2+2] cycloaddition reactions furnishes the polysubstituted product. The transformation provides a route to generate a number of spirocyclic-β-lactams from imine-tethered aryl iodides, imines and CO.</dc:abstract><dc:abstract>La carbonylation d'halogénure d'aryle catalysé au palladium peut s'avérer être une méthode efficace pour la synthèse de composés carbonylés. Cette thèse décrit le développement de deux nouvelles variantes de réactions de carbonylation catalysées au palladium qui offre des routes de synthèses efficaces afin de générer des électrophiles réactifs ou des hétérocycles. Ces réactions peuvent être réalisées à partir de produits commercialement disponibles, qui incluent les iodures d'aryles, imines, chlorures d'acides et le monoxyde de carbone.Le deuxième chapitre décrit le développement d'une nouvelle méthode d'utilisation du palladium comme catalyseur pour générer des électrophiles réactif : les chlorures d'acides. Cette transformation procède via la métathèse de liens sigma entre les fragments Ar-X. Cette réaction montre la nature dynamique du palladium face à l'addition oxydante/élimination réductrice de composés organiques et offre une approche efficace pour incorporer des groupes fonctionnels chlorure d'acide aux halogénures d'aryle par réactions d'échange. En général, ceci ouvre la voie à une nouvelle route de synthèse de chlorures d'acide sans l'utilisation de substances hautement corrosives et toxiques, mais plutôt à partir d'échanges avec d'autres chlorures d'acide. En couplant les chlorures d'acide formés in situ avec divers nucléophiles permet la synthèse efficace de nombreux composés carbonylés. Le troisième chapitre décrit le développement d'une nouvelle réaction multicomposant catalysé au palladium pour la synthèse de β-lactames spirocyclique. Cette réaction procède via deux réactions tandem catalytiques de carbonylation, où un seul catalyseur de palladium sert de médiateur pour la formation de chlorures d'acide, α-chloroamides et cétènes comme intermédiaires. Le cétène subséquemment piégé par réaction de cycloaddition [2+2] procure les composés polysubstitués. Cette transformation procure une route de synthèse pour générer un nombre de β-lactame spirocyclique à partir d'imines attachées à un iodure d'aryle, d'imines et de monoxyde de carbone.</dc:abstract><ual:supervisor>Bruce A Arndtsen (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/z029p6933.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/v692t8628</ual:fedora3Handle><dc:subject>Chemistry</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A3j333460q"><dcterms:title>Effcient group-sparse transceiver design for multiuser MIMO relaying in C-RAN</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Saab, Ayoub</ual:dissertant><dc:abstract>Cette thèse porte sur la conception de relais type amplification-et-transfert (AF) à plusieurs entrées et plusieurs sorties (MIMO) dans un réseau d'accès radio "cloud" (C-RAN), du point de vue de l'efficacité énergétique. L'objectif est de sélectionner conjointement des têtes- radio-distantes (RRH) et d'optimiser leur émetteur-récepteur, chacune représentée par une matrice AF, afin de faciliter la communication entre plusieurs paires source-destination. Nous formulons le problème de conception sous la forme d'une minimisation de fuite d'interférences soumise à des contraintes de puissance par relais, tout en imposant un ensemble de contraintes linéaires pour préserver les signaux souhaités chez les destinations. Pour obtenir une solution de relais économe en énergie, la fonction d'objectif est pénalisée par un terme de régularisation qui favorise la parcimonie de groupe parmi les poids de relais résultants. Un algorithme itératif de faible complexité basé sur la méthode des multiplicateurs de direction alternée (ADMM) est alors proposé pour résoudre le problème régularisé, ce qui donne des solutions explicites à chaque itération. Cela conduit à une opération de seuillage qui permet de sélectionner un sous-ensemble de relais, et par suite à un ensemble de matrices AF qui obéissent strictement à la parcimonie de groupe. Les résultats de simulation démontrent les avantages explicites de l'algorithme proposé, ce qui se traduit par une consommation d'énergie et une complexité de calcul nettement inférieures à celles des méthodes de conception de relais classiques.</dc:abstract><dc:abstract>This thesis addresses the design of multiuser multiple-input multiple-output (MIMO) amplify-and-forward (AF) relaying within a cloud radio access network (C-RAN) from an energy efficient perspective. The aim is to jointly select remote radio heads (RRH) and optimize their transceiver, each represented by an AF matrix, in order to assist the communication between multiple source-destination pairs. We formulate the design problem as an interference leakage minimization subject to per relay power constraints, while imposing a set of linear constraints to preserve the desired signals at the destinations. To obtain an energy efficient relaying solution, the objective function is penalized with a regularization term which promotes group-sparsity among the resultant relaying weights. A low-complexity iterative algorithm based on the alternating direction method of multipliers (ADMM) is then proposed to solve the regularized problem, which yields closed-form solutions at eachiteration. The closed-form solution leads to a thresholding operation that enables the selection of a relay subset, thus yielding solutions for the set of AF matrices that are exactly group-sparse. Simulation results demonstrate the explicit benefits of the proposed algorithm, which results in notably lower power consumption and computational complexity than conventional relaying design methods.</dc:abstract><ual:supervisor>Benoit Champagne (Internal/Cosupervisor2)</ual:supervisor><ual:supervisor>Ioannis Psaromiligkos (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/1544br74d.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/3j333460q</ual:fedora3Handle><dc:subject>Electrical and Computer Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Aj9602324b"><dcterms:title>Maintenance strategies and design recommendations on input devices for musical expression</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Schulich School of Music</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Nieva Chavez, Luis</ual:dissertant><dc:abstract>Différents défis sont à surmonter lors de la conception et la construction d'interfaces pour l'expression musicale telles que les instruments de musique numériques (IMNs), les technologies portables pour la performance, entre autres. Les principaux enjeux techniques sont le développement rapide et imprévisible de la technologie, les changements dans le personnel de soutien et le manque de documentation technique. Ces défis, s'ils ne sont pas traités de manière adéquate, conduisent, dans de nombreux cas, à l'abandon de tels dispositifs. Cette thèse présente trois études de cas qui visent à fournir des recommandations relatives à l'entretien et à la conception pour la création d'interfaces plus robustes et durables. La première étude de cas illustre le défi d'entretenir différents modèles d'un IMN appelé le T-Stick dans l'espoir de prolonger leur durée de vie. Les T-Sticks ont été originalement conçus en 2006 et 20 exemplaires ont été construits au cours des 12 dernières années. Bien que tous les instruments préservent le concept original d'IMN, leur évolution les a distingués par des variations spécifiques dans le choix des microcontrôleurs, des capteurs, ainsi que de leur taille. Pour cette étude de cas, nous avons travaillé avec huit exemplaires de T-Sticks afin de résoudre les problèmes liés à l'obsolescence des composants électroniques, aux changements de logiciels externes, aux incohérences entre les versions de microprogrammes, au manque de documentation et, de manière générale, au problème de maintenance technique. Dans la deuxième étude de cas, nous avons reconceptualisé l'électronique d'un neuvième T-Stick, le WiFi Sopranino, tout en conservant son concept d'IMN original et en se basant sur les résultats tirés de la première étude de cas. Ce travail a mené à la troisième étude de cas, pour laquelle nous avons conçu une nouvelle interface pour l'expression musicale afin d'accroître les possibilités gestuelles et visuelles liées à la performance du violoncelle. Cette thèse vise à relier les concepts de maintenance technique et de conception électronique afin de fournir une approche systématique pour l'entretient de dispositifs. Nous proposons des recommandations telles que la maintenabilité, la re-usabilité et l'auto-confinement comme des outils pour la conception d'interfaces pour l'expression musicale.</dc:abstract><dc:abstract>Various challenges must be overcome when designing and building input devices for musical expression such as digital musical instruments (DMIs), electronic wearables for performance, among others. Amid the technical ones are the rapid unpredictable advancement of technology, changes in supporting personnel, and a lack of technical documentation. These challenges, if not adequately addressed, in many cases lead to abandonment of such devices and endeavors. This thesis presents three case studies that aim to provide maintenance strategies and design recommendations for the creation of more robust, long-lasting interfaces. The first case study illustrates the challenge of maintaining several models of the DMI called the T-Stick in the hopes of extending their useful lifetime. The T-Sticks were originally conceived in 2006 and 20 copies have been built in the past 12 years. Although all of the instruments preserve the original DMI design concept, their evolution has distinguished them through variations in choice of microcontrollers, sensors, and size. For this case study, we worked with eight copies of the T-Sticks to overcome issues related to the aging and obsolescence of components, changes in external software, inconsistencies in firmware across versions, a lack of documentation, and, in general, the problem of technical maintenance. In the second case study, we redesigned the electronics of a ninth T-Stick, the WiFi Sopranino. For this process we used the lessons learned from the first case study, while keeping its original DMI design concept. This work, in turn, informed the third case study, where we sought to design and build a new interface for musical expression to augment cello performance by installing a visual affordance on the instrument. In short, this thesis aims to connect the concepts of technical maintenance and electronic redesign and design to provide a systematic approach to the maintenance of these type of devices. We articulate design recommendations such as maintainability, reusability, and self-containment as useful in the design of input devices for musical expression.</dc:abstract><ual:supervisor>Marcelo Wanderley (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/0v838275t.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/j9602324b</ual:fedora3Handle><dc:subject>Music</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Aqz20sw074"><dcterms:title>Lawyers as corruption brokers: The "production" of a corrupt legal profession and the Chinese state</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of Political Science</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>An, Ran</ual:dissertant><dc:abstract>Over the past decades, corruption in China's courts has become a salient issue. A recent report published in the Chinese mainstream media demonstrates that judicial corruption has infiltrated all levels of courts and tainted court adjudications in all types of litigations. As a result of deep-seated grievances brought by judicial corruption, scholars have analyzed the genesis of corruption from different angles and, in particular, they have examined the political interference on the judiciary and a lack of professionalism and accountability of judges in China's courts. The role of other legal actors, who frequently interact with judges and facilitate corrupt practices, has been neglected. This thesis provides an exploratory study of the Chinese lawyers who, as multiple evidence seems to suggest, are deeply involved in judicial corruption. The study engages with this phenomenon and addresses why a nascent law profession in China becomes deeply corrupt. Theoretically, it engages with the research on brokerage, a mechanism that facilitates corruption. It also links the sociological study of professions to the institutional setting of the state, and argues that dependent law professionals, who rely on the Chinese state in the judicial decision making process and for their career resources, become corruption brokers due to such reliance. The empirical analysis looks into lawyers' interactions with the state apparatus in the judicial process, pressures in the market for business, and deficient discipline and sanction under dual regulation, and the analysis is further illustrated by concrete cases from an original collection of data on corruption trials. Ultimately, this study reflects on the arduous path of building a law profession in an authoritarian post-communist state undergoing enormous changes at all levels, but also gives a balanced account of Chinese lawyers without neglecting the profession's efforts to defend the rights of the Chinese citizens. </dc:abstract><dc:abstract>Au cours des dernières décennies, la corruption du système judiciaire chinois est devenue un problème majeur. Un rapport récent publié dans la presse chinoise illustre un degré de corruption qui touche tous les niveaux de ce système et porte atteinte aux jugements émis dans toutes sortes de litiges. Ce problème a propagé un sentiment d'amertume profond que les chercheurs ont tenté de cerner depuis ses origines et à partir de différentes perspectives. Ils ont notamment examiné les interférences exercées par le politique sur le judiciaire et le manque de professionnalisme et de responsabilité de la part des juges chinois. Le rôle des autres acteurs de ce système, qui interagissent fréquemment avec les juges et facilitent ainsi la corruption, a été négligé. Cette thèse étudie le rôle des avocats chinois qui, comme le suggèrent un nombre croissant d'éléments, participent à la corruption du système judiciaire. Cette étude analyse ce phénomène et cherche à comprendre pourquoi la profession du droit en Chine est devenue aussi corrompue. Elle s'appuie sur les recherches faites au sujet des intermédiaires de ce système, dont l'action facilite la corruption. Elle établit aussi des liens sociologiques entre l'étude de la profession et le cadre institutionnel chinois. L'analyse montre que la dépendance de la profession du droit envers le gouvernement pour son influence dans la prise de décisions judiciaires, en fait un intermédiaire du processus de corruption. La justification du recours à la corruption de la part des avocats, les relations entretenues avec l'appareil d'État, les pressions qui existent sur le marché pour les entreprises, le manque de discipline et de sanctions sous la règlementation actuelle, sont illustrées par des cas concrets tirés de différentes données sur des procès de corruption. Finalement, cette étude réfléchit à la difficulté d'établir la profession du droit dans un État autoritaire postcommuniste où se produisent des changements majeurs à tous les niveaux. Elle fournit un examen détaillé sur les avocats en Chine, sans négliger pour autant les efforts de la profession afin de défendre les droits des citoyens chinois.</dc:abstract><ual:supervisor>Juan Wang (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/47429c560.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/qz20sw074</ual:fedora3Handle><dc:subject>Political Science</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ag158bk461"><dcterms:title>Exposure to freeze-thaw conditions increases virulence of «Pseudomonas aeruginosa» to «Drosophila melanogaster»</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Chemical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Hakimzadeh Rezaeyeh, Arsham</ual:dissertant><dc:abstract>Groundwater contamination by pathogenic bacteria present in land-applied manure poses a threat to public health. In cold climate regions, surface soil layers experience repeated temperature fluctuations around the freezing point known as freeze-thaw (FT) cycles. With global climate change, annual soil FT cycles have increased, and this trend is expected to continue. It is therefore of interest to understand how FT cycles impact soil microbial communities. This study investigates the influence of FT cycles on the growth, culturability, biofilm formation, and virulence of the opportunistic pathogen Pseudomonas aeruginosa, a ubiquitous bacterium found in soil and water, and responsible for infections in immunocompromised hosts. Our findings demonstrate that exposure to FT had no significant effect on growth or culturability of the bacteria. However, FT treatment significantly increased biofilm formation and delayed the onset of swimming motility, factors that are important for the pathogenicity of P. aeruginosa. An in vivo study using a chronic infection model revealed an increase in the virulence of P. aeruginosa after FT exposure. These results suggest that the impact of climate change on natural FT cycles may be affecting the ecology of soil-borne pathogens and host-pathogen interactions in unexpected ways.</dc:abstract><dc:abstract>La contamination d'eaux souterraines par des bactéries pathogènes présentes dans le fumier épandu représente un danger considérable pour la santé publique. Dans les régions froides, les couches de sol de surface subissent des variations de température aux alentours du point de congélation connues sous le nom de «freeze-thaw (FT) cycles» (périodes de gel-dégel). Sous l'influence du réchauffement climatique, les cycles FT annuels sont d'autant plus courants, et cette tendance semble s'intensifier. Il est par conséquent crucial de comprendre l'impact des cycles FT sur les bactéries des sols. Cette recherche tente de comprendre l'influence des cycles FT sur la croissance, la cultivabilité, la formation de biofilm, et la virulence du pathogène opportuniste Pseudomonas aeruginosa, une bactérie omniprésente dans les eaux et les sols, et responsable d'infections chez les hôtes au système immunitaire affaibli. La recherche présentée ici démontre que l'exposition au FT n'a aucun effet significatif sur la croissance et la cultivabilité de la bactérie. Cependant, les traitements FT ont significativement augmenté la formation de biofilm et retardé l'initiation de la motilité de type «swimming», pouvant être des facteurs favorables à la virulence de P. aeruginosa. Une étude in vivo faisant usage d'un modèle d'infection chronique a démontré une augmentation dans la virulence de P. aeruginosa après une exposition au FT. Ces résultats suggèrent que l'impact du réchauffement climatique sur les cycles naturels FT pourrait affecter l'écologie de pathogènes provenant du sol et les interactions hôtes-agents pathogènes de façons inattendues.</dc:abstract><ual:supervisor>Eric Déziel (Internal/Cosupervisor2)</ual:supervisor><ual:supervisor>Nathalie Tufenkji (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/8c97ks66q.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/g158bk461</ual:fedora3Handle><dc:subject>Chemical Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A2f75rb05m"><dcterms:title>Inorganic carbon dynamics and CO2 fluxes in the Saguenay Fjord (Québec, Canada)</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Earth and Planetary Sciences</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Delaigue, Louise</ual:dissertant><dc:abstract>Le fjord du Saguenay est un tributaire majeur de l'estuaire du Saint-Laurent et est fortement stratifié. Une couche d'eau saumâtre de 6-8 m recouvre généralement jusqu'à 270 m d'eau de mer. Malgré toutes les recherches effectuées à ce jour, le mode, l'ampleur et la fréquence des échanges d'eau et de carbone entre l'estuaire et le fjord ne sont pas quantifiés. Comparativement au fleuve Saint-Laurent, les eaux de surface du fjord du Saguenay sont plus acides et contiennent moins de carbone inorganique dissous (CID) et plus de carbone organique dissous (COD). Les eaux de surface du fjord devraient constituer une source nette de CO2 vers l'atmosphère. Néanmoins, l'intrusion, en surface, d'eaux saumâtres de l'estuaire fluvial avec la marée montante, ainsi que le mélange d'eau de mer, débordant du seuil de l'estuaire maritime sous la pycnocline, modulent la dynamique du CO2 dans le fjord du Saguenay. A l'aide de traceurs géochimiques et isotopiques ainsi que d'un algorithme d'optimisation multiparamétrique (OMP), nous avons déterminé la contribution relative des sources connues à la colonne d'eau du fjord du Saguenay, y compris les eaux profondes provenant de l'estuaire maritime du Saint-Laurent et qui renouvellent les eaux des bassins profonds du fjord. Ces résultats, combinés à un modèle de mélange conservateur (salinité, température, alcalinité totale, carbone inorganique dissous) et comparés aux mesures sur le terrain, permettent d'identifier les facteurs dominants, autres que le mélange physique, tels que l'activité biologique (photosynthèse, respiration) et les échanges gazeux, qui influencent les propriétés des eaux (par exemple, pH, pCO2, concentration en nutriments) du fjord. Les résultats de cette étude indiquent que les eaux de surface du fjord sont une source nette de CO2 pour l'atmosphère pendant les périodes de fort apport en eau douce (par exemple, crues printanières) alors que les eaux de surface servent de puits net de CO2 atmosphérique lorsque la salinité excède ~ 5-10.</dc:abstract><dc:abstract>The Saguenay Fjord is a major tributary of the St Lawrence Estuary and is strongly stratified. A 6-8 m wedge of brackish water typically overlies up to 270 m of seawater. Despite all the research carried out to date, the mode, magnitude and frequency of water and carbon exchange between the estuary and the fjord remain unquantified. Relative to the St Lawrence River, the surface waters of the Saguenay Fjord are more acidic and host lower dissolved inorganic carbon (DIC) and higher dissolved organic carbon (DOC) concentrations. The surface waters of the fjord are projected to be a net source of CO2 to the atmosphere. Nonetheless, the intrusion, at the surface, of brackish water from the upper estuary with the rising tide, as well as mixing of seawater, overflowing the sill from the lower estuary, below the pycnocline modulate the CO2 dynamics in the Saguenay Fjord. Using geochemical and isotopic tracers as well as an optimization multiparameter algorithm (OMP), we determined the relative contribution of known source-waters to the water column in the Saguenay Fjord, including deep waters that originate from the Lower St. Lawrence Estuary and replenish the fjord's deep basins. These results, when combined to a conservative (salinity, temperature, total alkalinity, dissolved inorganic carbon) mixing model and compared to field measurements, serve to identify the dominant factors, other than physical mixing, such as biological activity (photosynthesis, respiration) and gas exchange at the air-water interface, that impact the water properties (e.g., pH, pCO2, nutrient concentration) of the fjord. Results indicate that the fjord's surface waters are a net source of CO2 to the atmosphere during periods of high freshwater discharge (e.g., spring freshet) whereas the surface waters serve as a net sink of atmospheric CO2 when their salinity exceeds ~ 5-10.</dc:abstract><ual:supervisor>Alfonso Mucci (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/sf2687465.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/2f75rb05m</ual:fedora3Handle><dc:subject>Earth and Planetary Sciences</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Aff3657454"><dcterms:title>Anomaly detection from videos: A deep learning approach</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Jacob, Seby</ual:dissertant><dc:abstract>This thesis proposes an innovative solution to detect and localize anomalous events in a video stream from a static camera. Anomalies are defined as events with a very low probability of occurrence in the scene or as events typically uncharacteristic of the scene. In this work, we employ a constrained convolutional auto-encoder to learn the scene characteristics. The autoencoder is trained on spatio-temporal video-volumes extracted from recorded videos of the scene. Once the training is complete, each incoming video-volume can be tested for its anomalous nature by analyzing the low-dimensional encodings and the quality of its reconstruction from the auto-encoder. Anomalies are heavily subjective to the scene being monitored. The most abnormal event in one scene could be the most normal event in another. Hence, special care has been taken to make the solution applicable for any scenario. Since training is unsupervised, this work is extremely general purpose and can be deployed on any scene as is. Apart from the discourse on a novel solution that is competitive with state-of-the-art methods, this work also has an additional contribution. Specifically, we present a framework for generating unlimited amounts of video data for anomaly detection from a static camera. This enables the evaluation of any deep learning models, that were previously not adaptable for the problem due to the limited training data available in benchmark datasets. We present results from extensive experimentation on popular benchmark datasets to show that our solution is effective and robust for anomaly detection. We also establish the importance of having sufficient training data via the evaluation of models trained on training- sets of varying sizes. Finally, the idiosyncratic nature of "What is an anomaly?" is subjected to analysis using an experimental methodology.</dc:abstract><dc:abstract>Cette thèse propose une solution innovante pour détecter et localiser les événements anormaux dans un flux vidéo provenant d'une caméra statique. Les anomalies sont définies comme des événements avec une très faible probabilité d'occurrence dans la scène ou comme des événements atypiques. Dans cette étude, nous utilisons un auto-encodeur convolutionnel limité pour analyser les caractéristiques de la scène. Le codeur automatique repose sur des volumes vidéo spatio-temporels extraits de vidéos enregistrées de la scène. Une fois l'entraînement terminé, chaque anomalie du volume vidéo entrant peut être testée en analysant les codages à faible dimension et la qualité de sa reconstruction à partir de l'encodeur automatique. Les anomalies sont fortement subjectives pour la scène surveillée. L'événement le plus anormal d'une scène pourrait être considéré comme étant le plus normal dans une autre. Par conséquent, une attention particulière a été apportée pour rendre la solution applicable à tous les scénarios. Puisque la formation n'est pas supervisée, cette recherche est extrêmement générale et peut être déployée sur n'importe quelle scène. Hormis le travail sur une nouvelle solution compétitive par rapport aux autres méthodes, ce dernier apporte également une contribution supplémentaire. Nous présentons un cadre pour générer des quantités illimitées de données vidéo afin de détecter des anomalies à partir d'une caméra statique. Cela permet d'évaluer de manière exhaustive tous les modèles d'apprentissage, qui auparavant n'étaient pas adaptées au problème en raison des données de formation limitées disponibles dans les ensembles de données de référence. Nous présentons les résultats d'une expérimentation basée sur des ensembles de données de référence populaires pour montrer que notre solution est efficace et solide en vue de détecter des anomalies. Par ailleurs, nous établissons l'importance de disposer de données de formation suffisantes à travers l'évaluation de modèles construits sur des ensembles de formation de différentes tailles. En définitive, la nature idiosyncratique de "Qu'est-ce qu'une anomalie?" est soumise à une analyse en utilisant une méthodologie expérimentale.</dc:abstract><ual:supervisor>Martin D Levine (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/5x21th688.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/ff3657454</ual:fedora3Handle><dc:subject>Electrical and Computer Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Awd375z70b"><dcterms:title>Evaluating multimodal feedback for accomplishing assembly tasks in virtual environment</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Yin, Guofan</ual:dissertant><dc:abstract>Operating power tools over extended periods of time can pose significant risks to humans, due to the strong forces and vibrations they impart to the limbs. Telemanipulation systems can be employed to minimize these risks, but may impede effective task performance due to the reduced sensory cues they typically convey. To address this shortcoming, we explore the benefits of introducing simple vibrotactile cues, in addition to auditory and low-level force feedback, on users' performance in a VR mechanical assembly task employing a simulated impact wrench. The vibrotactile effects rendered in this study represent not only collision states, but also simplified and attenuated renderings of the vibrations experienced while operating an actual impact wrench. Results from a user study comparing feedback modality combinations suggest that the introduction of vibrotactile feedback, in addition to auditory feedback, has the potential to significantly improve user performance as assessed by completion time, while the addition of force feedback did not further improve performance.</dc:abstract><dc:abstract>L'utilisation d'outils électriques pendant de longues périodes peut présenter des risques importants pour les humains, en raison des forces et des vibrations importantes qu'ils transmettent aux membres. Les systèmes de télémanipulation peuvent être utilisés pour minimiser ces risques mais peuvent entraver l'efficacité des tâches en raison des signaux sensoriels réduits qu'ils transmettent généralement. Pour combler cette lacune, nous explorons les avantages de l'introduction de signaux vibrotactiles simples, en plus de la rétroaction de force auditive et de bas niveau, sur la performance des utilisateurs dans une tâche d'assemblage mécanique VR utilisant une clé à chocs simulée. Les effets vibrotactiles rendus dans cette étude représentent non seulement des états de collision, mais aussi des rendus simplifiés et atténués des vibrations subies lors de l'utilisation d'une clé à chocs réelle. Les résultats d'une étude utilisateur comparant les combinaisons de modalité de rétroaction suggèrent que l'introduction de rétroaction vibrotactile, en plus de la rétroaction auditive, pourrait améliorer significativement les performances de l'utilisateur en fonction du temps d'acèvement, tandis que l'ajout de retour de force n'améliorerait pas les performances.</dc:abstract><ual:supervisor>Jeremy Cooperstock (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/5138jg939.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/wd375z70b</ual:fedora3Handle><dc:subject>Electrical and Computer Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ah989r533k"><dcterms:title>Catalytic ozonation for the removal of contaminants of emerging concern and disinfection of wastewater</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Chemical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Kolosov, Petr</ual:dissertant><dc:abstract>Les réglementations de plus en plus strictes relatives à la qualité des eaux usées et l'incapacité du traitement conventionnel des eaux usées à éliminer adéquatement les contaminants d'intérêt émergent (CIE) rendent essentiel le développement de nouvelles approches de traitement pour bonifier les systèmes de traitement existants. L'ozonation catalytique est l'un des plus récents procédés d'oxydation avancée (AOP) étudiés en tant que stratégie visant à améliorer la qualité des eaux usées avant leur rejet dans l'environnement. La présente thèse de doctorat est axée sur le développement de nouvelles connaissances relative à l'ozonation catalytique et l'identification de nouveaux matériaux comme catalyseurs efficaces pour l'élimination des CIE et la désinfection des eaux usées. Les résultats de cette recherche sont présentés dans deux manuscrits. Le premier article porte sur l'identification de catalyseurs potentiels, sur la cinétique apparente de réaction et sur la réutilisabilité des catalyseurs les plus prometteurs. L'étude a été effectuée dans un réacteur semi-continu dans de l'eau MilliQ (MQW) et de l'eau usée synthétique. Les résultats ont démontré que le TiO2/Al2O3, le AL-1010S (catalyseur à base de Al2O3) et le Polonite® amélioraient l'efficacité du traitement catalytique pour l'élimination des CIE et la désinfection de E. coli. La réaction cinétique apparente entre les espèces oxydantes (ozone et radicaux hydroxyles) et l'atrazine (ATZ) a été étudiée dans un réacteur semi-continu dans une matrice d'eau MQW et à l'aide de piégeurs de radicaux. Les expériences de réutilisation ont démontré que le TiO2/Al2O3 et AL-1010S maintenaient leur efficacité pendant quatre jours consécutifs d'opération, avec une élimination de l'ATZ supérieure à 90% et une efficacité de désinfection supérieure à celle obtenue avec une ozonation non catalytique de plus de 1,5 MPN Log unités. Le Polonite® a fourni le rendement le moins stable en fonction du temps, mais a fourni la meilleure désinfection. Le deuxième article rapporte l'effet des caractéristiques des eaux usées (concentration chimique en oxygène (DCO) et nitrite (NO2) et des conditions opératoires (rapport ozone / catalyseurs, concentration d'ozone et HRT) sur l'efficacité du procédé en utilisant les deux matériaux identifies comme étant les plus prometteurs, le Polonite® et le AL-1010S. Les paramètres optimaux pour la désinfection et l'élimination des ATZ ont été définis comme étant une concentration 8 g-O3 nm3 de le gaz d'alimentation, un temps de rétention de 10 minutes et un rapport de 0,11 de la concentration d'ozone relative à la charge de catalyseur. Les concentrations de NO2 et de DCO ont grandement influencé l'efficacité du traitement, mais l'utilisation d'AL-1010S ou de Polonite® a rendu le procédé moins sensible aux variations de ces caractéristiques des eaux usées. Les avantages de l'ozonation catalytique avec le AL-1010S ou le Polonite® ont été vérifiés pour la désinfection des effluents d'eaux usées collectés dans deux stations d'épuration municipales, mais les difficultés analytiques ont limité les informations disponibles pour conclure sur le potentiel d'amélioration de l'enlèvement des CIE.</dc:abstract><dc:abstract>The increasingly more stringent regulations related to wastewater quality and the inability of conventional wastewater treatment to adequately eliminate contaminants of emerging concern (CECs) make it essential to develop novel treatment approaches to upgrade existing treatment train. Catalytic ozonation is one of the newest advanced oxidation processes (AOPs) investigated as a strategy to improve the quality of wastewater prior to discharge in the environment. The present Ph.D. thesis focused on expending the knowledge about catalytic ozonation and identify novel materials as efficient catalysts for CECs removal and wastewater disinfection. The results of this research are presented in two manuscripts. The first manuscript reports on the screening of the potential catalysts, on the apparent reaction kinetics, and on the reusability of the most promising catalysts. The screening was conducted in a semi-batch reactor in MilliQ water (MQW) and synthetic wastewater. TiO2/Al2O3, AL-1010S (Al2O3-based catalyst), and Polonite® were shown to enhance the efficiency of catalytic treatment for the CECs removal and disinfection of E. coli. The apparent kinetic reaction between oxidative species (ozone and hydroxyl radicals) and atrazine (ATZ) was studied in a batch reactor in MQW with the addition of scavengers. The reusability experiments demonstrated that TiO2/Al2O3 and AL-1010S maintained their efficiency over four consecutive days, with removal of ATZ at the level of more than 90% and disinfection efficiency exceeding the one obtained using non-catalytic ozonation by more than 1.5 MPN Log units. Polonite® provided the least stable efficiency as a function of time but provided significant increase in disinfection. The second manuscript reports on the effect of wastewater characteristics (chemical oxygen demand (COD) and nitrite (NO2) concentration) and operating conditions (ozone to catalysts ratio, ozone concentration, and hydraulic retention time (HRT)) on process efficiency using the two most promising materials identified, Polonite® and AL-1010S. The optimal parameters for disinfection and ATZ removal were defined to be 8 g-O3 nm3 of ozone gas concentration, 10 minutes of HRT and a ratio of 0.11 of ozone gas concentration to catalyst loading. Both NO2 and COD concentrations greatly impacted the efficiency of treatment but the use of AL-1010S or Polonite® rendered the process less sensitive to variations of these wastewater characteristics. The benefits of catalytic ozonation using AL-1010S or Polonite® were verified for the disinfection of effluent wastewaters collected from two municipal wastewater treatment plants but analytical challenges limited the information available to conclude on the potential for improved CEC removal.</dc:abstract><ual:supervisor>Viviane Yargeau (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/z316q3744.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/h989r533k</ual:fedora3Handle><dc:subject>Chemical Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Aks65hf43j"><dcterms:title>Experimental and numerical investigations into thermal and hydraulic characteristics of artificial ground freezing</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Mining and Materials</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Alzoubi, Mahmoud</ual:dissertant><dc:abstract>The artificial ground freezing (AGF) system has been extensively employed as an excavation-support method in mining and civil engineering projects. Over the last few decades, AGF system has become one of the most favorable ground-support procedures in critical, long-term environmental projects such as underground uranium mines and hazardous-waste management sites. Despite its advantages, most of the conventional AGF systems require continuous energy input for extended periods of time to maintain sufficient frozen body. Essentially, the AGF process involves transient, multi-phase, conjugate heat transfer and fluid flow in a porous ground and bayonet freeze pipes. These complex phenomena and interactions are not well understood, making it difficult to predict the performance, the thermal ground response and, thus, optimize the system. It is also important to explore and devise new ideas that could lead to a more cost-effective and sustainable AGF system.This dissertation focuses on the thermal and hydraulic characteristics of AGF systems. It starts with reviewing current research and technology of AGF system to identify the research gaps and formulate research directions. Further, a controlled novel laboratory-scale experiment that mimics the AGF process is conceived and developed. The apparatus is thermally controlled and equipped with advanced measurement instrumentation and control systems. It provides a deep understanding of the AGF process and generates a comprehensive database for thorough model validation. The rig is further used to introduce and demonstrate a novel concept of freezing-on-demand (FoD) for the first time to save energy while maintaining safe operation in AGF system.A mathematical model that effectively incorporates the multi-physics, multi-scale transport phenomena in the porous ground structure and the freeze pipes is derived, analyzed, and validated against the experimental data. The validated model is extended to mine field conditions to study the impact of various design and operating parameters, such as pipe spacing, groundwater seepage, ground temperature and freeze brine temperature. The growth of the frozen body and closure time is analyzed by quantifying the net energy flux and groundwater streamlines. The heatlines visualization is further implemented for the first time in AGF process to better understand the heat transfer mechanism that governs the ice growth. The model's framework is then employed to evaluate the energy consumption of the AGF system operates under continuous and FoD modes. The results suggest that the concept of the FoD could reduce energy consumption by up to 46%, as compared to the conventional counterpart which highlights its potential for practical applications.</dc:abstract><dc:abstract>Le système de Congélation Artificielle des Sols (CAS) est une méthode de soutènement d'excavations couramment utilisée dans les projets miniers et civils. Depuis quelques une vingtaine d'années, la CAS est devenue la technique de soutènement de prédilection pour les projets qui on des impacts environnementaux probables critiques et à long terme, tel que les mine d'uranium et les sites de gestion de déchets dangereux. Malgré ses avantages, la majorité des systèmes de CAS conventionnels nécessitent une source énergétique constante et continue sur de longues périodes afin de maintenir une congélation du sol sécuritaire. Le processus de CAS est un produit de l'écoulement des fluides ainsi que du transfert de chaleur transitoire, multi-phase et conjugué qui ont lieu dans les tubes de réfrigération en baïonnette et dans le sol poreux. La compréhension limitée de ces phénomènes et interactions complexes complique la prédiction de la performance du système et de la réponse thermique du sol, et en conséquent nuit à l'optimisation de ces systèmes. L'exploration de nouvelles idées et nouveaux paradigmes pourrait aussi amener des améliorations au niveau des coûts et des impacts environnementaux des systèmes de CAS.Cette dissertation se concentre sur les caractéristiques thermales et hydrauliques des systèmes CAS. Au début, une revue des recherches et technologies des systèmes de CAS cerne les lacunes de recherches et formule une direction de recherche. À cette fin, une nouvelle plateforme expérimentale à échelle de laboratoire reproduisant les conditions et processus de CAS est conçue et créée. Cet équipement permet un contrôle thermique étendu et contient une instrumentation avancée de lecture thermique qui permet une compréhension en profondeur des processus de CAS ainsi qu'une base de données compréhensive pour une validation approfondie de modèles numérique. La plateforme expérimentale est de plus utilisée pour introduire et démontrer le nouveau concept de Congélation sur Demande (CsD) afin de diminuer la demande énergétique tout en maintenant la sécurité du système.Le modèle mathématique choisi incorpore efficacement les phénomènes de transport multi-échelle et multi-physiques dans les structures poreuses du sol et dans les tubes de congélation. Ce modèle est dérivé, analysé et validé grâce aux données expérimentales. La portée du modèle validé est étendue aux dimensions et conditions présentes dans les opérations minières souterraines afin d'étudier l'impact des paramètres de conception et d'opération variés, tel que l'espacement entres les tubes de congélation, l'infiltration souterraine, la température du sol et la température du liquide de congélation. L'analyse de la croissance de la masse congelée et de son temps de fermeture découle de la quantification du flux énergétique net et des lignes de courant de l'eau souterraine. De plus, les lignes de chaleur sont utilisées pour la première fois dans le contexte de CAS afin d'aider à la compréhension des mécanismes de transferts de chaleur qui gouvernent la croissance du corps congelé. Le cadre du modèle est ensuite utilisé pour évaluer et comparer la consommation énergétique du système de CAS en mode continu contre une opération en CsD. Les résultats suggèrent que le concept de CsD pourrait réduire la consommation d'énergie jusqu'à 46% par rapport à une utilisation conventionnelle. Cette amélioration souligne le potentiel de CsD pour des applications pratiques.</dc:abstract><ual:supervisor>Agus Sasmito (Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/tm70mx75j.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/ks65hf43j</ual:fedora3Handle><dc:subject>Mining and Materials</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ak643b3358"><dcterms:title>Modelling neuromuscular disorders: from the animal model to state-of-the-art stem cell cultures</dcterms:title><ual:graduationDate>2019</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Integrated Program in Neuroscience</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><ual:dissertant>Larroquette, Frederique</ual:dissertant><dc:abstract>Les troubles neuromusculaires forment un large groupe de maladies débilitantes affectant principalement les systèmes moteurs. Dans la majorité des cas, les mécanismes impliqués dans le dévelopement de ces maladies sont peu compris et aucun traitement efficace n'est disponible. Dans le contexte de maladies neurodégénératives, il est difficile d'obtenir des échantillons de patients. Pour cette raison, la recherche repose principalement sur l'utilisation de modèles cellulaires ou animaux. Cependant, pour la plupart de ces troubles, la création de nouveaux modèles est encore nécessaire pour étudier plus efficacement les mécanismes pathologiques, et améliorer le processus de découverte de médicaments. Cette thèse est focalisée sur deux maladies neuromusculaires toujours incurables, la sclérose latérale amyotrophique (SLA) et l'atrophie musculaire spinale et bulbaire (AMSB), pour lesquelles de nouveaux modèles ont été créés et caractérisés. Ces deux pathologies partagent des caractéristiques communes, incluant la dégénérescence des neurones moteurs, la fonte musculaire et le déclin moteur progressif. Ainsi, malgré les éléments distinctifs de ces deux maladies, la compréhension des mécanismes pathologiques de l'une pourraient aussi aider à la compréhension de l'autre. Un nouveau modèle murin de SLA a été créé, basé sur la mutation du gène Vapb. Contrairement aux précédents modèles souris créés pour ce gène, ces animaux expriment plusieurs phénotypes attendus, tels que le déclin moteur progressif, la dénervation musculaire, les défauts de jonctions neuromusculaires, le stress neuronal et la formation d'inclusions cellulaires contenant la protéine VAPB.Pour l'AMSB, des cellules induites pluripotentes humaines générées depuis des individus sains et des patients AMSB ont été différentiées en neurones moteurs. Ces neurones ont été caractérisés et certains phénotypes pathologiques ont été investigués dans les lignées de patients. Les premières étapes d'optimisation pour générer des co-cultures entre neurones moteurs et muscles ont aussi été réalisées. Une fois perfectionné, cet outil pourrait être utilisé pour l'étude des mécanismes de la maladie dans un modèle humain, ainsi que pour le criblage de nouveaux médicaments.</dc:abstract><dc:abstract>Neuromuscular disorders form a large group of debilitating diseases primarily affecting motor systems. For the majority of them, the mechanisms involved in pathogenesis are poorly understood and no efficient therapies are available. In the context of neurodegeneration, patient samples are not easily accessible. Thus, research relies mostly on cellular and animal models to study these disorders. However, in most cases, new models are still required to better dissect pathological mechanisms and optimize the drug discovery process.  In this thesis, the focus was given to two yet untreatable neuromuscular diseases, amyotrophic lateral sclerosis (ALS) and spinal and bulbar muscular atrophy (SBMA), for which new models were generated and characterized. Both disorders share common hallmarks, including motor neuron degeneration, muscle wasting and progressive motor decline. Thus, even though they are distinguishable conditions, unravelling pathological mechanisms of one disorder might also help understand degeneration occurring in the other.   A new knock-in mouse model of ALS was created, based on a mutation in the ALS-related gene Vapb. Unlike previous Vapb murine models, these knock-in mice recapitulated expected disease phenotypes, such as progressive motor decline, muscle denervation, neuromuscular junctions defects, motor neuron stress and the formation of VAPB-positive cellular inclusions. For SBMA, human induced pluripotent stem cells derived from healthy individuals and SBMA patients were differentiated into motor neurons (MNs). These MNs were shown to differentiate properly and pathological phenotypes were investigated in the patient lines. The first optimization steps to generate MN-muscle co-cultures were also undertaken. Once perfected, this tool could be used to dissect SBMA pathogenesis in a human model and for therapeutic compound screening. </dc:abstract><ual:supervisor>Edward A Fon (Internal/Supervisor)</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/7d278w49f.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/k643b3358</ual:fedora3Handle><dc:subject>Neuroscience</dc:subject></rdf:Description></rdf:RDF>