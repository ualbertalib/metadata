<?xml version="1.0" encoding="UTF-8"?><rdf:RDF xmlns:oai="http://www.openarchives.org/OAI/2.0/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:ual="http://terms.library.ualberta.ca/" xmlns:bibo="http://purl.org/ontology/bibo/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:schema="https://schema.org/" xmlns:etdms="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Azc77st44d"><ual:graduationDate>1965</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Soil Science</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Exchange of sodium on clay minerals by leaching with calcium sulphate</dcterms:title><ual:dissertant>Chaudhry, Ghulam Haider</ual:dissertant><dc:abstract>Accumulation of sodium in soil is a serious problem in arid and semi-arid regions of the world. Millions of acres of once fertile land have been thrown out of cultivation and-millions more are being added every year. The magnitude of the problem can be visualized from the fact that in Alberta alone 10 million acres are either seriously or partially affected by excess salinity and/or exchangeable sodium. In West Pakistan 100,000 acres go out of cultivation annually because of this menace and in the United States, out of 300 million acres under irrigation, between 25 and 30 percent are affected to varying degrees. [...]</dc:abstract><ual:supervisor>Warkentin, B.</ual:supervisor><ual:supervisor>Carter, A. L.</ual:supervisor><ual:supervisor>MacKenzie, A. F.</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/1z40kx29v.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/zc77st44d</ual:fedora3Handle><dc:subject>Soil Science</dc:subject><dc:subject>Soil chemistry</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A7s75dh02z"><ual:graduationDate>1965</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of French Language and Literature</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Grotesques et maniaques dans A la recherche du temps perdu</dcterms:title><ual:dissertant>Charney, Ann Korsower</ual:dissertant><dc:abstract>De même que le critique est l'ombre de l'écrivain, l'oeuvre artistique est une sorte de miroir qui renvoie toutes les apparences qui s'y reflètent. C'est ainsi que A la recherche du temps perdu fait surgir à chaque nouvel examen minutieux, une nouvelle image de la réalité, et aboutit à la création d'un monde qui brave tout ce que nous connaissons ou pouvons imaginer. L'univers entier y trouve son double, et toutes les vies sont résumées dans l'aventure singulière qui est l'oeuvre de Proust. C'est comme si l'auteur, émule de l'Eternel, avait créé sa propre Genèse. [...]</dc:abstract><ual:supervisor>Lariviere, H.</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/r207ts585.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/7s75dh02z</ual:fedora3Handle><dc:subject>French</dc:subject><dc:subject>Proust, Marcel, 1871-1922. À la recherche du temps perdu</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Afb494c75t"><ual:graduationDate>1965</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Physiology</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Semipermeable aqueous microcapsules</dcterms:title><ual:dissertant>Chang, Thomas Ming Swi</ual:dissertant><dc:abstract>The title of this thesis requires some explanation. The term "microcapsules" is a coinage of my own. The Concise Oxford Dictionary gives several definitions of "capsule" (from Latin capsa, a case). Two of these definitions are relevant to my usage: a capsule is a "membranous envelope (Physiol.)" or a "gelatine envelope enclosing pill (Med.)". A "semipermeable aqueous microcapsule" is therefore an envelope of semipermeable membrane enclosing a very small aqueous compartment. At this point it may be useful to discuss also the terms "membrane" and "semipermeable". [...]</dc:abstract><ual:supervisor>MacIntosh, F.</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/zs25xd092.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/fb494c75t</ual:fedora3Handle><dc:subject>Physiology</dc:subject><dc:subject>Cell Membrane Permeability</dc:subject><dc:subject>Membranes, Artificial</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Af1881q484"><ual:graduationDate>1965</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Social Work</schema:inSupportOf><dc:contributor>School of Social Work</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Views on professional collaboration for mental health</dcterms:title><ual:dissertant>Chang, James G.</ual:dissertant><dc:abstract>Thirty psychiatrists and social workers were interviewed concerning their views on: (1) the feasibility of collaboration between psychiatric treatment centers and community group-work recreational agencies in the provision of after-care services for discharged mental patients; and (2) a number of theoretical assertions on social isolation, affects of prolonged hospitalization, plight of the unattached person, need for after-care services, and the desirability of collaboration. The sample of respondents were chosen on the basis of seniority in their professions and the administrative responsibilities they assumed in their respective institutions. An interview guide was constructed and the interviews were conducted by the writer. [...]</dc:abstract><ual:supervisor>Katz, M.</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/8049g842h.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/f1881q484</ual:fedora3Handle><dc:subject>Social Work</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A5h73q055j"><ual:graduationDate>1965</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Social Work</schema:inSupportOf><dc:contributor>School of Social Work</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Social adaptation of the hemiplegic patients: a study of the psycho-social, environmental and cultural aspects of illness and disability and their implications for the social worker in rehabilitation of the hemiplegic patients</dcterms:title><ual:dissertant>Chan, Peggy J. Y.</ual:dissertant><dc:abstract>This review examines the opinions of a number of physicians, social workers, psychologists, sociologists and psychiatrists on the psychosocial, environmental and cultural aspects of illness and disability and their implications for the social worker in the rehabilitation of the hemiplegic patients, as reflected in the professional literature. The review was organized into five areas, namely, a brief description of the nature of hemiplegia as a medical condition, a study of the possible personality change and the psychological functions of the hemiplegic patient, an analysis of the social adaptation problems of the hemiplegic patient, a study of the suggestions reflected in the literature, concerning the role of the social worker in the rehabilitation of the hemiplegic patient, and finally, a study of the professional team collaboration. [...]</dc:abstract><ual:supervisor>Shiner, E. V.</ual:supervisor><ual:supervisor>Katz, M.</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/rv042x52q.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/5h73q055j</ual:fedora3Handle><dc:subject>Social Work</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Af1881q49d"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Faculty of Dentistry</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Surface reactivity of tooth enamel with dyes, oxidizing agents and magnesium ions and its effect on tooth color</dcterms:title><ual:dissertant>Abdallah, Mohamed Nur</ual:dissertant><dc:abstract>Enamel, the outer protective layer of human teeth, is constantly interacting with its surrounding harsh environment. These interactions play a major role in many mechanisms that affect the dental health such as tooth caries, tooth discoloration and plaque formation. Accordingly, most treatments used to maintain and/or restore dental health focus first on the enamel surface.    Even though most of the enamel structure has been thoroughly studied, many of the enamel surface features, and the chemical reaction that occur on it, are not well understood. Extrinsic tooth discoloration poses a major problem to many patients and dentists.  Most causes of extrinsic tooth staining have been well identified and are usually treated with hydrogen peroxide. However, the mechanism of extrinsic tooth discoloration and tooth bleaching using peroxide oxidizers are not fully understood. It is unknown why certain staining molecules attach to the enamel surface, whether peroxide radicals make teeth whiter by removing these stains, and why sometimes hydrogen peroxide does not work. Also, treating darkened teeth with peroxide agents has its limitations and disadvantages. This has pushed us to look for better and less harmful whitening agents.  Recent studies have revealed that there is a correlation between crystallographic characteristics of enamel and its physical properties, such as tooth shade and microhardness. This discovery predicts that tooth properties can be changed by modifying its crystallographic structure. Since magnesium ions are known to react with synthetic hydroxyapatite and affect its crystallographic properties, it is possible that magnesium ions could react with dental enamel and induce changes in dental enamel crystallographic, optical and mechanical properties. Several significant conclusions and achievements are presented in this thesis. We demonstrated the presence of a carbon rich layer on the surface of enamel that contains relatively high amounts of calcium. This layer might explain the high staining ability of certain types of anionic staining agents that are among the most common causes of external tooth discoloration.   Moreover, we showed that hydrogen peroxide does not induce significant changes in tooth enamel organic and inorganic relative contents, and it whitens teeth just by oxidizing their organic matrix. This finding is of great clinical significance since it explains the mechanism of tooth bleaching and the reasons behind the limited predictability of the treatment outcomes. Finally, we showed for the first time that magnesium ions can react with tooth enamel and induce a reduction in the size of enamel hydroxyapatite nanocrystals. This change in crystallography affected the enamel optical and mechanical properties; making the enamel harder and whiter.  This is a new method that can be exploited to whiten teeth without using peroxide-based bleaching agents. We concluded that crystallographic ultrastructure plays a key role in defining the tooth enamel properties which can be tailored through ionic substitution for improvement of optical and mechanical properties without causing the possible negative effects of peroxide agents.</dc:abstract><dc:abstract>L'émail est la couche protectrice externe des dents humaines en constante interaction avec son environnement hostile. Ces interactions jouent un rôle important dans de nombreux mécanismes qui influencent la santé dentaire, tels que les caries dentaire, la coloration dentaire et la formation de plaque. Par conséquence, la majorité des traitements utilisés pour maintenir et/ou restaurer la santé dentaire se concentre principalement sur la surface de l'émail. Tandis que la structure de l'émail a été largement étudiée, les caractéristiques de sa surface, ainsi que les réactions chimiques se produisant à son niveau ont rarement été décrites. La coloration extrinsèque des dents pose un problème majeur pour certains patients et dentistes. La majorité des causes de colorations extrinsèques des dents ont été bien identifiées et sont habituellement traitées avec du peroxyde d'hydrogène. Cependant, le mécanisme de coloration extrinsèque des dents et de blanchiment des dents à l'aide des oxydants du peroxyde ne sont pas entièrement décrits. Les raisons pour lesquelles certaines molécules colorantes s'attachent à la surface de l'émail, comment les radicaux de peroxyde peuvent blanchir les dents en enlevant ces colorations, ainsi que la raison pour laquelle le peroxyde d'hydrogène n'est pas optimal en terme de blanchiment des dents, restent toujours méconnus. De plus, le traitement avec des agents de peroxyde de dents noircies présente certaines limitations et inconvénients. Ce qui nous a motivés à intensifier les recherches pour de meilleurs agents de blanchiment avec le moins d'effets nuisibles.Des études récentes ont montré qu'il existait une corrélation entre les caractéristiques cristallographiques de l'émail et ses propriétés physiques, comme la couleur de la dent et la microdureté. Cette découverte prédit que les propriétés de la dent peuvent être changées par la modification de sa structure cristallographique. Comme les ions du magnésium sont connus de leur capacité de réagir avec l'hydroxyapatite synthétique et d'affecter ses propriétés cristallographiques, il est possible que ces ions puissent réagir avec l'émail dentaire et induire des changements cristallographiques à son niveau ainsi que des changements de ses propriétés optiques et mécaniques.Plusieurs conclusions et réalisations importantes sont présentées dans cette thèse. Nous avons montré la présence d'une couche riche en carbone sur la surface de l'émail qui contient des quantités relativement élevées de calcium. Cette couche pourrait expliquer la capacité colorante élevée de certains types d'agents anioniques, qui sont parmi les causes les plus communes de la coloration extrinsèque des dents. De plus, nous avons montré que le peroxyde d'hydrogène ne provoque pas de changements significatifs dans le contenu organique et inorganique relatif à l'émail des dents, ainsi qu'il blanchit les dents uniquement en oxydant leur matrice organique. Cette conclusion est d'une valeur clinique importante car elle explique le mécanisme de blanchiment des dents et les raisons de la prévisibilité limitée des résultats du traitement. Enfin, nous avons montré pour la première fois que les ions du magnésium puissent réagir avec l'émail des dents et provoquent une réduction de la taille des nano-cristaux d'hydroxyapatite. Ce changement dans la cristallographie affecte les propriétés optiques et mécaniques de l'émail et le rend plus dur et plus blanc. Cette nouvelle méthode peut être exploitée pour blanchir les dents sans avoir recours à l'utilisation d'agents de blanchiment à base du peroxyde. Nous avons conclu que l'ultrastructure cristallographique joue un rôle clé dans la définition des propriétés de l'émail des dents, ce qui peut être ajusté par la substitution ionique afin d'améliorer les propriétés optiques et mécaniques et sans causer des effets potentiels nocifs des agents basés sur le peroxyde.</dc:abstract><ual:supervisor>Faleh Tamimi Marino</ual:supervisor><ual:supervisor>Marta Cerruti</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/vd66w3164.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/f1881q49d</ual:fedora3Handle><dc:subject>Health Sciences - Dentistry</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Amc87pv06f"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Natural Resource Sciences</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Nitrogen fertilization and soil mineral nitrogen dynamics to optimize canola yield and nutrition in Québec</dcterms:title><ual:dissertant>Su, Jinghan</ual:dissertant><dc:abstract>Canola is an ideal feedstock for biodiesel production because of its high oil and low saturated fat concentrations. There is interest in producing more canola in Québec, but producers lack fertilization guidelines to optimize high oilseed yield and quality in canola. Nitrogen (N) is the most important determinate of oilseed yield and quality and N fertilization is important for biomass accumulation during the early vegetative stage and for oil synthesis during the reproductive stage. The first objective of this study was to monitor soil mineral N (NO3-N + NH4-N) dynamics and canola straw nutrition in response to N fertilization. Two fertilization methods - a pre-plant and split application of fertilizer N were studied at the Emile A. Lods Agronomy Research Centre on the Macdonald Campus of McGill University at Ste-Anne-de-Bellevue, Québec, using a fractional factorial experimental design. The second objective was to evaluate N use efficiency (NUE) and harvest index (HI) of canola grown in pots containing soils from Ste-Anne-de-Bellevue, St-Augustin-de-Desmaures and Ottawa using a completely randomized design. Split application of a sidedressed N fertilizer did not increase the post-harvest soil mineral N concentration or increase straw nutrition compared with the pre-plant N application. There was considerable spatio-temporal heterogeneity in soil mineral N dynamics, so additional field trials are warranted. The pot study showed inconsistent correlations between straw N concentration and yield in canola grown in the soils collected from Ste-Anne-de-Bellevue (not related), St-Augustin-de-Desmaures (negative), and Ottawa (positive). Straw N concentrations were related to low straw and oilseed yield, indicating there is an optimal straw N concentration to achieve target yields. Seeding in late May and disease occurrence close to the end of flowering stage reduced the oilseed yield more than straw yield. Future research on the pattern of N translocation (e.g.: from leaf to pod, then to oilseed) under Québec climatic conditions will contribute to the development of an N fertilization guideline. Since some soils in Québec have an appreciable soil N supply, knowledge of how much soil N is used to meet canola N requirement will keep N fertilizer costs low while optimizing oilseed yield and quality.</dc:abstract><dc:abstract>Le canola est une matière première idéale pour la production de biocarburant car il a une teneur élevée en huile et basse en gras saturés. Au Québec, les producteurs sont intéressés à cultiver davantage de canola, mais font face à un manque de directives en matière d'engrais nécessaire afin d'obtenir un haut rendement d'huile de qualité à partir du canola. L'azote (N) est chez les oléagineux le facteur le plus important déterminant le rendement et la qualité de l'huile; l'engrais azoté est important pour l'accumulation de biomasse pendant le premier stade végétatif et pour la production d'huile pendant le stade reproductif. Le premier objectif de la présente étude a été de suivre l'évolution de la dynamique de l'azote minéral du sol (NO3-N + NH4-N) et la nutrition de la paille de canola en réponse à l'engrais azoté. Deux méthodes de fertilisation – fertilisation en présemis et fertilisation partagée fractionnée ont été étudiées au Centre de recherche agronomique Emile A. Lods, au campus Macdonald de l'université McGill à Ste-Anne-de-Bellevue, Québec, utilisant un plan d'expérience factoriel fractionnel. Le deuxième objectif a été d'évaluer l'efficacité d'utilisation de l'azote (NUE) et l'indice de récolte (HI) du canola cultivé en pots avec du sol provenant de Ste-Anne-de-Bellevue, de St-Augustin-de-Desmaures et d'Ottawa, utilisant un plan d'expérience entièrement aléatoire (conception de bloc complètement randomisé). La fertilisation fractionnée et l'application d'azote en bande avec de l'engrais azoté de couverture n'a pas augmenté la concentration d'azote minéral du sol après-récolte, ni la nutrition de la paille de canola comparativement à la fertilisation azotée précoce (see correction above for précoce). Dû à l'importante hétérogénéité spatio-temporelle de la dynamique de l'azote minéral du sol, des études sur le terrain additionnelles sont à recommander. L'étude des plants en pots a démontré une corrélation linéaire négative entre la concentration en azote de la paille et le rendement de la paille. Les concentrations en azote de la paille ont été corrélées avec des bas rendements de paille et d'huile, indiquant qu'il existerait une concentration idéale de l'azote de paille pour obtenir les rendements visés. Certains facteurs réduisent la qualité de l'huile ainsi que le rendement de la paille, soit de semer vers la fin mai ainsi que les maladies qui apparaissent lors de la floraison. D'autres études sur la translocation de l'azote (p. ex. de la feuille à la gousse, puis à la graine) sous les conditions climatiques du Québec contribueront au développement des directives en matière de fertilisation azotée. Puisque certains sols du Québec ont des réserves appréciables d'azote du sol, connaître la quantité d'azote du sol nécessaire afin de satisfaire aux besoins en azote du canola permettra de maintenir de bas coûts pour l'engrais azoté, ainsi que d'optimiser le rendement et la qualité de l'huile des oléagineux.</dc:abstract><ual:supervisor>Joann Karen Whalen</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/nc580r08s.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/mc87pv06f</ual:fedora3Handle><dc:subject>Agriculture - Soil Science</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Acj82kb80h"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Chemical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Adsorption and distribution of fluorescent solutes near the articular surface of mechanically injured cartilage</dcterms:title><ual:dissertant>Decker, Sarah</ual:dissertant><dc:abstract>Articular cartilage demonstrates a very limited capability for self-repair and thus injury, when left unnoticed, often results in further degradation of the tissue. Detection of early stage indicators of injury, such as surface and biochemical changes, is necessary to provide possible treatment which could alter the course of degradation. For this reason, the development of cartilage-specific imaging contrast agents is an active area of research aiming to characterize tissue integrity and composition by minimally invasive means. The development of a technique which highlights surface changes in clinical images of cartilage could provide for sensitive indications of post-traumatic injury. The objective of this thesis was therefore to examine solute adsorption and distribution near the articular surface of mechanically injured cartilage for potential use in cartilage integrity assessment.Using viable, live cartilage explants injured by an established mechanical compression protocol, solute distributions were observed after absorption and subsequent desorption to assess solute-specific matrix interactions for three common fluorophores (fluorescein isothiocyanate (FITC), tetramethylrhodamine isothiocyanate (TRITC) and carboxytetramethylrhodamine (TAMRA)). Both absorption and desorption processes demonstrated a trend of significantly less solute adsorption at surfaces of fissures compared to adjacent intact surfaces of damaged explants or surfaces of uninjured explants. Surface adsorption of solute was strongest for FITC and weakest for TAMRA; no solutes negatively affected cell viability. Results support the development of imaging agents which highlight distinct differences between fissured and intact cartilage surfaces. </dc:abstract><dc:abstract>Le cartilage articulaire démontre une capacité très limité pour l'autoréparation ainsi une lésion, lorsqu'elle est laissé inaperçue, peut souvent entraîner la dégradation plus pire. La détection des premiers stades de lésion, tel que les changements biochimiques ou structurels, est nécessaire pour fournir les traitements qui pourrait altérer l'évolution de la dégradation. Pour cette raison, le développement des agents d'imageries spécifique au cartilage est un domaine actif de recherche avec l'intention de caractériser la composition et l'intégrité du tissu par les méthodes qui sont minimalement invasive. Le développement d'une technique qui souligne les changements de surface dans les images cliniques de cartilage pourrait fournir les indications sensibles des lésions post-traumatiques. L'objectif de cette thèse était donc d'examiner l'adsorption et la distribution des solutés près de la surface articulaire du cartilage mécaniquement blessé.En utilisant les échantillons de cartilage vivants qui ont été blessé par un protocole de la compression mécanique déjà établie, les distributions de soluté ont été étudies après les processus de l'absorption et désorption pour évaluer les interactions de soluté spécifique à la matrice pour trois solutés fluorescents communes (fluorescein isothiocyanate (FITC), tetramethylrhodamine isothiocyanate (TRITC) et carboxytetramethylrhodamine (TAMRA)). Les deux processus ont démontré une tendance de l'adsorption de soluté significativement moins pour les surfaces de fissures comparé aux surfaces adjacentes et intactes des échantillons endommagés ou aux surfaces des échantillons indemnes. L'adsorption de soluté était le plus fort pour FITC et le plus faible pour TAMRA; les solutés on eu aucun effet négatif sur la viabilité des cellules. Les résultats sont favorables au développement des agents d'imageries qui souligne les différences entre les surfaces de cartilage fissurées ou intactes.  </dc:abstract><ual:supervisor>Thomas Quinn</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/w3763b296.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/cj82kb80h</ual:fedora3Handle><dc:subject>Engineering - Chemical</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Asj139549f"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Mathematics and Statistics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Copula-based tests of independence for bivariate discrete data</dcterms:title><ual:dissertant>Murphy, Orla</ual:dissertant><dc:abstract>De nouvelles statistiques sont proposées pour tester l'indépendance de deux aléas non continus. Ces statistiques, qui mènent à des tests convergents, sont des fonctionnelles de type Cramér–von Mises et Kolmogorov–Smirnov de la copule en damier. La puissance des nouveaux tests est comparée par simulation à celle des tests fondés sur les statistiques du khi-deux de Pearson, du rapport des vraisemblances et de la statistique de Zelterman souvent utilisées dans ce contexte. Pour étudier leur puissance, on génère des données de cinq familles de lois bivariées dont les marges peuvent être connues ou non. Dans tous les cas considérés, les nouveaux tests s'avèrent plus puissants que les tests standard. À l'instar du test de Zelterman, les nouveaux tests maintiennent leur seuil lorsque les données sont clairsemées; comme on le sait, ce n'est pas le cas des tests du khi-deux de Pearson et du rapport des vraisemblances. À la lumière des résultats présentés ici, les nouvelles statistiques de Cramér–von Mises peuvent être recommandées pour tester l'indépendance entre deux aléas en présence d'ex æquo dans les données.</dc:abstract><dc:abstract>New statistics are proposed for testing the hypothesis that two non-continuous random variables are independent. These statistics, which lead to consistent tests, are Cramér–von Mises and Kolmogorov–Smirnov type functionals of the checkerboard copula. The power of the new tests is compared via simulation to those based on the Pearson chi-squared, likelihood ratio, and Zelterman statistics often used in this context. To study their power, data are generated from five families of bivariate distributions whose margins may be known or not. In all cases considered, the new tests are seen to be more powerful than the standard tests. The new tests and the Zelterman statistic maintain their levels when the data are sparse; as is well known, this is not the case for Pearson's chi-squared and the likelihood ratio test. On the basis of the results presented here, the new Cramér–von Mises statistics can be recommended to test the independence between two random variables in the presence of ties in the sample.</dc:abstract><ual:supervisor>Johanna Neslehova</ual:supervisor><ual:supervisor>Christian Genest</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/g158bm84n.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/sj139549f</ual:fedora3Handle><dc:subject>Pure Sciences - Statistics</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Adv13zx68q"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of Political Science</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Responsiveness in non-democratic regimes: The role of elections, legislatures and parties</dcterms:title><ual:dissertant>Boulianne Lagacé, Clara J</ual:dissertant><dc:abstract>Le but de ce mémoire est de comprendre comment des régimes autoritaires et semi-autoritaires peuvent en venir à répondre aux besoins de leur population en l'absence d'élections justes et libres, et parfois même mieux que certaines démocraties. Ce mémoire, pour répondre à cette question, se concentre sur des pays situés en Asie du Sud-est. Plusieurs régimes autoritaires et semi-autoritaires dans la région ont démontré une forte tendance à répondre aux besoins de leur population, comme le Vietnam, la Malaisie et Singapour, alors que les régimes démocratiques ont souvent échoué à remplir une telle fonction. Pour expliquer ces résultats surprenant, l'argument avancé est que la présence d'institutions nominalement démocratiques, telles que des élections, parlements et partis, a grandement aidé les régimes non-démocratiques à répondre aux demandes de leur population. De telles institutions communiquent de l'information sur les préférences de la population, ce qui aide les régimes à savoir comment répondre à ses demandes et besoins, alors qu'elles peuvent également améliorer la capacité des régimes à mettre en œuvre des politiques à cet effet. Cependant, pour avoir un tel impact, les élections doivent être semi-compétitives, les législatures doivent représenter certains secteurs de la société, et les partis doivent être institutionnalisés. Dans de telles conditions, des institutions nominalement démocratiques aident les régimes autoritaires et semi-autoritaires à répondre à leur population. L'absence de certaines de ces conditions au sein des régimes démocratiques en Asie du Sud-est explique pour sa part leur faible tendance à faire de même. Puisque la mesure dans laquelle les régimes répondent aux besoins de leur population est fortement liée au bien-être de cette dernière, il semble crucial de comprendre comment des régimes non-démocratiques peuvent répondre de cette façon, alors que certains régimes démocratiques n'y parviennent toujours pas.</dc:abstract><dc:abstract>The purpose of this thesis is to understand how authoritarian and semi-authoritarian regimes can become responsive in the absence of free and fair elections, sometimes even more so than democracies. To address this issue, the thesis focuses on cases drawn from Southeast Asia. Many semi-authoritarian and authoritarian regimes in the region seem to be responsive, such as Vietnam, Malaysia and Singapore, while democracies have often failed to respond in a similar manner. To account for these surprising results, the argument put forth in this thesis is that the presence of nominally democratic institutions - elections, legislatures and parties - can contribute greatly to the responsiveness of non-democratic regimes. Such institutions make important information about a population's preferences available, and responsiveness therefore becomes easier, while they can also improve a regime's capacity to implement responsive policies. To contribute to responsiveness in this way, elections need to be semi-competitive, legislatures have to allow for some representation, and parties must be institutionalized. Under these conditions, nominally democratic institutions favor responsiveness in non-democratic regimes. Meanwhile, the absence of some of these requirements in Southeast Asian democracies helps account for their low levels of responsiveness. Since responsiveness is deeply linked to the well-being of the populations living under different regimes, it seems crucial to understand how non-democratic regimes can become responsive, while democratic regimes can fail to become so.</dc:abstract><ual:supervisor>Erik Kuhonta</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/vd66w317d.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/dv13zx68q</ual:fedora3Handle><dc:subject>Political Science - General</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Az316q5029"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of History and Classical Studies</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>The military policy of the Hellenistic Boiotian League</dcterms:title><ual:dissertant>Post, Ruben</ual:dissertant><dc:abstract>This thesis analyzes the military history of the Boiotian League during the Hellenistic period (338-200 BC). It argues that Boiotia experienced a large population increase in the fourth century BC followed by a steady population decline throughout the next two centuries caused primarily by environmental collapse. During the late Classical period (490-338 BC), one of the Boiotian League's primary focuses was protecting its plentiful population and agricultural land through an extensive network of fortifications. After the defeat they suffered in the battle of Chaironeia in 338 BC, the Boiotians became vulnerable to attack, and their federal government no longer possessed the resources to maintain this extensive defensive system. The Boiotian League then began to move towards more flexible modes of defense, but this proved too little too late when the Aitolian League inflicted a major defeat on the ill-prepared Boiotians in 245 BC. This forced the government into reforming its military on the model of the Makedonian army and instituting a rigorous training regimen for all Boiotian troops. The environmental and demographic decline occurring at this time drove many Boiotians to poverty, however, and many poor farmers were unable to spare the time to undergo intensive training during the second half of the third century BC. The Boiotian military thus became smaller, more professionalized, better coordinated, and ultimately better able to defend the large territory under the League's control. This allowed the federal government to face foreign threats with a flexible and dynamic defensive force despite the crisis of declining arable land and population it faced at this time.  </dc:abstract><dc:abstract>Cette thèse analyse l'histoire militaire de la Confédération béotienne cours de la époque hellénistique (338-200 av. J.-C.). Il fait valoir que Béotie connu une croissance démographique importante dans le quatrième siècle av. J.-C. suivie d'un déclin de sa population au cours des deux siècles suivants causés principalement par l'effondrement de l'environnement. Au cours de la dernière époque classique (490-338 av. J.-C.), l'une des principale de la Confédération béotienne se concentre protéger sa population a été abondante et les terres agricoles à travers un vaste réseau de fortifications. Après la défaite qu'ils ont subie dans la bataille de Chéronée en 338 av. J.-C., les Béotiens sont devenus vulnérables à l'invasion, et le gouvernement fédéral ne possédait plus les moyens d'entretenir ce vaste système défensif. La Confédération béotienne a alors commencé à se déplacer vers des modes plus souples de la défense, mais cela s'est avéré trop peu trop tard quand la Confédération aitolienne infligé une défaite majeure sur les Béotiens mal préparés en 245 av. J.-C. Cela a forcé le gouvernement à réformer son armée sur le modèle de l'armée macedonienne et en instituant un régime d'entraînement rigoureux pour toutes les troupes béotiens. La dégradation de l'environnement et démographiques se produisent à l'heure actuelle conduit de nombreux Béotiens à la pauvreté, cependant, et de nombreux paysans pauvres n'ont pas pu trouver le temps de suivre une formation intensive au cours de la seconde moitié du IIIe siècle av. J.-C. L'armée béotienne est ainsi devenu plus petit, plus professionnalisée, mieux coordonnée, et finalement mieux à même de défendre le vaste territoire sous le contrôle de la Confédération. Cela a permis au gouvernement fédéral de faire face aux menaces étrangères ayant une force souple et dynamique défensive malgré la crise des terres arables diminue et la population qu'elle fait face en ce moment.</dc:abstract><ual:supervisor>John Serrati</ual:supervisor><ual:supervisor>Hans Beck</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/wd3761121.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/z316q5029</ual:fedora3Handle><dc:subject>History - Ancient</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A9w0326445"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Natural Resource Sciences</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Wild edible plants (WEPs) and their contribution to food security: an analysis of household factors, access and policy in the semi-arid midlands of Kenya</dcterms:title><ual:dissertant>Shumsky, Stephanie</ual:dissertant><dc:abstract>Food insecurity and malnutrition are issues that affect approximately one in seven people worldwide and climate change threatens to increase those risks in the future. Many of the policies that address future food systems emphasize resilience - a combination of flexibility in the face of disturbance and the capacity to adapt to change. In Sub-Saharan Africa many households employ livelihood systems that are highly sensitive to change and cannot adapt well to changing environmental conditions, leaving them vulnerable and reliant on coping strategies. Wild edible plants (WEPs) are a particularly common and effective strategy for coping with food insecurity. This research, conducted in rural Eastern Province, Kenya, suggests that certain demographic characteristics and access conditions are correlated with greater use of WEPs. Food insecure households, and those families lacking off-farm income or with lower levels of assets were found to consume WEPs with greater frequency. Access to WEPs was also a major factor, with smaller farm sizes and increased distance to harvest areas correlated significantly to lower levels of WEP use. After reviewing the existing laws pertaining to State forests, privatization trends of communal land and an increasingly formalized management regime for private land tenure, I find that access to WEPs is declining. Development practitioners', governments' and donor organizations' focus on commercialization and commodity value has led extension agents and land owners to ignore the subsistence value of WEPs, especially for poorer populations. The household characteristics identified in this study are specific enough that they can be used to determine the demographic groups that rely heavily on WEPs, and the access conditions that are likely to increase the ability of those vulnerable groups to employ WEPs as a coping strategy to increase system resilience. Protecting and promoting sustainable use of WEPs could increase the current contribution of these valuable resources to household food security, especially if policies can be tailored for the groups that depend on them the most.</dc:abstract><dc:abstract>L'insécurité alimentaire et la malnutrition affectent environ une personne sur sept à travers le monde et le changement climatique menace d'accroître ces risques à l'avenir. La plupart des politiques qui concernent les systèmes alimentaires futures mettent en relief la résilience - une combinaison de flexibilité face à la perturbation et la capacité de s'adapter au changement. En Afrique sub-saharienne de nombreux ménages utilisent des stratégies de moyens de subsistance qui sont très sensibles aux changements et ne peuvent bien s'adapter aux conditions environnementales, ce qui les rendent vulnérables et dépendants des stratégies de survie. L'utilisation des plantes sauvages comestibles (WEPs) représente une stratégie particulièrement commune et efficace. Cette recherche réalisée dans la Province de l'Est du Kenya suggère que certaines caractéristiques démographiques et conditions d'accès sont en corrélation avec une augmentation de la consommation de WEPs. Les lois forestières dans les zones de conservation, la privatisation des terres communales, et la formalisation des régimes de gestion contribuent à la réduction d'accès aux ressources WEP, tout en mettant l'accent sur la commercialisation et la valeur de ces produits pour l'export, ce qui a provoqué les agents de vulgarisation et les propriétaires fonciers à ignorer la valeur substantielle des WEPs, en particulier pour les populations les plus pauvres. La protection et la promotion de l'utilisation durable des WEPs pourraient augmenter la contribution actuelle de ces ressources importantes à la sécurité alimentaire des ménages, et d'autant plus si les politiques peuvent être adaptées pour les groupes qui dépendent le plus sur les WEPs.</dc:abstract><ual:supervisor>Gordon Hickey</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/2227mt29d.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/9w0326445</ual:fedora3Handle><dc:subject>Agriculture - Forestry and Wildlife</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A6682x728h"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Chemical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Compatibilization of poly(styrene-acrylonitrile) (SAN) / poly(ethylene) blends via amine functionalization of SAN chain ends</dcterms:title><ual:dissertant>Oxby, Keith</ual:dissertant><dc:abstract>Les copolymères de styrène/acrylonitrile (SAN) avec des excellente fidélité en bout de chaîne et des faible polydispersité Mw/Mn (1,10 - 1,30) ont été synthétisés par polymérisation des nitroxydes (NMP) dans une solution de diméthylformamide (DMF) avec d'ester de succinimidyle (NHS) groupe terminal de l'soi-disant SG1 résidus nitroxyde. Ces copolymères ont été stabilisée thermiquement par élimination du groupe N-tert-butyl-N-[1-diéthylphosphono-(2,2-diméthylpropyl) nitroxyde] (SG1), et ensuite modifiée pour former une amine primaire à fonctionnalité en bout de chaine des copolymères (SAN-NH2) . Réactions de couplage homogènes et transformée de Fourier spectroscopie infrarouge (FTIR) a indiqué que le groupe amine a effectivement été placé en bout de chaîne. SAN-NH2 a été réactive mélangée avec l'anhydride maléique greffé  poly(éthylène) (PE) au chargement de 20% en poids à 180 °C et la morphologie obtenue a été comparée à la mélange non réactif. Dans le cas réactif, microscopie électronique à balayage (MEB) ont indiqué plus fines domaines de SAN ~1 um qui étaient stables thermiquement après recuit. Les domaines dispersés SAN ont été réorientés en utilisant un dé canal pour donner domaines allongés avec des rapports d'aspect ~14, ce qui serait souhaitable pour des matériaux barrières.</dc:abstract><dc:abstract>Styrene/acrylonitrile (SAN) copolymers with excellent chain-end fidelity and low polydispersity Mw/Mn (1.10 – 1.30) were synthesized by nitroxide mediated polymerization (NMP) in dimethylformamide (DMF) solution with a succinimidyl ester (NHS) terminal group from the so-called SG1 nitroxide residue.  These copolymers were thermally stabilized by removing the N-tert-butyl-N-[1-diethylphosphono-(2,2-dimethylpropyl) nitroxide] (SG1), and then modified to form primary amine end-functional SAN (SAN-NH2).  Homogeneous coupling reactions and Fourier-transform infrared spectroscopy (FTIR) indicated that the amine group was effectively placed at the chain end.  SAN-NH2 was reactively blended with maleic anhydride grafted poly(ethylene) (PE) at 20 wt.% loading at 180 °C and the resulting morphology was compared against the non-reactive blend. Scanning electron microscopy (SEM) indicated finer SAN domains ~ 1 μm which were thermally stable upon annealing in the reactive case.  The dispersed SAN domains were reoriented using a channel die to impart elongated domains with aspect ratios ~ 14, which would be desirable for barrier materials.</dc:abstract><ual:supervisor>Milan Maric</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/jw827g180.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/6682x728h</ual:fedora3Handle><dc:subject>Applied Sciences - Plastics Technology</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Aq811kp113"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Schulich School of Music</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Automatic guitar tablature transcription online</dcterms:title><ual:dissertant>Burlet, Gregory</ual:dissertant><dc:abstract>Transcrire à la main une tablature pour guitare à partir d'un enregistrement audio est un processus difficile et long, même pour les guitaristes chevronnés. Bien que plusieurs algorithmes aient été créés pour extraire automatiquement les notes d'un enregistrement audio, et d'autres pour préparer des arrangements de notes de tablature pour guitare tels qu'on les retrouve dans la création musicale, aucun environnement n'a été mise en place pour faciliter l'association de ces algorithmes. Le travail qui suit présente un environnement accessible sur l'Internet, permettant la transcription et la préparation d'arrangements de tablatures de guitare, directement à partir d'un enregistrement audio. Cet environnement de transcription, nommée Robotaba, facilite la création d'applications Web, dans lesquelles la transcription polyphonique et les algorithmes d'arrangements de tablature pour guitare peuvent être intégrés. Une telle application Web permet d'obtenir un système unifié, capable de transcrire une tablature pour guitare à partir d'un enregistrement audio numérique, et d'afficher la tablature obtenue dans un navigateur Web. La performance de la transcription polyphonique mise en place et des algorithmes d'arrangements de tablature pour guitare est évaluée à l'aide de plusieurs paramètres et d'un nouvel ensemble de données, constitué de transcriptions manuelles recueillies dans des sites Web consacrés aux tablatures.</dc:abstract><dc:abstract>Manually transcribing guitar tablature from an audio recording is a difficult and time-consuming process, even for experienced guitarists. While several algorithms have been developed to automatically extract the notes occurring in an audio recording, and several algorithms have been developed to produce guitar tablature arrangements of notes occurring in a music score, no frameworks have been developed to facilitate the combination of these algorithms. This work presents a web-based guitar tablature transcription framework capable of generating guitar tablature arrangements directly from an audio recording. The implemented transcription framework, entitled Robotaba, facilitates the creation of web applications in which polyphonic transcription and guitar tablature arrangement algorithms can be embedded. Such a web application is implemented, resulting in a unified system that is capable of transcribing guitar tablature from a digital audio recording and displaying the resulting tablature in the web browser. The performance of the implemented polyphonic transcription and guitar tablature arrangement algorithms are evaluated using several metrics on a new dataset of manual transcriptions gathered from tablature websites.</dc:abstract><ual:supervisor>Ichiro Fujinaga</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/8g84mq89g.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/q811kp113</ual:fedora3Handle><dc:subject>Communications And The Arts - Music</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A7s75dh037"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Schulich School of Music</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>A historical survey of music recommendation systems: Towards evaluation</dcterms:title><ual:dissertant>Qin, Ying</ual:dissertant><dc:abstract>The development of the Internet and the emergence of audio compression technologies have contributed to the realization of making millions of music titles accessible to millions of users. Due to the extensive distribution of music, consumers are being presented with a problem of information overload, while the music industry is being faced with the challenge of personalized promotion and distribution. Music recommendation systems aim to ease the task of finding the music items that might interest the users by generating meaningful recommendations. The recommendation for music is different from those for books and movies, due to its low cost per item, short consumption time, high per-item reuse, highly contextual usage, and numerous item types. Understanding the patterns of music listening and consumption is important to create accurate and satisfying music recommendations. This thesis reviews state-of-the-art music recommendation and discovery methods with the goal of presenting the historical developments in this area. Traditional music recommendation systems can be classied as one of two major kinds: collaborative filtering and content-based filtering. Recently, the research community has broadened its attention to include other aspects, such as hybrid approaches, context awareness, social tagging, music networks, visualization, playlist generation, and group recommendation. For the evaluation of music recommendation systems, researchers or developers need to take into account properties such as accuracy, coverage, confidence, novelty, diversity, and privacy. These properties can be measured in an offline simulation, a user study, or an online evaluation. Suggestions for future work in both the design and the evaluation of music recommendation systems are given.</dc:abstract><dc:abstract>Le développement d'Internet et l'émergence des technologies de compression audio ont contribué à rendre des millions de titres de musique accessibles à des millions d'utilisateurs. Due à la large distribution de musique, les consommateurs ont des problèmes de téléchargement d'information, pendant que l'industrie de la musique faisait face aux défis de la promotion et de la distribution personnalisée. Les systèmes de recommandation de musique ont pour objectif de faciliter la tâche dans la recherche d'articles de musique qui peuvent intéresser l'utilisateur en générant des suggestions signicatives. La recommandation de musique est différente de celle des livres et des films; cette différence est explicable par le bas coût de chaque article, le court temps de consommation, le haut taux de réutilisation de chaque article, l'utilisation hautement contextuelle immédiat et le grand nombre d'articles possibles. La compréhension des schémas d'écoute et de consommation de la musique est importante afin de concevoir des recommandations musicales pertinentes et satisfaisantes. Ce mémoire passe en revue l'état des recherches sur la recommandation musicale et les méthodes de découverte, dans le but de dressez un historique des développements de ce domaine. Les systèmes de recommandation de musique traditionnels se divisent en deux catégories principales: le filtrage collaboratif ou filtrage fonde sur le contenu. Récemment,la communauté de chercheurs a élargit ces champs d'investigation en incluant d'autres aspects: tels que, les approches hybrides, la sensibilité au contexte, le marquage social, les réseaux de musique, la visualisation, la génération de liste de lecture et les recommandations de groupe. Pour l'évaluation des systèmes de recommandation de musique, les chercheurs et les promoteurs ont besoin de prendre en compte des propriétés, comme la précision, la couverture,la confiance, la nouveauté, la diversité et la protection de la vie privée. Méthodologiquement, ces propriétés peuvent être mesurées dans des simulations hors connexion, dont l'étude du comportement des utilisateurs, ou lors d'évaluations en ligne. Des suggestions pour de futures recherches en design et évaluation de systèmes de recommandation de musique seront abordées.</dc:abstract><ual:supervisor>Ichiro Fujinaga</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/rb68xg29p.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/7s75dh037</ual:fedora3Handle><dc:subject>Communications And The Arts - Information Science</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Aj098zf59s"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Laws</schema:inSupportOf><dc:contributor>Faculty of Law</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Straddling the fence of computer programs' patentability: how to foster software invention and innovation</dcterms:title><ual:dissertant>Bruneau, Mathieu</ual:dissertant><dc:abstract>Ce mémoire identifie des moyens accessibles aux décideurs politiques et aux acteurs de l'industrie informatique pour promouvoir l'inventivité et l'innovation de logiciels. Pour ce faire, la clôture de la brevetabilité des programmes informatiques est chevauchée : ne prenant pas parti à ce débat, le point de vue qu'elle procure est utilisé pour apprécier sur deux volets des outils favorisant l'inventivité et l'innovation de logiciels. D'abord, leur faisabilité est évaluée de façon pragmatique en analysant la superstructure du droit international de la propriété intellectuelle, principalement l'Accord sur les aspects des droits de propriété intellectuelle qui touchent au commerce, qui prévoit des dispositions auxquelles les Membres de l'Organisation mondiale du commerce doivent donner effet. Ensuite, des intérêts bénéfiques potentiels de ces mesures sont discutés en lien avec quatre éléments qui justifient la non-brevetabilité des sujets abstraits à l'intérieur de la logique utilitaire des systèmes canadien et américain des brevets, soit la préemption issue de l'exclusivité octroyée par les brevets, la structure par combinaison et accumulation de l'inventivité, les obstructions causées par un trop grand nombre de brevets et la désincarnation. Parmi ces instruments, sont notamment discutés les normes de brevetabilité des programmes informatiques, la prescription d'exploitation des brevets, la révocation de brevets, l'ingénierie inversée, la dépendance au sentier, les clauses de non-concurrence, les effets de l'entreprise réseau sur l'innovation, les pratiques contractuelles en lien avec les brevets, les autorités de concurrence et la rivalité entre les deux principales approches en développement de logiciels : l'appropriation privative et le logiciel libre et ouvert.</dc:abstract><dc:abstract>This thesis identifies means available to industry actors and policy makers to foster invention and innovation in the software industry. To this end, the fence of computer programs' patentability is straddled: not taking any particular position on this debate, the standpoint that this fence provides is used to assess instruments stimulating software invention and innovation on two criteria. First, their pragmatic feasibility is examined by analysing the international law superstructure for intellectual property, mainly the Agreement on Trade Related Aspects of Intellectual Property Rights, which sets minimum standards that Members of the World Trade Organisation have to give effect to. Second, their consequential desirability is assessed by reference to four elements of the utilitarian rationale on which is predicated the exclusion of abstract subject matter from patent-eligibility in Canadian and U.S. patent law, namely, pre-emption, the building-block structure of the inventive process, the risks of patent thickets and disembodiment. Instruments discussed this way include standards for computer programs' patent-eligibility, patent working requirements, revocation of patent rights, reverse-engineering, path dependency, covenants not to compete, models of innovation favoured by the network enterprise, contractual patent practices, antitrust authorities and competition between the two main schemes of software development: exclusionary appropriation and free and open source software.</dc:abstract><ual:supervisor>David Lametti</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/t148fm613.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/j098zf59s</ual:fedora3Handle><dc:subject>Social Sciences - Law</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A4b29b940t"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Real-time specularity detection and recovery</dcterms:title><ual:dissertant>Tian, Qing</ual:dissertant><dc:abstract>Specularity is a very common phenomenon in the real world and confounds many computer vision tasks such as stereo. The first purpose of this thesis is to design a real-time algorithm of specularity detection. After that, with the knowledge of where the specularities are, a stereo correspondence approach robust to specularity is proposed. Finally, a specularity recovery method is presented to recover the underlying diffuse color using the stereo correspondence information. For real-time specularity detection, a new concept of unnormalized Wiener entropy (UW Entropy) is first proposed in this thesis, which has the desirably simple final form and requires no information about the lighting condition, surface structure, imaging process, pre-segmentation, polarization state, and so forth. However, like other specularity detection methods based on color alone, some false positives may be detected. To distinguish between genuine specularities and false positives, a Support Vector Machine is learned in the proposed SpecLBP space as well as three other spaces as comparisons. An alternative version is also presented for the beam-splitter based stereo pairs in the 3D movie industry, where the curse of side-effect of the beamsplitter is turned into a blessing for identifying problematic specularities. After the genuine specularities are spotted, a new specularity-invariant stereo correspondence method is proposed. By constructing an UW Entropy based matching energy and minimizing it in the MAP-MRF framework using graph cuts, a disparity map robust to specularities can be gained, which offers a precious piece of information for specularity recovery in the ending part of this thesis. Experiment results show our methodology's efficacy in real-time specularity detection, specularity-invariant stereo correspondence, as well as specularity recovery and demonstrate our methodolodgy's great potential for the 3D movie industry. By comparing the performance of the proposed SpecLBP code and three other LBP variants, the SpecLBP code's better performance justifies our claim that the best texture code is task specific, not the one that captures the most information.</dc:abstract><dc:abstract>La réflexion spéculaire est un phénomène fréquemment observé dans la nature. Et pourtant, ce type de réflexion pose encore problème à plusieurs algorithmes de vision artificielle telle que l'interprétation de l'imagerie stéréoscopique. Cette thèse a pour premier objectif de concevoir un algorithme temps réel capable de détecter les réflexions spéculaires. Par la suite, connaissant l'endroit où apparait ce phénomène dans l'image, une approche pour la correspondance stéréoscopique robuste aux réflexions spéculaires est proposée. Et enfin, une méthode de récupération de la couleur diffuse sous-jacente aux réflexions est présentée, en tirant profit de l'information acquise par la correspondance stéréo. Pour effectuer la détection des réflexions spéculaires en temps réel, un nouveau concept d'entropie de Weiner non normalisée (entropie UW) est d'abord proposé par cette thèse. L'entropie UW est caractérisée par une formulation analytique simple qui ne requière aucune information supplémentaire sur les conditions d'éclairage, la structure de la surface, la prise d'image, l'état de polarisation de la lumière, aucune présegmentation et ainsi de suite. Cependant, comme d'autres méthodes de détection des réflexions spéculaires basées seulement sur la couleur, de faux positifs peuvent être obtenus. Pour faire la distinction entre les réflexions spéculaires véritables et les faux positifs, un séparateur à vaste marge (SVM) est entrainé dans l'espace « SpecLBP » proposé, et également dans trois autres espaces de la littérature, à titre de comparaison. Une adaptation du système est également présentée pour traiter les paires d'images stéréo obtenues à l'aide d'un miroir semi-argenté, tel qu'utilisé dans l'industrie du film 3D, où les effets indésirables du miroir deviennent plutôt d'une aide précieuse pour localiser les réflexions problématiques. Pour faire suite à la détection des réflexions authentiques, une nouvelle méthode de correspondance stéréo robuste aux réflexions est proposée. En formulant l'entropie UW sous forme d'énergie, et en minimisant cette énergie dans le cadre d'un PAM-MRF (résolu en utilisant des coupes de graphes), une carte de disparité stéréoscopique robuste aux réflexions peut être acquise. Cette évaluation de la disparité en présence des réflexions est une information précieuse pour la récupération de la couleur qui est présentée dans la dernière partie de cette thèse.Les résultats expérimentaux obtenus démontrent l'efficacité des méthodes proposées pour la détection des réflexions spéculaires en temps réel, pour la correspondance stéréo en présence de réflexions, ainsi que pour la récupération de la couleur sous-jacente aux réflexions. Les expérimentations permettent également de démontrer le potentiel de cette méthode pour l'industrie du cinéma 3D. En comparant la performance de la représentation « SpecLBP » proposée et les trois autres variantes de LBP, la performance supérieure du code « SpecLBP » valide notre hypothèse selon laquelle une représentation de la texture est meilleure, lorsqu'adaptée à une tâche spécifique, et non lorsqu'elle capture un maximum d'informations.</dc:abstract><ual:supervisor>James J. Clark</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/v118rh796.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/4b29b940t</ual:fedora3Handle><dc:subject>Engineering - Electronics and Electrical</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Aqz20sx32p"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Chemical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Experimental measurement of air-water capillary pressure curves at elevated temperatures</dcterms:title><ual:dissertant>Shrestha, Kiran</ual:dissertant><dc:abstract>A capillary pressure curves provides important information about the porous system such as porosity, breakthrough pressure, fluid–solid wettability and capillary hysteresis. The measurement of capillary pressure curves is one of the most commonly adopted methods of measuring wettability in a porous system. However, to date these measurements are done only at room temperature because of the limitations of utilising existing equipment at higher temperatures. The capillary behaviour of liquid in porous system can be a different when subjected to harsh condition such as high temperature and pressure. An experimental setup has been designed and developed to measure air-water capillary pressure curves for gas diffusion layers (GDLs) used in polymer electrolyte membrane fuel cells at elevated temperatures.  Experiments were conducted at various temperatures in the direction of increasing and decreasing temperatures for Toray 120 and Toray090 with varying PTFE loadings.  Notable shifts in the capillary behavior were seen and in some cases the shifts were of the same size as PTFE addition.  In untreated samples the results suggest that GDL wettability changes with temperature once the temperature dependence of the surface tension has been accounted for.  In treated samples, however, the wettability remains more or less constant with temperature.  This behavior is in agreement with the temperature dependent values of water contact angle on PTFE and graphite. Observed shift with temperature for treated samples are more or less reversible during decreasing temperatur</dc:abstract><dc:abstract>A courbes de pression capillaire fournit des informations importantes sur le système poreux tels que la porosité, la pression de fuite, le liquide-solide mouillabilité et l'hystérésis capillaire. La mesure des courbes de pression capillaire est une des méthodes les plus couramment adoptée pour mesurer la mouillabilité dans un système poreux. Cependant, à ce jour, ces mesures sont effectuées uniquement à la température ambiante en raison des limitations de l'utilisation des équipements existants à des températures élevées. Le comportement capillaire de liquide dans le système poreux peut être un différent lorsqu'elle est soumise à l'état dur, comme la température et une pression élevées. Un dispositif expérimental a été conçu et développé pour mesurer air-eau courbes de pression capillaire pour les couches de diffusion de gaz (GDL) utilisés dans les cellules à électrolyte polymère à combustible à membrane à des températures élevées. Expériences ont été réalisées à différentes températures dans le sens d'une augmentation et la diminution des températures de Toray120 et Toray090 avec différents chargements PTFE. Changements notables dans le comportement capillaire ont été observées et, dans certains cas, les changements étaient de la même taille que l'addition de PTFE. Dans les échantillons non traités les résultats suggèrent que les changements de mouillabilité GDL avec la température une fois que la dépendance en température de la tension de surface a été pris en compte. Dans les échantillons traités, cependant, la mouillabilité reste plus ou moins constant avec la température. Ce comportement est en accord avec les valeurs dépendantes de la température de l'angle de contact de l'eau de PTFE et de graphite. Décalage observé avec la température pour les échantillons traités sont plus ou moins réversible pendant la température diminue.</dc:abstract><ual:supervisor>Jeff Gostick</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/v118rh80z.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/qz20sx32p</ual:fedora3Handle><dc:subject>Engineering - Chemical</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Aqb98mj855"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Mechanical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Improved unsteady aerodynamic influence coefficients for dynamic aeroelastic response</dcterms:title><ual:dissertant>Murphy, Quinn</ual:dissertant><dc:abstract>Le flottement, ou instabilité dynamique des ailes d'un avion dû à sa charge aérodynamique, doit être considéré lors de la conception d'un avion. Pour cette raison, la méthode d'analyse de l'aéroélasticité d'un avion développée par Bombardier Aéronautique, doit être améliorée. La nouvelle méthode, utilisant un code de calcul dynamique des fluides, ou Computational Fluid Dynamics(CFD), remplace la méthode originale du "Doublet Lattice Method". La nouvelle charge aérodynamique est transmise au module d'aéroélasticité de NASTRAN à l'aide d'un "Coefficient d'Influence Aérodynamique (AIC)" amélioré. Précédemment, seules les données stationnaires étaient de  haute fidélité et un facteur de correction était nécessaire pour compléter les données instationnaires. Ces données fournissaient de bons résultats pour les calculs du flottement en régimes subsonique et transsonique. Cependant, pour les cas de régimes transsonique et supersonique, des données aérodynamiques instationnaires sont nécessaires pour améliorer les résultats. Cette étude introduit donc les données instationnaires de haute fidélité provenant du calcul dynamique des fluides. Les données instationnaires générées par le calcul dynamique des fluides sont obtenues au moyen  de la "Méthode par Transpiration". Cette méthode permet de prendre en compte la composante instationnaire tout en minimisant le temps de calcul nécessaire pour déformer et remailler le maillage aérodynamique à chaque pas de temps. La méthode par Transpiration a été validé par deux tests standards, pour des cas de déflections statiques et de mouvements cycliques instationnaires. Une fois cette méthode validée, les résultats de haute fidélité du calcul dynamique des fluides peuvent être utilisés pour la méthode AIC.La méthode AIC est initiée avec des modes de bases obtenus pour des ailes, ce qui permet de calculer une base aérodynamique. Cette base aérodynamique est ensuite transférée à NASTRAN en utilisant la méthode AIC. La forme des modes naturels de la nouvelle configuration, avec les bases modales de la méthode AIC, permet d'approximer la charge aérodynamique de la nouvelle configuration. Cette charge est ensuite utilisée par NASTRAN pour résoudre l'analyse du flottement pour la nouvelle configuration.</dc:abstract><dc:abstract>Flutter, or the dynamic instability of an aircraft wing due to aerodynamic loads, must be considered when designing an aircraft. For this reason work has been done to improve a method developed at Bombardier Aerospace to analyze the dynamic aeroelastic response of aircraft. This method replaces original Doublet Lattice Method (DLM) aerodynamic data with that from high-fidelity Computational Fluid Dynamics (CFD) codes. The new aerodynamic loads are transmitted to the NASTRAN aeroelastic module through improved Aerodynamic Influence Coefficients (AIC). Previously this high-fidelity data was solely steady, and weighting factors were needed to obtain unsteady data. This gave good results for flutter calculations in the subsonic and transonic regime, however, for improved results in the transonic and supersonic regime, unsteady aerodynamic data was needed. This research incorporates unsteady high-fidelity CFD data into this analysis method.The unsteady CFD data was obtained by means of the Transpiration Method. This allowed for the unsteady movement of the model to be accounted for, while saving compu- tational time needed to deform and remesh the aerodynamic mesh at each time step. The transpiration method was validated with two standard test cases, for both static deflections and unsteady cyclic movement. Once this method was validated, high-fidelity CFD results could then be used in the AIC method.The AIC method begins with a set of baseline modes being obtained for the wing model. From these modes an aerodynamic base is calculated. Using the AIC method this aerodynamic base is transferred to NASTRAN. The natural mode shapes of a new configuration, along with the modal-based AIC method are used to approximate aerodynamic loads for the new configuration. These loads are used in NASTRAN to compute the flutter analysis of the new configuration.</dc:abstract><ual:supervisor>Mathias Legrand</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/h128nj16c.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/qb98mj855</ual:fedora3Handle><dc:subject>Engineering - Mechanical</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A47429d808"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Human Genetics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Molecular genetic studies of childhood blindness</dcterms:title><ual:dissertant>Keser, Vafa</ual:dissertant><dc:abstract>Childhood blindness due to hereditary retinal disease represents a huge clinical problem. Morbidity, blindness but also a major lack of understanding the molecular genetic events that lead to blindness in very young children hamper clinical management of this important and common problem. One way to get entry into the disease mechanism of childhood retinal blindness is to study Mendelian disease entities that are caused by relatively straightforward links between mutations in genes that lead to aberrant retinal protein function and the resulting disease phenotype. These discoveries in the Mendelian model would lead to understanding of the genetics, proteomics and most importantly retinal disease mechanisms and cycles that underlie the more complex diseases causing blindness. We have assembled a very exciting collection of 21 consanguineous pedigrees with a devastating autosomal recessive Mendelian disease, nonsyndromic congenital retinal nonattachment (NCRNA) and 16 families with autosomal recessive retinitis pigmentosa (arRP). Our main guiding hypothesis is that a significant portion of NCRNA will be caused by mutations in novel retinal genes as currently only one NCRNA gene is known (ATOH7). These novel genes may give us insight into the disease pathways of retinal detachment itself, a huge and clinically unmet medical need. Adult retinal detachments are common and the disease pathways are unknown.In a preliminary study of our cohort, we performed SNP genotyping where we aimed to identify homozygous (hmz) regions. Homozygous regions contain the causal gene(s) in consanguineous families. We found that in many of our patients known retinal detachment or RP gene(s) resided in one of the top 5 largest homozygous segments documented by the SNP array. Direct sequencing of these genes identified the causal mutations in known retinal genes in 11 out of our 21 retinal detachment families and 2 out of our 16 RP families. Thus, 35% of the patients were successfully genotyped in our study with six novel and seven previously reported mutations in known genes. Interestingly, 65% of our cohort of arRP and NCRNA patients remains genetically undetermined, despite our intensive search. After our prescreening for known mutations in NCRNA and RP genes using a combination of conventional genotyping methods, the genetic defects in 10 NCRNA and 14 RP patients remained unexplained suggesting new gene(s) in those patients. Although the clinical diagnosis of all children was NCRNA, in eight families, the molecular diagnosis determined that the disease process was in fact, familial exudative vitreoretinopathy (FEVR), a rare inherited vitreoretinal dystrophy characterized by the disruption of  retinal vascular development (FEVR; MIM 133780), caused by pathogenic variation occurred in LRP5, TSPAN12 and NDP genes. However, the phenotype remains the very severe congenital retinal detachment, previously not known to be associated with FEVR mutations. Therefore, we have expanded the phenotypic spectrum of FEVR, a severe retinal detachment phenotype that clinically overlaps with NCRNA. Also, we identified in our Pakistani cohort, the previously identified large deletion (6523 bp del) in ATOH7 found in the Kurdish founder population of Northern Iranian with a high incidence of NCRNA (Ghiasvand et. al, 2011) [5]. We therefore establish for the first time genetic overlap between the Iranian and Pakistani populations. </dc:abstract><dc:abstract>La cécité infantile causée par des maladies héréditaires de la rétine représente un énorme problème clinique. La morbidité, la cécité mais aussi le manque important de la compréhension des événements moléculaires génétiques conduisant à la cécité chez les très jeunes enfants diminuent la capacité de gérer cliniquement ce problème important et commun. Un moyen de comprendre le mécanisme de la maladie de la cécité infantile est d'étudier les maladies mendéliennes causées par des liens relativement simples entre les mutations génétiques, qui rendent aberrant le fonctionnement des protéines rétiniennes, et le phénotype de la maladie qui en résulte. Ces découvertes dans le modèle mendélien conduiraient à la compréhension des mécanismes des maladies rétiniennes ainsi que d'autres maladies plus complexes provoquant la cécité. Nous avons rassemblé une collection très intéressante de 21 pedigrees consanguins dont les membres possèdent une maladie autosomique récessif aux effets dévastatrices: nonsyndromic congenital retinal nonattachement (NCRNA) ainsi que 16 familles avec rétinite pigmentaire autosomique récessive (arRP). Notre principale hypothèse de base est que une partie importante de NCRNA sera causée par des mutations de nouveaux gènes rétiniennes puisque actuellement un seul gène NCRNA est connu (ATOH7). Ces nouveaux gènes peuvent nous donner des informations sur la mécanisme de la maladie de la détachement rétinienne. Décollement de la rétine chez les adultes sont fréquents et les voies de la maladie sont inconnues. Dans une étude préliminaire de notre cohorte, nous avons effectué de génotypage de SNPs où nous avons cherché à identifier des régions homozygotes (hmz). Les régions homozygotes contiennent le gène responsable dans des familles consanguines.  Nous avons constaté que, parmi beaucoup de nos patients, les gènes de la détachement rétinienne ou de RP résidaient dans l'un des 5 plus grands secteurs homozygotes documentés par l'ensemble SNP. Le séquençage direct de ces gènes nous a permis d'identifier les mutations responsables dans les gènes rétiniens connus pour 11 sur nos 21 familles de décollement de la rétine et 2 sur nos 16 familles de RP. Conséquemment, six nouvelles mutations et sept mutations rapportées dans des gènes connus se trouvent dans 35% des patients. Fait intéressant, 65% de notre cohorte de patients arRP et NCRNA demeurent génétiquement indéterminée, en dépit de notre recherche intensive. Après notre présélection pour les mutations connues dans les gènes NCRNA et RP en utilisant une combinaison de méthodes de génotypage conventionnelles, les défauts génétiques dans 10 patients NCRNA et 14 patients RP sont restées inexpliqués suggérant de nouveaux gène(s) chez ces patients. Bien que le diagnostic clinique de tous les enfants était NCRNA, dans huit familles, le diagnostic moléculaire a déterminé que le processus de la maladie était en fait familial exudative vitreoretinopathy FEVR, une rare dystrophie vitréo-rétinienne héréditaire caractérisée par la perturbation du développement vasculaire rétinienne (FEVR; MIM 133780), causé par des variations pathologiques survenues dans les gènes LRP5, TSPAN12 et NDP. Cependant, le phénotype reste d'être des détachements de la rétine congénitale sévères qui n'étaient pas connue pour être associée à des mutations FEVR. Par conséquent, nous avons élargi le spectre phénotypique de la FEVR, un phénotype de détachement rétinien sévère contenant des caractéristiques cliniques similaires à NCRNA. En outre, Nous avons trouvé, dans notre cohorte pakistanaise, la suppression de grande taille (6523 pb del) dans ATOH7 préalablement identifiée parmi la population fondatrice kurde du nord de l'Iran chez qui on retrouve une incidence élevée de NCRNA (Ghiasvand et. al., 2011). Nous avons donc établi, pour la première fois, le chevauchement génétique entre les populations iraniennes et pakistanaises. </dc:abstract><ual:supervisor>Robert Koenekoop</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/12579w66p.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/47429d808</ual:fedora3Handle><dc:subject>Biology - Genetics</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Akk91fq32p"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Molecular beam epitaxial growth, characterization, and nanophotonic device applications of InN nanowires on Si platform</dcterms:title><ual:dissertant>Zhao, Songrui</ual:dissertant><dc:abstract>Les nanofils semi-conducteurs sans dislocations sont une voie très prometteuse vers l'intégration des semi-conducteurs composés avec la technologie silicium. Cependant, un contrôle précis de dopage des nanofils, ainsi que les propriétés de charge de surface, reste un défi universel à ce jour. À cet égard, nous avons étudié la croissance épitaxiale par faisceau moléculaire et les propriétés de surface corrélés électriques et optiques des nanofils de InN sur du substrat de silicium, qui ont émergé comme candidat prometteur pour l'avenir des dispositifs électroniques et photoniques à très haute vitesse et à échelle nanométriques.Pour la première fois, en améliorant le processus de croissance épitaxiale, InN intrinsèque est atteint, à la fois dans le volume et sur les surfaces non polaires de InN. Le niveau de Fermi à la surface est mesuré et localisée sous le CBM, ce qui suggère l'absence d'accumulation d'électrons en surface. Ces nanofils InN intrinsèques possédent une concentration de porteurs libres très faible ~1e13 /cm3, ainsi que d'une mobilité proche de le théoriquement prédite d'électrons entre 8000 à 12000 cm2/V·s à température ambiante. Ce résultat est en contraste direct avec les 2DEG observés sur les surfaces d'InN. En outre, les propriétés de charge de surface de nanofils InN, y compris la formation de 2DEG et les caractéristiques d'émission optiques, peut être réglé avec précision, pour la première fois, par l'intermédiaire du contrôle d'incorporation de dopants de type n.Plus important encore, dopage de type p dans les nanofils InN est également réalisé pour la première fois. La présence de niveaux d'énergie Mg-accepteur est démontrée par les spectres de PL. Dans ces nanofils dopés de Mg, il n'y a pas d'accumulation d'électrons de surface et le niveau de Fermi dans le volume est proche de la VBM, ce qui indique un matériau de type p.En fin, la jonction p-i-n basé sur des nanofils InN photodétecteurs qui peut être utilisé en mode photovoltaïque est démontrée, avec une réponse à la lumière jusqu'à la longueur d'onde des télécommunications à de basses températures. Ce travail de thèse fournit un exemple frappant, ainsi que prépare le terrain pour le développement "matériaux par conception" de la technologie des dispositifs en silicium intégrée à base InN à l'échelle nanométrique.</dc:abstract><dc:abstract>Dislocation-free semiconductor nanowires are an extremely promising route towards compound semiconductor integration with silicon technology. However, precise control over nanowire doping, together with the surface charge properties, has remained a near-universal material challenge to date. In this regard, we have investigated the molecular beam epitaxial growth and the correlated surface electrical and optical properties of InN nanowires, a promising candidate for future ultrahigh-speed nanoscale electronic and photonic devices and systems, on Si platform.By dramatically improving the epitaxial growth process, intrinsic InN nanowires are achieved, for the first time, both within the bulk and on the non-polar InN surfaces. The near-surface Femi-level is measured to locate below the CBM, suggesting the absence of surface electron accumulation. Such intrinsic InN nanowires can possess an extremely low free carrier concentration of ~1e13 /cm3, as well as a close-to-theoretically-predicted electron mobility in the range of 8,000 to 12,000 cm2/V·s at room temperature. This result is in direct contrast to the universally observed 2DEG on the InN grown surfaces. Furthermore, the surface charge properties of InN nanowires, including the formation of 2DEG and the optical emission characteristics can be precisely tuned, for the first time, through the controlled n-type doping.More importantly, p-type doping into InN nanowires is also realized, for the first time. The presence of Mg-acceptors is clearly demonstrated by the PL spectra. Furthermore, p-type surface is observed from the XPS experiments, indicating the presence of free holes. Additionally, p-type conduction is directly measured by single nanowire field effect transistors.In the end of this thesis, InN nanowire p-i-n photodiodes are fabricated, with a light response up to the telecommunication wavelength range at low temperatures. This thesis work provides a vivid example, and paves the way for the rational “materials by design” development of silicon integrated InN-based device technology in the nanoscale.</dc:abstract><ual:supervisor>Zetian Mi</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/bv73c4041.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/kk91fq32p</ual:fedora3Handle><dc:subject>Engineering - Materials Science</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Acn69m742m"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Bioresource Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Evaluation of biochar soil amendments in reducing soil and water pollution from pathogens in poultry manure</dcterms:title><ual:dissertant>Arief Ismail, Shoieb Akaram</ual:dissertant><dc:abstract>Ce projet répond aux préoccupations du public canadien au sujet de la qualité de l'eau dans les régions où de nombreuses exploitations agricoles sont présentes. Les coliformes fécaux sont endémiques chez les volailles et sont difficiles à éradiquer des sites de production. Le biochar, un charbon produit par pyrolyse de la biomasse, gagne de plus en plus de reconnaissance à l'échelle mondiale en raison de ses propriétés uniques lorsqu'il est utilisé comme amendement de sol. Sa demi-vie est estimée à des centaines d'années. Par conséquent, son rôle dans la réduction de la pollution agricole pourrait s'étendre sur une longue période.Dans cette étude, nous examinons l'efficacité du biochar dans la prévention de la lixiviation des coliformes fécaux dans l'eau de surface. Les organismes ciblés dans cette étude sont Escherichia coli (E coli.) et les coliformes totaux. E. coli est reconnu comme étant  l'organisme indicateur de la présence de coliformes fécaux et les coliformes totaux comme étant révélateur du taux de désinfection. L'étude est composée de deux parties, l'une effectuée en laboratoire et l'autre sur le terrain.Dans l'étude en laboratoire, l'efficacité d'absorption et de désorption d'E. coli de trois différents types de biochar a été étudiée. Par le moyen de tests d'adsorption, une analyse comparative a été effectuée afin de déterminer la différence entre du biochar pur, un sol amendé par du biochar et un sol non-amendé dans leur efficacité d'élimination d'E. coli. Les analyses statistiques ont montré que le biochar comme amendement du sol joue un rôle important dans l'adsorption d'E. coli.Le sol amendé par du biochar et le sol non-amendé ont ensuite été soumis à un test de désorption afin de tester leur capacité de rétention. Les analyses statistiques ont démontré que deux types de sol amendés de biochar (l'un issu de la pyrolyse lente et l'autre de la pyrolyse rapide) retenaient E. coli. La capacité d'adsorption du biochar s'est révélée être directement proportionnelle à sa porosité et inversement proportionnelle à sa teneur en cendres. Les deux types de biochars ont été sélectionnés et utilisés comme traitements dans l'étude de terrain. L'étude de terrain a été réalisée sur des lysimètres pendant soixante jours afin d'évaluer l'efficacité du biochar dans l'élimination et la réduction du lessivage des coliformes fécaux (E. coli) venant du fumier de volaille. Le témoin contenait seulement du sol et le biochar sélectionné (l'un issu de la pyrolyse lente et l'autre de la pyrolyse rapide) a été utilisé comme traitement. Le biochar a été mélangé avec 5 cm de sol en partant de la surface (rapport de sol a biochar de 99:1). Le fumier de volaille a été répandu sur le sol dans tous les lysimètres. Les lysimètres ont été protégés de la pluie afin de simuler l'irrigation. L'irrigation a été simulée en 4 événements au cours des soixante jours. Le sol (3 profondeurs d'échantillonnage) et les échantillons de lixiviat ont été prélevés et analysés à des intervalles temporels prédéterminés. Dans cette étude, E. coli et les coliformes totaux se sont infiltrés à travers les profils de sol, et leurs concentrations ont diminués avec le temps et la profondeur du sol. Les analyses statistiques (P ≤ 0.05) des échantillons de sol et des lixiviats ont montré que la concentration d'E. coli dans les traitements aux trois profondeurs et dans le lixiviat étaient différente du contrôle, ce qui est attribué à l'efficacité des traitements de réduction du lessivage des coliformes fécaux. Cependant, la concentration de coliformes totaux était significatif (P ≤ 0.05) sur certains intervalles et insignifiant sur d'autres, ce qui peut être lié a une présence antérieure de coliformes totaux dans le sol et a l'efficacité des traitements qui suggèrent un taux de désinfection efficace. Le sol amendé de biochar a donc été considéré comme étant efficace dans la réduction du lessivage des coliformes fécaux a travers les profils de sol.</dc:abstract><dc:abstract>This project addresses concerns from the Canadian public about the quality of water in regions where many agricultural operations are located. Fecal coliforms are endemic in poultry and are difficult to eradicate from production facilities. Poultry manure is a reservoir of Campylobacter jejuni, Escherichia coli (including O157:H7) and Salmonella spp. Biochar, the charcoal produced from pyrolysis of biomass, is gaining global recognition due to its unique properties when applied as a soil amendment. Biochar could play an important role in controlling the mobility of pathogens in soil and water environment. Its half-life is estimated to be hundreds of years so it is expected that its role in reducing agricultural pollution could be very long-lasting, and hence very cost-effective.In this study we investigated the effectiveness of biochar in preventing the leaching of fecal coliforms into surface water. The target organisms in this study were Escherichia coli (E .coli) and total coliform. E. coli is widely recognized as the indicator organism for presence of fecal coliform and total coliforms to determine disinfection rate. The study was divided into two components, namely laboratory study and field study.In laboratory study, the effectiveness of three different types of biochar (variation based on production temperature, time and raw material) in adsorption and desorption of E. coli was studied. In adsorption test, a comparative analysis was carried out to understand the differences between biochar, soil amended biochar (soil to biochar ratio of 99:1) and un-amended soil in the removal of E. coli. The statistical analysis showed the adsorption of E. coli was significantly higher in the soil amended biochar treatment. The soil amended biochar and the un-amended soil treatments were further subjected to desorption to test their retention capacity. The statistical analysis showed that two types of soil amended biochars (slow pyrolysis biochar and fast pyrolysis biochar) retained E. coli significantly better. The adsorption capacity of biochar was directly proportional to its porosity and inversely proportional to its ash content. The two types of soil amended biochar were shortlisted based on sorption and retention capacity and were used as treatments in the field study.A sixty-day study was conducted using field lysimeters to evaluate the effectiveness of soil amended biochar in removing or reducing the leaching of fecal coliforms (E. coli) from poultry manure. Lysimeter with only soil was used as control and the shortlisted biochars (slow pyrolysis biochar and fast pyrolysis biochar) were used as treatments. In the biochar-amended treatments, the top 0.05 m of soil was amended with biochar in a proportion of 1:99 biochar:soil. Poultry manure was spread over the soil in all lysimeters. The lysimeters were protected from natural rainfall, and the simulated rainfall was applied as 4 events over a sixty day period. Both soil (3 sampling depths) and leachate samples were collected and analyzed at predetermined time intervals.  In the experiment, E. coli and total coliform were found to leach down through the soil profiles, and their concentrations decreased with soil depth and time. The statistical analysis of soil samples and leachate showed that the concentration of E. coli in the treatments at the three sampling depths and in the leachate were significantly different from control (P ≤ 0.05), which is attributed to the effectiveness of the treatments in reducing the leaching of fecal coliforms. However, the concentration of total coliforms was significant (P ≤ 0.05) on certain intervals and insignificant in the others; this can be attributed to already present total coliforms in the soil system and effectiveness of the treatments to hinder coliform transport. Soil biochar amendment was thus seen to be effective in reducing the leaching of fecal coliforms through soil profiles and providing fecal coliforms free leachate.</dc:abstract><ual:supervisor>Shiv Prasher</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/3j333582z.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/cn69m742m</ual:fedora3Handle><dc:subject>Engineering - Environmental</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ax346d7546"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Mining and Materials</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Surface constrained stochastic life-of-mine production scheduling</dcterms:title><ual:dissertant>Marinho de Almeida, Alexandre</ual:dissertant><dc:abstract>The maximization of mining project discounted cash flows by defining the best sequence of extraction of underground materials requires understanding the availability of uncertain metal quantities throughout the deposit. This thesis proposes two versions of a stochastic integer programming formulation based on surfaces to address the optimization of life-of-mine production scheduling, whereby the supply of metal is uncertain and described by a set of equally probable simulated orebody models. The first version of the proposed formulation maximizes discounted cash flows, controls risk of deviating from production targets and is implemented sequentially, facilitating production scheduling for relatively large mineral deposits. Applications show practical intricacies and computational efficiency. The second variant extends the first to a two-stage stochastic integer programming formulation that manages the risk of deviating from production targets. The sequential implementation is considered first for pit space discretization and it is followed by the life-of-mine production scheduling at a relatively large gold deposit. The case studies show the computational efficiency and suitability of the method for realistic size mineral deposits, with production targets controlled, risk postponed to later stages of production and improvements in expected NPV, when compared to deterministic industry practices.</dc:abstract><dc:abstract>La maximisation du flux de trésorerie actualisé des projets miniers fait en définissant la meilleure séquence d'extraction de matériaux souterrains exige une bonne compréhension  de l'incertitude sur la disponibilité de la quantité de métal provenant du gisement souterrain. Ce mémoire propose deux formulations basées sur des surfaces afin d'optimiser la séquence d'extraction tout au long du projet où la quantité de métal est incertaine et décrite par un ensemble de simulations équiprobables. La première simulation maximise le flux de trésorerie actualisé, contrôle le risque d'écart par rapport aux objectifs de production et est implémentée de façon séquentielle, ce qui facilite la planification pour des gisements relativement grands. L'application de cette formulation sur des problèmes montre une complexité pratique et une efficacité computationnelle. La seconde formulation étend la première en une formulation stochastique en nombres entiers à deux étapes qui permet de gérer le risque d'écart par rapport aux objectifs de production. L'implémentation séquentielle considère d'abord une discrétisation du gisement  puis génère une séquence d'extraction annuelle et est appliquée sur un dépôt d'or de grande taille. Les études de cas montrent l'efficacité computationnelle et une adaptation adéquate pour des problèmes de taille réelle avec des objectifs de production contrôlés, un risque reporté à des étapes ultérieures du développement et une amélioration dans la valeur nette actualisée comparée aux meilleures pratiques déterministes de l'industrie.</dc:abstract><ual:supervisor>Roussos G. Dimitrakopoulos</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/q811kp12c.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/x346d7546</ual:fedora3Handle><dc:subject>Engineering - Mining</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Amg74qq62t"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Medicine</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Investigating novel therapies for breast cancers resistant to Trastuzumab</dcterms:title><ual:dissertant>Balachandran, Banujan</ual:dissertant><dc:abstract>Approximately 20% of all metastatic breast cancers overexpress the HER-2 receptor, a cell surface-bound receptor tyrosine kinase upstream of crucial proliferation and cell survival pathways. Trastuzumab, a humanized monoclonal antibody binding to the extracellular domain of HER-2, has proven to be a beneficial treatment for patients diagnosed as HER-2+ but continues to have limitations. With low response rates for patients when administered alone and for patients having received prior chemotherapy, the true potential of trastuzumab seems to arrive only through combination therapies. However, the majority of advanced HER-2 positive breast cancer patients still develop resistance to the therapy by the end of the first year or present de novo resistance. For this reason, it is important to continue to investigate therapies to give in combination with trastuzumab to improve progression-free survival and overall survival in this clinical setting. Two Phase II Astra Zeneca compounds: AZD0530, a dual Src and Abl kinase inhibitor and AZD8931, a pan-erbb tyrosine kinase inhibitor abrogating EGFR-, HER-2-, and HER-3-mediated signaling were explored in this context using established trastuzumab-naïve and trastuzumab-resistant cell lines. AZD0530 was not effective when administered alone and any combinations with trastuzumab showed positive responses only in those models in which some form of response to AZD0530 alone had been seen. Clinically-relevant responses to AZD8931 were seen in all cell lines tested and for this reason a head-to-head comparison was carried out with lapatinib, the FDA-approved therapy for patients progressing on trastuzumab. AZD8931 alone and in combination with trastuzumab worked effectively to stop proliferation and induce cell death in both trastuzumab-naïve and trastuzumab-resistant cell lines at clinically relevant doses. AZD8931 had similar activity to lapatinib in the SKBR3-based ER-negative cell lines, but was less active in the BT474-based ER-positive cell lines. From this study, it appears AZD8931 is a therapeutic candidate for overcoming trastuzumab resistance but further investigation is required, before translation into the clinical setting, including the use of animal models of trastuzumab-resistance, specifically in the ER-negative subtype.</dc:abstract><dc:abstract>20% des cancers du sein sur-expriment le récepteur membranaire, HER-2 ayant une forte activité enzymatique tyrosine kinase et qui est impliqué dans l'activation de plusieurs voies de signalisation comme la prolifération et la survie cellulaire. Trastuzumab, un anticorps monoclonal spécifique pour la portion extracellulaire de HER-2 et a été démontré efficace dans le traitement des cancers du sein positifs pour HER-2, mais son efficacité cliniques a des limites. En effet, avec un faible taux d'efficacité lorsqu'administré seul chez les patients ayant été préalablement traités ou non avec la chimiothérapie, le vrai potentiel de Trastuzumab ne semble se dévoiler qu'en combinaison avec d'autres thérapies. Effectivement, la majorité des patients atteints d'un cancer du sein avancé et sur-exprimant HER-2 deviennent insensibles au Trastuzumab avant la fin de leur première année de traitement ou présentent une résistance intrinsèque. Pour cette raison, il est important de poursuivre la recherche pour permettre la découverte de nouvelles thérapies à administrer en combinaison avec Trastuzumab dans le but de prévenir la progression de la maladie et d'améliorer la survie des patients. Deux médicaments développés par AstraZeneca font présentement l'objet d'essai cliniques de phase II : AZD0530, un double inhibiteur des kinases Src et Abl ainsi que AZD8931, un inhibiteur de tyrosine kinase bloquant la signalisation via les récepteurs EGFR, HER2 et HER3. Dans la présente étude, l'efficacité de AZD0530 et AZD8932 a été analysée dans des lignées cellulaires n'ayant jamais été exposées au Trastuzumab ainsi que des lignées résistantes au trastuzumab. Non-efficace lorsqu'administré en monothérapie, AZD0530 s'est montré actif en combinaison avec Trastuzumab, mais seulement à des concentrations où AZD0530 utilisé seul avait un effet positif. Quant à AZD8931, son efficacité a pu être observée à des concentrations pertinentes en clinique dans toutes les lignées cellulaires testées. Conséquemment, une étude comparative entre AZD8931 et Lapatinib a été menée, lapatinib étant le traitement approuvé par la FDA pour les patients dont la maladie progresse sous Trastuzumab.  Les résultats démontrent que AZD8931, en monothérapie ou en combinaison avec Trastuzumab limite efficacement la prolifération et induit la mort cellulaire dans chacune des lignées évaluées, résistante ou non au Trastuzumab, à des doses cliniquement pertinentes. Cette étude nous permet aussi de montrer que AZD8931 a une activité similaire à celle de Lapatinib dans la lignée cellulaire SKBR3 qui ne sur-exprime pas le récepteur à l'estrogène (ER), mais qu'il était toutefois moins efficace dans la lignée positive pour ER, BT474. Cette étude nous permet donc de conclure que AZD8931 pourrait être un important candidat thérapeutique pour contrer la résistance au Trastuzumab. D'autres analyses sont toutefois requises, tel que l'utilisation d'un modèle vivant de résistance au Trastuzumab dans un contexte de lignées négatives pour le ER, avant de confirmer le potentiel de AZD8931 comme agent de seconde ligne et d'appliquer ces résultats en clinique. </dc:abstract><ual:supervisor>Mark Basik</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/qn59q769s.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/mg74qq62t</ual:fedora3Handle><dc:subject>Health Sciences - Medicine and Surgery</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A2f75rc39n"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Surgery</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Automated sedation integrated with a decision support for patients undergoing hip or knee arthroplasty under spinal anesthesia with controlled sedation</dcterms:title><ual:dissertant>Zaouter, Cedrick</ual:dissertant><dc:abstract>Les systèmes automatisés pour l'administration de propofol et les systèmes d'aide décisionnel (DSSs) permettent de diminuer la charge de travail des anesthésistes et d'accroître leurs vigilances pendant la chirurgie, respectivement. Cependant, les systèmes automatisés d'injection de prpofol ont été utilisés principalement pour l'anesthésie générale, mais jamais pour la sédation consciente. De plus, les DSSs n'ont jamais été utilisés auparavant pour aider les anesthésistes à surveiller les patients recevant une rachianesthésie avec sédation. Ainsi, nous avons développé le premier dispositif médical incorporant un système en boucle fermée pour la sédation automatisée avec propofol incluant un DSS pour la surveillance de patients subissant une intervention d'arthroplastie du genou ou de la hanche sous rachianesthésie et sédation consciente. Le projet vise à déterminer les performances et la sécurité de ce nouveau dispositif médical hybride. L'hypothèse est que ce nouveau dispositif offre une meilleure sédation que le contrôle manuel et une détection plus précoce des événements critiques qui peuvent survenir pendant la rachianesthésie avec sédation utilisant le propofol. Le système hybride testé dans cet essai permet de contrôler la sédation avec propofol mieux que l'administration manuelle et peut détecter les événements critiques plus vite permettant un traitement de ces derniers plus rapide.</dc:abstract><dc:abstract>Automated systems for propofol delivery and decision support system (DSS) have been shown to decrease anesthesiologists' workload and increase their vigilance during surgery, respectively. However, automated systems have been used mainly for general anesthesia but never for controlled sedation alone. In addition, DSSs have never been used before to help anesthesiologists to monitor patients receiving a spinal anesthesia with sedation. Thus, we have developed the first medical device incorporating a closed loop system for sedation and a decision support system for controlled sedation for patients undergoing knee or hip arthroplasty under spinal anesthesia with controlled sedation. The present project aims to determine the performances and the safety of this novel hybrid medical device. The hypothesis is that this novel device provides better sedation than manual control and could help to detect critical events, which could occur during spinal anesthesia with sedation, more promptly. The hybrid system tested in this trial can control sedation better than manually delivered propofol sedation and can detect critical events in a shorter time length allowing faster therapeutic treatments.</dc:abstract><ual:supervisor>Thomas Hemmerling</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/kd17cx65s.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/2f75rc39n</ual:fedora3Handle><dc:subject>Health Sciences - Medicine and Surgery</dc:subject></rdf:Description></rdf:RDF>