<?xml version="1.0" encoding="UTF-8"?><rdf:RDF xmlns:oai="http://www.openarchives.org/OAI/2.0/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:ual="http://terms.library.ualberta.ca/" xmlns:bibo="http://purl.org/ontology/bibo/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:schema="https://schema.org/" xmlns:etdms="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Avq27zr392"><ual:graduationDate>2007</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Physics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>The development of new devices for accurate radiation dose measurement: a guarded liquid ionization chamber and an electron sealed water calorimeter</dcterms:title><ual:dissertant>Stewart, Kristin Joy</ual:dissertant><dc:abstract>Dans ce travail nous avons développé deux nouveaux détecteurs qui visent à améliorer l'exactitude de la dosimétrie relative et de référence en radiothérapie: une chambre d'ionisation liquide gardée (GLIC) et un calorimètre d'eau scellé pour les électrons (ESW). Avec la GLIC nous avons visé à développer un détecteur indépendant de l'énergie et libre de perturbations avec une résolution spatiale élevée pour la dosimétrie relative. Nous avons atteint une stabilité suffisante pour des mesures à court terme en utilisant la GLIC-03, qui a un volume sensible d'approximativement 2 mm3. Nous avons évalué la recombinaison générale des ions dans des faisceaux de photons pulsés en utilisant un modèle théorique et nous avons également déterminé une nouvelle méthode empirique, permettrant de corriger pour les différences relatives de recombinaison générale, qui pourrait être employée dans les cas où le modèle théorique ne serait pas applicable. La dépendance d'énergie du GLIC-03 était 1.1% dans des faisceaux de photon entre 6 et 18 MV. Les mesures dans la région de déséquilibre électronique ('build-up') d'un faisceau du 18 MV ont indiqué que ce détecteur introduit une perturbation minimale du champ de rayonnement et ont confirmé la validité de la correction empirique de recombinaison. Le calorimètre ESW a été conçu pour mesurer directement la dose absorbée dans les faisceaux d'électrons cliniques. Nous avons obtenu des mesures reproductibles pour des faisceaux de 6 à 20 MeV. Nous avons déterminé les corrections nécessaires pour tenir compte des perturbations du champ de rayonnement introduites par le récipient de verre du calorimètre et du transfert thermique de conduction dû au gradient de dose et au fait que les matériaux ne sont pas de l'eau. L'incertitude globale sur la dose pour le calorimètre ESW était 0.5% pour les faisceaux de 9 à 20 MeV et 1.0% pour 6 MeV, prouvant pour la première fois que le d</dc:abstract><dc:abstract>In this work we developed two new devices that aim to improve the accuracy of relative and reference dosimetry for radiation therapy:  a guarded liquid ionization chamber (GLIC) and an electron sealed water (ESW) calorimeter. With the GLIC we aimed to develop a perturbation-free energy-independent detector with high spatial resolution for relative dosimetry.  We achieved sufficient stability for short-term measurements using the GLIC-03, which has a sensitive volume of approximately 2 mm3.  We evaluated ion recombination in pulsed photon beams using a theoretical model and also determined a new empirical method to correct for relative differences in general recombination which could be used in cases where the theoretical model was not applicable.  The energy dependence of the GLIC-03 was 1.1% between 6 and 18 MV photon beams.  Measurements in the build-up region of an 18 MV beam indicated that this detector produces minimal perturbation to the radiation field and confirmed the validity of the empirical recombination correction.  The ESW calorimeter was designed to directly measure absorbed dose to water in clinical electron beams.  We obtained reproducible measurements for 6 to 20 MeV beams.  We determined corrections for perturbations to the radiation field caused by the glass calorimeter vessel and for conductive heat transfer due to the dose gradient and non-water materials.  The overall uncertainty on the ESW calorimeter dose was 0.5% for the 9 to 20 MeV beams and 1.0% for 6 MeV, showing for the first time that the development of a water-calorimeter-based standard for electron beams over a wide range of energies is feasible.  Comparison between measurements with the ESW calorimeter and the NRC photon beam standard calorimeter in a 6 MeV beam revealed a discrepancy of 0.7±0.2% which is still under investigation.  Absorbed-dose beam quality conversion factors in electron beams were measured using the ESW calorimeter for the Exradin A12 and PTW Roos ionization</dc:abstract><ual:supervisor>Jan Peter Frans Seuntjens</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/6969z370t.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/vq27zr392</ual:fedora3Handle><dc:subject>Physics - Radiation</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A4x51hn11p"><ual:graduationDate>2007</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Biochemistry</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Development and application of novel computational tools for structure based drug design</dcterms:title><ual:dissertant>Bhat, Sathesh</ual:dissertant><dc:abstract>Computational structure-based methods represent valuable tools in the drug design pipeline, as evidenced by their widespread use. This thesis describes five research projects that represent important computational advances in the methodologies and protocols of lead discovery and optimization. The first project demonstrates that the current paradigm of utilizing a fixed 1.4 Å solvent probe radius when generating the molecular surface results in unrealistic hydrophobic cavities and pockets on the surface. A novel method is developed which allows the solvent probe to change size according to its contacting atoms on the surface, thereby producing a more accurate representation of protein clefts, pockets and cavities, as well as giving a better tuned description of shape complementarity and electrostatic energies. The second project demonstrates that utilizing hydration parameters for calculation of electrostatic binding free energies results in a large mean error between predicted and experimental binding affinities. Consequently, a novel solvated interaction energy (SIE) scoring function is developed that parameterizes the electrostatic model using experimental binding data. The SIE scoring function is able to reproduce the affinities of 99 varied ligand-protein complexes with a mean error of 1.29 kcal/mol. In the third project, the SIE scoring function is incorporated into a novel virtual screening (VS) pipeline. The discriminative power of the SIE function is improved by including terms that account for entropy and hydrogen bonding. The resulting VS pipeline outperforms the majority of other VS methodologies in the literature. In the fourth project, a modified version of the VS pipeline is employed to predict the binding mode of a glycopeptide antibiotic to the bacterial sulfotransferase StaL. The predicted binding mode is in good agreement with experimental findings. In the fifth project, a novel method to compute electrostatic optimal charge selectivity, termed</dc:abstract><dc:abstract>Les méthodes de modélisation basées sur la structure tridimensionnelle des protéines sont d'une grande utilité dans le développement de médicaments. Cette thèse résume cinq projets de recherche proposant des avancées dans la méthodologie et les protocoles liés à la découverte et à l'optimisation de petites molécules actives. Le premier projet démontre que le paradigme voulant que la surface moléculaire exposée au solvant soit décrite par le contact d'une sonde sphérique de rayon constant de 1.4Å avec la protéine fait apparaître des poches et des cavités hydrophobes irréalistes sur la surface. Une méthode novatrice est présentée où le rayon de la sonde change au contact des différents types d'atome produisant ainsi une représentation plus réaliste des aspérités de la surface ayant pour effet une meilleure définition de la complémentarité de la forme moléculaire ainsi qu'une meilleure estimation de l'énergie électrostatique. Le deuxième projet démontre que l'utilisation d'un simple coefficient d'hydratation pour corriger le calcul de l'énergie libre de liaison entraîne une erreur moyenne importante entre les affinités calculées et mesurées expérimentalement.  Conséquemment, une nouvelle fonction d'énergie tenant compte de la solvatation (SIE) a été développée appuyant sa paramétrisation sur des données expérimentales.  La fonction SIE est en mesure de reproduire les affinités de 99 complexes ligand-protéine différents avec une erreur moyenne de 1.29 kcal/mol. Dans le troisième projet, la fonction SIE est introduite dans une nouvelle procédure de criblage virtuel (CV). La capacité de la fonction SIE est accrue par l'ajout d'un terme d'entropie et d'un terme décrivant les liaisons hydrogène. La procédure de criblage qui en résulte déclasse la majorité des autres méthodes publiées. Dans le quatrième projet une version modifiée de la procédure de criblage est utilisée pour prédire les modes de</dc:abstract><ual:supervisor>Enrico Purisima</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/zc77ss77r.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/4x51hn11p</ual:fedora3Handle><dc:subject>Biophysics - General</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A37720g684"><ual:graduationDate>2007</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Mathematics and Statistics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Estimating nonlinear mixed-effects models by the generalized profiling method and its application to pharmacokinetics</dcterms:title><ual:dissertant>Wang, Liangliang</ual:dissertant><dc:abstract>Il n'y a aucune solution de exacte pour beaucoup de modèles non-linéaires à  effets mixtes (NLME) exprimés comme un ensemble d'équations ordinaires (ODE) en modèles de compartiment. Cette thèse passe en revue plusieurs méthodes et outils courants de logiciel pour NLME, et explore une nouvelle manière d'estimer des effets mixtes non-linéaires en modèles de compartiment basée sur le cadre de la méthode de profilage généralisée proposée par Ramsay, Hooker, Campbell, et Cao (2007).     Quatre types de paramètres sont identifiés et estimés d'en cascade par une optimisation de multiple-niveau: le paramètre regularisateur  est choisi par le critère de la contre-vérification généralisée (GCV); les paramètres structuraux, y compris les effets fixes, la matrice de variance-covariance pour les effets aléatoires, et la variance résiduelle  sont optimisés par un critère basé sur une expansion de premier ordre de Taylor de fonction non-linéaire ; les effets aléatoires  sont optimisés par une methode des moindres carrés non-linéaires pénalisés ; et les coefficients d'expansions  de fonction de base sont optimisés par un lissage pénalisé avec la pénalité définie par l'equation differentielle. En conséquence, certains  des paramètres sont exprimés en tant que fonctions explicites ou implicites d'autres paramètres. La dimensionnalité de l'espace des paramètres est réduite, et la surface d'optimisation devient plus lisse. L'algorithme de Newton-Raphson est appliqué aux paramètres d'évaluation pour chaque niveau d'optimisation, où le théorème des fonctions implicites est employé couramment pour établir les gradients et les matrices de Hessiennes de facon analytiques.    La méthode proposée et des codes de MATLAB sont examinés par des applications à plusieurs modèles de compartiment en pharmacocinétique sur des donnees simulées et vraies. Des résultats sont comparés aux valeurs ou aux évaluations vraies obtenues pa</dc:abstract><dc:abstract>Several methods with software tools have been developed to estimate nonlinear mixed-effects models. However, fewer have addressed the issue when nonlinear mixed-effects models are implicitly expressed as a set of ordinary differential equations (ODE's) while these ODE's have no closed-form solutions. The main objective of this thesis is to solve this problem based on the framework of the generalized profiling method proposed by Ramsay, Hooker, Campbell, and Cao (2007).   Four types of parameters are identified and estimated in a cascaded way by a multiple-level nested optimization. In the outermost level, the smoothing parameter is selected by the criterion of generalized cross-validation (GCV).  In the outer level, the structural parameters, including the fixed effects, the variance-covariance matrix for random effects, and the residual variance, are optimized by a criterion based on a first-order Taylor expansion of the nonlinear function. In the middle level, the random effects are optimized by the penalized nonlinear least squares. In the inner level, the coefficients of basis function expansions are optimized by penalized smoothing with the penalty defined by ODE's. Consequently, some types of parameters are expressed as explicit or implicit functions of other parameters. The dimensionality of the parameter space is reduced, and the optimization surface becomes smoother. The Newton-Raphson algorithm is applied to estimate parameters for each level of optimization with gradients and Hessian matrices worked out analytically with the Implicit Function Theorem.   Our method, along with MATLAB codes, is tested by estimating several compartment models in pharmacokinetics from both simulated and real data sets. Results are compared with the true values or estimates obtained by the package nlme in R, and it turns out that the generalized profiling method can achieve reasonable estimates without solving ODE's directly.</dc:abstract><ual:supervisor>James Owen Ramsay</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/2227ms70x.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/37720g684</ual:fedora3Handle><dc:subject>Pure Sciences - Statistics</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Aht24wn10k"><ual:graduationDate>2007</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of History</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>A cabinet in the clouds: J.A. de Luc, H.B. de Saussure and the changing perception of the High Alps, 1760-1810</dcterms:title><ual:dissertant>Goldstein, Eric</ual:dissertant><dc:abstract>Today, the perception of the Alps – and mountains in general - as an object or place of scientific and aesthetic value is an acknowledged element of Western culture. Before the eighteenth century, however, Europe possessed a markedly different mentality towards its mountain heart – one of fear and disdain toward the dangerous alpine desert. Yet the eighteenth century witnessed a reversal of this centuries-long prejudice as the cultivation of empirical methodology, coupled with the concomitant institutionalization of science and emergence of bourgeois culture paved the way for a transformation of Europe's alpine mentality. The pioneers of this change were Horace-Benedict de Saussure and Jean-André de Luc, natural philosophers of Swiss descent. Advocating meticulous observation, precision instrumentation and fieldwork, along with an implicit awareness of alpine aesthetics, Saussure and de Luc became the first to systematically study and appreciate the scientific and aesthetic value of the high Alps. Investigating the roles of Saussure and de Luc in transforming the perception of the Alps, this dissertation will focus on the core elements of their scientific methodology, demonstrating how the confluence of these components provided the catalytic force necessary to cast the Alps anew.</dc:abstract><dc:abstract>De nos jours, la façon de voir les Alpes et les montagnes en général, en tant qu'objet ou lieu qui a une valeur scientifique et esthétique, est tout à fait accepté par la Culture occidentale, Cependant, avant le XVIII ième siècle, l'Europe possédait une mentalité totalement différente à l'égard de son coeur montagnard, elle considérait ce désert alpin dangereux avec peur et mépris. Le XVIII ième siècle a vu un revirement de ce préjudice qui datait de centaines d'années. La culture de la méthodologie empirique à laquelle s'ajoutera l'institutionnalisation des Sciences et la naissance de la culture bourgeoise, ont ouvert la voie à une transformation de la mentalité alpine en Europe. Horace-Benedict de Saussure et Jean-André de Luc,tous deux physiciens d'origine Suisse, furent les pionniers de ce revirement. C'est en poussant à faire des observations méticuleuses, avec des instruments de précision et en faisant des recherches sur le terrain tout en ayant une sensibilisation absolue à propos des principes esthétiques alpins, c'est ainsi que Saussure et de Luc devinrent les premiers à en faire une étude systématique et à apprécier la valeur à la fois scientifique et esthétique des Hautes Alpes. Cette dissertation mettra l'accent sur les rôles de Saussure et de de Luc quant à la transformation de la perception des Alpes et se concentrera sur les éléments principaux de leur méthodologie scientifique, montrant comment la convergence de ces éléments fournit la force catalytique nécessaire pour présenter les Alpes dans un nouveau contexte. fr</dc:abstract><ual:supervisor>Nicholas Dew</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/44558h03x.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/ht24wn10k</ual:fedora3Handle><dc:subject>History - History of Science</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Azp38wg42n"><ual:graduationDate>2007</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Bioresource Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Effect of UV-C hormesis on quality attributes of tomatoes during post treatment handling</dcterms:title><ual:dissertant>Lingegowdaru, Jagadeesh</ual:dissertant><dc:abstract>Effect of UV-C Hormesis on Quality Attributes of Tomatoes during Post treatment Handling  Post harvest losses are quite high in fresh fruits and vegetables. Although refrigeration is an effective method of storage, its advantage is limited to some crops that are not susceptible to chilling injury. Tomato (Lycopersicon esculentum Mill.) is one such crop where other alternatives are sought for. Experiments were conducted to assess the effect of post-harvest treatment with artificial ultraviolet (UV-C) radiation (~254 nm) on quality and physiology of treated tomatoes during post treatment handling. Antioxidant composition of tomatoes was studied in relation to the consequence of UV irradiation.              Tomato fruits (variety DRK-453) were irradiated (3.7 kJ/m2) at mature green stage and stored at 13oC and 95% RH along with a set of control. The tomatoes were randomly sampled after 10, 20 and 30 days from the cold storage chamber, and ripened for 7 and 14 days at room temperature and analyzed for different quality parameters.              The results showed that post-harvest UV treatment significantly reduced the surface color change of tomatoes whereas the other quality parameters such as TSS, titratable acidity, pH and TSS/acidity ratio were not influenced. This indicates that ripening process had similar pace in both control and UV treated fruits. Apparent firmness observed in the irradiated fruits was not reflected in the objectively measured firmness values.  Today, estimation of antioxidant activity has become an important parameter to evaluate the nutritional quality of food. In tomato fruit the carotenoid lycopene is the main phytochemical purported to carry benefit to human health. UV treatment induced a significant decrease in the lycopene content of tomatoes in the later stage during handling. The other antioxidant components namely, ascorbic acid and total phenolic contents increased with the increase in storage and ripening period. The significantly</dc:abstract><dc:abstract>Effets d’un traitement hormesis aux UV-C sur la qualité post-récolte des tomates    Les pertes après-récolte des fruits et des légumes sont relativement élevées. Quoique que l’utilisation du froid a permis d’accroître de façon marquée la durée de conservation de plusieurs fruits et légumes, ses effets bénéfiques sont limités sur les produits sensibles au froid comme la tomate (Lycopersicon esculentum Mill.). Des essais en laboratoire ont été effectués pour évaluer les effets d’un traitement hormesis au rayonnement ultraviolet (UV-C) sur la qualité de la tomate. Ce traitement aurait pour effet de causer un stress physiologique bénéfique qui se traduirait par une amélioration de la conservation et des qualités nutritives du fruit.  Des tomates de variété DRK-453 et ayant atteintes un stage de maturité verte/mature ont été divisées en deux lots. Le premier a été exposé à un traitement hormesis au UV-C (3.7 kJ/m2) tandis que le second a servi de contrôle. Immédiatement après le traitement, tous les fruits ont été entreposés à 13oC et 95% d’humidité relative. Après 10, 20 et 30 jours de conservation au froid, des échantillons de tomates ont été prélevés de façon aléatoire dans chacun des lots. Puis, les fruits ont mûri à la température de la pièce pour une période de 7 ou 14 jours. A la fin du mûrissement, la qualité de conservation et la qualité nutritive ont été évaluées.                L’analyse comparative des résultats a indiqué que, chez la tomate, l’exposition à la dose prescrite du rayonnement UV-C réduisait de façon significative le développement de la couleur rouge, mais qu’il n’affectait pas le pH, la fermeté, l’acidité titrable, la teneur total en solides solubles (TSS) et le rapport TSS/acidité. Par conséquence, le processus de mûrissement était similaire pour les fruits traités et non-traités.   La tomate contient une quantité appréciable d’antioxydants do</dc:abstract><ual:supervisor>G. S. Vijaya Raghavan</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/c247dv977.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/zp38wg42n</ual:fedora3Handle><dc:subject>Agriculture - Food Science and Technology</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A9g54xm541"><ual:graduationDate>2007</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>School of Dietetics and Human Nutrition</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Protein synthesis and gastrointestinal pathophysiology in a piglet model of colitis: importance of nutrition and probiotics</dcterms:title><ual:dissertant>Harding, Scott Vincent</ual:dissertant><dc:abstract>Objectifs La bonne nutrition et les probiotiques ont prouvé réduire la sévérité de la colite. Cependant, leur impact sur le métabolisme des protéines gastro-intestinales et hépatiques n’a pas encore été étudié. Notre objectif premier était de comparer l’effet indépendant des probiotiques à celui d’un régime alimentaire adéquat, sur la synthèse des protéines, chez le porcelet présentant une colite, recevant une diète restreinte en macronutriments. Le but secondaire de cette étude était de déterminer les contrastes histologiques ainsi que les variations au niveau des marqueurs du stress oxydatif, résultant de l’effet des probiotiques dans les deux cas de malnutrition et de nutrition adéquate. Nous avons aussi mesuré l’équilibre et les concentrations de cuivre, fer et zinc dans le plasma durant les 5 jours de colite, dans le but de déterminer comment les probiotiques et la colite affectent tous deux la balance des oligo-éléments. Méthodes et analyses Vingt-quatre porcelets, recevant 1g/kg/jour de sulphate de dextran (DS), ont été randomisés en quatre groupes : deux groupes recevant une diète appauvrie en macronutriment à 50%, avec (MR+PRO) ou sans (MR) probiotiques, et un groupe recevant une diète contenant 100% des besoins nutritionnels  pour porcelets, suivant les standards NRC (WN). Un quatrième groupe comprenant huit porcelets recevant une diète adéquate et ne présentant pas de colite (REF) a été inclus à des fins de comparaisons histologiques ainsi qu’au niveau des oligo-éléments. Une infusion constante du traceur L-[ring-2H5]phenylalanine a été effectuée pour déterminer la synthèse des protéines de la muqueuse de l’intestin grêle, colon, foie et plasma. Les techniques de « staining » standard, in situ et immunohistologiques ont été utilisées pour les déterminations histologiques, et des analyses du pouvoir antioxydant, ELISA F2-isoprostane assay, ainsi que le ratio cuivre:zinc ont été$</dc:abstract><dc:abstract>THESIS ABSTRACT Objectives.  Adequate nutrition and probiotics have both been shown to reduce the severity of colitis but their impact on hepatic and gastrointestinal protein metabolism has not been studied.  Our primary objective was to compare the independent effect of probiotics vs. providing adequate nutrition on protein synthesis in a macronutrient-restricted piglet model of colitis.  The secondary outcomes of this study were to determine histological contrasts and changes in oxidative stress markers resulting from probiotics in the malnourished state or providing adequate nutrition.  Finally, we also measured mass balance and plasma concentrations of copper, iron and zinc over 5 days of colitis to determine how trace element nutrition is impacted by both colitis and probiotics.  Design and Analysis.  Twenty-four piglets, receiving 1g•kg-1•d-1 dextran sulphate (DS), were randomized to receive a 50% macronutrient restricted diet without (MR) and with probiotics (MR+PRO) or a diet providing 100% NRC requirements for growing piglets (WN). Eight other piglets were randomized into a well-nourished group without colitis (REF) for histological and trace element comparisons.  A primed constant infusion of the tracer L-[ring-2H5]phenylalanine was performed to determine the protein synthesis in small intestinal mucosa, colon, liver and of plasma proteins.  Standard, in situ and immunohistological staining techniques were used for histological assessment and the ferric reducing antioxidant power assay, ELISA F2-isoprostane assay and plasma copper:zinc ratio were used as oxidative stress markers.   Results.  Providing adequate nutrition increased protein synthesis in colon, liver and plasma albumin pool and decreased colitis severity.  Probiotics stimulated protein synthesis in the liver as well as synthesis of all liver-derived plasma proteins, without affecting GI protein synthesis.  Iron and zinc appear to be affected by both colitis and colitis with superimposed</dc:abstract><ual:supervisor>Linda J. Wykes</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/tt44pq759.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/9g54xm541</ual:fedora3Handle><dc:subject>Health Sciences - Nutrition</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Aqb98mj21m"><ual:graduationDate>2007</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Chemical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Methane hydrate film growth measurements by microscopy</dcterms:title><ual:dissertant>Breton, Andre</ual:dissertant><dc:abstract>Gas Hydrates are a specific type of inclusion compound in which water molecules arrange themselves by hydrogen bonding to form cages accommodating a guest molecule of appropriate size.  These compounds are thermodynamically stable at low temperatures (~ 0°C) and relatively high pressures.  These conditions are typically found in deep oceans and make gas hydrates the most abundant hydrocarbon source on earth. Gas hydrates have also been investigated because they are known to plug oil pipelines.  Experiments were carried out to determine how efficient VP/VC was at slowing down gas hydrate formation when compared to de-ionized water.  Kinetics of formation of methane hydrate film was compared using two measurement methods: Microscopy and gas consumption.  Experiments were conducted for each solution at temperatures and pressures ranging from 274-278 K and 5000-7000 kPa respectively.  Gas consumption by the system and spatial movement of the hydrate film were monitored simultaneously.  It was noticed that hydrate film growth measured by microscopy could be separated in two steps; initial and second growth stages.  Initial growth rates measured were significantly higher than second growth rates (3 to 300 times higher).  It is suspected that liquid saturation affects initial growth rates and initial film thicknesses.  It was noticed that at 1 and 2°C, initial growth rates in presence of VP/VC were higher than with water.  Initial growth rates with VP/VC were lower than those of water at 3°C.  Results of initial film thicknesses show an inversely proportional trend with subcooling conditions.  Second growth rates were shown to increase when hydrate formation driving force increased in presence of water.  Results with VP/VC were significantly lower than with water and were not shown to depend noticeably on experimental conditions.</dc:abstract><dc:abstract>Les hydrates gazeux font partis de la catégorie des complexes d’inclusion.  Ce type de molécule se forme lorsque des molécules d’eau se structurent par liaisons hydrogène pour former une cage pouvant accepter une molécule «invité» d’une grandeur appropriée.  Ces complexes sont thermodynamiquement stable à basse temperatures (~ 0°C) et pressions relativement élevées.  Ces conditions sont reproduites dans les fonds marins.  Ceux-ci abritent une énorme quantité d’hydrates gazeux, ce qui en fait la plus grande source d’hydrocarbures sur terre.  Les hydrates gazeux sont également étudiés parce qu’ils se forment dans les conduits transportant du gaz ou du pétrole causant plusieurs problèmes.  Une série d’expériences a été réalisée afin de déterminer l’efficacité de VP/VC à ralentir la croissance d’hydrates par rapport à une solution d’eau déionisée.  La cinétique de formation d’une pellicule d’hydrate a été comparée en utilisant deux méthodes d’analyse: la microscopie et la consommation de gaz par le système.  Les pressions and températures examinées pour chaque solution variaient respectivement entre 5000-7000kPa et 274-276K.  La consommation de gaz et la hauteur du film étaient suivies tout au long de l’expérience.  Il a été remarqué que la période de croissance du film d’hydrates mesurée par microscopie pouvait être séparée en deux phases distinctes: la croissance initiale et la deuxième croissance.  La vitesse de croissance initiale mesurée était significativement supérieure à celle de la deuxième croissance (3 à 300 fois supérieure).  La saturation de la phase liquide est suspectée d’influencer les valeurs de vitesse de croissance initiale ainsi que la hauteur initiale du film.  La vitesse croissance initiale mesurée avec VP/VC était plus élevée qu’en présence d’eau déionisée à 1 et 2°C.  Les résultats à 3°C montraient une tendance inverse.  Les estimations d</dc:abstract><ual:supervisor>Phillip Servio</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/pc289m82h.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/qb98mj21m</ual:fedora3Handle><dc:subject>Engineering - Heat and Thermodynamics</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A4q77fv38m"><ual:graduationDate>2007</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Bioresource Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Comparative performance of solar cabinet, vacuum assisted solar and open sun drying methods</dcterms:title><ual:dissertant>Perumal, Rajkumar</ual:dissertant><dc:abstract>Tomato (Lycopersicon esculentum L.var) is one of the most important vegetables in our diet and dried tomato products are becoming popular for the preparation of various food items. Though sun drying has been used for the preservation, it is a slow process and the quality of the dried product is often inferior due to contaminations. Therefore, a lab model solar cabinet and vacuum assisted solar dryers were developed to study the drying kinetics of tomato slices (4, 6 and 8 mm thicknesses) and the results were compared individually with open sun drying under the weather conditions of Montreal, Canada. The drying kinetics using thin layer drying models and the influence of weather parameters such as ambient air temperature, relative humidity, solar insolation and wind velocity on drying of tomato slices were evaluated.  During drying, it was observed that the temperatures inside the solar cabinet and vacuum chamber were increased to 63 and 48oC when the maximum ambient temperature was only 30oC.  The tomato slices of 4, 6 and 8 mm thicknesses could be dried from 94.0 to 11.5% wet basis moisture content, respectively in 300, 420 and 570 min using solar cabinet, in 360, 480 and 600 min using vacuum assisted solar dryer and it took 435, 615 and 735 min under open sun drying method.  The quality of tomato slices in terms of physicochemical parameters such as colour retention, water activity, rehydration capacity and ascorbic acid retention were evaluated and the overall study concluded that good quality dehydrated tomato slices could be produced by using vacuum assisted solar dryer compared to solar cabinet and open sun drying methods. The Page model was found to be better in describing the drying kinetics of tomato slices in all the drying methods studied.</dc:abstract><dc:abstract>La tomate (Lycopersicon esculentum L. var) est une importante source nutritive de notre alimentation et les tomates séchées gagnent en popularité dans de nombreuses préparations alimentaires.  Le séchage naturel est la méthode traditionnelle utilisée pour la production de tomates séchées, cependant c’est un processus lent et la qualité du produit séché est variable et sujette à la contamination.  Un séchoir solaire et un séchoir solaire sous-vide furent donc développés afin d’étudier le séchage solaire de tranches de tomates (4, 6 et 8 mm d’épaisseur) en comparaison au séchage naturel sous les conditions météorologiques de Montréal, Canada.  La cinétique du séchage des tranches de tomates suivant des modèles en couches minces a été établie en fonction de l’influence des conditions météorologiques telles que la température ambiante, l’humidité relative, le rayonnement solaire et la vitesse du vent. Lors du séchage dans le séchoir solaire et le séchoir solaire sous-vide, la température interne des deux séchoirs a atteint 63° et 48°C respectivement alors que la température ambiante était de 30°C.  Les tranches de tomates de 4, 6 et 8 mm d’épaisseur ont pu être séchées d’un taux d’humidité de 94% à 11.5% (état humide) et ce après 300, 420 et 570 minutes en utilisant le séchoir solaire, en 360, 480 et 600 minutes grâce au séchoir solaire sous-vide, alors qu’il en a pris 435, 615 et 735 minutes par séchage naturel.   La qualité des tranches de tomates a été évaluée en fonction de certains paramètres physico-chimiques tels que la stabilité de la couleur, l’activité de l’eau, la capacité de réhydratation, et la conservation de l’acide ascorbique.  Des tranches de tomates séchées de meilleure qualité peuvent être produites par séchage solaire sous-vide en comparaison avec le séchage solaire et le séchage naturel.  La modélisation de Page offre une très bonne représentation$</dc:abstract><ual:supervisor>G. S. Vijaya Raghavan</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/5425kd53s.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/4q77fv38m</ual:fedora3Handle><dc:subject>Agriculture - Food Science and Technology</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A0g354j12r"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Schulich School of Music</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>A comparison of piano performance evaluations given under audio-only, limited and full audiovisual conditions</dcterms:title><ual:dissertant>Chan, Kelvin Man Lok</ual:dissertant><dc:abstract>Au cours des dernières années, de nombreux chercheurs dans les domaines d'éducation musicale et de psychologie ont exploré l'impact de différentes conditions auditives et visuelles sur l'évaluation de prestations pianistiques. La majorité des recherches a démontré que la composante visuelle des prestations pianistiques influence significativement l'évaluation de l'expression du jeu pianistique et que des paramètres, tels que la quantité d'information audiovisuelle, les gestes du pianiste, le niveau de maîtrise du jeu de l'interprète et les critères expressifs peuvent aussi influer sur l'évaluation du jeu pianistique. Le but principal de cette étude était de vérifier si la composante visuelle du jeu pianistique a un impact significatif en contexte d'évaluation. La principale contribution de cette étude au domaine de l'évaluation du jeu pianistique réside dans la méthodologie employée.  En effet, la combinaison des différents éléments méthodologiques, dont la condition audio-visuelle limitée des mains et des bras,  la variété de styles de répertoire utilisés, et l'emploi d'interprètes amateurs et professionnels, est originale dans le domaine.   Soixante pianistes, possédant au moins dix années de formation pianistique et ayant eu une expérience de concert et d'enseignement au cours des trois dernières années, ont évalué dix pièces du répertoire pianistique sous l'une des conditions suivantes: auditive seulement, audiovisuelle limitée (seuls les mains et bras du pianiste sont visibles), et audiovisuelle complète (l'ensemble du haut du corps de l'interprète est visible). Dix pièces de styles variés ont été interprétées par des pianistes de niveaux amateur ou professionnel. Trois groupes de 20 participants ont chacun été soumis à une seule condition d'évaluation afin d'évaluer chaque pièce selon quatre critères expressifs: le phrasé, les dynamiques, le rubato, et la qualité expressive globale du jeu. Une analyse de variance à un facteur (ANOVA) a démontré une différence significative (p &lt; .05) entre les conditions d'écoute auditive seulement et audiovisuelle complète ainsi qu'entre les conditions audiovisuelle limitée et complète mais pas entre les conditions d'écoute auditive seulement et audiovisuelle limitée. Trois analyses de variance à deux facteurs (ANOVA) ont démontré des interactions entre les conditions d'évaluation et les pièces, ainsi qu'entre les conditions d'évaluation et les niveaux de maîtrise des pianistes (p &lt; .05) mais pas entre les conditions d'évaluation et les critères expressifs.  Ces résultats renforcent les conclusions d'études précédentes selon lesquelles la composante visuelle a un impact significatif sur l'évaluation du jeu pianistique.  L'étude supplémentaire de différents types de gestes, en particulier ceux des mains et des bras, ainsi que leur impact sur la perception de l'expression musicale contribuerait à l'avancement des connaissances dans ce domaine. Mots clés: évaluation du jeu pianistique, conditions auditives et visuelles, geste pianistique, compétence instrumentale, critères expressifs</dc:abstract><dc:abstract>In recent years, numerous music educators and psychologists have explored the impact of the visual channel on piano performance evaluation. The majority of them found that the visual component of piano performances has a significant impact on ratings of expression, and that variables such as the amount of audiovisual information, performer body movements, performer proficiency, and expressive criteria could also be influential factors in piano performance evaluation. The main goal of the current study was to investigate whether the visual component of piano performances has a significant impact on their ratings in a performance evaluation context. The main contribution of the current study to the piano performance evaluation is its combination of elements in methodological design that is new to research in the field: isolating the hands and arms for study, utilizing a wide variety of repertoire, and employing both expert and amateur performers. In this study, 60 pianists with at least 10 years of piano training, as well as performing or teaching experience in the last 3 years, rated 10 piano performances under one of three rating conditions: audio-only, limited audiovisual (only the hands and arms of the performer are visible), and full audiovisual (the entire upper body of the performer is visible). The performances featured pieces of diverse styles, as well as pianists of either amateur or professional proficiency. The participants were divided into three groups of 20, with each group being subjected to one rating condition. The participants rated each performance under four expressive criteria: Phrasing, Dynamics, Rubato, and Overall Quality. An independent-sample t-test (one-way ANOVA) shows that a significant difference existed between audio-only and full audiovisual, as well as limited and full audiovisual ratings at the p &lt; .05 level, but not between audio-only and limited audiovisual ones. Three two-way ANOVAs show that interactions between Rating Condition and Performance, as well as Rating Condition and Performer Proficiency at the p &lt; .05 level were also found, but not between Rating Condition and Expressive Criteria.  The main finding of this study further reinforces the results of existing research, which demonstrated that the visual component of piano performances has a significant impact on their evaluation. Additional research on the various types of body movements, particularly those of the hands and arms, as well as their impact on the perception of musical expression would be valuable in furthering this topic of study. Keywords: piano performance evaluation, audiovisual, body movements, performer proficiency, expressive criteria</dc:abstract><ual:supervisor>Isabelle Cossette</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/g732dc724.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/0g354j12r</ual:fedora3Handle><dc:subject>Music</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Acr56n391k"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Medicine</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Role of Ubiquitin Lingase RNF149 in Gonocyte Development</dcterms:title><ual:dissertant>Kong, Chi Chon</ual:dissertant><dc:abstract>La fonction reproductrice mâle dépend de la formation de cellules souches spermatogoniales à partir de précurseurs néonataux, les gonocytes. Au cours de nos recherches sur les mécanismes régulant la differentiation des gonocytes néonataux en spermatogonies, nous avons mis en évidence la participation de plusieures enzymes du système protéasomal de l'ubiquitine (UPS), et identifié plusieures enzymes UPS dont l'expression était modifiée de façon dynamique pendant la différentiation des gonocytes. La présente étude est centrée sur la compréhension du rôle de la protéine "RING finger"149 (RNF149), une ligase de type E3 que nous avons précédemment trouvée fortement exprimée et régulée à la baisse dans les spermatogonies. La mesure des transcripts de RNF149 par PCR quantitative en temps réel des jours 2 à 35 (puberté) après la naissance dans les testicules, cerveau, foie, rein et cœur, indiquait les niveaux les plus élevés dans les testicules. Nous avons ensuite performé des expériences de blocage d'expression de RNF149 utilisant un RNA court d'interférence (siRNA), un nucléotide non-specifique brouillé, ou du milieu (mock). Alors que la combinaison proliferative de PDGF-BB et 17β-estradiol (P+E) entrainait une augmentation d'expression des transcripts du marqueur de prolifération PCNA et de RNF149 dans les cellules mock, les effets de P+E sur l'expression de ces gènes étaient réduits dans les cellules traitées avec le siRNA de RNF149. Ces résultats suggèrent que l'expression de RNF149 est regulée au cours de la prolifération des gonocytes, ainsi que l'existence d'un lien fonctionnel entre RNF149 et PCNA. Afin de déterminer la localisation subcellulaire de RNF149, nous avons généré des vecteurs d'expression fusionnant EGFP et RNF149, après avoir déterminé la séquence du transcript de RNF149 dans le testicule de rat. Curieusement, deux transcripts variants sont exprimés dans les tissus de rats, prédisant deux protéines tronquées, l'une contenant le domaine fonctionnel PA et l'autre le domaine RING de RNF149. Nous avons performé des experiences sur les lignées cellulaires de carcinoma embryonal de souris F9 et de spermatogonies de souris C18-4 qui ont révélé des différences de profiles d'expression entre les deux protéines tronquées. Les résultats de cette étude supporte l'idée d'un rôle de RNF149 dans la prolifération des gonocytes et suggère que sa transcription mène à la formation de mRNA variants codant pour deux protéines avec des domaines fonctionnels differents. Des études futures examineront les rôles respectifs de ces protéines variantes dans les lignées cellulaires et les gonocytes.</dc:abstract><dc:abstract>Male reproductive function depends on the formation of spermatogonial stem cells from their neonatal precursors, the gonocytes. In a previous study of the mechanisms regulating gonocyte development, we unveiled the participation of the ubiquitin proteasome system (UPS) in this process and identified several UPS enzymes dynamically altered during gonocyte differentiation. The present work focuses on understanding the role of the RING finger protein 149 (RNF149), an E3 ligase previously found strongly expressed in gonocytes and down-regulated in spermatogonia. The quantification of RNF149 mRNA by qPCR from postnatal-day (PND) 2 to 35 (puberty) in rat testis, brain, liver, kidney, and heart indicated that its highest levels are found in testis. Silencing experiments were performed in PND3 rat gonocytes by electroporation with RNF149 siRNA, a scrambled nucleotide or medium (Mock). While a proliferative cocktail of PDGF-BB and 17β-estradiol (P+E) increased both the expression levels of the cell proliferation marker PCNA and RNF149 in mock cells, the effects of P+E on both genes were reduced in cells treated with RNF149 siRNA, suggesting that RNF149 expression is regulated during gonocyte proliferation and that there might be a functional link between RNF149 and PCNA. Lastly, in order to examine RNF149 subcellular localization, EGFP-tagged RNF149 vectors were constructed, after determining rat testis RNF149 mRNA sequence. Surprisingly, two variant transcripts were expressed in rat tissues, predicting truncated proteins, one containing the PA and the other the RING functional domains. Transfection in the mouse F9 embryonal carcinoma cells and C18-4 spermatogonial cell line showed differential subcellular profiles of the two truncated proteins. The results of this study support a role for RNF149 in gonocyte proliferation and suggest its transcription to variant mRNAs resulting in two proteins with different functional domains. Future studies will examine the respective roles of these variants proteins in the cell lines and isolated gonocytes.</dc:abstract><ual:supervisor>Martine Culty</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/jq085p09k.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/cr56n391k</ual:fedora3Handle><dc:subject>Medicine</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A2801pk053"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>School of Physical and Occupational Therapy</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Is the finger-to-nose test adequate for evaluating upper-limb coordination in patients with stroke?</dcterms:title><ual:dissertant>Rodrigues, Marcos</ual:dissertant><dc:abstract>Background and purpose: The Finger-to-Nose Test (FNT) is the clinical gold standard measure for upper-limb coordination. However, the assumption that FNT assesses coordination has not been empirically verified. Our goal was to determine the ability of the FNT metric, time, to identify coordination deficits in people with stroke using both endpoint performance measures and movement quality measures. Methods: Age- and gender-matched healthy controls (n=20) and subjects with stroke (n=20) performed 2 blocks of 10 continuous to and fro movements of the finger between a target located at 90% arm length and the nose (ReachIn, ReachOut). Upper-limb kinematics were recorded (Optotrak, 100Hz). Results: Compared to controls, stroke subjects made more curved endpoint trajectories (Index of curvature: stroke=1.23, control=1.04, p&lt;0.05, ReachIn) and used less shoulder horizontal abduction (stroke=11.8º, control=17.6º, p &lt;0.001, ReachIn). Compared to their less-affected side, stroke subjects moved their more-affected arm slower (ReachIn: 18%, ReachOut: 43%; for both directions F1, 113=14.136, p&lt;0.001) and had more curved trajectories (ReachIn: 18%, ReachOut: 27%; for both directions F1, 114=6.003, p&lt;0.05), while interjoint coordination was similar. FNT movement time correlated with endpoint straightness (r=0.77, p=0.001), temporal (r=0.63, p=0.001) and spatial (r=-0.61, p&lt;0.05) interjoint coordination. Shoulder horizontal abduction range (β=0.127), temporal (β=0.855) and spatial (β=-0.191) interjoint coordination explained 82% of the variance in the time to perform the FNT.Discussion and conclusions: Shoulder movement and temporal and spatial interjoint coordination predicted the time to perform the FNT, indicating that this clinical test can be used to measure upper-limb coordination after stroke.Key words: Stroke, Cerebral infarct, Motor Skills Disorders, Coordination, Upper Extremity, Upper Limb, finger to nose test, FNT.</dc:abstract><dc:abstract>Introduction et objectif: Le test doigt-nez (TDN) est l'outil clinique le plus utilisé pour mesurer la coordination des membres supérieurs. Cependant, les suppositions que le TDN évalue la coordination n'ont pas été vérifiées de façon empirique. Notre objectif est de déterminer les habilités métriques du temps nécessaire pour compléter le TDN, et d'identifier les déficits de coordination chez les individus ayant eu un accident vasculaire cérébral (AVC) en utilisant des mesures de performance du point final et des mesures de la qualité du mouvement.Méthodes: Un groupe de 20 individus avec un AVC ont été appariés selon l'âge et le sexe avec un groupe contrôle de 20 participants sains. Les individus ont effectués 2 blocs de 10 mouvements consécutifs d'un mouvement aller-retour du doigt entre la cible qui est située à 90% de la longueur du bras et du nez (AtteinteAvant, AtteinteArrière). La cinématique des membres supérieurs a été enregistrée (Optotrak, 100Hz).Résultats: En comparaison avec le groupe contrôle, les mouvements des individus avec un AVC ont eu une courbe plus prononcée des trajectoires du point final (Index de courbure : AVC=1.23, contrôle = 1.04, p&lt;0.05, AtteinteAvant) et ont une diminution de l'abduction horizontale de l'épaule (AVC=11.8º, contrôle=17.6º, p &lt;0.001, AtteinteAvant). Comparativement au côté le moins affecté, les individus avec un AVC ont bougé leur membre le plus affecté plus lentement (AtteinteAvant: 18%, AtteinteArrière: 43% ; pour les deux directions, F1, 113=14.136, p&lt;0.001) et ont eu une courbe plus prononcée pour les trajectoires du point final (AtteinteAvant: 18%, AtteinteArrière: 27%; pour les deux directions  F1, 114=6.003, p&lt;0.05), alors que la coordination interarticulaire était similaire. La durée du mouvement du TDN est corrélée avec la droiture  de la trajectoire du point final (r=0.77, p=0.001), la coordination interarticulaire temporale (r=0.63, p=0.001) et spatiale (r=-0.61, p&lt;0.05). L'amplitude de l'abduction horizontale de l'épaule (β=0.127), la coordination interarticulaire temporale (β=0.855) et spatiale (β=-0.191) expliquent 82% de la variance du temps pour effectuer le TDN.Discussion et conclusions: Les mouvements de l'épaule et la coordination interarticulaire temporale et spatiale ont prédit le temps pour effectuer le TDN, indiquant que ce test clinique peut être utilisé pour mesurer la coordination des membres supérieurs après un AVC.Mots-clés: Accident vasculaire cérébral, infarctus cérébral, troubles moteurs, coordination, extrémité supérieure, membre supérieur, test doigt-nez, TDN</dc:abstract><ual:supervisor>Mindy Levin</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/tt44pq76k.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/2801pk053</ual:fedora3Handle><dc:subject>Physical &amp; Occupational Therapy</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Arj4307471"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of Integrated Studies in Education</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Remembering the teacher: An autobiographical reflective journey through the memories of a teacher and his former students</dcterms:title><ual:dissertant>Nardozza, Matthew</ual:dissertant><dc:abstract>This study explores how interviewing and gathering feedback from former students can benefit in the professional development of a teacher. Although there is an extensive amount of literature concerning teacher reflection focusing on the perspective of the teacher, this study places importance on both the perspectives of the teacher and his former students. Building on the works of Dewey, Tyler and Aoki concerning educational experiences, Korthagen's approach to teacher reflection, Eakin and Graham's ideas concerning autobiography and Barone and Yoder and Strong-Wilson's views on learning from the stories of others, the author takes existing literature and builds on it, suggesting a unique approach to further his own development as a teacher. Using an autobiographical narrative approach, the author represents the memories of both the teacher and student(s) in a series of vignettes. The sample of students interviewed covers a spectrum of six years of experience that the teacher has been teaching. These vignettes highlight the memories of the teacher concerning his former students and the memories/feedback of the students concerning their former teacher and the time spent in his class. Furthermore, each vignette is written in the third person to create some distance between the author and the data gathered. The analysis consists of looking for common themes that arose while gathering the data among the nine former students interviewed, and aims to describe what the teacher learned during the research process to better himself for future experiences in his teaching. By conducting the research in this way, the teacher can dwell in a rich reflective practice that combines unique perspectives of firsthand accounts belonging to those who his teaching affected directly: himself and his students.    </dc:abstract><dc:abstract>Cette étude explore comment des entrevues avec d'anciens élèves de même que la collecte de leurs commentaires peuvent être bénéfiques au dévelopement professionnel d'un enseignant. Malgré le fait qu'il y ait une très grande quantité de litérature qui concerne ce sujet du point de vue de l'enseignant, cette étude met l'emphase autant sur le point de vue de l'enseignant que sur celui des anciens étudiants.  S'appuyant sur les travaux de Dewey, Tyler et Aoki portant sur les expériences éducatives, sur l'approche de Korthagen face à la rélexion de l'enseignant, sur les idées de Eakin et Graham concernant l'autobiographie de même que sur les points de vue de Barone, Yoder et Strong-Wilson sur ce qu'on peut apprendre des histoires des autres, l'auteur prend la litéraure existante et propose une approche unique afin d'approfondir sa propre évolution en tant qu'enseignant. Utilisant une approche narrative autobiographique, l'auteur présente les souvenirs de l'enseignant et des élèves dans une série de vignettes.  L'échantillon d'élèves interviewés couvre un spectre de six années d'expérience de l'enseignant dans son domaine.  Ces vignettes mettent en lumière les souvenirs de l'enseignant face à ses anciens élèves de même que ceux que les étudiants ont par rapport à leur ancien enseignant et à leur temps passé en classe.  De plus, chaque vignette est rédigée à la troisième personne de façon à créer une certaine distance entre l'auteur et les informations recueillies.  L'analyse consiste à rechercher des thèmes communs qui sont ressortis durant la collecte de données effectuées avec les neuf anciens élèves interviewés et aussi à décrire ce que l'enseignant a appris durant le processus de recherche qui pourra par la suite l'aider à s'améliorer dans de futures expériences d'enseignement.  En effectuant la recherche de cette façon, l'enseignant se retrouve dans une pratique réfléchie qui combine les perspectives uniques de ceux qui ont été directement touchés par son enseignement: lui-même et ses élèves.</dc:abstract><ual:supervisor>Teresa Strong</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/7p88ck441.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/rj4307471</ual:fedora3Handle><dc:subject>Integrated Studies in Education</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Apc289m86m"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Geography</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Historical trends of ecosystem services in Canada, 1911-2011</dcterms:title><ual:dissertant>Clark, Emily</ual:dissertant><dc:abstract>Ecosystem services (ES) refer to the flow of ecosystem benefits to people, and are classified as either provisioning, cultural, or regulating services. Canadian landscapes have been transformed by a land-use history that often prioritized provisioning services, at the expense of regulating and cultural services. Although the latest scholarship acknowledges the importance of assessing historical legacies to understand current ecosystem functioning, most studies are time and space static. This thesis considers a century of Canadian ecological history (15 time steps from 1911-2011) at a national scale and county-level resolution (n=293 in 2011). Data were obtained from a variety of archival sources including the Canadian Census of Agriculture, The Atlas of Canada Protected Areas data, and Parks Canada visitation records, and were used to quantify 16 ES. Historical county boundary maps were used to standardize the data relative to the changes of boundaries though time, and to produce a series of maps of ES bundles. A K-means analysis and mapping were used to assess changes in the composition and distribution of ES bundles. Finally, these long-term dynamics were evaluated qualitatively, through the lens of an historian. The political climate and social attitudes towards management and conservation were narrated in order to interpret quantitative trends, and to provide a more complete picture of ecological development during the twentieth century.Overall, there was an increase in the number and complexity of ES bundles over time, and a trend towards regional specialization. Bundles generally transitioned according to three trends: (1) relatively unproductive bundles transitioning into service provisioning, (2) bundles transitioning to include a new dominant service, and (3) bundles that were replaced by different functional compositions entirely. Ninety-six percent of counties (n=273) experienced a transition in bundles at least once over the one hundred-year period. Eastern Canada was shown to be more dynamic in terms of the number of bundle transitions than other parts of Canada. Ultimately, the perspective provided by such a long history demonstrates the dynamism of ES in response to management decisions and the interactions between multiple ES and socio-political variables. </dc:abstract><dc:abstract>Le terme de service écologique (ES) se rapporte aux flux de bénéfices que la population reçoit des écosystèmes, et sont classés en services d'approvisionnement, culturels ou de regulation. Les paysages canadiens ont été transformés par une utilisation des terres qui a historiquement  prioriser les services d'approvisionnement, aux dépens des services de régulation et culturels. Si les récentes recherches reconnaissent l'importance de prendre en compte l'héritage de l'histoire pour comprendre le fonctionnement actuel des écosystèmes, la plupart des études restent focalisées sur un point dans le temps et l'espace. Cette thèse porte sur un siècle d'histoire écologique canadienne (15 pas de temps de 1911 à 2011) à l'échelle nationale et à la résolution des comtés (n=293 en 2011). Les données ont été obtenues de divers documents d'archives, tels que le recensement de l'agriculture canadienne, le département des Ressources Naturelles Canada, l'atlas canadien des aires protégées et le registre des visites de Parc Canada, et utilisées pour quantifier 16 SE. Des cartes historiques montrant les limites administratives des comtés ont été utilisées pour standardiser les données relativement aux changements de ces limites au cours du temps, et pour produire des séries de cartes représentant les bundles de SE (groupes de SE corrélés positivement dans le temps et l'espace). Des méthodes d'analyses de K-moyenne et de cartographie ont été utilisées pour évaluer les changements dans la composition et la distribution spatiale des bundles de SE au cours du temps. Enfin, les dynamiques temporelles ont été évaluées qualitativement, avec le regard d'un historien. Le climat politique et les attitudes sociales envers la gestion et la conservation ont été narrés de manière à interpréter les résultats quantitatifs, et à fournir une image plus complète du développement de l'écologie canadienne au 20ème siècle.    De manière générale, le nombre et la complexité des bundles de SE ont augmenté au cours du temps, avec une tendance vers une spécialisation régionale de leur provision. Les transitions temporelles entre bundles suivent trois voies générales : (1) les bundles relativement peu productifs transitionnent vers la provision de services d'approvisionnement, (2) d'autres transitions impliquent l'incorporation d'un service dominant, (3) des bundles changent entièrement de composition fonctionnelle. Les bundles produits dans quatre-vingt-six pourcent des comtés (n=273) ont subi au moins une transition au cours des 100 années étudiées. L'est du Canada a montré plus de dynamisme en terme de nombre de transitions de bundles que les autres régions canadiennes. Au final, la perspective offerte par une longue histoire révèle la dynamique des SE en réponse aux décisions de gestion ainsi que les interactions entre plusieurs SE et des variables socio-politiques. </dc:abstract><ual:supervisor>Benjamin Forest</ual:supervisor><ual:supervisor>Jeanine Rhemtulla</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/3f462818p.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/pc289m86m</ual:fedora3Handle><dc:subject>Geography</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ad217qs55k"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of History and Classical Studies</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Worlds of protest &amp; worlds of dissent: a comparison of West German protest and Czechoslovak dissent</dcterms:title><ual:dissertant>Aitken, David</ual:dissertant><dc:abstract>This thesis explores the similarities and dissimilarities between West German protest and Czechoslovak dissent during the 1960s and 1970s. It argues that Jonathan Bolton's conception of Czechoslovak dissent, as one "world" or many different "worlds" of experiences, can be used to fruitfully examine roughly contemporaneous protest movements on the other side of the Iron Curtain during the postwar period. Appealing to Bolton's description of the "worlds of dissent" in Czechoslovakia, this thesis introduces the idea of the "worlds of protest" in West Germany. What is sought is a better understanding of the nature of protest and the nature of dissent as related but distinct forms of political and cultural phenomena. It claims that both West German protest and Czechoslovak dissent were intertwined with a concurrent "crisis of credibility" facing the political and social orders of each country. The oppositional movements, which emerged in West Germany and Czechoslovakia during the 1960s and 1970s, developed critiques of their respective regimes through reflections on the legacies of fascism and Stalinism in each country. This paper further argues that the strength of these critiques was largely derived from the extent to which the movements achieved an accurate understanding of the real nature of the regimes they criticised. While Czechoslovaks achieved a more cogent understanding of Gustáv Husák's Communist regime during the 1970s, West German's were unable to develop as rigorous an understanding of the Federal Republic due to their continued tendency to approach the Bonn regime through reflections on Germany's Nazi past. In general, this thesis contends that investigating West German protest in light of Czechoslovak dissent opens up new avenues for scholarly inquiry, which will allow us to move past the "global narratives of social unrest" that dominate much of the historical literature written on the 1960s and 1968, in particular.</dc:abstract><dc:abstract>Cette thèse explore les similitudes et les différences entre la protestation dans l'Allemagne de l'Ouest et de la dissidence tchécoslovaque entre les années 1960 et 1970. Il soutient que la conception de Jonathan Bolton de la dissidence tchécoslovaque comme un «monde» ou de plusieurs différents «mondes» d'expériences, peut être utilisé pour examiner dans un façon productive les mouvements de protestation plus ou moins contemporains de l'autre côté du Rideau de Fer pendant la période d'Après-Guerre. En appel à la description de Bolton des «mondes de la dissidence» en Tchécoslovaquie, cette thèse introduit l'idée des «mondes» de protestation en Allemagne de l'Ouest. Ce qui est recherché est une meilleure compréhension de la nature de la protestation et de la nature de la dissidence en tant que formes connexes, mais aussi comme deux distinctes phénomènes politiques et culturels. Ça postule que les deux protestation, Allemagne de l'Ouest et de la dissidence tchécoslovaque sont étroitement liés à une «crise de crédibilité» face aux ordres politiques et sociaux de chaque pays. Ces mouvements oppositionnels, qui ont émergés pendant des années 1960 et 1970, ont développés des critiques de leurs régimes respectifs par des réflexions sur les héritages de la fascisme et de la Stalinisme dans chaque pays De plus, il affirme que la force de ces critiques a été largement dérivée de la mesure dans laquelle les mouvements ont obtenu une compréhension exacte de la vraie nature des régimes qu'ils ont critiquer. En conclusion, on verra que les Tchécoslovaques on atteint une compréhension plus convaincante du régime communiste de Gustáv Husák au cours des années 1970, les ouest-allemands étaient incapables de développer une compréhension aussi rigoureuse de leur propre République fédérale en raison de leur tendance d'approcher le régime Bonn à travers du passé nazi de l'Allemagne. En général, cette thèse soutient que l'enquête des protestations de Allemagne de l'Ouest en vue de la dissidence tchécoslovaque ouvre de nouvelles voies pour la recherche académique qui nous permettront d'aller au-delà des «récits mondiaux de désordre sociale» qui dominent une grande partie de la littérature historique écrit sur les années 1960 et 1968 en particulier.</dc:abstract><ual:supervisor>James Krapfl</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/tq57nt69x.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/d217qs55k</ual:fedora3Handle><dc:subject>History and Classical Studies</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Agf06g5493"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Mechanical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>A process modelling and parameters optimization and recommendation system for binder jetting additive manufacturing process</dcterms:title><ual:dissertant>Chen, Han</ual:dissertant><dc:abstract>Binder Jetting (BJ) process is an Additive Manufacturing (AM) process in which powder materials are selectively joined by binder materials. Products can be manufactured layer by layer directly from 3D model data. It is not always easy for manufacturing engineers to choose proper BJ process parameters to meet the end-product quality and fabrication time requirements. This is because the quality properties of the products fabricated by the BJ process are significantly affected by the process parameters. The relationships between process parameters and quality properties are also very complicated. It is because the BJ AM process involves many different disciplines and physics theories, such as 3D computer graphics, Computer Numerical Control (CNC), metallurgy theory, materials science and chemistry, etc. In this research, a process model is developed by the Backward Propagation (BP) Neural Network (NN) algorithm based on 16 groups of orthogonal experiments designed by the Taguchi Method to express the relationships between 4 key process parameters and 2 key quality properties. The results are also converted to Signal-to-Noise (S/N) ratios and analyzed by the Analysis of Variance (ANOVA). An intelligent parameters recommendation system is developed to predict end-product quality properties and printing time with a given design. It can recommend process parameters based on the quality requirements. Some physical interpretations are introduced to explain the experiment results. 4 different sets of optimal parameters are concluded. They are verified by 4 groups of confirmation tests as well. A case study of an aircraft engine bracket is also conducted to verify the proposed system. The research outcome can be used as a guideline for selecting the proper printing parameters to achieve the desired properties and help to improve the quality control of components fabricated by the BJ AM process.</dc:abstract><dc:abstract>Le procédé par jet de liant est un procédé de fabrication additive consistant à déposer, de manière sélective, un liquide adhésif sur un matériau poudreux afin de créer un solide. Avec ce procédé, le produit peut être fabriqué couche par couche directement à partir d'une géométrie tridimensionnelle. En raison de la relation complexe entre les paramètres de production et les propriétés du produit fini, la sélection de ces paramètres pose un défi aux ingénieurs dont l'objectif est d'avoir un produit de qualité un temps raisonnable. Le procédé par jet de liant relie plusieurs disciplines en physique et ingénierie tel que l'infographie tridimensionnelle, la programmation de commande numérique, la métallurgie, la science des matériaux, la chimie, etc. D'où vient la complexité des paramètres de production. L'objectif de cette recherche est donc d'élaborer un modèle pour prédire les propriétés physiques des pièces fabriquées en fonction des paramètres choisis. Cette modélisation a été conçue en utilisant un «système neuronal à propagation inverse» (Backward Propagation (BP) Neural Network (NN)). Cet algorithme, basé sur 16 groupes d'expérience orthogonaux, est dérivé de la méthode Taguchi pour exprimer la relation entre quatre paramètres clés de fabrication et deux paramètres de qualité. Les résultats de ce modèle sont convertis en utilisant un rapport signal sur bruit (Signal-to-Noise (S/N)) et analysés avec une analyse de la variance (ANOVA). À partir de cela, un système intelligent de recommandations a été créé pour aider les utilisateurs dans leur sélection des paramètres de fabrication. Les recommandations par le système varient en fonction des prérequis du projet. Au cours du déroulement de cette recherche, ce système a été validé avec quatre tests expérimentaux. Les résultats ici peuvent être utilisés comme exemple pour sélectionner les paramètres et ainsi la qualité des pièces produites par jet de liant.</dc:abstract><ual:supervisor>Yaoyao Zhao</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/9s161902d.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/gf06g5493</ual:fedora3Handle><dc:subject>Mechanical Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ahh63sz75d"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Tunable absolute capacitive MEMS pressure sensor on a pure play commercial process</dcterms:title><ual:dissertant>Allan, Charles</ual:dissertant><dc:abstract>Une nouvelle méthode pour fabrique des capteurs de pression MEMS absolue a été développée sur la plateforme MIDISTM. MIDISTM est un procédé commercial offert par Teledyne DALSA. Les capteurs de pression MEMS utilise le vide ultra base avec un taux de fuite ultra base de 45 molécules par seconde [2, 3] comme référence ultra stable. Cette méthode de fabrication est aussi compatible avec les accéléromètres 3 axes et les gyroscopes 3 axes, ouvrent la possibilité de fabriqué des systèmes de mesure inertiel (SMI) de 10 axes dans un puce [4]. Une méthode pour caractériser les propriétés mécanique de la membrane est introduite. La méthode utilise le FT-MTA02 de FemtoTools. La méthode montre une bonne corrélation de la constante de déflection entre les mesures et les simulations. Une méthode pour mesurer la performance électrique des capteurs de pression est aussi introduite. Cette méthode va être utilisée pour caractériser des capteurs avec des diamètres de 210-360um et  épaisseurs de membranes de 3 et 5um.  Cette information sera utiliser pour montre la versatilité de cette méthode de fabrication de capteurs de pression MEMS absolue.  Les capteurs devront détecter résolution de 0.01kPa avec une précision de +/-0.7% dans un emballage de seulement 2mmx2mmx0.8mm. Le capteur consume seulement 24uA en haute résolution, et 3.3uA en bas résolution.</dc:abstract><dc:abstract>A new method for manufacturing absolute MEMS (microelectromechanical systems) capacitive pressure sensors was developed using MIDISTM, a commercially available Pure Play process offered by Teledyne DALSA. The method takes advantage of the clean vacuum and low leak rate of 45 molecules/s (7.5E−13 atm∙cc/s) [2, 3] as a highly stable reference. The method allows absolute capacitive pressure sensors to be manufactured alongside 3-axis accelerometers and 3-axis gyroscopes opening the possibility of 10-axis IMUs on a single dye [4]. A method for characterizing the mechanical properties of the sensing membrane using FT-MTA02 Micromechanical Testing and Assembly Station by FemtoTools showed an accurate correlation of membrane deflection constant with simulated results. Finally, a testing set up was designed and built to measure the electrical performance of the pressure sensors under the biomedical, environmental and energy extraction applications. This pressure testing set up will be used to compare sensor data from sensors with diameters ranging from 210-360um with membrane thicknesses of 3 and 5um. The data will be valuable in showcasing the range and versatility of this method for manufacturing absolute pressure sensors. From the simulations we expect our sensors to have a resolution of 0.01kPa with an accuracy of +/-0.7% in the smallest package (2mmx2mmx0.8mm) while consuming only 24uA in high resolution and 3.3uA in low resolution. A high performance, low power, customizable pressure sensor that can be fabricated alongside accelerometers, gyroscopes allowing for 10-axis IMUs on a single dye.</dc:abstract><ual:supervisor>Vamsy Chodavarapu</ual:supervisor><ual:supervisor>Milica Popovich</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/47429d23n.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/hh63sz75d</ual:fedora3Handle><dc:subject>Electrical and Computer Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Atx31qm616"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Integrated Program in Neuroscience</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>The role of dopamine in multiple memory systems in navigation: an acute phenylalanine/tyrosine depletion study</dcterms:title><ual:dissertant>Chaudhary, Zarah</ual:dissertant><dc:abstract>Il existe multiples systèmes de mémoire dans le cerveau qui fonctionnent indépendamment et en parallèle pour acquérir différentes formes de connaissances. Dans le domaine de la navigation humaine, cela se traduit de façon qu'il existe différentes stratégies spontanées pour se déplacer dans l'environnement. Les gens qui utilisent spontanément la stratégie spatiale démontrent plus d'activité cérébrale et de matière grise dans l'hippocampe et ceux qui utilisent spontanément la stratégie d'associations stimuli-réponse démontrent plus de fonction et de matière grise dans le noyau caudé du striatum. Au-delà des corrélats neuronaux et fonctionnels de ces stratégies, il reste encore beaucoup d'inexploré y compris les travaux de translation en ce qui concerne la détermination de la neurochimie de ces systèmes de mémoire. Il est présumé que les systèmes dopaminergiques affectent les systèmes de mémoire de façon indépendante mais leur rôle relatif dans le contexte des stratégies est inconnu. Si la dopamine (DA) affecte les stratégies de navigation de façon générale ou bien différentielle est une question ouverte au débat. L'étude actuelle vise à déterminer a) si la DA a un effet général sur la navigation humaine et b) si les implications de la DA sont différentes entre ceux qui emploient spontanément une stratégie de navigation par rapport à l'autre. Nous avons étudié l'effet de l'épuisement des précurseurs de la DA sur les stratégies de navigation chez les jeunes adultes en bonne santé par moyen d'une méthode établie d'épuisement expérimentale des précurseurs de la DA, « acute phénylalanine / tyrosine depletion » (APTD), validée pour produire une diminution transitoire de synthèse de la DA. Trente et un jeunes adultes en bonne santé sans antécédents de troubles psychiatriques ou neurologiques ont pris part à un total de trois études pilotes - deux mesures répétées (étude 1, N = 9 et l'étude 2, N = 11) et une avec modèle intergroupes (étude 3, N = 11) en utilisant les procédures double aveugle contre placebo et contre-équilibrées. Dans les études à mesures répétées, les participants ont participé à deux jours de test séparés d'un mois d'intervalle où ils ont ingéré un breuvage protéiné d'acide aminé (AA) qui était soit i) nutritionnellement équilibré (BAL), ou ii) dépourvu des précurseurs de la DA, la phénylalanine et la tyrosine (APTD). Dans l'étude intergroupes, les participants ont été randomisés pour recevoir soit le breuvage d'AA BAL soit APTD. Les participants ont ensuite complété une tâche de navigation virtuelle (4/8 Virtual Maze) qui dissocie les stratégies. L'apprentissage fut ressemblante sous l'effet des breuvages APTD et BAL pour les participants utilisant la stratégie spatiale et les stratégies d'association stimuli-réponse ce qui est en accord avec la littérature suggérant que la DA n'est pas impliqué dans l'apprentissage en tant que tel. Nos résultats préliminaires constatent que les stratégies qui repose sur le striatum sont plus sensibles à la diminution de la neurotransmission de la DA, suggéré par une dépendance plus exagérée sur les points de repères suite au breuvage d'AA APTD chez les apprenants des associations stimuli-réponse ce qui suggèrerait une transition possible aux stratégies spatiales. Ces données ne confirment pas l'hypothèse que la réduction globale de la transmission DA provoque un effet général de la navigation, mais plutôt que les effets spécifiques sont liés aux stratégies spontanées.</dc:abstract><dc:abstract>Multiple memory systems in the brain work independently and in parallel to acquire different forms of knowledge. In human navigation, this translates behaviourally to different spontaneous wayfinding strategies in a given environment.  Participants who spontaneously use the spatial strategy show greater activity and grey matter in the hippocampus and those that spontaneously use the response strategy show corresponding increases in function and grey matter in the dorsal striatum.  Beyond the functional and neural correlates of these strategies, much remains unexplored including translational work in determining the neurochemistry of these memory systems. Dopaminergic systems are believed to affect both memory systems independently but their relative role in the context of strategies is unexplored. Whether dopamine (DA) affects navigation strategies ubiquitously or differentially is a question open to debate. The current study seeks to determine a) whether DA has a general effect in navigation and b) whether DA may be implicated differently between those that spontaneously employ one strategy over the other. We studied the effect of DA precursor depletion on navigational strategies in healthy young adults by means of an established method of experimentally depleting precursors of dopamine, acute phenylalanine/tyrosine depletion (APTD), validated to produce transient decreases in dopamine synthesis and release.  Thirty one healthy young adults with no history of psychiatric or neurological disorders took part in a total of three pilot studies- two within subject (Study 1, N = 9 and Study 2, N = 11) and one between-group (Study 3, N = 11) design studies using double-blind, counter-balanced, placebo-controlled procedures. In the within subject studies, participants took part in two testing days one month apart where they ingested an amino acid (AA) mixture that was i) nutritionally balanced (BAL), or ii) devoid of the DA precursors, phenylalanine and tyrosine (APTD). In the between-group study, participants were randomized to either the BAL or APTD AA mixture group. Participants then completed a virtual navigation task (the 4/8 Virtual Maze) that dissociates spatial learners from response learners.  There was similar learning under APTD and BAL sessions in both spatial and response learners concordant with literature that dopamine is not involved in learning per se. We report preliminary findings that striatum-based response strategies may be more susceptible to decreased dopamine neurotransmission as shown by greater reliance of landmarks under APTD in response learners suggesting a possible shift to spatial strategies. These data do not support the hypothesis that global reduction in DA transmission causes a general effect in navigation but rather that specific effects are related to spontaneous strategies.</dc:abstract><ual:supervisor>Veronique Bohbot</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/g445ch189.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/tx31qm616</ual:fedora3Handle><dc:subject>Neuroscience</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A2z10wt31j"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Integrated Program in Neuroscience</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>The role of hippocampal and amygdala volumes in mediating the effects of prenatal maternal stress on cognitive and behavioural outcomes in the child</dcterms:title><ual:dissertant>Dufoix, Romane</ual:dissertant><dc:abstract>Problem Statement Prenatal maternal stress (PNMS) has been associated with increased behavioural problems and cognitive deficits in exposed children. Interestingly, research has shown that the developing brain is sensitive to PNMS. In particular, animal studies suggest that exposure to PNMS alters hippocampal (HC) and amygdala (AG) volumes, two regions important for cognition and emotions. Changes in HC and AG volume have been associated with behavioural problems and cognitive deficits. Yet, no studies have assessed the mediating effect of the HC and AG on the association between the various components of PNMS (i.e., objective stress, subjective stress and cognitive appraisal) and behavioural and cognitive outcomes in humans. Objectives The objectives were (1) to determine the extent to which cognitive appraisal, objective and/or subjective PNMS affect HC and AG volume in 11½ year old children; (2) To determine the extent to which hippocampal subfield volumes are altered by PNMS, and determine the extent to which the effects of PNMS on the right versus left HC and AG differ; (3) to determine the extent to which timing moderates the effects of PNMS on HC and AG volumes; and (4) To determine the extent to which HC and AG volumes mediate the effects of PNMS on behavioural and cognitive outcomes at age 11½  in children exposed in utero to varying levels of disaster-related PNMS. Methods T1-weighted images using a Siemens 3T scanner were acquired and HC and AG volume measured using semi-automated segmentation from 69 11½ year-old children whose mothers were pregnant during the January 1998 Quebec Ice Storm, or became pregnant within three months of exposure to the storm. The mother's objective stress, subjective stress and cognitive appraisal of the storm were assessed in June 1998. Behavioural and cognitive assessments were also obtained at 11½ year-old assessments. Results In girls, higher levels of maternal objective stress predicted higher IQ and this was associated with an increase in both left and right HC volume. In boys and girls, higher levels of objective and subjective stress were associated with more externalizing problems, and this was in part associated with an increase in AG volume. In boys, the greatest impact was seen when PNMS occurred during late gestation. Other results suggested that earlier age of menarche was associated with larger HC volume at age 11 ½. Discussion Findings from the present study provide support for the premise that cognitive abilities and susceptibility to behavioural problems may, in part, be programmed in utero, and that this effect may be mediated through changes in anatomy of the HC and AG. The effect of PNMS on the local development of AG and HC volumes seems to be stronger in girls. This may be explained by sex-specific placental adaptation to stress exposure or increase susceptibility of female brain to its milieu given the more rapid neurodevelopment trajectory in females compared to males.</dc:abstract><dc:abstract>Problématique Les enfants exposés à un stress maternel prénatal (SMPN) ont été associés à une augmentation de problèmes comportementaux et de déficits cognitifs. Il est intéressant de noter que des études ont montré que le cerveau est sensible au SMPN. En particulier, des études faites chez les animaux suggèrent qu'être exposé au SMPN affecte les volumesde l'hippocampe (HC) et de l'amygdale (AG), deux régions importantes pour la cognition et les émotions. Des changements de volumes dans l'HC et l'AG ont été associés avec des problèmes comportementaux et des déficits cognitifs. Néanmoins, aucune étude n'a testé l'effet de médiation de l'HC et l'AG sur l'association entre les différentes composantes du SMPN (i.e., le stress objectif, le stress subjectif et l'évaluation cognitive) et les issues comportementales et cognitives chez l'humain. Objectifs Nos objectifs étaient de (1) déterminer dans quelle mesure l'évaluation cognitive, le stress objectif et / ou subjectif affecte l'HC et l'AG chez les enfants de 11½ ans ; (2) déterminer dans quelle mesure les volumes des sous-parties de l'HC sont altérées, et dans quelle mesure l'effet de SMPN sur l'HC et l'AG droite versus gauche diffère ; (3) déterminer dans quelle mesure le timing modère l'effet du SMPN sur les volumes de l'HC et l'AG ; et (4) déterminer dans quelle mesure les volumes de l'HC et l'AG expliquent l'effet de SMPN sur le comportement et la cognition chez des enfants de 11½ ans qui ont été exposés à une catastrophe naturelle pendant la période de gestation.Méthode69 enfants de 11½  dont les mères étaient enceintes pendant la tempête de glace du Québec en 1998 ou sont tombées enceintes jusqu'à trois mois après la tempête ont été recrutés. Des images T1 pondérées ont été acquises à l'aide d'un scanner 3T Siemens, et lesvolumes de l'HC et l'AG mesurés par segmentation manuelle. Le stress objectif, subjectif et l'évaluation cognitive ont été mesuré en juin 1998. Les évaluations comportementales et cognitives ont été effectuées à l'âge de 11½. Résultats Chez les filles, un niveau de stress objectif élevé chez la mère était associé à un QI plus élevé, et ceci était expliqué par une augmentation du volume de l'HC droite et gauche. Chez les garçons et les filles, un niveau de stress objectif et subjectif maternel élevé était associé avec plus de problèmes d'extériorisations et ceux-ci était en partie expliqué par une augmentation du volume de l'AG. Chez les garçons, l'effet était plus important lorsqu'ils étaient exposé au stress plus tard dans la gestation. D'autres résultats montre aussi que une ménarche plus prematuré etait associé avec un plus grand volume de l'HC. Discussion Les résultats de cette étude soutiennent l'idée que les capacités cognitives et la susceptibilité aux problèmes comportementaux sont, en partie, programmées in utero, et que cet effet peut être expliqué à travers des altérations dans l'anatomie de l'HC et l'AG. L'effet de SMPN sur le développement de l'HC et l'AG paraît être plus important chez les filles. Ceci pourrait être expliqué par l'adaptation du placenta en réponse au stress ou par une sensibilité du cerveau à son environnement plus forte chez les filles étant donné la croissance neurodeveloppemental plus rapide qu'elles ont comparé aux garçons.</dc:abstract><ual:supervisor>Jens Pruessner</ual:supervisor><ual:supervisor>Suzanne King</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/nk322h392.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/2z10wt31j</ual:fedora3Handle><dc:subject>Neuroscience</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Avh53wz68r"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Medical Physics Unit</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Investigation of the uncertainties involved in the low energy proton interactions in Geant4</dcterms:title><ual:dissertant>Mirzakhanian, Lalageh</ual:dissertant><dc:abstract>One of the main concerns in proton therapy applications is the production of secondary neutrons causing secondary cancer especially in children and young adults. Different Monte Carlo codes such as Geant4 and MCNP6 have been used to investigate the production of secondary particles. However, there is no cross section and valid physical model in Geant4 for handling low energy protons below 200 MeV. The aim of this study was to investigate the uncertainties involved in the low energy proton interactions in Geant4 and MCNP6 for proton therapy applications. In this study, TENDL-2012 library was added to the default version of Geant4.10.00 and MCNP6, hereafter referred to as Geant4-TENDL and MCNP6-TENDL for a more correct handling of particles with energies below 200 MeV. For each version of the codes two geometry setups were simulated: The first setup was a proton irradiation of a simple water phantom, the second setup was the implementation of an experimental in-phantom proton depth-dose measurement performed at The Svedberg Laboratory (TSL) in Uppsala, Sweden. The depth-dose curve, primary and secondary particle fluence were scored inside the water phantom. The results obtained with Geant4 and MCNP6 were compared with results calculated with Geant4-TENDL and MCNP6-TENDL. The depth-dose calculation was compared with measurement performed at TSL. In Geant4, the secondary particles fluence was filtered by all physics processes to find the physics process that causes the difference between Geant4 and Geant4-TENDL. Despite good agreement in depth-dose curve and proton fluence, significant discrepancy was observed in fluence of secondary gam- mas and neutrons. Thermal neutron energy fluence calculated with Geant4-TENDL, MCNP6 and MCNP6-TENDL was 80.4%, 222.6% and 617.4% higher than Geant4 respectively, while for fast neutrons (6.3 MeV) the results obtained with Geant4- TENDL and MCNP6-TENDL were 122.9% and 124.2% higher than Geant4 while MCNP6 gave 20.6% lower value than Geant4. Regarding secondary gammas, at ener- gies above 10 MeV, Geant4-TENDL and MCNP6-TENDL had higher gamma fluence comparing to Geant4 and MCNP6 while at energies below 10 MeV, Geant4-TENDL and MCNP6-TENDL had lower gamma fluence. The main difference between the results from the model-based simulation and TENDL cross sections based simulation in Geant4 was due to proton inelastic process. Therefore, further experimental stud- ies are needed to find the most accurate cross section/models for handling nuclear interactions for low energy protons in Geant4.</dc:abstract><dc:abstract>Une des principales préoccupations en proton-thérapie est la production de neutrons secondaires, qui peuvent potentiellement être la cause de cancers secondaires, notamment chez les enfants et jeunes adultes. Divers codes Monte Carlo tels que Geant4 et MCNP6 ont été utilisés dans le but d'étudier la production de particules secondaires. Cependant, il n'existe pas de sections efficaces et de modèle physique valide dans Geant4 pour simuler les protons de basse énergie sous 200 MeV. Le but de ce travail est d'étudier les incertitudes reliées aux protons de basse énergie dans Geant4 et MCNP6 pour la proton-thérapie. Dans cette étude, la librairie TENDL-2012 à été ajoutée aux versions de base de Geant4.10.00 et MCNP6 (renommés Geant4-TENDL ainsi que MCNP6-TENDL, pour référence future) dans le but d'obtenir une précision accrue dans le transport de particules d'énergie inférieure à 200 MeV. Pour chaque version des codes, deux modèles géométriques ont été simulés : la simulation de l'irradiation d'un simple volume d'eau et la simulation d'une expérience effectuée au Laboratoire Svedberg (TSL, Uppsala, Suède). Les courbes de déposition de dose en profondeur ainsi que les fluences des particules primaires et secondaires ont été calculées à l'intérieur d'un fantôme d'eau. Les résultats obtenus avec Geant4-TENDL et avec MCNP6- TENCL ont été comparés avec ceux obtenus avec les versions de base de Geant4 et MCNP6. Les courbes de déposition de dose en profondeur ont aussi été comparées à des mesures expérimentales prises au TSL. Dans Geant4, les particules secondaires ont été triées par processus physique pour comparer Geant4 et Geant4-TENDL. Les résultats démontrent que malgré un bon accord pour les courbes de déposition de dose en profondeur et de fluence de protons, les fluences d'énergie calculées avec Geant4-TENDL, MCNP6 et MCNP6-TENDL sont respectivement 80.4%, 222.6% et 617.4 % plus grandes qu'avec Geant4 pour les neutrons thermalisés. Pour les neutrons rapides (6.3 MeV), les résultats obtenus avec Geant4-TENDL et MCNP6-TENDL sont 122.9% et 124.2% plus grands qu'avec Geant4, tandis que MCNP6 donne des valeurs de 20.6% plus basses que Geant4. En ce qui concerne les rayons gammas secondaires à des énergies supérieures à 10 MeV, Geant4-TENDL et MCNP6-TENDL une fluence plus élevée comparativement à Geant4 et MCNP6. Pour des énergies inférieures à 10 MeV, Geant4-TENDL et MCNP6-TENDL ont produit des fluences de rayons gammas inférieures à Geant4 et MCNP6. La principale différence entre les sections efficaces des modèles de Geant4 et celles de la librairie TENDL est due aux interactions inélastiques des protons. Conséquemment, des études expérimentales additionnelles sont nécessaires afin de déterminer des modèles et sections efficaces plus précis dans le but de simuler les interactions nucléaires pour les protons de basse énergie dans Geant4.</dc:abstract><ual:supervisor>Shirin Abbasi Nejad Enger</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/x633f411n.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/vh53wz68r</ual:fedora3Handle><dc:subject>Physical &amp; Occupational Therapy</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A5425kd55b"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Physics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Jet energy loss with finite-size effects and running coupling in MARTINI</dcterms:title><ual:dissertant>Park, Chanwook</ual:dissertant><dc:abstract>The suppression of jet production in heavy ion collisions is a sign of the creation of the hot and dense medium where quarks and gluons are deconfined. A number of phenomenological and theoretical descriptions have been proposed to address jet energy loss mechanisms in the QCD medium. In this thesis, we focus on the radiative energy loss and, following individual proposals by Caron-Huot and Gale and Young, Schenke, Jeon, and Gale, study the finite formation time of a splitting process and the running effect of the strong coupling in an emission vertex. We utilize a Monte Carlo event generator, MARTINI (Modular Algorithm for Relativistic Treatment of heavy IoN Interactions), in which the two radiative energy loss models are incorporated. Using MARTINI, we compute jet quenching observables in PbPb collisions at centre of mass energy of 2.76TeV using the ideal (3+1) dimensional hydrodynamics background. We obtain a good description of charged particle nuclear modification factors at different centrality classes with a gradual rise up to 100GeV. Also we present distributions of dijet imbalance compared to experimental measurements from the CMS. These results suggest that the two models play an significant role in the radiative energy loss. Finally, we discuss possibilities for improvement of this study by expanding the kinematic domain into that of the recent LHC energy scale and by applying more realistic hydrodynamical descriptions for the background medium.</dc:abstract><dc:abstract>La suppression de la production de jets dans les collisions d'ions lourds est un signe de la création de la matière chaude et dense où les quarks et les gluons sont déconfinés. Un certain nombre de descriptions phénoménologiques et théoriques ont été proposés afin d'aborder les mécanismes de perte d'énergie des jets dans les états de la QCD. Dans cette thèse, nous nous concentrons sur la perte d'énergie par rayonnement et nous étudions le temps de formation finie d'un processus de fractionnement ainsi que l'effet en cours d'exécution du couplage fort dans un sommet d'émission, suivant les propositions individuelles de Caron-Huot et Gale et de Young, Schenke, Jeon, et Gale. Nous utilisons un générateur d'événement de Monte-Carlo, MARTINI (Modular Algorithm for Relativistic Treatment of heavy IoN Interactions), dans lequel les deux modèles de perte d'énergie par rayonnement sont incorporés. À l'aide du MARTINI, nous calculer observables de jet trempe dans des collisions plomb-plomb à 2.76TeV en utilisant l'arrière-plan idéal de (3+1)-dimensionnelle hydrodynamique. Nous obtenons une bonne description de la particule nuclear modification factors chargée à différentes classes de centralité jusqu'à une augmentation graduelle de 100GeV. Aussi, nous présentons la répartition des dijet déséquilibre que nous avons comparée aux mesures expérimentales du CMS. Ces résultats suggèrent que les deux modèles jouent un rôle important dans la perte d'énergie par rayonnement. Enfin, nous discutons des possibilités pour améliorer cette étude en élargissant le domaine de la cinématique dans celui de l'échelle d'énergie récente LHC et en appliquant des descriptions hydrodynamiques plus réalistes pour la matière de QGP.</dc:abstract><ual:supervisor>Sang Yong Jeon</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/tq57nt70p.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/5425kd55b</ual:fedora3Handle><dc:subject>Physics</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Az029p758q"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Mechanical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Experimental study and numerical simulation of defect formation during compression moulding of discontinuous long fibre carbon/PEEK composites</dcterms:title><ual:dissertant>Landry, Charles Benoit</ual:dissertant><dc:abstract>Composite materials continue to replace metal in a growing number of applications due to their recognized performance, tailorability, life-cycle, and manufacturing advantages. While continuous fibre composites are the primary materials employed to replace metallic components in aerospace applications, their current use is generally limited to large shell-like structures. There is thus an emerging interest in the aerospace industry to use composite materials at a smaller scale to replace complex-shaped metallic components. This presents some unique challenges, mainly because traditional continuous fibre composite materials are practically unusable for this type of application, while short-fibre injection moulded parts have limited mechanical properties, although being highly versatile geometrically. Lying between these two extremes are discontinuous long fibre (DLF) composites, a bulk moulding compound type of material that can be compression moulded into complex-shaped parts. This technique has been shown to be very effective for moulding net-shaped components having features such as varying wall thickness, tight radii, reinforcing ribs, flanges, mould-in holes, etc. However, the increase in part complexity introduces manufacturing problems. One problem in particular arises during processing of thermoplastic composites, where inconsistent part quality may occur if the consolidation pressure is lost before solidification of the matrix during cooling. Such a phenomenon can be difficult to predict due to the complex nature of DLF composite parts. Given that understanding and predicting defect formation is crucial to achieving success in manufacturing of complex-shaped composite parts, a threefold approach was used in this thesis to study the phenomena that influence this behaviour. First, crystallization kinetics, thermal and crystallization shrinkage, and modulus development of carbon/Polyetheretherketone (PEEK) composites were characterized during cooling down from the melt temperature using thermal analyses. The results showed very rapid changes in thermomechanical properties during crystallization. The mechanisms responsible for the loss of pressure during cooling and subsequent defect formation were identified. Second, an experimental investigation of the moulding defects formed during cooling of DLF composite was conducted. Loss of contact between the material and the tooling surfaces due to thermal shrinkage was observed experimentally. Moulding defects were reproduced on simple flat panels using an instrumented test fixture and the critical temperature range of defect formation was identified. The effect on mechanical properties was quantified by comparing the strength of specimens having different levels of moulding induced defects. The sensitivity to void content observed was much higher than what is commonly reported for continuous fibre composites. The importance of a proper cooling strategy was demonstrated by successfully moulding a defect-free L-bracket with a rib feature.Finally, a finite element model was developed to predict defect formation during compression moulding of DLF carbon/PEEK composites. The process model showed that the maximum temperature at which the pressure is lost during cooling is very sensitive to the temperature variation of the part and the applied moulding pressure. It was also demonstrated that the order in which components are cooled is key to ensure a good consolidation of complex-shaped features.Material characterization and processes modelling developed from simple experiments allowed for successful understanding of the nature of the mechanisms responsible for defect formation during moulding of DLF composites. The approach presented in this work could be used to identify problematic regions of a part before manufacturing, considerably reducing the trial and error often required to successfully manufacture defect-free DLF composite parts.</dc:abstract><dc:abstract>Les matériaux composites sont utilisés pour remplacer des pièces métalliques dans un nombre grandissant d'applications. La popularité de ceux-ci est principalement due à leur haute performance, leur excellente adaptabilité et leurs avantages au niveau de la fabrication. Bien que les composites à fibres continues sont les matériaux principalement utilisés pour la conception de pièces à haute performance en aérospatiale, leur utilisation actuelle est généralement limitée à de grandes structures à paroi mince. Il y a donc un intérêt émergeant dans l'industrie aérospatiale pour faire l'usage des matériaux composites à plus petite échelle, afin de remplacer des pièces métalliques complexes. Cela présente des défis uniques, car les composites à fibres continues traditionnels sont pratiquement inutilisables pour ce type d'application. D'autre part, les pièces fabriquées par injection de plastique avec fibres courtes ont des propriétés mécaniques inférieures, bien qu'étant très polyvalentes géométriquement. Entre ces deux extrêmes, les composites à fibres longues discontinues (FLD) offrent la possibilité de fabriquer des pièces à géométrie complexe par l'entremise du moulage par compression. Cette technique s'est avérée très efficace pour le moulage de pièces à finition immédiate ayant des caractéristiques telles que des variations d'épaisseur, des rayons serrés, des nervures de renfort, etc. Cependant, l'augmentation de la complexité des pièces peut introduite des problèmes de fabrication. Un problème en particulier se pose lors de la fabrication des composites thermoplastiques, où une variation de la qualité des pièces peut survenir si la pression de consolidation est perdue avant la solidification de la matrice durant le refroidissement. Ce phénomène peut être difficile à prédire en raison de la nature complexe des pièces composites FLD. Étant donné que la compréhension et la prédiction de la formation de défauts sont cruciales dans la fabrication de pièces composites à géométrie complexe, une approche en trois volets a été utilisée dans cette thèse pour étudier les phénomènes qui influencent ce comportement. Tout d'abord, la cinétique de cristallisation, le retrait thermique et de cristallisation, ainsi que le développement du module d'élasticité du composite carbone/polyétheréthercétone (PEEK) ont été caractérisés au cours du refroidissement à partir de la température de fusion en utilisant des analyses thermiques. Les résultats ont démontré des changements très rapides dans les propriétés thermomécaniques au cours de la cristallisation. Les mécanismes responsables de la perte de pression durant le refroidissement et la formation subséquente de défauts ont été identifiés.Ensuite, une étude expérimentale sur les défauts de moulage formés au cours du refroidissement des composites FLD a été effectuée. Les défauts de moulage ont été reproduits sur des panneaux plats à l'aide d'un montage instrumenté. La plage de température critique de la formation de défauts a été identifiée. L'effet sur les propriétés mécaniques a été quantifié en comparant la résistance d'échantillons ayant différents niveaux de défauts de moulage. La sensibilité à la porosité observée était beaucoup plus élevée que celle communément rapportée pour les composites à fibres continues. L'importance d'une stratégie de refroidissement adéquate a été démontrée en fabriquant avec succès une pièce complexe sans défauts.Finalement, un modèle d'éléments finis a été développé pour prédire la formation de défauts pendant le moulage par compression des composites FLD. Le modèle a démontré que la température maximale à laquelle la pression est perdue au cours du refroidissement est très sensible à la variation de température dans la pièce ainsi qu'à la pression de moulage appliquée. Il a également été démontré que l'ordre dans lequel les composants sont refroidis est très important afin d'assurer une bonne consolidation sur les pièces complexes.</dc:abstract><ual:supervisor>Pascal Hubert</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/qb98mj24f.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/z029p758q</ual:fedora3Handle><dc:subject>Mechanical Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ar781wj930"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Integrated Program in Neuroscience</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Role of GABAA receptor signaling in ictogenesis and in the modulation of high-frequency oscillations</dcterms:title><ual:dissertant>Hamidi, Shabnam</ual:dissertant><dc:abstract>Temporal lobe epilepsy (TLE) is a form of partial epilepsy in which recurrent seizures originating from the hippocampus proper and para-hippocampal structures (i.e. amygdala, entorhinal cortex and temporal neocortex) occur after a latent period of many years following an initial neurological insult. TLE affects between 50-60% of patients suffering from partial epilepsy, and despite a tremendous increase in the number of antiepileptic drugs made available over the past few decades, up to 80% of these patients are non-responsive to anti-epileptic drugs. Although, hypersynchronous activity of neuronal network is responsible for generating epileptic activities, the mechanisms underlying the excessive neuronal synchronization are yet to be understood. γ-Aminobutyric acid (GABA), which acts as the main inhibitory neurotransmitter in the brain, has been identified to play a role in initiation and maintenance of epileptiform discharges. Interestingly, under specific pharmacological manipulations, GABAA receptor-mediated currents are the sole synaptic mechanism contributing to ictogenesis in the hippocampus and they are associated with marked increases in extracellular [K+]. Therefore, it has been proposed that the initiation and maintenance of ictal activity may result from the inability of the neuronal K+-Cl− co-transporter KCC2 to control intra¬cellular Cl− thus inducing depolarizing (and potentially excitatory) GABAA receptor-mediated Cl− currents along with HCO3−-mediated currents.  In my thesis, I addressed the role of GABAA receptor-mediated signaling in ictogenesis. The main findings of my studies can be summarized as follows:First I used field potential recordings in extended in vitro brain slices containing the piriform and entorhinal cortices to clearly identify the characteristics of epileptiform discharges and concomitant high-frequency oscillations (HFOs) during bath application of the K+ channel blocker 4-aminopyridine (4AP). Second, I employed this in vitro brain slice preparation, to study the effects induced by KCC2 blockers and by a KCC2 enhancer on the epileptiform discharges and associated HFOs occurring the in piriform and entorhinal cortices during 4AP application. Here, I discovered that in both regions, blocking KCC2 activity abolished ictal discharges whereas enhancing its activity increased the duration of ictal discharge.Next, to support the view that GABAA receptor signaling actively participates to epileptiform synchronization, I analyzed the effects of a carbonic anhydrase inhibitor on the epileptiform activity. My results demonstrate that GABAA receptor-mediated HCO3− efflux is necessary for the long-lasting ictal discharges induced by 4AP. Finally, I studied the contribution of GABAA receptor-mediated signaling to short- and long-lasting 4AP -induced interictal events recorded from the CA3 region of hippocampus by application of KCC2 blockers/enhancer and carbonic anhydrase inhibitor.Altogether, my findings demonstrated that GABAergic transmission can actively contribute to the generation of hypersynchronous activity and epileptiform discharges through KCC2 dependent increases in extracellular [K+]. In addition, excessive load of Cl− into the postsynaptic neuron during activation of GABAA receptors results in dominance of HCO3− current and depolarizing GABA. I anticipate that my findings will provide new information concerning the role of inhibitory transmission in the generation of epileptic discharges as well as a better understanding of the impact of different anti-epileptic drugs.</dc:abstract><dc:abstract>L'épilepsie du lobe temporale (ETL) est une forme d'épilepsie partielle dont les crises d'origine hippocampique et para-hippocampique (i.e. l'amygdale, le cortex entorhinal et le néocortex temporal) surviennent après une période de latence de plusieurs années suivant une insulte neurologique initiale.  L'ETL affecte 50 à 60 % des patients souffrant d'épilepsie partielle et malgré le nombre important d'antiépileptiques disponibles au cours des dernières décennies, 80 % de ces patients ne répondent pas au traitement. Malgré le fait que nous sachions que l'activité hypersynchrone des réseaux neuronaux est responsable de la genèse des crises épileptiques, les mécanismes qui sous-tendent cette synchronisation neuronale excessive demeurent jusqu'à maintenant inconnus.  Il a été montré que l'acide γ-aminobutyrique (GABA), le principal neurotransmetteur inhibiteur du cerveau, joue un rôle important dans l'initiation et le maintien dans le temps des décharges épileptiformes. Il est cependant intéressant de noter que dans certaines conditions pharmacologiques, l'activation des récepteurs GABAA serait l'unique mécanisme synaptique contribuant à l'ictogénèse dans l'hippocampe et serait associé à une augmentation importante extracellulaire de [K+]. Ainsi, il a été proposé que l'initiation et le maintien dans le temps de l'activité ictale pourrait résulter de l'incapacité du transporteur KCC2 à contrôler les concentrations intracellulaire de Cl−, ce qui induirait un courant lié au chlore et un courant lié au HCO3− dépolarisants (et potentiellement excitateurs) modulés par l'activité des récepteurs GABAergiques. J'ai étudié les courants modulés par les récepteurs GABAA au cours de l'ictogénèse. Les principaux résultats de mes études sont :J'ai employé des techniques d'enregistrement in vitro des potentiels de champs dans des tranches de cerveau contenant le cortex piriforme et entorhinal afin d'identifier les caractéristiques des décharges épileptiformes et des oscillations à hautes fréquences (OHF) après l'application de 4AP. Grâce à l'usage de cette préparation, j'ai étudié les effets d'antagonistes et agonistes de l'activité KCC2 sur les décharges épileptiformes et sur les OHF dans le cortex piriforme et entorhinal. J'ai découvert que dans ces deux régions, bloquer l'activité du KCC2 abolit les décharges ictales tandis qu'une augmentation de son activité induit une augmentation de leur durée.  Afin de soutenir l'hypothèse que l'activité modulée par les récepteurs GABAA contribue à la synchronisation épileptiforme, j'ai analysé les effets d'un inhibiteur de l'anhydrase carbonique sur l'activité épileptiforme. Mes résultats ont montré que l'efflux de HCO3− modulé par les récepteurs GABAA est nécessaire à la genèse de l'activité ictale de longue durée.  Finalement, j'ai étudié la contribution des courants modulés par les récepteurs GABAA dans la genèse de pointes interictales de longue et courte durée enregistrées dans la région CA3 de l'hippocampe suite à l'application de bloqueurs de l'activité KCC2 et d'inhibiteurs de l'anhydrase carbonique.  Dans l'ensemble, mes résultats montrent que la transmission GABAergique peut contribuer à la génèse d'une activité hypersynchrone et de décharges épileptiformes par une augmentation de la concentration extracellulaire de [K+] dépendante du KCC2. De plus, une concentration excessive de Cl− dans le neurone postsynaptique durant l'activation des récepteurs GABAA conduit à une importante dominance du courant  HCO3− et de GABA dépolarisant. Je prévois que mes résultats apporteront des nouvelles informations concernant les rôles de la transmission inhibitrice dans la genèse des décharges épileptiques ainsi qu'une meilleure compréhension de l'impact des antiépileptiques. </dc:abstract><ual:supervisor>Massimo Avoli</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/m326m474k.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/r781wj930</ual:fedora3Handle><dc:subject>Neuroscience</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A4x51hn14h"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Integrated Program in Neuroscience</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Expression of ionotropic glutamate receptors in neocortical microcircuits</dcterms:title><ual:dissertant>Lalanne, Txomin</ual:dissertant><dc:abstract>La transmission synaptique, mais aussi le développement et la réorganisation constante des circuits nerveux, ou plasticité synaptique, dépendent de la composition en récepteurs et canaux ioniques des éléments pré et postsynaptiques. Notamment, au niveau des connexions entre neurones excitateurs les récepteurs NMDA jouent un rôle fondamental dans l'induction de la plasticité à long terme, qui elle même sous-tend théoriquement l'apprentissage et la mémoire en permettant l'entrée de calcium dans la cellule postsynaptique, activant une cascade de signalisation aboutissant au renforcement de la connexion. Etant donné que les récepteurs NMDA sont ouverts lors de la combinaison d'une dépolarisation postsynaptique et de la libération présynaptique de glutamate, ils jouent le rôle de détecteurs de coïncidence aux synapses excitatrices. La complexité des circuits du neocortex ainsi que la grande diversité de neurones inhibiteurs qui s'y trouve rendent leur étude difficile. La plasticité des connections excitatrices sur les neurones inhibiteurs est de fait moins bien connue mais il est clair qu'elle varie avec le type cellulaire et dans certains cas ne requière pas de récepteurs NMDA. En effet, certains neurones inhibiteurs de l'hippocampe, de l'amygdale ou encore du cervelet expriment très peu voir aucun récepteur NMDA. Le calcium nécessaire à l'induction de plasticité pourrait provenir de récepteurs AMPA perméables au calcium, mais le pattern d'expression de ces récepteurs par les différents types de neurones inhibiteurs n'est pas clairement établi, notamment du fait de leur diversité et de la difficulté à les distinguer. Ici, nous avons combinés des enregistrements quadruples en configuration cellule-entière avec la microscopie 2-photons ainsi que le décageage optique de AMPA afin de déterminer l'expression des récepteurs AMPA perméables au calcium ainsi que des récepteurs NMDA aux synapses excitatrices sur deux type majeurs de neurones inhibiteurs néocorticaux : les cellules en panier et les cellules de Martinotti.  Nous avons ainsi pu déterminer que les récepteurs AMPA perméables au calcium sont spécifiquement exprimés aux synapses sur les cellules en panier mais pas sur les cellules de Martinotti. La combinaison de modèle informatique et de d'enregistrements « dynamic clamp » nous a par ailleurs permis d'identifier une fonction possible des récepteurs dans les circuits de la couche 5 du neocortex. Nous avons par le passé démontré l'expression de récepteurs NMDA présynaptiques spécifiquement aux synapses sur les cellules de Martinotti mais pas celles sur les cellules en panier. Finalement, nous explorons les conséquences possibles de cette double expression spécifique de deux types majeurs de canaux ioniques sur la plasticité synaptique, en particulier la plasticité « spike-timing-dependent ». Au final, ces travaux aideront à déterminer comment et pourquoi la plasticité synaptique diffère d'un type de neurone inhibiteur à un autre et donc de mieux comprendre d'une part comment se forment les circuits néocorticaux, et d'autre part comment l'information est traitée dans ces réseaux.</dc:abstract><dc:abstract>Synaptic transmission as well as the constant reorganization of connections between neurons — known as synaptic plasticity — depend on the composition of synaptic ion channels and receptors. At excitatory connections onto excitatory cells, NMDA receptors play a critical role in long-term plasticity. Upon glutamate binding, NMDA receptors allow the entry of calcium into postsynaptic compartments, which initiates a cascade of reactions leading to the strengthening of the connection. Because postsynaptic NMDA receptors are only open when the postsynaptic cell is depolarized and the presynaptic cell has released glutamate, NMDA receptors act as coincidence detectors. The complexity of the neocortical circuitry and the diversity of the inhibitory neuron population make it difficult to study the plasticity of a precise, well-defined synapse type involving inhibitory neurons. As a consequence, plasticity of excitatory connections onto inhibitory neurons has been less studied and seems more variable, not always requiring NMDA receptors. Indeed, some inhibitory neuron types in the hippocampus, amygdala and cerebellum express little, if any, NMDA receptors. Yet synapses onto these interneurons undergo plasticity, and there is evidence that the calcium required to trigger this plasticity may arise from calcium-permeable AMPA receptors. The gating properties of calcium-permeable AMPA receptors are almost opposite to that of NMDA receptors: calcium-permeable AMPA receptors are open at negative membrane potentials but are closed at positive. Indeed, this may explain why synaptic plasticity in interneurons often is quite different. However, the precise expression pattern of calcium-permeable AMPA receptors in neocortical inhibitory neurons remains poorly studied, perhaps due to the challenge posed by their clear identification. Here, we combined multiple whole-cell recordings with uncaging and two-photon laser-scanning microscopy to determine the pattern of expression of calcium permeable AMPA receptors and NMDA receptors in two major neocortical layer 5 inhibitory neuron types: basket and Martinotti cells. We found that excitatory connections onto basket but not onto Martinotti cells expressed calcium-permeable AMPA receptors. Combining computer modeling and dynamic clamp recordings, we showed that the presence of calcium-permeable AMPA receptors may help sharpen response latencies and durations in basket cells. Moreover, we previously demonstrated that presynaptic NMDA receptors are specifically expressed at excitatory connections onto Martinotti cells but not onto basket cells. Finally, we explored the possible consequences of synapse specific expression of AMPA and NMDA receptors for long-term synaptic plasticity. My work will help determine how and why plasticity differs between inhibitory neuron types and it will improve our understanding of information processing in neocortical microcircuits.</dc:abstract><ual:supervisor>Per Jesper Sjostrom</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/rn301423p.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/4x51hn14h</ual:fedora3Handle><dc:subject>Neuroscience</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ax920g051n"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Mathematics and Statistics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Aspects of random squarings</dcterms:title><ual:dissertant>Leavitt, Nicholas</ual:dissertant><dc:abstract>Cette thèse présente un processus qui génère "un rectangle aléatoire pavé d'infiniment de carrés", basé sur le travail de Addario-Berry et Leavitt. En utilisant une procédure introduite par Addario-Berry pour la croissance de cartes aléatoires 3-connexes et une construction par Brooks et d'autres dans les années 1940 qui associe à chaque carte avec une arête raciné un rectangle pavé de carrés, nous construisons un rectangle pavé d'infiniment de carrés qui a une loi décrite par la "carte 3-connexe infinie uniform". La convergence presque sûre de ce processus est prouvé ainsi que le fait qu'il a presque surement un seul point d'accumulation. D'autres propriétés et plusieurs problèmes ouverts liées aux carrés et aux cartes aléatoire sont également discutés, notamment en matière de résistance et de comportements limitants du rectangle pavé d'infiniment de carrés.</dc:abstract><dc:abstract>This thesis presents a process which generates "random infinite squarings of rectangles", based on work by Addario-Berry and Leavitt. Using a procedure introduced by Addario-Berry for growing random 3-connected planar maps and a construction by Brooks et al. in the 1940s which associates to any edge-rooted planar map a squaring of a rectangle we construct an infinite squaring which has a law described by "the uniform infinite 3-connected planar map". The almost-sure convergence of this process is proved as well as the fact that it almost-surely has a single point of accumulation. Additional properties and open problems relating to the random squarings and graphs are also discussed, especially in relation to resistance and limiting behaviors of the infinite squaring.</dc:abstract><ual:supervisor>Dana Louis Addario-Berry</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/h415pd40g.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/x920g051n</ual:fedora3Handle><dc:subject>Mathematics and Statistics</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Axd07gw596"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Earth and Planetary Sciences</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Magmatic and volcanic processes at near-ridge seamounts</dcterms:title><ual:dissertant>Coumans, Jason</ual:dissertant><dc:abstract>Short chains of seamounts are common on the flanks of fast- to intermediate-spreading mid-ocean ridges in the Pacific Ocean. They have been studied extensively in order to understand the nature of off-axis magma production from melting anomalies in an upwelling mantle. One of the most important characteristics of near-ridge seamounts is their larger trace element and isotopic variation when compared to an adjacent spreading center. This larger variation implies that near-ridge seamount magma bypasses mixing and homogenization processes at the axial reservoir, thus making them excellent geologic targets for investigating heterogeneity in the depleted upper mantle. However, a number of important questions remain regarding the spatial and temporal scale of mantle heterogeneities, melting processes in the mantle, modification during transport to a shallow crustal reservoir, and magmatic processes occurring in a sub-caldera reservoir.Taney Seamount-A, the largest and oldest seamount in the Taney near-ridge chain, exhibits complex shallow and surface processes such as repeated caldera collapses and explosive volcanism. Taney Seamount-A has four well-defined calderas with clear cross-cutting relationships, providing a relative chronology of volcanism. Therefore, Taney Seamount-A represents an ideal target site to investigate the unresolved questions outlined above. To address these questions, I have undertaken a multi-tiered approach incorporating submersible sampling and observation, geochemical analysis and modelling, and scaled analogue experiments.Geochemical analyses and modelling of lavas, crystals, and melt inclusions show that the magmatic history beneath Taney Seamount-A is complex. Lavas vary from typical peridotite-derived mid-ocean ridge basalt compositions (N-MORB) to those with an apparent residual garnet signature. Geochemical modelling suggests that the observed garnet signature can be reproduced by decompression melting of a MORB mantle peridotite which has been re-fertilized by garnet pyroxenite partial melts. Large anorthite-rich plagioclase crystals entrained in lavas have textural evidence of melt-rock interaction. Furthermore, melt inclusions within plagioclase exhibit a non mantle-derived geochemical signal indicating partial melting of a plagioclase-rich cumulate. Volatile saturation pressures from H2O-CO2 relationships in the melt inclusions imply that the large plagioclase crystals formed at the Moho. During transport from the mantle to a shallow magma reservoir, melts ponded at the Moho and underwent melt-rock interaction characterized by episodic partial melting, magma mixing, and recrystallization of plagioclase cumulates. Temporal changes of major elements of the lavas are consistent with an open-system sub-caldera reservoir that undergoes periodic caldera collapse, replenishment, shallow crystallization and eruption. In summary, the magmatic history at Taney Seamount-A comprises magma generation by melting of a two-component mantle, melt-rock interaction at the Moho, open system evolution in a sub-caldera magma reservoir, and caldera collapse. Caldera collapse processes at Taney Seamount-A and other near-ridge seamounts are complex and dependent upon the orientation of the edifice above the magma reservoir. Scaled analogue  experiments of caldera collapse at near-ridge seamounts suggests that an offset position of the volcanic edifice induces a trapdoor style of caldera collapse. This style of collapse is characterized by initial subsidence on a reverse fault resulting in the buildup of antithetic flexural tension in a hinge area and formation of a graben structure. The tilting of offset near-ridge seamount calderas towards the ridge axis, as well as structures observed on trapdoor basaltic volcanoes, suggest that complicated asymmetric caldera collapse processes illustrated in analogue experiments also occur in nature.</dc:abstract><dc:abstract>Courts chaînes de monts sous-marins sont communs sur les flancs de fast- à dorsales médio-océaniques intermédiaires répartition dans l'océan Pacifique. Ils ont été largement étudiés afin de comprendre la nature de la production de magma hors axe de la fonte des anomalies dans un manteau d'upwelling. Taney Seamount-A, le mont sous-marin grand et plus ancien dans le Taney chaîne quasi-crête, présente les processus de surface peu profondes et complexes tels que l'effondrement de la caldeira répétées et volcanisme explosif. Taney Seamount-A dispose de quatre caldeiras bien définis avec des relations transversales claires, fournissant une chronologie relative du volcanisme. Par conséquent, Taney Seamount-A représente un site cible idéale pour enquêter magmatiques et volcaniques processus de génération de fusion pour le manteau à l'éruption sur la thèse seafloor.This utilisé une approche à plusieurs niveaux intégrant échantillonnage submersible et l'observation, l'analyse et la modélisation géochimique, et mis à l'échelle expériences analogiques.Les analyses géochimiques et de la modélisation de laves, des cristaux, et fondre inclusions montrent que l'histoire magmatique sous Taney Seamount-A est complexe. Laves varient de compositions typiques de péridotite dérivé dorsale basalte (N-MORB) à ceux qui ont une signature grenat résiduelle apparente. La modélisation géochimique permet de croire que la signature de grenat observé peut être reproduite par décompression fusion d'un manteau péridotite MORB qui a été re-fécondé par grenat pyroxenite fusions partielles. Gros cristaux de plagioclase anorthite riche entraînées dans les laves ont des preuves de texture de l'interaction fusion-rock. En outre, faire fondre inclusions dans plagioclase présentent un signal géochimique non mantellique indiquant fusion partielle d'un cumul de plagioclase riche. Pressions de saturation volatils issus de relations H2O-CO2 dans les inclusions vitreuses impliquent que les grands cristaux de plagioclase formés au Moho. Pendant le transport du manteau à un réservoir magmatique peu profonde, des masses fondues sont accumulées au Moho et a subi une interaction fondre-rock caractérise par la fusion partielle épisodique, mélange de magmas, et la recristallisation de plagioclase cumule. Les changements temporels des éléments majeurs des laves sont compatibles avec un réservoir sous-caldeira système ouvert qui subit effondrement périodique de la caldeira, le réapprovisionnement, la cristallisation superficielle et éruption. En résumé, l'histoire magmatique au Taney Seamount-A comprend la production de magma en fusion d'un manteau à deux composants, l'interaction fondre-rock au Moho, l'évolution de système ouvert dans un réservoir de magma sous-caldeira, et effondrement de la caldeira.Processus d'effondrement Caldera à Taney Seamount-A et d'autres monts sous-marins quasi-crête sont complexes et dépend de l'orientation de l'édifice au-dessus du réservoir de magma. Expériences analogiques en écailles effondrement de la caldeira de monts sous-marins quasi-crête suggère que une position décalée de l'édifice volcanique induit un style de trappe d'effondrement de la caldeira. Ce style de l'effondrement est caractérisé par la subsidence initiale sur une faille inverse provoque l'accumulation de la tension de flexion antithétique dans une zone de la charnière et la formation d'une structure de graben. Le basculement du décalage quasi-crête caldeiras de monts sous-marins vers l'axe de la crête, ainsi que les structures observées sur les volcans basaltiques trappe, suggèrent que les processus d'effondrement de la caldeira asymétrique complexes illustrées dans les expériences analogiques se produisent aussi dans la nature.</dc:abstract><ual:supervisor>John Stix</ual:supervisor><ual:supervisor>William Minarik</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/v118rh290.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/xd07gw596</ual:fedora3Handle><dc:subject>Earth and Planetary Sciences</dc:subject></rdf:Description></rdf:RDF>