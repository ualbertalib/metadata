<?xml version="1.0" encoding="UTF-8"?><rdf:RDF xmlns:oai="http://www.openarchives.org/OAI/2.0/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:ual="http://terms.library.ualberta.ca/" xmlns:bibo="http://purl.org/ontology/bibo/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:schema="https://schema.org/" xmlns:etdms="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A9s1618824"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Atmospheric and Oceanic Sciences</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Evaluating precipitation forecasts from the High Resolution Ensemble Kalman Filter (HREnKF) over the Pacific Northwest</dcterms:title><ual:dissertant>Cookson-Hills, Phillipa</ual:dissertant><dc:abstract>Le nord-ouest du Pacifique reçoit certaines des plus fortes précipitations de la planète. Par conséquent, prévoir précisément les précipitations pour cette aire géographique est essentiel pour avertir les différents secteurs de la société du moment et de l'intensité des précipitations. Cependant, la prévision des précipitations reste généralement difficile, et dans le Pacifique Nord-Ouest en particulier, en raison des conditions atmosphériques incertaines et d'un terrain complexe. En outre, l'estimation des précipitations observées dans la région est difficile en raison de la faible densité des données de pluviomètre et de la couverture radar limitée en terrain complexe. Dans le but d'améliorer la qualité des prévisions dans cette région, Evironnement et Changements Climatiques Canada a développé un système de prédictions d'ensemble utilisant un filtre régional Ensemble Kalman à haute résolution (HREnKF). Le HREnKF a une résolution et 2,5 km assimile les observations de surface et aérologiques heure par heure. Pour déterminer l'avantage de cette augmentation de résolution, les prévisions quantitatives de précipitations (QPF) du HREnKF sont comparées au système de prévisions à plus basse résolution (15km) du REnKF, qui assimile les données toutes les 6 heures. En outre, pour séparer l'impact de l'augmentation de résolution spatiale horizontale de celui de l'augmentation de l'assimilation des données, les prévisions sont également générées à partir d'un système d'ensemble à échelle réduite du REnKF (DS), utilisant la même résolution horizontale que le HREnKF mais sans assimilation de données explicite. Pour évaluer la performance du modèle, plusieurs produits d'observation, dont des pluviomètres, sont intégrés aux données radar et utilisés par la suite comme produits de vérification. Les QPFs de tous les modèles sont ensuite comparés aux produits de vérification à l'aide d'une série de méthodes d'évaluation déterministe et probabiliste. Enfin, les incertitudes d'observation sont également prises en compte dans l'exécution de la vérification. Les paramètres de vérification traditionnels et l'évaluation spatiale indiquent tous deux une performance supérieure du système à haute résolution par rapport au REnKF. Cependant, l'effet de l'assimilation des données à haute résolution temporelle et spatiale est négligeable. En effet, le système HREnKF offre des performances très similaire au DS, pour tous les cas. Par conséquent, le DS moins, coûteux en ressources informatiques, pourrait être plus approprié que le HREnKF pour prévoir les précipitations sur le nord-ouest du Pacifique .</dc:abstract><dc:abstract>The Pacific Northwest endures some of the heaviest precipitation on the planet. Therefore, producing accurate precipitation forecasts for this area is essential to warn different sectors of society of the timing and intensity of precipitation events. However, forecasting precipitation remains difficult in general, and in the Pacific Northwest in particular, owing to the uncertain atmospheric conditions and complex terrain. In addition, observational precipitation estimation is difficult due to sparseness of the rain gauge data and to the limited radar coverage in complex terrain. In an effort to improve forecast skill in this region, Environment and Climate Change Canada developed a regional High-Resolution Ensemble Kalman Filter (HREnKF) ensemble prediction system. The HREnKF has a 2.5km resolution and assimilates surface and upper air observations every hour. To determine the benefit of increasing the resolution, quantitative precipitation forecasts (QPF) from the HREnKF are compared to forecasts from the lower resolution (15km) REnKF system, which assimilates data every 6 hours. Furthermore, to separate the impact of increasing horizontal resolution from increased data assimilation, forecasts are also generated from a Down-Scaled (DS) ensemble system, which is downscaled from the REnKF using the same grid as the HREnKF but with no explicit data assimilation. To evaluate model skill, rain gauges and several other radar-based gridded observational products are used as the verification products. QPFs from all models are then compared to the verification products using a suite of deterministic and probabilistic evaluation methods. Finally, observational uncertainties are also addressed and considered in performing the verification. Both the traditional verification metrics and the spatial evaluation indicate a better performance of the high-resolution system compared to the REnKF. However, the effect of data assimilation at high temporal and spatial resolution is found to be negligible, as the HREnKF performs very similarly to the DS for all cases. Therefore, the computationally less expensive DS could be more appropriate than the HREnKF to forecast precipitation over the Pacific Northwest.</dc:abstract><ual:supervisor>Daniel Kirshbaum</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/z890rx15f.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/9s1618824</ual:fedora3Handle><dc:subject>Atmospheric and Oceanic Sciences</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Azk51vk52c"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Atmospheric and Oceanic Sciences</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Performance of the EarthCARE cloud profiling radar in marine stratus clouds</dcterms:title><ual:dissertant>Burns, David</ual:dissertant><dc:abstract>Les nuages stratiformes marins sont une cible difficile pour les radars spatiaux en raison de leur proximité de la surface de la Terre, de leur étendue verticale limitée et de leur faible réflectivité. La mission "Earth Clouds, Aerosol et Radiation Explorer" (EarthCARE), une colaboration entre les agences spatiales européenne et japonaise (ESA-JAXA), est prévue pour 2018 et propose de mettre en orbite le premier profileur de nuages radar (CPR) avec capacité Doppler. On évalue la performance du CPR dans la détection de ces nuages, leurs limites et leurs vitesses de gouttelettes de bruine. Les observations de la Atmospheric Radiation Measurement (ARM) Mobile Facility sur les Açores et la Marine ARM GPCI Investigation of Clouds sont utilisés comme entrée à un simulateur de CPR. Les vastes observations au sol sont traités comme la vérité et comparées aux observations EarthCARE CPR simulées. L'impact du retour de l'écho de surface, la sensibilité du radar, et la résolution en portée sont discutées, et les techniques de post-traitement tels qu'un algorithme de masquage d'entités, l'inversion de la plage de résolution, et des filtres associés à la vitesse Doppler sont présentés et testés. La fraction de nuage détectée par le EC-CPR est d'environ 70-80 % de celui des radars W-band au sol, les résultats dépendent de l'intégration along-track et la configuration de l'algorithme de masquage d'entités. La résolution de portée de la EC-CPR introduit un biais de réflectivité moyenne de +1 dB et un biais dans l'estimation du haut des nuages de +100 m (égale à la fréquence d'échantillonnage de portée du CPR), mais ceux-ci peuvent être considérablement réduits (0,1 dB et 30 m respectivement) par l'application d'une technique d'inversion de résolution de portée. L'analyse indique qu'on peut atteindre un incertitude de environ 0.5 ms-1 pour la vitesse CPR avec soit une intégration along-track de 5 km ou une combinaison de filtres associés à la vitesse Doppler et une intégration de 1 km du champ de vitesse CPR Doppler.</dc:abstract><dc:abstract>Marine stratiform clouds are a challenging target for spaceborne radars due to their proximity to Earth's surface, limited vertical extent, and low radar reflectivity. The joint European Space Agency-Japanese Aerospace Exploration Agency (ESA-JAXA) Earth Clouds, Aerosol, and Radiation Explorer (EarthCARE) mission is scheduled for launch in 2018 and features the first spaceborne Cloud Profiling Radar (CPR) with Doppler capability. In this work, the performance of the CPR in detecting these clouds, their boundaries, and their drizzle droplet velocities is evaluated. Observations from the Atmospheric Radiation Measurement (ARM) Mobile Facility at the Azores and the Marine ARM GPCI Investigation of Clouds are used as input to a CPR simulator. The extensive ground-based observations are treated as the truth and compared to the simulated EarthCARE CPR observations. The impact of the surface echo return, radar sensitivity, and range resolution are discussed, and post-processing techniques such as a feature mask algorithm, range resolution inversion, and matched filters for Doppler velocity are presented and tested. The EC-CPR detected cloud fraction is found to range from approximately 70-80 % that of ground-based W-band radars, depending on the along-track integration and configuration of the feature mask algorithm. The range resolution of the EC-CPR introduces an average reflectivity bias of +1 dB and cloud top overestimation bias of 100 m (equal to the range sampling rate of the CPR), but these may be significantly reduced (to 0.1 dB and 35 m respectively) by the application of a range resolution inversion technique. The analysis indicates a CPR velocity uncertainty of approximately 0.5 ms-1 is achievable with either a 5 km along-track integration or a combination of matched filtering and along-track integration to 1 km of the CPR Doppler velocity field.</dc:abstract><ual:supervisor>Pavlos Kollias</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/k643b3650.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/zk51vk52c</ual:fedora3Handle><dc:subject>Atmospheric and Oceanic Sciences</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ag445ch014"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>School of Computer Science</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Depth discrimination from occlusions in 3D clutter</dcterms:title><ual:dissertant>Zheng, Haomin</ual:dissertant><dc:abstract>Les objets tels que les arbres, arbustes et herbes hautes sont composés de milliers de petites surfaces distribuées dans un volume 3D. Une tâche visuelle naturelle est d'estimer la profondeur des objets dans une scène encombrée de surfaces en désordre. Par exemple, un humain peut estimer la distance d'un prédateur ou d'une proie, et peut décider si un fruit, parmi le feuillage, est accessible. Pour estimer la profondeur dans un fouillis 3D, un système visuel peut utiliser la disparité binoculaire et des mouvement parallaxes, mais ces indices de profondeur sont moins fiables dans un fouillis 3D parce que les surfaces sont souvent partiellement occlus. Par contre, les occlusions ne nuisent pas nécessairement à la perception de profondeur dans un fouillis 3D, puisque les occlusions eux-mêmes fournissent de l'information sur la profondeur. Des études précédentes ont seulement examiné l'occlusion des géométries dans des scènes simples, mais nous ne savons pas si les systèmes visuels peuvent utiliser les indices fournis par les occlusions pour déterminer les profondeurs dans un fouillis 3D. Ici, nous présentons un ensemble d'expériences qui s'agissent de différencier la profondeur en utilisant les indices visuels fournis par les occlusions dans un fouillis 3D. Nous identifions deux occlusion repères probabilistes. La première est basée sur la partie d'un objet qui est visible, les «indices de visibilité», et la seconde, la «gamme d'indices», est basée sur la gamme de profondeur des obstructeurs. Nous démontrons que le système visuel utilise les deux indices d'occlusion. Nous définissons également les observateurs idéaux, basés sur ces indices, et nous montrons que la performance de l'observation humaine est proche de l'idéal utilisant les indices de visibilité, mais elle est loin d'être idéale utilisant la gamme d'indices, la raison étant que la gamme d'indices dépend elle-même de l'estimation de la profondeur des obstructeurs, des indices provenant de la vision stéréoscopique binoculaire ou des mouvements parallaxe qui sont moins fiables dans un fouillis 3D. Ainsi, nos résultats fournissent des contraintes fondamentales sur l'information disponible provenant des occlusions dans un fouillis 3D, et montrent comment le système visuel peut distinguer la profondeur en combinant les indices d'occlusion et les indices stéréos et de mouvements.</dc:abstract><dc:abstract>Objects such as trees, shrubs, and tall grass consist of thousands of small surfaces that are distributed over a 3D volume. A natural visual task in 3D cluttered scenes is to estimate the depth of objects that are embedded within the clutter. For example, one might estimate the distance to a predator or prey, or decide if a fruit is reachable. To estimate depth in 3D clutter, a visual system can use binocular disparity and motion parallax cues, but these depth cues are less reliable in 3D clutter because surfaces tend to be partly occluded. However, occlusions are not necessarily a nuisance for depth perception in 3D clutter, since occlusions themselves provide depth information. It is unknown whether visual systems can use occlusion cues in 3D clutter, though, as previous studies have considered occlusions for simple scene geometries only. Here we present a set of depth discrimination experiments that examine depth from occlusion cues in 3D clutter. We identify two probabilistic occlusion cues. The first one, visibility cue, is based on the fraction of an object that is visible, and the second one, range cue, is based on the depth range of the occluders. We show the visual system uses both of these occlusion cues. We also define ideal observers that are based on these cues, and show that human observer performance is close to ideal using the visibility cue but far from ideal using the range cue. The reason is that the range cue itself depends on depth estimation of the occluders from binocular stereopsis or motion parallax cues which is less reliable in 3D clutter. Our results thus provide fundamental constraints on the information that is available from occlusions in 3D clutter, and show how the visual system can discriminate depth by combining these occlusion cues with stereo and motion cues.</dc:abstract><ual:supervisor>Michael Langer</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/cv43p084d.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/g445ch014</ual:fedora3Handle><dc:subject>Computer Science</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A6w924f34d"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Geography</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>The impacts of meteorological exposures on perinatal health: a mixed methods study of Kanungu District, Uganda</dcterms:title><ual:dissertant>MacVicar, Sarah</ual:dissertant><dc:abstract>Maternal and child health disparities and climate change are grand challenges to achieving global health equity. These challenges do not exist in isolation from one another; both manifest through existing social gradients. There is minimal research, however, on the interactions of climate and perinatal health, particularly among vulnerable populations. Though there is prior evidence that season and weather may affect birth outcomes, the nature of these effects and the causal mechanisms that drive them vary in different regional contexts. In this study, I aim to address this research gap by investigating how birth weight is affected by perinatal meteorological exposures in rural southwestern Uganda. This study was conducted in Kanungu District, Uganda, a remote and rural region that is home to both Indigenous Batwa and non-Indigenous Bakiga populations. Significant health disparities exist along these ethnic lines, with the historical traumas and deprivation faced by the Batwa manifesting in present-day poorer health outcomes. The objectives of this thesis are fourfold: 1) to assess associations between meteorological exposures incurred in utero and birth weight in Kanungu, 2) to test for effect modification by ethnicity (Indigenous vs. non-Indigenous) of these associations, 3) to elucidate potential causal pathways through which such exposures could lead to physiological impacts on mother and infant, and 4) to characterize the experiences and perceptions of Indigenous and non-Indigenous mothers of weather impacts on birth outcomes in Kanungu District. In Manuscript 1, I aim to establish the association between meteorological exposures and birth weight (Obj. 1), and to assess any effect modification of these associations by ethnicity (Obj. 2).  Results indicate that exposure to more days of precipitation in the third trimester was associated with increased birth weight, while subset analyses of the Indigenous Batwa sample revealed associations between increased birth weight and increased average temperature throughout pregnancy. In Manuscript 2, I address my third objective: to understand the ways weather may impact perinatal health in sub-Saharan Africa in general, and Kanungu District in particular. The pathways though which mothers were affected by weather and season were consistent with those observed in the literature: variation in maternal nutritional status and physical labour output due to harvest cycles and patterns of seasonal illnesses. While the mechanisms linking weather to birth experiences did not differ between Indigenous and non-Indigenous mothers in Kanungu, the magnitudes of weather impacts on birth were reported to be substantially higher among Indigenous Batwa. The findings of this study provide evidence not only that in utero weather exposures are associated with birth weight in Kanungu, but that this relationship is influenced by the social gradient that exists between non-Indigenous and Indigenous mothers in the region. These results can be used to inform interventions to ensure that the nutritional needs of mothers facing a third trimester in the dry season are met, and that Batwa mothers receive additional support throughout their pregnancies. As the region faces a less predictable climate with more extreme weather conditions, this knowledge can be applied in adaptation planning to ensure future generations of mothers and babies are adequately protected from the elements. More broadly, these findings provide impetus for region-specific research to understand how relationships between meteorological exposures and birth outcomes may differ in different contexts and for further investigation into how interventions on social gradients can offer protection from adverse climate impacts.</dc:abstract><dc:abstract>Les changements climatiques et les disparités dans le domaine de la santé maternelle et juvénile sont des  enjeux importants dans la lutte pour l'équité en santé mondiale. Ces défis ne sont pas indépendants, mais se manifestent bien à travers des gradients sociaux existants. Il n'existe toutefois que très peu de recherches portant sur l'interaction entre les changements climatiques et la santé périnatale, particulièrement chez les populations vulnérables. La recherche provenant de régions de l'Afrique sub-saharienne est particulièrement limitée à ce sujet. Dans le cadre de cette étude, j'adresse cette lacune dans la recherche en investiguant les effets sur le poids à la naissance des expositions météorologiques périnatales en Ouganda rurale du sud-ouest. Cette étude s'est déroulée dans la région rurale et isolée du district de Kanungu, Ouganda, où résident deux populations ethniques, le groupe indigène des Batwas et le groupe non-indigène des Bakigas. Il existe d'importantes disparités en santé entre les deux groupes; les traumatismes historiques et la privation auxquels les Batwas ont été confronté se manifestant à travers un niveau de santé actuel précaire. Les objectifs de cette thèse sont quadruple: 1) évaluer les liens entre les expositions météorologiques encourues in utero et les poids à la naissance dans le district de Kanungu, 2) tester la modification d'effet de ces associations selon l'ethnicité (indigène vs non-indigène), 3) élucider les potentiels voies de causales à travers desquels ces expositions pourraient entraîner des répercussions sur les mères et les nourrissons, 4) décrire les expériences et perceptions de mères indigènes et non-indigènes quant aux impacts de la température sur l'issue des grossesses à Kanungu.      Dans le manuscrit 1, je vise d'une part à déterminer l'association qui existe entre les expositions météorologiques et les poids à la naissance (obj. 1), et d'autre part à établir la modification de ces associations selon l'ethnicité (obj. 2). Les résultats indiquent que l'exposition à davantage de journées de précipitations au cours du troisième trimestre était associée à une augmentation du poids à la naissance, alors que l'analyse de sous-groupe de l'échantillon des Batwas indigènes démontre une association entre le poids à la naissance et l'augmentation moyenne de la température au cours de la grossesse. Dans le deuxième manuscrit, j'adresse mon objectif 3 : comprendre les mécanismes causaux sous-tendant les associations entre les expositions météorologiques et les poids à la naissance. Les voies par lesquelles les mères furent affectées par la température et les saisons concordent avec celles observées dans la littérature : variation dans le statut nutritionnel maternel et réalisation de travail physique résultant des cycles de récolte et tendances dans les maladies saisonnières. Alors que les mécanismes liant température et issues de grossesses ne différaient pas entre les mères indigènes et non-indigènes de Kanungu, les ampleurs des impacts de la température sur les naissances furent rapportées comme étant substantiellement plus significatives sur les Batwas indigènes. Les résultats de cette étude suggèrent non seulement que les expositions météorologiques in utero sont associées au poids à la naissance à Kanungu, mais aussi que cette relation est influencée par le gradient social qui existe entre les mères indigènes et non-indigènes de la région. Ces résultats peuvent être utiles pour l'élaboration d'interventions ciblées afin, d'une part, de s'assurer de répondre aux besoins nutritionnels des mères faisant face à leur troisième trimestre lors de la saison sèche, et d'autre part, d'offrir du soutien additionnel aux mères Batwas tout au long de leur grossesse. À la lumière de cette étude, il serait également important pour la recherche future d'investiguer de quelles manières les interventions auprès des gradients sociaux pourraient prémunir contre les impacts climatiques néfastes.</dc:abstract><ual:supervisor>Lea Berrang Ford</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/9593tx77b.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/6w924f34d</ual:fedora3Handle><dc:subject>Geography</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A1v53k065f"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Natural Resource Sciences</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Optimization of sampling designs for validating digital soil maps</dcterms:title><ual:dissertant>Zhang, Yakun</ual:dissertant><dc:abstract>Meeting food demand for ever increasing global population can be attained through sustainable management of soil resources. This requires a thorough understanding of soil properties and processes and calls for methods to quantify and display spatial variability of soil. Three dimensional digital soil mapping (3D-DSM) with its ability to quantify both the horizontal and the vertical variability has become popular in recent days. The state-of-the-art data mining techniques including 3D regression kriging (RK) has been used to uncover complex soil-landscape relationships but not assessed at small scales. In addition, recent advances in proximal soil sensing allow measurement and prediction of various soil properties simultaneously and rapidly at multiple depths and provide required information for DSM. Furthermore, sampling design (SD) plays a vital role in providing a reliable input for DSM, whereas its effectiveness on 3D-DSM has not been tested. A total of 148 sample locations, identified by six SDs, including grid sampling (GS), grid random sampling (GRS), simple random sampling (SRS), stratified random sampling (StRS), transect sampling (TS), and conditioned Latin hypercube sampling (cLHS), were used to collect vis-NIR spectra data to about 1-m depth in-situ using a commercial soil profiler from a small agricultural farm in Macdonald campus, McGill University. A subset of 32 sample locations were identified to collect soil cores down to 1-m depth and sampled at 10-cm depth intervals. A total of 251 samples were analyzed in laboratory for a range of soil properties. Partial least square regression was used to develop soil-spectral relationship model. Predicted soil and uncertainty maps for soil properties were developed using 3D-DSM with RK from the calibration dataset (103 locations) and assessed using validation dataset (45 locations). Further three regression techniques, including generalized linear model (GLM), regression tree (RT), and random forest (RF) were tested and compared for accuracy and efficiency. Maps developed using sub samples (45 locations) identified by six SDs were further compared with the original map produced by the full dataset (148 locations) and individually validated by the rest 103 locations.The results showed that a good prediction was obtained for soil organic matter (SOM) and water-related soil properties from in-situ vis-NIR spectra, while a fair prediction was obtained for other properties. RF outperformed GLM and RT by quantifying the non-linear soil-landscape relationship, displaying weak spatial structure of regression residuals, and resulting in a more robust prediction model with high accuracy and low uncertainty. The predicted maps clearly presented the soil spatial variability, reflected the interactions among soil properties, and displayed the associated soil forming processes. Among the SDs, StRS with both good spatial and feature space coverage better represented the distribution of original maps and showed a small prediction uncertainty, while cLHS produced higher validation accuracy. SRS resulted in good validation results, while requires further exploration for its robustness. The main contribution of this thesis was to assess and optimize the methods and techniques for 3D-DSM and associated SDs and quantify both the horizontal and vertical variability of multiple soil properties.</dc:abstract><dc:abstract>La réponse à la demande alimentaire pour une population mondiale croissante peut être atteinte à travers une gestion durable des ressources du sol. Ceci exigerait une compréhension des propriétés et des processus du sol et nécessiterait des méthodes de quantification de la variabilité du sol. La cartographie numérique à trois dimensions (CNS-3D) a une capacité de quantifier à la fois la variabilité horizontale et verticale s'est répandue dernièrement. Les dernières techniques incluant la régression à trois dimensions dite 'Kriging' (RK) a été utilisée pour explorer la relation complexe sol-paysage et non pour une évaluation à petite échelle. En outre, les récents progrès dans la détection proximale du sol permettent de mesurer et de prédire simultanément et rapidement les différentes propriétés du sol à multiples profondeurs et fournissent les informations nécessaires pour la cartographie numérique du sol (CNS). De plus, le plan d'échantillonnage (PE) joue un rôle essentiel en fournissant un apport solide pour la cartographie numérique à trois dimensions, alors que son efficacité à trois dimensions n'a pas été testée. Sur le terrain agricole du campus Mcdonald à l'université McGill, un total de 148 sites d'échantillonnage, identifiés par six SDs incluant une grille d'échantillonnage (GE), une grille d'échantillonnage aléatoire (GEA), un échantillonnage aléatoire simple (EAS), un échantillonnage aléatoire stratifié (EASt), un échantillonnage transect (ET) et  échantillonnage Hypercube latin (EHL), ont été utilisés in situ pour recueillir des données du spectre vis-NIR à environ 1 m de profondeur avec un profileur de sol. Un sous-ensemble de 32 sites d'échantillonnage a été identifié pour un carottage de sol jusqu'à 1 m de profondeur avec un intervalle de 10 cm. Un total de 251 échantillons a été analysé au laboratoire pour une gamme de propriétés de sol. Un modèle de régression partielle des moindres carrés a été utilisé pour développer un modèle de la relation sol-spectre. La prédiction de la carte et des propriétés du sol a été développée en utilisant la cartographie numérique à trois dimensions associée à la régression 'kriging' de l'ensemble des données d'étalonnage (103 sites) et évalués par la validation de l'ensemble des données (45 sites). Pour la précision et l'efficacité, trois autres techniques incluant le modèle linéaire généralisé (GLM), l'arbre à régression (AR) et la forêt aléatoire (FA) ont été testées et comparées.Les résultats ont montré qu'une bonne prédication a été obtenue pour la matière organique du sol et l'eau en relation avec les propriétés du sol à partir du spectre vis-NIR in situ,  tandis qu'une prédiction juste a été obtenue pour les autres propriétés. La forêt aléatoire a dépassé le modèle linéaire généralisé et l'arbre à régression en quantifiant la relation non linéaire sol-paysage, affichant une faible structure spatiale de la régression résiduelle, et résultant en un modèle de prédiction plus robuste avec une grande précision et une faible incertitude. Les cartes prédites présentent clairement la variabilité spatiale du sol, reflétant les interactions entre les propriétés du sol, et ont affiché les processus associés à la formation du sol. Parmi les différents PE, les EASt ayant à la fois une bonne couverture spatiale et une caractéristique dans l'espace représentent mieux la distribution des cartes originales et montrent une petite incertitude de prédiction, alors que l'EHL a démontré une grande précision de validation. L'EAS a aboutit à de bons résultats de validation, alors qu'il nécessite une exploration plus poussée pour sa robustesse. La contribution principale de cette thèse était d'évaluer et d'optimiser les méthodes et techniques pour la cartographie numérique à trois dimensions et les plans d'échantillonnage associés, et de quantifier la variabilité horizontale et verticale les différentes propriétés du sol.</dc:abstract><ual:supervisor>Asim Biswas</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/w9505305w.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/1v53k065f</ual:fedora3Handle><dc:subject>Natural Resource Sciences</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A0g354h88w"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of Integrated Studies in Education</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Towards a comprehensive understanding of nonformal Holocaust education: the role of community organizations in Canadian Holocaust education (1976-2016)</dcterms:title><ual:dissertant>Kerr-Lapsley, Sarah Jane</ual:dissertant><dc:abstract>Depuis la fin des années 1970, les initiatives non formelles en matière d'éducation de l'Holocauste — telles que promues dans les centres d'éducation, les organismes communautaires locaux, les fondations familiales et les musées — ont rendu possible l'éducation de l'Holocauste au Canada en développant des ressources, en coordonnant des rescapés éducateurs, en mettant sur pied un colloque à propos de l'enseignement de l'Holocauste, ainsi qu'en offrant du développement professionnel pour les enseignants. Malgré ce rôle central, les initiatives non formelles n'ont jamais fait l'objet de recherches sérieuses. Cette thèse se penche sur la mise en application de l'enseignement non formel dans le contexte de l'éducation de l'Holocauste, et elle explore les premiers développements canadiens en cette matière ainsi que l'évolution et la structure actuelle de ces initiatives. Elle rend compte de la place centrale que tiennent, pour les éducateurs de l'Holocauste, les ressources, les colloques sur l'enseignement, les trousses pédagogiques ainsi que la valeur éducationnelle des rescapés éducateurs. Par ces moyens, l'éducation non formelle de l'Holocauste se lie aux notions de la pensée et de la conscience historique. Cette recherche introduit aussi le concept d'une collaboration entre pédagogies formelle et non formelle afin de mieux comprendre la relation entre ces initiatives et les enseignants qui les professent. À terme, elle propose que des communautés de pratiques aux échelles micro et macro – unies par l'intention de former une communauté de pratique compréhensive, soit une communauté de meilleure pratique — forment un modèle conceptuel pour mieux comprendre les relations entre les différentes initiatives non formelles d'enseignement de l'Holocauste au Canada.</dc:abstract><dc:abstract>Since the late 1970s, nonformal Holocaust education initiatives – such as education centres, local community organizations, family foundations and museums – have facilitated Holocaust education in Canada, developing resources, coordinating survivor educators, running Holocaust education symposia, and providing professional development for teachers. In spite of their central role, comprehensive research has never been conducted on nonformal initiatives in this context. This thesis discusses the applicability of nonformal education in the context of Holocaust education, and explores both the development of early Canadian Holocaust education, and the current structure of these nonformal initiatives. It identifies the centrality of Holocaust educator resources, education symposia, classroom kits, and the experiential authority of survivor educators, and connects nonformal Holocaust education to notions of historical thinking and historical consciousness. This research also introduces the concept of formal-nonformal pedagogical collaboration as a way of understanding the relationship between these initiatives and classroom teachers, and proposes micro- and macro-communities of practice – as well as a desire for a comprehensive community of practice, or a community of best practice – as a way of conceptualizing the relationship(s) between Canadian nonformal Holocaust education initiatives.</dc:abstract><ual:supervisor>Eric Caplan</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/r781wj71z.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/0g354h88w</ual:fedora3Handle><dc:subject>Integrated Studies in Education</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Adv13zx109"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>fre</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of French Language and Literature</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Le poids de la fiction dans "Le Dictateur et le Hamac", suivi du texte de création "Dédales"</dcterms:title><ual:dissertant>Leblan, Perrine</ual:dissertant><dc:abstract>Ce mémoire s'intéresse, dans un premier temps, au commentaire métatextuel sur la nature de la fiction qui se déploie dans Le Dictateur et le Hamac de Daniel Pennac, et à la théorie de la fiction ainsi mise en récit. On trouve en effet dans l'œuvre de nombreux procédés narratifs qui transgressent les niveaux diégétiques, en particulier la métalepse genettienne, qui se manifeste notamment lorsque l'auteur, Pennac, décrit sa rencontre avec son propre personnage. À l'aide de ces procédés, le roman met en scène un brouillage des frontières entre « fiction » et « réalité » qui permet de remettre en question le statut accordé à la fiction. Les réponses qu'offre Le Dictateur et le Hamac sont complexes et souvent paradoxales, mais le texte accorde surtout à la fiction une existence aussi substantielle qu'au réel. Dans un second temps, mon texte de création, un récit intitulé Dédales, propose une autre manière de penser la fiction à travers la fiction, avec des personnages qui entretiennent tous un rapport confus à la réalité. Après la mort de leur mère, les jumeaux Eirwen et Dylan essayent de s'expliquer sa fin tragique en interrogeant le seul membre de leur famille qu'il reste et en retournant sur les lieux de leur enfance. Pour retrouver cet endroit, ils ne disposent cependant que des récits largement fictionnels de leur mère et de la mémoire défaillante de leur oncle, et c'est finalement la fiction qui va leur offrir des pistes de réponses.</dc:abstract><dc:abstract>This thesis first examines the metatextual commentary on the nature of fiction that unfolds in The  Dictator and the Hammock by Daniel Pennac, and the theory of fiction that is thus turned into a narrative. There are indeed a lot of narrative devices that transgress diegetic levels in the text, in particular Genette's metalepsis, which notably manifests itself when the author, Pennac, describes his meeting with his own character. Using these devices, the novel stages a blurring of the borders between « fiction » and « reality », which allows it to question the status granted to fiction. The answers provided by The Dictator and the Hammock are complex and often paradoxical, but what the text gives above all to fiction is an existence as substantial as reality. My creative writing piece, a story titled Dédales, then provides another way of thinking about fiction through fiction, with characters who all have a confused relationship with reality. After their mother's death, twins Eirwen and Dylan try to explain her tragic end by questioning the only remaining member of their family and by returning to the place of their childhood. To find this location however, they can only rely on their mother's largely fictional stories and their uncle's failing memory, and, in the end, it is fiction that will offer them some hints of answers.</dc:abstract><ual:supervisor>Isabelle Arseneau</ual:supervisor><ual:supervisor>Pascal Brissette</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/9s161883d.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/dv13zx109</ual:fedora3Handle><dc:subject>French Language and Literature</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A6d570018z"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Earth and Planetary Sciences</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Role of colloidal transport in the formation of high-grade gold veins at Brucejack, British Columbia</dcterms:title><ual:dissertant>Harrichhausen, Nicolas</ual:dissertant><dc:abstract>Low solubility of Au in hydrothermal fluids at epithermal pressures and temperatures make it difficult to reconcile extremely localized, very high Au grades in epithermal vein deposits. Au has been known to form colloidal suspensions (sols) of nanoparticles when it is super-saturated within solution. Drop in temperature and/or pressure of hydrothermal fluids causing super-saturation of Au is also known to saturate a fluid with respect to silica leading to the precipitation of silica nanoparticles. Au can adhere to silica nanoparticles causing the stability of Au within suspension to be greatly enhanced increasing transport distance. A silica-protected Au sol allows a much higher flux of Au through a hydrothermal system and deposition of very concentrated Au grades within an epithermal vein system. Depressurization caused by fracture and fault-slip within the epithermal environment commonly causes supersaturation of silica leading to sudden precipitation of amorphous silica phases such as opal, which traps any suspended Au nanoparticles. Subsequent recrystallization of amorphous silica alters depositional textures by forcing nanoparticles to quartz grain boundaries. Deformation and metamorphism will further recrystallize quartz, obscuring evidence of this process. This thesis presents structural data, and detailed optical and electron microscopy observations of epithermal quartz-carbonate vein stockwork systems at Brucejack, British Columbia and Dixie Valley, Nevada that are used to test a colloidal Au transport model. At the Jurassic aged Brucejack Au-Ag deposit, very high grades up to 41 582 ppm Au are reported within electrum that is hosted within metamorphosed and deformed quartz-carbonate stockwork. I show that initial stockwork development occurred during north-south extension and formation of mode 1 fractures with continued stockwork development within major normal fault zones. Electrum mineralization within these veins is shown to consist of an amalgamation of nanoparticles. Observations made on quartz formed within the recently active Stillwater fault zone at Dixie Valley, Nevada show that quartz here has recrystallized from an amorphous silica phase. Using these observations for comparison, quartz associated with nanoparticulate electrum at the much older Brucejack deposit is shown to also have recrystallized from an amorphous phase. The association between amorphous silica and nanoparticulate electrum indicates a colloidal origin for high-grade Au at the Brucejack deposit.</dc:abstract><dc:abstract>La faible solubilité de l'or dans les fluides hydrothermaux à des températures et pressions hydrothermales rend difficile la réconciliation avec des zones aurifères extrêmement localisées, à très hautes teneurs dans des gîtes à veines épithermales. Il est connu que l'or forme des suspensions colloïdales (sols) de nanoparticules lorsqu'il est sursaturé dans une solution. Une importante diminution température et/ou de pression des fluides hydrothermaux causant une sursaturation de l'or est aussi reconnue pour saturer le fluide en silice entraînant la précipitation de nanoparticules de silice. L'or peut adhérer aux nanoparticules de silices, améliorant considérablement la stabilité de l'or dans le fluide à être grandement améliorée, et ainsi augmenter la distance de transport. Un sol d'or protégée par de la silice permet un flux d'or beaucoup plus important dans le système hydrothermal et la déposition aurifère à très hautes teneurs dans un système de veines épithermales. La dépressurisation causée par la fracturation et le développement de failles dans un environnement épithermal provoquent communément une sursaturation de silice donnant lieu à une précipitation soudaine de phases amorphes de silice telle que l'opale, qui peut emprisonner les nanoparticules d'or en suspension. Une recristallisation subséquente de la silice amorphe altère les textures de déposition en forçant les nanoparticules aux surfaces des grains de quartz. La déformation et le métamorphisme vont recristalliser le quartz, masquant les indications de ce processus. Cette thèse présente des données structurales et des observations détaillées au microscopes optique et électronique du stockwork de veines épithermales de quartz-carbonates à Brucejack en Colombie-Britannique et à Dixie Valley au Nevada qui sont utilisées pour tester un modèle de transport d'or colloïdal. Au dépôt Jurassique Au-Ag de Brucejack, de très hautes teneurs allant jusqu'à 41 582 ppm d'or ont été rapportées dans l'électrum du stockwork déformé et métamorphisé de quartz-carbonate. Je démontre que le développement initial du stockwork s'est produit durant une phase d'extension nord-sud et durant la formation de fractures de type 1 en développement continu du stockwork dans des zones de failles majeures normales. La minéralisation en électrum dans ces veines semble consister d'un amalgame de nanoparticules. Des observations faites sur le quartz formé dans la zone récemment active Stillwater Fault à Dixie Valley au Nevada montre que le quartz a été recristallisé à partir d'une phase amorphe de silice. En comparant les observations des deux sites, on remarque que le quartz associé aux nanoparticules d'électrum au plus vieux dépôt Brucejack semble s'être également recristallisé à partir d'une phase amorphe de silice. L'association entre la silice amorphe et les nanoparticules d'électrum indique que les hautes teneurs aurifères du dépôt Brucejack sont d'origine colloïdale.</dc:abstract><ual:supervisor>Christen Danielle Rowe</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/3t945t55n.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/6d570018z</ual:fedora3Handle><dc:subject>Earth and Planetary Sciences</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A02870z673"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of Integrated Studies in Education</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>The effectiveness of form-focused instruction, textual enhancement and corrective feedback on second language word order acquisition</dcterms:title><ual:dissertant>Hao, Jun Ming</ual:dissertant><dc:abstract>Taking the sequencing assumption (for which this study proposes the term "sequencing hypothesis") as theoretical underpinnings, this study applies a particular research design of form-focused instruction (FFI), that is, a sequential FFI (SFFI). In the SFFI treatment, language was always the focus, but meaningful context was provided in the form of written texts followed by opportunities for output practice as implemented by the teachers based on the textbook. The purpose of this study is to investigate the effectiveness of SFFI on word order learning by second language (L2) learners of Mandarin.Participants were 59 international adult Mandarin learners in a language training program at a university in Shanghai. They were assigned randomly to one of four groups: the FFI-prompt group, the FFI-recast group, the FFI-only group, and the Control group. The FFI-only group received sequential instruction composed of noticing (taking the form of textually enhanced input) and awareness activities followed by controlled and communicative practice. In addition to receiving this same instruction, the FFI-prompt and FFI-recast groups received prompts or recasts, respectively. The Control group received similar instruction, minus the noticing activity, and no corrective feedback. Before the instruction, a written pretest was administered on participants in four groups. After 4.5 hours of instruction on Mandarin comparative word order, two assessment tasks were administered, including an immediate posttest, and a delayed posttest in written production, which took the form of a grammaticality judgment and error correction test. In addition, an immediate posttest and a delayed posttest were administered to assess oral production, which took the form of a description and a discussion test.Results from paired sample t-tests and one-way ANCOVAs with pairwise comparisons revealed that (a) the SFFI treatment effect was significant with and without the mediation of textually enhanced input, and with or without the provision of corrective feedback; (b) textually enhanced input did not show significant effects in target form acquisition; (c) the groups with corrective feedback outscored the other groups in 3 of 4 posttests, but only the FFI-prompt group outperformed the Control group in written posttest 1 and the Control group and the FFI-only group in written posttest 2. The findings of this study demonstrate the effectiveness of the sequential FFI, and partially of corrective feedback, but no positive evidence for textually enhanced input in this particular instructional setting. </dc:abstract><dc:abstract>Prenant l'hypothèse de séquençage comme fondements théoriques, cette étude applique un modèle de recherche particulier de l'enseignement axé sur la forme (EAF), qui est, un EAF séquentiel (EAFS). Dans le traitement de l'EAFS, les traits linguistiques sont d'abord mis en évidence dans un contexte signifiant fourni sous forme de textes écrits et ensuite mis en pratique par le biais d'activités de production adaptées à partir du manuel. Cette étude a pour but d'examiner l'efficacité de l'EAFS sur l'apprentissage de l'ordre des mots par les apprenants du mandarin langue seconde (L2).La cohorte de participants était composée de 59 apprenants adultes internationaux qui apprenaient le mandarin L2 dans un programme de formation linguistique dans une université à Shanghai. Ils ont été divisés au hasard en quatre groupes: le groupe EAF-incitation, le groupe EAF-reformulation, le groupe EAF-seul et le groupe témoin. Le groupe EAF-seul a reçu l'EAFS composé d'activités de perception (sous forme de la mise en évidence visuelle) et de conscientisation, suivi de la pratique contrôlée et communicative. En plus de recevoir ce même traitement, le groupe EAF-incitation et le groupe EAF-reformulation recevaient des incitations ou des reformulations, respectivement. Le groupe témoin a reçu un enseignement similaire, sans l'activité de perception (soit la mise en évidence visuelle) et sans rétroaction corrective. Avant l'intervention, un prétest écrit a été administré aux participants en quatre groupes. Au bout de 4.5 heures d'enseignement sur l'ordre des mots dans la phrase comparative en mandarin, deux tâches d'évaluation ont été administrés, y compris un posttest immédiat, et un posttest différé en production écrite, exigeant le jugement de grammaticalité et la correction des erreurs, ainsi que le test 1 et le test 2 à l'oral sous forme de description et de discussion.Les résultats indiquent que (a) l'EAFS a des effets significatifs avec ou sans mise en évidence visuelle et avec ou sans rétroaction corrective; (b) la mise en évidence visuelle avaient quelques effets négatifs; (c) les groupes recevant de la rétroaction corrective ont dépassé les autres groupes dans 3 des 4 tests après l'EAFS, mais seulement le groupe EAF-incitation a fait significativement mieux que le groupe témoin en posttest 1 écrit et que le groupe témoin et le groupe EAF-seul en posttest 2 écrit. Les résultats de cette étude témoignent de l'efficacité de l'EAFS, et partiellement de la rétroaction corrective, mais aucune preuve positive pour la mise en évidence visuelle dans ce contexte d'enseignement particulier.</dc:abstract><ual:supervisor>Roy Lyster</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/7h149s32h.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/02870z673</ual:fedora3Handle><dc:subject>Integrated Studies in Education</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A4b29b875q"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Bioresource Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Development of zein protein-based hydrogels and aerogels having potentials as heavy metal ion chelators and diesel fuel absorbents</dcterms:title><ual:dissertant>Ni, Na</ual:dissertant><dc:abstract>Les protéines sont des macromolécules riches en groupements fonctionnels. L'utilisation de protéines comme matière première pour la synthèse de matériaux a été sous-évalué dans une large mesure. Beaucoup de sous-produits riches en protéines proviennent de l'industrie de l'élevage, de l'agriculture et de la production alimentaire. Toutefois, ces sous-produits sont traditionnellement utilisés dans la formulation de nourriture pour animaux. Les chercheurs ont exploré l'utilisation de protéines comme monomères pour la production de matériaux fonctionnels. Parmi les matériaux polymères, les hydrogels à base de protéines sont attrayants en raison de leur biocompatibilité, biodégradabilité et de leur sensibilité aux stimulations environnementales. Par conséquent, une revue de la littérature portant sur les hydrogels à base de protéines provenant de sous-produits industriels a été produite. De par cette revue de la littérature, il a été constaté que les applications développées pour les hydrogels à base de zéine se limitaient à la microencapsulation pour la libération contrôlée des composés alimentaires et pharmaceutiques. Le caractère hydrophobe de la zéine est un avantage pour la synthèse de matériaux servant à l'encapsulation, mais c'est aussi un obstacle pour le développement d'hydrogels servant à d'autres fins. Par conséquent, l'objet de ce mémoire de maîtrise fut axé sur le développement et les applications potentielles des hydrogels et aérogels à base de zéine. Les hydrogels furent synthétisés en solution par copolymérisation avec greffage d'acide acrylique sur la zéine en présence d'un agent de réticulation (N, N'-méthylène bis (acrylymide)) et d'initiateurs (sodium bisulfite et potassium persulfate). La calorimétrie à balayage différentielle et des tests de gonflement à l'équilibre ont été réalisés afin d'évaluer les effets des formulations sur les propriétés des hydrogels qui en résultent, incluant la quantité d'agent de réticulation et d'initiateur utilisés, ainsi que le ratio entre l'acide acrylique et les protéines. Il a été constaté que ces hydrogels étaient hautement sensibles au pH. La plus haute valeur de gonflement à l'équilibre a été atteinte à pH 7 (239,6 g/g). De plus, les hydrogels ont démontrés une bonne capacité de chélation des ions de cuivre (maximum de 1 073 mg/g à pH5). Par conséquent, les hydrogels synthétisés dans cette étude pourraient être utilisés dans le traitement des eaux usées contenant des ions de métaux lourds.Afin d'augmenter les possibilités d'applications non alimentaires de la zéine, des aérogels furent synthétisés à partir des hydrogels à base de zéine. La quantité d'acide acrylique utilisée pour la synthèse des aérogels a eu un effet sur les propriétés thermiques, les propriétés d'absorption de l'eau et d'absorption du diesel des matériaux. Il a été constaté que la capacité d'absorption de l'eau ainsi que du diesel fut influencée par les conditions de congélation avant l'étape de séchage puisque les hydrogels congelés à l'aide d'azote liquide (-196 ° C) avaient une aire de surface plus élevée par rapport aux hydrogels congelés à -20 °C. La plus haute valeur d'absorption d'eau à l'équilibre a atteint 119,5 g/g d'aérogel après 1 h alors que la valeur d'absorption du diesel à l'équilibre a atteint 45,8 g/g d'aérogel en 15 min. Par conséquent, les aérogels synthétisés à partir de la zéine ont démontré un potentiel comme absorbant de carburant. </dc:abstract><dc:abstract> Proteins are widely available macromolecules rich in functional groups. The use of proteins as feedstock for the synthesis of materials has been undervalued to a large extent. Many protein-rich byproducts are generated from agricultural and food production industries. However, these byproducts are traditionally used for low-value animal feed. Researchers have been exploring the utilization of proteins as biopolymers for the production of functionalized materials. Among polymeric materials, protein-based hydrogels are increasingly attractive due to their biocompatibility, biodegradability and sensitivity to environmental stimulations. Therefore, a thorough review of the literature about protein-based hydrogels derived from industrial byproducts was produced. Through this review, it was found that the application of zein protein-based hydrogels was limited to microencapsulation for the controlled release of nutritional and pharmaceutical compounds. The hydrophobic character of zein is an advantage for the synthesis of encapsulation materials, but it is also an obstacle for developing hydrogels for other purposes. Therefore, the subject of this thesis focused on the development and the potential applications of zein protein-based hydrogels and aerogels.  Zein protein-based superabsorbent hydrogels were developed by solution based grafting polymerization technique. Partially neutralized acrylic acid monomers were grafted on zein protein backbones in the presence of a crosslinker (N,N'-methylenebis (acrylamide)) and initiators (sodium bisulfite and potassium persulfate). Differential scanning calorimetry and swelling tests were performed to evaluate the effects of the formulations on the properties of the resultant hydrogels, including the amount of crosslinker, initiators and the ratio of acrylic acid to zein proteins. It was found that these superabsorbent hydrogels were highly sensitive to pH and reached the highest swelling value at pH 7 (239.6 g/g). Moreover, the hydrogels had a good copper ion chelation capacity (maximum of 1073 mg/g at pH5). Therefore, zein based superabsorbent hydrogels synthesized in this study may find application in the treatment of wastewater containing heavy metal ions.To extend the non-food applications of zein proteins, zein-based aerogels were developed based on freeze-dried hydrogels. The amount of acrylic acid used for the synthesis of the aerogels had an effect on the thermal properties, the water absorption and the diesel absorption capacities. It was found that the water and the diesel absorption capacities were influenced by the freezing conditions prior to the drying step since freezing the materials using liquid nitrogen at -196 °C increased the surface area of the aerogels as compared to freezing at -20 °C. The highest equilibrium water absorption of aerogels in distilled water reached 119.5 g/g of aerogel after 1 h while the highest equilibrium absorption in diesel fuel reached 45.8 g/g of aerogel in 15 min. Therefore, the obtained zein-based aerogels showed potential as diesel fuel absorbents.</dc:abstract><ual:supervisor>Marie-Josee Dumont</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/8k71nk801.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/4b29b875q</ual:fedora3Handle><dc:subject>Bioresource Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ans0648550"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of Art History and Communication Studies</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>After Nirbhaya: anti-sexual violence activism and the politics of transnational social media campaigns</dcterms:title><ual:dissertant>Vemuri, Ayesha</ual:dissertant><dc:abstract>En décembre 2012, le viol collectif brutal d'une jeune femme dans un bus à New Dehli a généré une vague de manifestations a travers l'Inde. Maintenant connu sous le nom d'affaire Nirbhaya, cet incident a généré un scandale médiatique mondial, attirant une attention renforcée sur la violence sexuelle en Inde, révélant aussi des perceptions orientalistes et néocoloniales sur la violence à caractère sexiste en Inde. Dans cette thèse, j'analyse trois campagnes qui sont devenues virales sur les réseaux sociaux a la suite de l'affaire Nirbhaya. La campagne publicitaire Abused Goddesses utilise des images de déesses battues pour sensibiliser le public à propos de la violence domestique. Priya's Shakti est un magazine de bandes dessinées utilisant la réalité augmentée et qui présente la survivante d'un viol comme une 'super hero' qui se lance dans une aventure pour renverser la culture du viol et la logique de déresponsabilisation. Finalement, Talk To Me est projet de performance artistique qui adresse la peur ressentit par de nombreuses femmes dans les espaces publics en Inde, en utilisant les outils du dialogue et de l'esprit communautaire au delà des frontières de classe, caste, sexe et de langue. J'analyse le débat entourant ces trois campagnes à travers le filtre conceptuel de la solidarité féministe transnationale, comme décrit dans le travail des féministes post-colonialistes tel que Chandra Talpade Mohanty, Jacqui Alexander, Inderpal Grewal et Caren Kaplan. Je soutiens que les reportages des médias internationaux qui célèbrent sans discernement l'utilisation de la mythologie Hindoue dans les campagnes sur la violence sexuelle contribuent à la ténacité des perceptions orientalistes et néocolonialistes. De plus, ils aident à rendre invisible la violence actuelle et grandissante des fondamentalistes Hindous en Inde. Je préconise un effort conscient pour s'éloigner de ces représentations discursives étroites de la violence sexuelle en Inde, pour se rapprocher vers un récit plus réfléchi et nuance. J'argumente que cet éloignement crée une opportunité pour former des coalitions et de la solidarité parmi les féministes transnationalistes au delà des frontières de classe, race, caste, sexualité, nationalité, religion et sexe.</dc:abstract><dc:abstract>In December 2012, the brutal gang rape of a young woman in a moving bus in New Delhi resulted in widespread protests across India. Now known as the Nirbhaya case, this incident generated a mass media furor around the globe, bringing intensified attention to sexual violence in India, as well as revealing orientalist and neocolonial perceptions about gender violence in India. In this thesis, I analyse three campaigns that went viral on social media following the Nirbhaya incident. The Abused Goddesses advertising campaign uses images of battered Hindu goddesses to create awareness about domestic violence. Priya's Shakti is an augmented reality comic book that presents a rape survivor as a 'superhero' who embarks on a journey to overturn rape culture and victim blaming. Finally, Talk to Me is a site-specific performative art project that addresses the fear that defines the experience of many women in India's public spaces, by using the tools of dialogue and community building across borders of class, caste, gender, and language. I view the discourse surrounding these three campaigns through the conceptual lens of transnational feminist solidarity, as articulated in the work of postcolonial feminists such as Chandra Talpade Mohanty, Jacqui Alexander, Inderpal Grewal and Caren Kaplan. I argue that international media reports which uncritically celebrate the use of Hindu mythology in campaigns about sexual violence contribute to the persistence of orientalist and neocolonial perceptions of India. In addition, they help render invisible the ongoing and increasing violence of Hindu fundamentalism in India. I advocate a conscious effort to move away from such narrow discursive portrayals of sexual violence in India, towards a more reflective and nuanced narrative. This move, I argue, creates the opportunity for forming coalitions and solidarity amongst transnational feminists across borders of class, race, caste, nationality, religion, sexuality and gender.</dc:abstract><ual:supervisor>Carrie Rentschler</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/ns0648568.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/ns0648550</ual:fedora3Handle><dc:subject>Art History and Communications Studies</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Azk51vk53n"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Mechanical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Computation of nonlinear modes of vibration of systems undergoing unilateral contact through the semi-smooth Newton approach</dcterms:title><ual:dissertant>Shi, Yulin</ual:dissertant><dc:abstract>Dans le domaine de la dynamique des structures, les systèmes conservatifs autonomes sont caractérisés par la présence de familles continues d'orbites périodiques dans l'espace des phases, communément appelées \emph{modes de vibration}. L'ambition principale de l'analyse modale est le calcul précis des fréquences naturelles et de la forme des modes de vibration correspondants de systèmes mécaniques. En effet, dans le cadre linéaire, ces deux quantités permettent de correctement prédire les conditions selon lesquelles les systèmes forcés associés vont entrer en résonance vibratoire. Caractériser les modes de vibration de systèmes mécaniques non-linéaires mais réguliers (systèmes gouvernés par des équations différentielles ordinaires qui impliquent des fonctions régulières du déplacement et de la vitesse), tels que les oscillateurs de Duffing, est un sujet de recherche très actuel dans les sphères académique et industrielle. De nombreux outils, comme la méthode des éléments finis, la méthode de l'équilibrage harmonique, les techniques de continuation et les diagrammes fréquence-énergie participent à une meilleure compréhension de la dynamique modale. Néanmoins, des difficultés numériques et théoriques émergent lorsque l'on s'intéresse à des problèmes non-réguliers, comprenant des contraintes de contact unilatéral et de frottement. La nature mathématique de ces termes remet en question l'utilisation de méthodes de résolution non-linéaires usuelles comme celle de Newton-Raphson.  Dans ce travail, seules les conditions de contact unilatéral sont considérées. Leur expression usuelle sous forme complémentaire est transformée en ensemble solution d'équations semi-régulières. En statique, la solution peut alors être calculée grâce à la version semi-régulière de la méthode de Newton-Raphson et des taux de convergence peuvent être estimés. En analyse vibratoire, dans des configurations forcée ou autonome, une solution périodique est supposée et la forme semi-régulière des conditions de contact permet l'implantation immédiate de la Méthode de l'Équilibrage Harmonique par projection de Galerkin. Les équations non-linéaires résultantes sont semi-régulières et sont, à nouveau, résolues par une méthode de Newton semi-régulière. Une technique de continuation par longueur d'arc permet de suivre les branches de solution affichées sur des diagrammes fréquence-énergie. A des fins de comparaison, les solutions construites par intégration temporelle servent de référence. Il est montré que la formulation proposée est capable de trouver les résonances vibratoires principales, les résonances des sous-harmoniques ainsi que les résonances internes propres aux systèmes dynamiques non-linéaires. Les algorithmes peuvent être étendus au calcul de modes de vibration de systèmes mécaniques de forme et d'interface de contact quelconque grâce à la méthode des éléments finis. Une question théorique sur la validité des solutions forcées trouvées par la méthode de l'équilibrage harmonique est soulevée en annexe mais reste en suspend.</dc:abstract><dc:abstract>In structural dynamics, autonomous conservative systems most commonly exhibit continuous families of periodic orbits in the phase space, usually known as modes of vibration. The main task of modal analysis is to accurately compute natural frequencies and corresponding mode shapes of vibratory mechanical systems as they are known, at least in a linear context, to properly predict the conditions under which the associated periodically forced systems will resonate. Characterizing the modes of vibration of nonlinear yet smooth mechanical systems (systems governed by ordinary differential equations that are smooth with respect to the unknown displacement and velocity), such as Duffing oscillators, is a current topic of interest in the industrial and academic spheres. Many useful tools, such as the finite element method, the harmonic balance method, the continuation techniques and the frequency-energy plots provide great assistance in understanding the modal dynamics. However, theoretical as well as numerical issues arise when extending these tools to nonsmooth problems, such as unilateral contact and frictional formulations. The mathematical nature of these terms is such that the use of conventional nonlinear solvers such as Newton's method is questionable.  In this work, unilateral contact conditions are considered. Their common complementarity form is expressed as the root set of semismooth functions. In statics, the solution can thus be retrieved through the semismooth version of Newton's method for which convergence rates can be derived. In vibration analysis, in the frameworks of either periodically forced or autonomous dynamics, a periodic solution is assumed and the proposed semismooth form of the unilateral contact conditions allows for the straightforward implementation of Galerkin-like methods such as the harmonic balance method. The resulting nonlinear equations stemming from Galerkin projection on the Fourier basis are still semismooth thus solvable using semismooth Newton's method. Arclength continuation is then implemented to follow the solution branches displayed in Frequency-Energy plots. For comparison purposes, time-marching solutions serve as references. It is demonstrated that the proposed formulation is capable of capturing the main vibratory resonances, the sub-harmonic resonances as well as the internal resonances known to emanate in nonlinear dynamics. The proposed algorithms can be extended to finding the modes of vibration of mechanical bodies with arbitrary shapes and challenging contact interfaces using the finite element method. In Appendix B, a theoretical question on the meaning of the forced responses found via the harmonic balance method is raised but remains unanswered.</dc:abstract><ual:supervisor>Mathias Legrand</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/g158bk924.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/zk51vk53n</ual:fedora3Handle><dc:subject>Mechanical Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Amw22v8189"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Decoding local field potential oculomotor signals during reach planning for neural prosthetic systems</dcterms:title><ual:dissertant>Thorn, Brendan</ual:dissertant><dc:abstract>Des systèmes prothétiques neuronaux sont une option prometteuse pour rétablir le contrôle moteur indépendant aux personnes avec les blessures permanentes, telles que la paralysie. Dans cette mémoire, nous étudions les signaux oculomoteurs qui sont encodés dans le potentiel de champ local (PCP) cortical pendant la planification de portée. Les PCPs enregistrées des zones du cerveau sensorimoteur médial intra-pariétal (MIP) et dorsale pré-moteur (PMd) - connus pour encoder les intentions de portée comme les coordonnées liées à la position de l'oeil - sont transformés au domaine temps-fréquence en utilisant l'analyse multi-effilage. Nous examinons si le PCP peut être décodé d'une manière fiable pour deux nouveaux objectifs: i) pour déterminer si la direction saccade ou poursuite peut être vérifiée près du temps de son commencement pendant qu'une portée instruite précédemente est prévue simultanément; et ii) dans le même scénario de planification de la portée, pour déterminer si les saccades ou poursuites peuvent être détectées dans les 100 ms avant le commencement du mouvement. Tout d'abord, en utilisant un classificateur de Bayes naïf, nous montrons que la direction du mouvement de l'oeil est encodée dans la puissance spectrale du PCP, mais la précision du décodage est sévèrement diminuée par la planification de la portée concurrente. Deuxièmement, nous proposons un algorithme qui est causal, général et basé sur un machine à vecteurs de support pour détecter le commencement des mouvements oculaires en temps réel de la puissance spectrale du PCP. Nous menons les simulations seules essaies pour démontrer son comportement qualitativement souhaitable. Nous utilisons les données enregistrées des zones MIP et PMD pour montrer que les fausses détections sont regroupés de manière disproportionnée à proximité de la période de commencement et les taux de vraies détections positives sont considérablement au-dessus le hasard pour les saccades et poursuites. Nos résultats suggèrent que la puissance spectrale du PCP n'est peut-être pas un signal de commande porté-prothétique acceptable pour obtenir de l'information oculomoteur directionnelle; cependant, il peut être efficace comme source temps réel des informations temporelles liées à des changements dans l'état comportemental, et en particulier, l'apparition des saccades et des poursuites.</dc:abstract><dc:abstract>Using signals recorded from the brain to control an artificial device, neural prosthetic systems are a promising option for restoring independent motor control to people with permanent injuries, such as paralysis. Since humans generally look towards their target before reaching or moving, motor prosthetic applications could be improved with reliable decoding of eye position. For this thesis, we studied oculomotor signals encoded in the cortical local field potential (LFP) during reach planning. LFPs recorded from the medial intra-parietal (MIP) and dorsal pre-motor (PMd) areas of the brain – known to encode reach intentions in coordinates related to eye position – were transformed to the time-frequency domain using multi-taper analysis. We investigated whether LFP spectral power can be decoded for two novel purposes: i) to determine saccade or pursuit eye movement direction during a concurrent reach planning period; and ii) in the same reach planning scenario, to detect saccade or pursuit eye movements within a 100 ms post-onset period. First, using a naïve Bayes classifier, we showed that eye movement direction is encoded in LFP spectral power independently of reach direction; however, decode accuracy may be degraded by concurrent reach planning. Second, we proposed a causal, general support vector machine-based algorithm for detecting eye movement onset in real-time. We then implemented single-trial simulations to demonstrate its qualitatively desirable behavior. We showed false detections were clustered near the post-onset period and true positive detections were made at a significantly above-chance rate for saccades and pursuits. Our results suggest that MIP and PMd LFPs could potentially be used to decode oculomotor signals and thereby improve reach-related neural prosthetic devices.</dc:abstract><ual:supervisor>Wissam Musallam</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/db78tf77c.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/mw22v8189</ual:fedora3Handle><dc:subject>Electrical and Computer Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ap5547v128"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of Kinesiology and Physical Education</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Knowledge and routines of NCAA hockey coaches during intermissions</dcterms:title><ual:dissertant>Allain, Julia</ual:dissertant><dc:abstract>Intermissions are a short period of time in the middle of competition where coaches have the opportunity to interact with their assistant coaches, adjust their game plan, and address their team as a whole. According to expert coaches, proper use of this critical time in competition is a learning process that improves with experience and relies on multiple contextual factors (Bloom, 1996). While research has demonstrated significant planning and thought behind the behaviors of coaches in competition (Bloom, Durand-Bush, &amp; Salmela, 1997; Debanne &amp; Fontayne, 2009; Smith &amp; Cushion, 2006), coach knowledge and routines during intermissions have yet to be the main focus of a study. The purpose of this study was to examine the knowledge and routines of coaches during intermissions, as well as the factors that influenced their individual and team interactions. Six highly experienced and successful NCAA Division I hockey coaches were purposely sampled and completed a two-part interview process that included both a semi-structured and stimulated recall interview. The purpose of the interviews was to discover what coaches do during intermissions and why they do it. A thematic analysis (Braun &amp; Clarke, 2013) of the semi-structured interviews revealed their specific coaching routines during intermissions as well as the factors that affected what they said during their team address. In addition, different situational factors such as the time of season, the score of the game, and the team performance influenced certain coaching behaviors, such as what technical and tactical adjustments the coaches made and how they communicated those adjustments to the team. The results from the thematic analysis were then used to deductively analyze (McCarthy &amp; Jones, 2007) the stimulated recall interviews. The stimulated recall data provided deeper insight to the decision-making process of coaches within the context of a specific intermission. In particular, the results revealed that intermissions are an emotional time for both the coaches and the athletes and that these emotions played a significant role in the decision-making process for coaches. The stimulated recall interviews allowed the coaches to identify specific emotions, such as frustration or excitement, experienced by themselves and their athletes as well as the strategies they used to manage these emotions in the given context. Furthermore, due to the extensive amount of experience in our sample of coaches, they all relied on their past experiences to guide their behaviors and decisions during the intermissions. Overall, this study adds to coaching literature by revealing both the behaviors and thought processes of experienced coaches during this somewhat overlooked but important time period during competition. Finally, the findings may benefit head coaches by offering insight to intermission knowledge and strategies of successful elite coaches.</dc:abstract><dc:abstract>Les entractes sont de courtes périodes de temps dans le milieu de la compétition où les entraîneurs ont la possibilité d'interagir avec leurs entraîneurs adjoints, d'ajuster leur plan de jeu et d'adresser leur équipe dans son ensemble. Selon des entraîneurs experts, l'utilisation de ce temps critique en compétition est un processus d'apprentissage qui s'améliore avec expérience et qui repose sur plusieurs facteurs contextuels (Bloom, 1996). Bien que la recherche a démontré beaucoup de planification et de réflexion derrière les comportements des entraîneurs en compétition (Bloom, Durand-Bush, &amp; Salmela, 1997; Debanne &amp; Fontayne, 2009; Smith &amp; Cushion, 2006), les connaissances et les routines des entraîneurs pendant les entractes n'ont pas encore été l'objet principal d'une étude. Cette étude visait à examiner les connaissances et les routines des entraîneurs durant les entractes ainsi que les facteurs qui ont influencé leurs interactions individuelles et d'équipe. Six entraîneurs de hockey très expérimentés et couronnés de la NCAA Division I ont été délibérément échantillonnés et ont complété un processus d'entretiens de deux parties qui comprenaient à la fois une entrevue semi-structurée et une entrevue de rappel stimulé. L'objectif de ces entretiens était de découvrir ce que les entraîneurs font pendant les entractes et les raisons pour lesquelles ils le font. Une analyse thématique (Braun &amp; Clarke, 2013) des entretiens semi-structurés a révélé des routines d'entraînements spécifiques pendant les entractes qui ont guidés les comportements des entraîneurs, tel que la façon dont ils recueillent des informations et les facteurs qui influencent ce qu'ils disent lorsqu'ils adressent leur équipe. En outre, différents facteurs situationnels tels que le temps de la saison, le pointage du jeu et la performance de l'équipe ont influencé quelques comportements des entraîneurs tout comme leurs ajustements techniques et tactiques ainsi que la façon dont ils communiquaient ces ajustements avec leur équipe. Les résultats de l'analyse thématique ont ensuite été utilisés pour analyser l'entrevue de rappel stimulé de façon déductive. Les données de l'entrevue de rappel stimulé ont donné un meilleur aperçu du processus de prise de décision dans le cadre d'un entracte précis. En particulier, les résultats ont révélé que les entractes sont un moment émouvant pour les entraîneurs et leurs athlètes et que ces émotions ont joué un rôle primordial dans le processus de prise de décision pour les entraîneurs. Les entrevues de rappel stimulé ont permis aux entraîneurs de déterminer des émotions spécifiques, comme la frustration ou l'excitation, vécues par eux-mêmes et leurs athlètes, ainsi que les stratégies utilisées pour gérer ces émotions dans le contexte donné. De plus, en raison des nombreuses années d'expérience dans notre échantillon d'entraîneurs, ils comptaient tous sur leurs expériences passées pour guider leurs comportements et leurs décisions pendant les entractes. En somme, cette étude ajoute à la littérature d'entraînement en révélant à la fois les comportements et le processus de réflexion des entraîneurs expérimentés au cours de cette période de temps un peu négligée, mais aussi importante au cours de la compétition. Enfin, les résultats de cette étude bénéficient les entraîneurs-chefs en offrant un aperçu des connaissances et des stratégies d'entraîneurs élites et couronnés. </dc:abstract><ual:supervisor>Gordon Bloom</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/9880vt484.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/p5547v128</ual:fedora3Handle><dc:subject>Kinesiology and Physical Education</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A8c97kt00t"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Physics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>A single pulse pipeline for the pulsar arecibo L-band feed array survey</dcterms:title><ual:dissertant>Patel, Chitrang</ual:dissertant><dc:abstract>PALFA (Pulsar Arecibo L-band Feed Array) est un recensement astronomique du disque galactique dans les fréquences entourant les 1.4 GHz et ayant pour but de trouver de nouveaux pulsars radio (étoiles à neutrons, grandement magnétisées, en rotation rapide). Ce recensement utilise le radiotélescope Arecibo; le plus grand télescope à antenne convergente au monde (305 mètres de diamètre), situé à Puerto Rico. Ayant débuté sa recherche de pulsars en 2004, PALFA a découvert 163 pulsars à ce jour, incluant 13 Rotating Radio Transients (RRAT, une nouvelle catégorie de pulsars ayant des émissions sporadiques), ainsi que 1 Fast Radio Burst (FRB, une toute récente classe emettant sporadiquement des signaux ne durant que quelques millièmes de secondes). Récemment, un nouveau système d'analyse de données conçu pour détecter les RRATs et les FRBs a été incorporé dans les routines d'analyses de PALFA. Cet algorithme apporte une meilleure performance au système d'analyse original quant à l'identification de pulsations individuelles dans le domaine temporel. Cet algorithme regroupe les pulsations individuelles en se basant sur la proximité dans le temps et dans la mesure de dispersion (Dispersion Measure (DM), propriété décrivant le nombre intégré d'électrons libres au long d'une ligne de mire spécifique) a été incorporé au système d'analyse de PALFA. Chaque groupe est par la suite classé quant à son potentiel à être issu d'une source astronomique. Des diagnostiques de candidats finaux sont ensuite produits sous forme de diagrammes. Chacun de ces candidats sont alors soumis à une séries d'évaluations conduites par une machine à intelligence-artificielle. Finalement, ces candidats évalués sont téléchargés sur un site internet permettant de visualiser les candidats dans le but d'être inspectés par les membres de PALFA. L'algorithme à la base du nouveau système d'analyse a permis la découverte de 2 RRATs et de 5 nouveaux pulsars. Parmi ces nouvelles sources, 3 ont été découvertes uniquement via cet algorithme, et 4 via l'algorithme de base du système de traitement original de PALFA ainsi que par le nouvel algorithme. Ces nouvelles étoiles à neutrons sont maintenant surveillées régulièrement avec le radiotélescope Arecibo dans le cadre de la campagne de cadencement de PALFA. Prochainement, toutes les observations archivées de PALFA seront réanalysées avec ce nouvel algorithme,ce qui permettrait possiblement de détecter au moins 9 nouveaux pulsars (incluant RRATs et FRBs) qui auraient pu être non-détecté précédemment, avec le système d'analyse original moins sophistiqué.</dc:abstract><dc:abstract>PALFA (Pulsar Arecibo L-band Feed Array) is an on-going survey of the Galactic plane at 1.4 GHz, searching for radio pulsars (rapidly rotating highly magnetized neutron stars) with the Arecibo 305-m single dish radio telescope located in Puerto Rico. Begun in 2004, PALFA has discovered 163 radio pulsars including 13 RRATs (Rotating RAdio Transients -- a recently discovered class of pulsars with sporadic emission) and 1 FRB (Fast Radio Bursts -- a mysterious new class of milliseconds duration bright radio bursts). We have written and implemented a new data analysis pipeline to improve the search for long period pulsars (spin period P &gt; 0.1 s), RRATs and FRBs. The new pipeline is an improvement to the original data analysis pipeline with a more systematic processing and post-processing approach to identify astrophysical individually detectable single pulses in the time  domain. The original pipeline consisted of a matched-filtering search technique as a part of the single pulse analysis of the pipeline. To do a more rigorous search, we appended the pipeline with a grouping algorithm which gathers similar single pulse events into a single group based on proximity in time and DM (dispersion measure -- the integrated column density of free electrons along a particular line of sight). Each group is ranked based on the criteria that astrophysical pulses follow (their signal-to-noise peaks at the optimal DM and falls off on either sides). A final candidate diagnostic plot is produced for each potential astrophysical candidate as identified by the grouping algorithm. Each candidate is then subject to a series of heuristic ratings followed by evaluation by a machine-learning algorithm. The final candidate diagnostic plots are uploaded to an online candidate viewer for by-eye inspection by the members of the PALFA consortium. Using this new pipeline we have discovered 5 new pulsars and 2 RRATs, 3 of which were detected uniquely by the single pulse analysis of the pipeline and 4 were detected by both single pulse and periodicity analysis. The discovered pulsars are now being regularly monitored as a part of our timing campaign. We plan to reprocess all PALFA archival data in Summer 2016 using this newly developed single-pulse pipeline. In doing so, we expect to find at least 9 new pulsars (including RRATs and FRBs) that could have been missed by the original pipeline.</dc:abstract><ual:supervisor>Victoria Kaspi</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/kk91fp405.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/8c97kt00t</ual:fedora3Handle><dc:subject>Physics</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A12579v93c"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Atmospheric and Oceanic Sciences</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Impact of near-inertial waves on a balanced flow</dcterms:title><ual:dissertant>Riopel, Alexis</ual:dissertant><dc:abstract>Near-inertial waves (NIWs), i.e. inertia-gravity waves with a frequency close to f , account for about half of the wave energy in the ocean. Forced mainly by winds, NIWs are ubiquitous in the oceans, superimposed over balanced currents. While NIWs have a strongly depth-dependent structure, the balanced flow is more often vertically uniform over a few hundreds of meters. It is unclear whether NIWs exchange energy with the balanced flow, thus influencing the oceanic circulation. Using a two-layer shallow-water model, we investigate this question. We compare our results with those from Xie &amp; Vanneste (2015), which highlights energy transfers from the balanced flow to NIWs potential energy when the length scale of NIWs reduces. We perform the same numerical experiment they did, where NIWs evolve over a depth-independent vorticity dipole. An important difference with our two-layer model is the interface deformation field between the two layers, and how it affects the kinetic energy budget, sometimes playing an intermediary role in the transfer of energy from the balanced flow to NIWs. We also conduct simulations with a turbulent background flow and a stratification typical of the mid-latitudes. Like Xie &amp; Vanneste (2015), we find that as long as the NIW scale is decreasing because of advection and refraction by the background flow, the wave potential energy is increasing. Moreover, we are able write down a compact expression for the energy transfer from the balanced flow to NIWs. This expression depends on the unbalanced, fast-timescale part of the baroclinic potential vorticity.</dc:abstract><dc:abstract>Les ondes quasi-inertielles (OQI), c'est-à-dire des ondes d'inertie-gravité dont la fréquence diffère peu de f , constituent environ la moitié de l'énergie des vagues dans l'océan. Principalement générées par le vent, les OQI sont omniprésentes dans les océans, superposées à des courants en équilibre. Tandis que les OQI présentent une structure qui varie rapidement le long de l'axe vertical, les courants en équilibre sont plus généralement indépendants de la profondeur. Il n'est pas encore bien compris si les OQI échangent de l'énergie avec les courants en équilibre et influencent la circulation océanique. À l'aide d'un modèle Saint-Venant à deux couches, nous nous penchons sur cette question. Nous comparons nos résultats à ceux de Xie &amp; Vanneste (2015), qui montrent un transfert d'énergie depuis du courant en équilibre vers l'énergie potentielle des OQI lorsque l'échelle spatiale des ondes rapetisse. Nous réalisons la même expérience numérique qu'eux où des OQI évoluent dans un vortex dipolaire. Une différence importante de notre modèle réside dans l'interface entre les deux couches, et comment cette déformation change le bilan d'énergie cinétique, jouant parfois le rôle d'un intermédiaire dans le transfert d'énergie vers les ondes. Nous réalisons aussi des simulations avec un champ turbulent en tant qu'écoulement en équilibre et une stratification typique des latitudes moyennes. Comme Xie &amp; Vanneste (2015), nous constatons que l'énergie potentielle des ondes augmente quand l'échelle spatiale des OQI diminue sous l'effet de l'advection et de la réfraction du courant d'arrière-plan. De plus, nous arrivons à écrire, à l'aide d'une expression compacte, comment l'énergie passe du courant en équilibre aux ondes. Cette expression dépend de la partie à haute fréquence du tourbillonnement potentiel barocline.</dc:abstract><ual:supervisor>David N. Straub</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/9306t1850.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/12579v93c</ual:fedora3Handle><dc:subject>Atmospheric and Oceanic Sciences</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Am326m455c"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of Art History and Communication Studies</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Deciphering crypto-discourse: articulations of internet freedom in relation to the state</dcterms:title><ual:dissertant>Hellegren, Zelda</ual:dissertant><dc:abstract>The understanding of what constitutes "Internet freedom" varies between countries and cultures. In Internet governance debates, a myriad of actors is invested in defining the meaning of "freedom" in relation to Internet-specific technologies. A central component in meaning-making processes about Internet-specific technologies and their functions is the constant negotiation of online rights, such as personal privacy and freedom of expression. In the process of these and other contestations over what should or should not constitute Internet freedom, this study explores how a specific community of participants in the Internet governance debate, namely public-key cryptography advocates, has constructed a discourse in which "crypto" (encryption software) serves as an enabler of freedom. While the design of "crypto" aims to render online communication illegible to anyone but its intended recipient(s), the representation of crypto serves as a battlefield in a larger discursive struggle to define the meaning of Internet freedom. This thesis investigates how crypto-advocates, and in particular Cypherpunks, have articulated crypto-discourse: a partially fixed construction of meaning that establishes a relationship between "crypto" and a negative conception of Internet freedom, in relation to the state. I argue that crypto-discourse excludes other possible positive meanings of Internet freedom. In so doing, the discourse removes responsibility from democratic states to secure online rights and freedoms for their citizens. To decipher crypto-discourse, I turn to three interrelated concepts central to Laclau and Mouffe's theory of discourse, namely, social antagonisms, empty signifiers, and logics of difference and equivalence. I map key discursive events pertaining to the articulation of "crypto" among interrelated discourse communities of cryptographers, hackers, online rights activists, and technology journalists during a period of forty years (1975 – 2015). I present the crypto-discourse timeline as comprised of three periods: the origins (1975 – 1990), crystallization (1990 – 2000), and revitalization of crypto-discourse (2000 – 2015). For each period, I analyze key discursive artifacts such as political manifestos produced by Cypherpunks and journalistic accounts produced by Wired magazine technology reporters using the discourse theoretical concepts. Lastly, I argue that this strategic articulation of crypto is suggestive of myth-making. The implications of this research call for a more contextualized debate about the role of democratic governments in upholding privacy rights and freedom of speech online.</dc:abstract><dc:abstract>L'interprétation de ce qui constituent les libertés sur Internet varie selon les pays et les cultures. Dans les débats sur la gouvernance de l'Internet, une myriade d'acteurs est impliquée dans la définition de la notion des « libertés » par rapport aux technologies spécifiques à Internet. Un élément central dans le processus de création de sens par rapport aux technologies spécifiques à Internet et de leurs fonctionnalités est la négociation constante des droits en ligne, tels que la vie privée et la liberté d'expression. Dans ce débat, ainsi que d'autres contestations sur ce qui devrait ou ne devrait pas constituer les libertés sur Internet, cette étude explore comment les partisans de la cryptographie, une communauté spécifique participant au débat sur la gouvernance de l'Internet, a construit un discours dans lequel « la crypto » (logiciel de chiffrement) sert en tant que facilitateur de la liberté. Alors que la « crypto », vise à rendre les données intelligibles, sauf au(x) destinataire(s) souhaité(s), la représentation de la « crypto » est en proie à une lutte discursive plus large qui contribue à définir le sens même de la liberté sur Internet. Ce mémoire traite des partisans de la « crypto », en particulier les Cypherpunks, et comment ils ont articulé un cryptodiscours : une construction de sens partiellement fixé qui établit une relation entre la « crypto » et une conception négative de la liberté sur Internet en relation avec l'État. J'avance que le cryptodiscours exclut d'autres sens positifs de la liberté sur Internet.  Ainsi, le cryptodiscours réduit la responsabilité des États d'assurer les droits et libertés en ligne de leurs citoyens. Afin de déchiffrer le cryptodiscours, j'utilise trois concepts centraux de la théorie du discours de Laclau et Mouffe, à savoir les antagonismes sociaux, les signifiants vides ainsi que les logiques équivalentes et différentielles. Je cartographie les évènements essentiels du discours relatifs à l'articulation de la « crypto » au sein des communautés de discours interdépendantes de cryptographes, de pirates informatiques, de militants des droits de l'Homme en ligne ainsi que de journalistes pendant une période de quarante ans (1975 - 2015). Je présente la trajectoire du cryptodiscours comme composée de trois périodes : l'origine du cryptodiscours (1975 – 1990), la cristallisation (1990 – 2000), et la revitalisation du cryptodiscours (2000 – 2015). J'analyse des artéfacts clés du discours incluant des manifestes politiques produits par les Cypherpunks ainsi que des récits journalistiques produits par des reporters du magazine technologique Wired. En terminant, je soutiens que cette articulation stratégique de « la crypto » est un processus suggestif de construction du mythe. Les implications de cette recherche appellent à un débat plus contextualisé a propos du rôle des gouvernements démocratiques dans le respect des droits de la vie privée et de la liberté d'expression en ligne. Je présente la trajectoire du cryptodiscours comme composée de trois périodes : l'origine du cryptodiscours (1975 – 1990), la cristallisation (1990 – 2000), et la revitalisation du cryptodiscours (2000 – 2015). Pour chaque période, j'analyse des artéfacts clés du discours incluant des manifestes politiques produits par les Cypherpunks ainsi que des récits journalistiques produits par des reporters du magazine technologique Wired. En terminant, je soutiens que cette articulation stratégique de « la crypto » est un processus suggestif de construction du mythe. Les implications de cette recherche appellent à un débat plus contextualisé à propos du rôle des gouvernements démocratiques dans le respect des droits de la vie privée et de la liberté d'expression en ligne.</dc:abstract><ual:supervisor>Roberta Lentz</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/pk02cd510.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/m326m455c</ual:fedora3Handle><dc:subject>Art History and Communications Studies</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A1v53k066q"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of Art History and Communication Studies</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Traces left behind: the materiality of white supremacy in nineteenth century Anglo-Caribbean illustrated travelogues</dcterms:title><ual:dissertant>Millar, Kristen</ual:dissertant><dc:abstract>Nineteenth-century illustrated travelogues on Anglo-Caribbean colonies served as an arm of British colonial visual culture propagating harmful racist stereotypes about black and Indigenous people that continue to exist globally; Antigua, Jamaica and Trinidad are the three specific nations of study in this project. Between 1820-1850 throughout the British Empire, slavery was abolished in 1833 that greatly affected how Anglo-European white men understood their collective identity in the face of ending an oppressive, racist institution that validated a false sense of superiority. The three authors central to this project William Clark (1770-1838), Richard Bridgens (1785-1846) and James M. Phillippo (1798-1879) represent abolitionist and pro-slavery advocates that shared a similar anxiety around the preservation of colonial Anglo white men's collective power. The examination of white men featured in these illustrations produced by white men demonstrates how violence is part of the mechanism in the formation, enactment and maintenance of whiteness as a colonial racial category. This project combines art historical methodology alongside critical race theory, post-colonial feminisms, Caribbean cultural history, sociology, anthropology and political science to unpack the underlying socio-racial connotations in the maintenance of colonial white supremacy. </dc:abstract><dc:abstract>Du XIXe siècle illustré travelogues environ colonies anglo-Caraïbes servi de branche de propagation de la culture visuelle coloniale stéréotypes racistes nocifs britanniques au sujet des Noirs et indigènes qui continuent d'exister dans le monde; Antigua, la Jamaïque et Trinidad sont les trois nations d'études spécifiques à ce projet. Entre 1820-1850 tout l'Empire britannique, l'esclavage a été aboli en 1833 qui a grandement affecté la façon dont les hommes blancs anglo-européenne ont compris leur identité collective face à la fin, une institution raciste oppressive qui valident un faux sentiment de supériorité. Les trois auteurs centraux de ce projet William Clark (1770-1838), Richard Bridgens (1785-1846) et James M. Phillippo (1798-1879) représentent les défenseurs abolitionnistes et pro-esclavagistes qui partagent une même anxiété autour de la préservation de la coloniale anglo puissance collective des hommes blancs. L'examen des hommes blancs présentés dans ces illustrations produites par des hommes blancs explique comment violence fait partie du mécanisme de dans la formation, l'adoption et le maintien de la blancheur comme une catégorie raciale coloniale. Ce projet combine l'art méthodologie historique aux côtés de la théorie critique de la race, féminismes postcoloniales, histoire culturelle des Caraïbes, la sociologie, l'anthropologie et la science politique à déballer les connotations socio-raciales sous-jacentes dans le maintien de la suprématie blanche coloniale.</dc:abstract><ual:supervisor>Charmaine Nelson</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/5999n604k.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/1v53k066q</ual:fedora3Handle><dc:subject>Art History and Communications Studies</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A4x51hm87t"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Atmospheric and Oceanic Sciences</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Evaluating the influence of sea surface temperature on tropical cyclone genesis: observations and simulations</dcterms:title><ual:dissertant>Defforge, Cecile</ual:dissertant><dc:abstract>Les cyclones tropicaux sont parmi les catastrophes naturelles les plus dangereuses, et leur formation est étroitement liée aux conditions environnementales. La température élevée des eaux de surface des océans (SST) est considérée comme l'un des facteurs favorisant la formation de cyclones tropicaux (TC). De nombreuses variables environnementales, dont la température de surface des océans, ont été perturbées par les activités humaines au cours des dernières décennies. Des études récentes ont examiné l'impact de ces changements climatiques sur la formation des cyclones tropicaux. Dans la présente étude, l'analyse bassin-par-bassin des températures de surface, dans les cinq bassins océaniques les plus actifs, montre que les distributions des températures au moment de la formation des cyclones sont proches de distributions gaussiennes et diffèrent d'un bassin à l'autre. Ceci indique donc que la définition à l'échelle globale d'un seuil minimum de température nécessaire à la formation de cyclones, est faussée par les bassins climatologiquement les plus froids. Par ailleurs, la comparaison de la distribution des températures au moment de la formation des cyclones avec la distribution des températures observées pendant la saison cyclonique indique qu'augmenter la température de l'eau favorise la formation des cyclones seulement pour les températures les plus froides observées pendant cette saison, sauf pour le Pacifique Est. Contrairement aux températures de surface, la distribution de la différence de température potentielle équivalente entre la haute et la basse troposphère, qui est une mesure de l'instabilité convective, diffère substantiellement entre la formation des cyclones et la saison cyclonique.Il y a une forte corrélation entre les séries temporelles de la température de surface au moment de la formation des cyclones et celles des températures observées pendant les saisons cycloniques dans les régions principales de formation des cyclones, et les deux montrent un réchauffement significatif au cours des 30 dernières années. Ces séries temporelles sont également similaires à celles obtenues en considérant tous les événements de convection profonde dans les tropiques. Alors que les tendances à long terme des températures observées pendant les événements tropicaux de convection profonde ont été précédemment documentées, les tendances des températures de surface au moment de la formation des cyclones n'avaient pas été examinées jusqu'à présent. Ces tendances à long terme représentent donc un changement anthropogénique de l'activité cyclonique nouvellement détecté. Le réchauffement observé à la surface des océans au moment de la formation des cyclones est principalement dû au réchauffement des océans avec le temps, ce qui est légèrement contrebalancé par l'effet de la migration des trajectoires des cyclones vers des régions climatologiquement plus froides. Enfin, des simulations de conditions climatiques zonalement asymétriques, avec différentes concentrations en CO2, montrent que la fréquence des cyclones tropicaux est particulièrement sensible au déplacement méridional de la zone de convergence intertropicale et, dans une moindre mesure, aux variations des températures de surface de l'océan. Dans les simulations, la réponse à l'échelle locale des variables environnementales (température et précipitation) et de la fréquence des cyclones tropicaux dans la région froide est plus marquée que la réponse dans la région chaude. Ceci entraîne donc une diminution du nombre global de cyclones tropicaux et d'ouragans, par rapport à des conditions climatiques zonalement symétriques.</dc:abstract><dc:abstract>Tropical cyclones are one of the most dangerous natural disasters and their genesis frequency is tightly linked to environmental conditions. Warm sea surface temperature (SST) is thought to be one of the factors favorable to tropical cyclone (TC) genesis. Recent studies have examined the role of anthropogenic changes in sea surface temperature and other environmental variables in determining changes in tropical cyclone genesis. Here, a basin-by-basin analysis of the SST distributions in the five most active ocean basins shows that the distributions of genesis SST are close to normal distributions that differ between basins, indicating that an apparent global threshold arises from the climatologically coldest basins. Furthermore, the resemblance between these distributions and those of SSTs observed during summer indicates that warm SSTs favor TC genesis only over the cold half of the SSTs encountered during summer, except for the East Pacific basin. In contrast to SST, the distribution of the difference between upper- and lower-level equivalent potential temperature, a measure of convective instability, differs substantially between TC genesis and summer seasons. There is a high level of correlation between time series of SST at TC genesis and SST observed over the main development regions and periods, and both feature significant warming trends over the past 30 years. These time series are also similar to those obtained considering all tropical deep convection events. While the long-term trend in SST observed during tropical deep convection events has previously been documented, the trend in SST at tropical cyclogenesis is a newly detected anthropogenic TC change. The warming trend observed for genesis SST is mostly due to the temporal warming of the oceans, which is slightly counterbalanced by the effect of poleward track migration, toward climatologically colder regions.Last, simulations of zonally asymmetric climate states with different CO2 concentrations show that TC frequency is mostly sensitive to the meridional shift of the inter-tropical convergence zone and, to a smaller extent, to SST changes. The local response of environmental variables (SST and precipitation rate) and of the TC frequency in the simulated cold region is stronger than in the warm region, resulting in a global decrease in the number of TCs and hurricanes, relative to symmetric climate states.</dc:abstract><ual:supervisor>Timothy Merlis</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/j098zd83n.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/4x51hm87t</ual:fedora3Handle><dc:subject>Atmospheric and Oceanic Sciences</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Apk02cd528"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Institute of Islamic Studies</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Gender and the political novel in Egypt through two works by Salwa Bakr &amp; Sonallah Ibrahim</dcterms:title><ual:dissertant>Mohamed, Ahmed</ual:dissertant><dc:abstract>This thesis is a critical analysis of two major works of Arab prison literature in the last quarter of the 20th Century, The Golden Chariot by Salwa Bakr and Sharaf by Sonallah Ibrahim. Through an analysis of each author's style and use of symbolism, the approach taken by Arab commentators that women's writing is fundamentally different from that of men is challenged. The value of such works is not determined by gender, but rather is an expression of the personal experiences of each author. Ibrahim, through his long period in an Egyptian prison, sees the country around him as trapped by corruption and imperialism. Bakr, while addressing these same concepts, focuses on the role of women and calls for the re-evaluation of traditions that have for so long relegated women to a secondary place in Egyptian society. Each of these works has had a profound impact on Egyptian literature, not only through their attention to the continuing problem of abuse in Egyptian prisons, but in calling for an end to the daily injustice faced by regular Egyptians, male and female, at the hands of both imperial powers and their local agents.  </dc:abstract><dc:abstract>Ce mémoire présente une analyse critique de deux œuvres majeures de la littérature carcérale arabe du dernier quart du 20ème siècle, The Golden Chariot, de Salwa Bakr et Sharaf, de Sonallah Ibrahim. Au moyen d'une analyse du style de chaque auteur et de l'usage du symbolisme, l'approche adpotée par les commentateurs arabes selon lequel l'écriture féminine serait fondamentalement différente de celle masculine se voit contesté. La valeur de ce type d'œuvres n'est pas déterminée par le genre, mais se veut plutôt une expression de l'expérience personnelle de chaque auteur. Ibrahim, au cours de son long séjour dans une prison égyptienne, perçoit le pays autour de lui comme piégé dans la corruption et l'impérialisme. Bakr, en abordant les mêmes concepts, se concentre sur le rôle des femmes et appelle à une réévaluation des traditions qui ont, pendant si longtemps, relégué les femmes à une place subalterne au sein de la société égyptienne. Chacune de ces œuvres a eu un impact profond sur la littérature égyptienne, non seulement de par l'attention portée au problème constant des mauvais traitements dans les prisons égyptiennes, mais aussi de par l'appel lancé à mettre fin à l'injustice quotidienne à laquelle font face tous les Égyptiens, hommes et femmes, que ce soit entre les mains des pouvoirs impérialistes ou de leurs agents locaux.</dc:abstract><ual:supervisor>Michelle Laura Hartman</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/tb09j8073.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/pk02cd528</ual:fedora3Handle><dc:subject>Islamic Studies</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Arb68xf375"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of Political Science</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Following the leader? The impact of federal party leaders on federal elections in Quebec</dcterms:title><ual:dissertant>Trotter, David</ual:dissertant><dc:abstract>The 2011 Canadian Federal Election provided one of the most significant shocks to the Canadian political system, which was the rise of the New Democratic Party in the province of Québec. During this election, NDP party leader Jack Layton showed his connection to Québec throughout the campaign, with his federal political party counterparts showing little to no understanding of Québec. Did this connection give Layton's NDP the advantage?This thesis seeks to understand the impact of political party leaders on vote choice in Québec, primarily through looking at a party leader's geographical, cultural and language connection to Québec. To see if these characteristics of party leaders do have an impact, this thesis created a single variable, called the Québec Score, to see if, holistically, they can contribute to explaining vote choice in Québec. Using aggregate-level data (electoral results at the riding level) for each major political party between 1968 and 2105, this thesis will compare each political party leader's Québec Score to the results in each riding, with controls for incumbent party and personal MP incumbency effects. The results of the thesis shows that there is a connection between these geographical, cultural, and language factors in relation to how successful a political party performs in Québec.</dc:abstract><dc:abstract>L'élection fédérale canadienne de 2011 a fourni l'un des chocs récents les plus importants au système politique canadien, qui fut la montée du Nouveau parti démocratique dans la province de Québec. Au cours de cette élection, le chef du parti néo-démocrate Jack Layton a fait montre de sa connexion au Québec tout au long de la campagne, tandis que ses homologues fédéraux des autres partis politiques ont démontré peu ou pas de compréhension du Québec. Cela a-t-il donné à Jack Layton un avantage? Cette thèse vise à comprendre l'impact des dirigeants de partis politiques sur le choix de vote au Québec, en s'attardant principalement à la connexion géographique, culturelle et linguistique d'un chef de parti avec le Québec. Pour voir si ces caractéristiques des chefs de parti ont un impact sur les résultats électoraux, cette thèse propose de créer une variable unique, appelée « score Québec », afin d'examiner si, globalement, elles peuvent contribuer à expliquer les choix électoraux au Québec. En utilisant des données agrégées (résultats électoraux agrégés au niveau de la circonscription) pour chaque parti politique fédéral majeur entre 1968 et 2015, cette thèse met en lien le score Québec de chaque chef de parti politique aux résultats obtenus par leur parti dans chaque circonscription, en contrôlant pour les effets associés aux phénomènes de parti sortant et de candidat sortant. Les résultats de la thèse indiquent qu'il existe un lien entre ces facteurs géographiques, culturels et linguistiques d'un côté et la réussite électorale au Québec d'un parti politique fédéral.</dc:abstract><ual:supervisor>Eric Belanger</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/rf55zb44t.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/rb68xf375</ual:fedora3Handle><dc:subject>Political Science</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A4x51hm883"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Bioresource Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Modified atmosphere storage of ginger rhizome using silicone-based membrane system under ambient temperature conditions</dcterms:title><ual:dissertant>Kamat, Priyanka</ual:dissertant><dc:abstract>Assurer la sécurité alimentaire partout dans le monde est un défi important pour les scientifiques et les décideurs politiques. Dans plusieurs régions, la production et l'approvisionnement de nourriture de qualité sont difficiles, tandis que dans d'autres, les pertes d'aliment sont importantes dus à l'absence de conditionnement post-récolte et au manque de planification pour le stockage des produits fraîchement récoltés. L'entreposage sous atmosphère modifiée est une technique qui permet d'accroître la durée de conservation des fruits et des légumes frais. Cette technique permet de contrôler la température, l'humidité relative (HR), et la concentration de gaz afin de créer les conditions optimales pour la conservation des produits frais. Il est essentiel d'effectuer des études pour définir les conditions optimales d'entreposage puisque ces dernières varient en fonction de la nature du produit. De plus, des études sont nécessaires pour développer de nouvelles technologies qui permettent d'obtenir et de maintenir les conditions requises. Cette étude porte sur le développement d'un système utilisant des membranes à base de silicone pour contrôles la composition des gaz pour l'entreposage des rhizomes de gingembre frais sous atmosphère modifiée. Dans un premier temps, cinq différents modèles de membranes disponibles commercialement (identifiées comme GA, GB, GC, MSM et CSM) ont été caractérisées afin d'identifier celles qui seraient le mieux adaptées pour la conservation sous atmosphère modifiée. Les caractéristiques mesurées étaient les propriétés physiques et mécaniques, les perméabilités aux gaz et le rapport de sélectivité dioxyde de carbone : oxygène. Les résultats ont indiqué que les membranes GC, MSM et CSM avaient les propriétés requises pour être utilisées dans les systèmes à atmosphère modifiée. Dans un deuxième temps, l'étude a porté sur des essais de conservation sous atmosphère modifiée de rhizomes de gingembre en utilisant les membranes sélectionnées. La méthodologie de surface de réponses à deux facteurs a été utilisée pour comparer les essais. Les facteurs étudiés étaient la concentration visée en oxygène et la durée d'entreposage, et les critères de qualité mesurés étaient la fermeté, la couleur, la perte de poids et la teneur totale phénolique des rhizomes de gingembre. Il est généralement reconnu qu'une diminution de la concentration en oxygène accompagnée d'une augmentation de la concentration dioxyde de carbone permet de ralentir l'activité métabolique entrainant une augmentation de la durée de l'entreposage. Les résultats ont indiqué que l'oxygène dans la chambre à atmosphère modifiée et l'intensité respiration des rhizomes diminuaient jusqu'au septième jour et après quoi il est demeuré relativement stable jusqu'au 21e jour de stockage. Lors des essais, les conditions maintenues ont permis de maintenir la fermeté du gingembre tout en minimisant les pertes de poids. Quoi qu'il n'y eût pas de différences significatives dans la teneur en composés phénoliques totaux entre les différentes membranes utilisées, les taux avaient diminué durant l'entreposage. Des différences significatives de la couleur de la pelure ont été observés entre les différentes membranes utilisées. Les membranes MSM et GC ont données des résultats similaires. Malheureusement, à la fin des essais, les rhizomes de gingembre entreposés sous atmosphère modifiée n'étaient plus commercialisables puisqu'ils avaient tous commencer à bourgeonner. Des études supplémentaires sont requises pour optimiser le système utilisant les membranes de silicone pour la conservation des rhizomes de gingembre frais. </dc:abstract><dc:abstract>Providing food security to people all over the world has become an important challenge for the scientists and the policy makers alike. In many areas of the world, the production and supply of food to the population is challenging, while the other areas face issues like food wastage due to the lack of proper conditions and planning for postharvest storage. The modified atmosphere storage is a technique for the storage of fresh fruits and vegetables, for a longer period of time under ideal storage conditions. In such systems, the external parameters like temperature, pressure, relative humidity (RH), and the atmospheric gas concentrations are manipulated and modified to create optimum storage conditions. The optimum conditions for storage vary depending on the product stored, hence studying the storage of various types of produce is absolutely essential. Membrane-based storage systems are a type of modified atmosphere storage system, involving the use of silicone-based membranes.This study investigates use of membrane system for improving the storage life of ginger rhizome. The first part of this thesis describes the characterisation and selection of membrane for use in storage. This comprises studying the physical and mechanical parameters of the silicone-based membranes including three commercially available membranes (GA, GB and GC) and two reference membranes (MSM and CSM). The permeability of the membrane and its selectivity ratio for the carbon dioxide gas remain as the main requirement for selection of membrane for food storage. Based on the preliminary studies, the MSM, CSM, and GC membranes were selected for investigating their application in ginger storage. The second phase of the study included ginger storage in the membrane-based system for prolonging the storage life while maintaining the visual appearance of the ginger to a desired level. The response surface methodology with two factors viz. duration of storage and membrane area was used to find the proper storage conditions for ginger. The investigated duration of storage ranged between 7 to 21 days with membranes of different surface areas providing an interface between the ambient air and the air in the storage container. Parameters like firmness, color difference, percent mass change, and total phenolic content of the ginger were measured before and after its storage. The change in oxygen concentration in the storage chamber and the respiration rate were decreased till the 7th day of storage and after which it remained steady until the 21st day of storage. Low oxygen concentration and high carbon dioxide concentration are desired in the modified atmosphere storage systems to slow down the metabolic activities and respiration rate. The results were similar when the GC and the MSM membranes were used for the storage of ginger. During the trials, the storage conditions have helped maintain the firmness of ginger roots while minimizing mass loss. Although no significant differences in the final content of total phenolic compounds were observed between the different membranes used, the contents decreased during storage. Significant differences in skin color were observed between the different membranes used. MSM and GC membranes had similar results. Unfortunately, at the end of the storage trials, ginger rhizomes stored under modified atmospheres were no longer marketable since they all started to bud. Further studies are required to optimize the silicone membrane system and storage conditions for the long term conservation of fresh ginger rhizomes.</dc:abstract><ual:supervisor>G. S. Vijaya Raghavan</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/x346d694z.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/4x51hm883</ual:fedora3Handle><dc:subject>Bioresource Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Aj098zd84x"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Mechanical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Parametric identification of geometric non-linearities of mechanical systems</dcterms:title><ual:dissertant>Delannoy, Joachim</ual:dissertant><dc:abstract>Le contrôle des vibrations est un problème classique en ingénierie. En effet, il est important de maîtriser les vibrations des structures mécaniques, qu'elles soient causées par une excitation externe ou par le fonctionnement interne du système, afin d'éviter d'éventuels dommages. Pour prévoir la réponse vibratoire, il est nécessaire d'identifier différentes caractéristiques de la structure considérée. Parmi celles-ci, le coefficient d'amortissement est l'un des paramètres structurels les plus importants puisqu'il a un effet direct sur l'amplitude maximum des vibrations lorsque le système entre en résonnance.Actuellement, le coefficient d'amortissement est identifié en régime linéaire (par l'étude de la réponse fréquentielle obtenue pour une très faible excitation). Cependant, il a été découvert récemment que le coefficient d'amortissement est susceptible d'augmenter avec la force d'excitation appliquée au système. Pour mieux comprendre ce phénomène, il est nécessaire d'obtenir le coefficient d'amortissement directement à partir des courbes obtenues pour de larges excitations et par conséquent de prendre en compte certains effets non-linéaires. L'objectif de cette étude est de construire un outil numérique fiable et rapide pour identifier les caractéristiques vibratoires d'un système quelconque à partir de courbes de réponse fréquentielle obtenues à différents niveaux d'excitation. Dans un premier temps, deux outils ont été développés pour identifier les caractéristiques de systèmes spécifiques (respectivement de plaques minces et de coquilles cylindriques) présentant des non-linéarités géométriques et un amortissement visqueux. Dans un deuxième temps, un outil plus général a été développé afin d'identifier des systèmes sans étude analytique préalable. Les procédures d'identification se basent sur une décomposition en série de Fourier du déplacement pour fonctionner avec les données expérimentales disponibles et sur une méthode des moindres carrés pour obtenir une valeur optimale des paramètres qui caractérisent le système.</dc:abstract><dc:abstract>A significant issue in mechanical design is excessive vibration which can lead to consequent damages within mechanical systems. To predict the vibration response, it is necessary to find several characteristics of the considered structures. Among them, the damping is particularly important to identify since it has a major effect on the peak amplitude vibration (maximum amplitude reached under a given excitation).Currently, the damping is identified through linear measurements (performed at a small excitation level). However, it was found recently that the damping coefficient may increase with the excitation force. To understand this phenomenon, it is necessary to extract the damping directly from large amplitude vibration. The object of this thesis is to build a reliable tool with a fast processing time to identify the vibration characteristics of non-linear mechanical systems from experimental response curves obtained at different excitation levels.  To do so, a numerical method was built to identify the parameters affecting the vibrations of non-linear mechanical systems. In a first attempt, two different tools are developed for plates and shells, with a stress-strain relation accounting for geometrical non-linearities and viscous damping. In a second attempt, a more general tool was developed to account for a larger variety of systems. The identification process relies on a harmonic decomposition of the displacement to cope with the available experimental data.</dc:abstract><ual:supervisor>Marco Amabili</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/k643b367j.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/j098zd84x</ual:fedora3Handle><dc:subject>Mechanical Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Am900nx224"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of History and Classical Studies</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Gaza as "The Theory of Everything" of the Ottoman universe: understanding contact and conflict in the Mediterranean</dcterms:title><ual:dissertant>Çevik, Deniz</ual:dissertant><dc:abstract>This study is an attempt to evaluate how encounters between Muslims and non-Muslims in the early modern Mediterranean were represented by the Ottomans. It compares the representations from two periods, medieval Anatolia and early modern Mediterranean, to discover the transitivity of manners of narrating encounters from a region to another, and from a time period to another. The main objective is to discuss the importance of "gaza" concept, which literally means "holy war" and of one of the most heated topic among Ottomanists, as the dominant way of narrating the encounters among Muslims in two periods. Through a comparative reading of two texts that reflect this concept, a prose biography of a Muslim corsair from the sixteenth century and a warrior epic from the thirteenth century, it offers a two-layered analysis of the subject. In the first layer, the resemblances between socio-political structures of medieval Anatolia and that of early modern Mediterrenean that allowed "gaza" to migrate from one to another will be evaluated. In the second layer, it shows the discursive similarities that prove the transitivity of "gaza" as a narrative tool from one textual world to another. </dc:abstract><dc:abstract>Ce mémoire a pour but d'analyser les réprésentations ottomanes des rencontres entre les musulmans et les chretiens dans la Méditerrannée durant l'époque moderne. Une comparaison entre des réprésentations écrites au Moyen Âge et à l'époque moderne sera effectuée afin de découvrir comment les discours sur les rencontres interconfessionnelles se sont transférés d'une région à une autre ainsi que d'une époque à une autre. Une attention particulière sera portée sur le concept de gaza (guerre sainte) qui était au fondement de ce discours. Ce dernier, est entre autre véhiculé par deux manuscrits qui seront analysés ici : une biographie d'un corsaire musulman très connu écrite au 16e siècle et une épique de guerre écrite au 13e siecle. L'analyse comportera deux niveaux. D'abord, des ressemblances entre les organisations sociopolitiques anatoliennes et méditéranéennes durant le Moyen Âge et l'époque moderne seront étayées. Ensuite, des similarités seront présentées venant ainsi prouver le transfert du concept de gaza en tant qu'outil discursif entre des mondes différents. </dc:abstract><ual:supervisor>Giancarlo Casale</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/mk61rk82b.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/m900nx224</ual:fedora3Handle><dc:subject>History and Classical Studies</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A47429c99s"><ual:graduationDate>2016</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Multi-armed bandits for MPSoC design space exploration</dcterms:title><ual:dissertant>Ma, Calvin</ual:dissertant><dc:abstract>La fiabilité des circuit intégrés devient un problème prédominant avec la miniaturisation des appareils électroniques.  Les technologies de procédés plus petites causent des densités de puissance accrues, entraînant des températures plus élevées et une usure d'appareil plus précoce.  Un façon de prévenir les défaillances consiste à sur approvisionner les ressources et de réorganiser les tâches des composantes défectueux ayant des capacités non utilisées ou résiduelles.  Étant donné que l'espace résiduel d'allocation conçu est grand, trouver la solution optimale est difficile car les approches force brute sont peu pratiques.  Les durées de vie des appareils sont typiquement évaluées à l'aide de la Simulation Monte-Carlo (MCS) en échantillonnant chaque modèle également; cette méthode est inefficace puisque des modèles mal conçus sont évalués avec précision en tant que modèles bien conçus.  Une meilleure méthode consacrera le temps d'échantillonnage sur les modèles qui sont difficiles à différencier; ceci peut être accompli à l'aide d'algorithmes Multi-Armed Bandit (MAB).  Ce travail démontre que l'algorithme MAB atteint une précision similaire à la simulation MCS en utilisant 1.45-5.26 fois moins d'échantillons pour les distributions.  Le MAB est aussi utilisé comme un algorithme de sélection dans un algorithme génétique  (GA).  Dans le meilleur cas de référence, un modèle avec une durée de vie plus longue de 0,01 ans peut être trouvé par le MAB au lieu du MCS.  L'algorithme GA est également appliqué pour résoudre le problème à objectif multiple d'optimisation de coût et vie. Il a été établi que l'algorithme MAB n'offre pas d'avantage évident.  L'importance pratique de l'utilisation de l'algorithme GA en utilisant le MAB est limitée.</dc:abstract><dc:abstract>Reliability in integrated circuits is becoming a prominent issue with the miniaturization of electronics. Smaller process technologies have led to higher power densities, resulting in higher temperatures and earlier device wear-out. One way to mitigate failure is by over-provisioning resources and remapping tasks from failed components to components with spare capacity, or slack. Since the slack allocation design space is large, finding the optimal is difficult as brute-force approaches are impractical. Device lifetimes are typically evaluated using Monte-Carlo Simulation (MCS) by sampling each design equally; this method is inefficient since poor designs are evaluated as accurately as good designs. A better method will focus sampling time on the designs that are difficult to distinguish; this can be accomplished using Multi-armed Bandit (MAB) Algorithms. This work demonstrates that MAB achieves the same level of accuracy as MCS in  1.45x-5.26x  fewer samples for lifetime distributions. MAB is applied as a selection algorithm in a genetic algorithm (GA). In the best case benchmark, a design with a higher lifetime of 0.01 years is found using MAB over MCS. The GA is extended to solve the multi-objective cost-lifetime problem; it was found that MAB does not offer a clear advantage. The practical significance of GA using MAB are limited. </dc:abstract><ual:supervisor>Mahajan, Aditya</ual:supervisor><ual:supervisor>Meyer, Brett</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/ns064857j.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/47429c99s</ual:fedora3Handle><dc:subject>Electrical and Computer Engineering</dc:subject></rdf:Description></rdf:RDF>