<?xml version="1.0" encoding="UTF-8"?><rdf:RDF xmlns:oai="http://www.openarchives.org/OAI/2.0/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:ual="http://terms.library.ualberta.ca/" xmlns:bibo="http://purl.org/ontology/bibo/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:schema="https://schema.org/" xmlns:etdms="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A2514np76t"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Testing the two-stream hypothesis in an immersive virtual environment</dcterms:title><ual:dissertant>Parasuraman Viswanat, Rajkumar</ual:dissertant><dc:abstract>Une grande partie de la recherche comportementale consiste d'une distinction proposée entre deux flux distincts pour le traitement visuel, la vision pour l'action et la vision pour la perception. La recherche sur les illusions perceptives et géométriques a parcouru un long chemin vers la détermination de cette proposition de la dissociation du traitement visuel. Ces illusions trompent le cerveau à mal juger les tailles des objets, tout sans empêchant les doigts de mettre à l'échelle les tailles correctes alors qu'ils saisissant ces objets. Cet effet persiste mêmequand les stimuli sont en trois dimensions. Les mécanismes qui facilitent le contrôle visuel des actions sur objects sont soupçonnés de fonctionner en coordonnées égocentriques. Nous aimerions donc savoir si cet effet persiste quand en essait d'attendre l'illusion en utilisant bras virtuel, où si il existe un couplage entre le visuel et la rétroaction proprioceptive, un processus essentiel pour la superimposition de la scène visuelle externe sur les coordonnées égocentriques. Notre recherche montre que, bien que l'effet de deux flux est maintenu dans un monde réel, il est perdu dans un monde virtuel où la rétroaction haptique est absente. Il est également observé que les participants sous-estimer la profondeur, à moins qu'une rétroaction externe est donné, dans notre cas, un changement de couleur dans le bras virtuel dans un environnement virtuel avec une grille de profondeurs.</dc:abstract><dc:abstract>A great deal of behavioural research has gone into a proposed distinction between two separate streams for visual processing, vision for action and vision for perception. Research on perceptual and geometric illusions has gone a long way in determining this proposed dissociation in visual processing. These illusions fool the brain into misjudging object sizes but at the same time do not affect fingers from scaling to the correct size while grabbing. This effect is maintained even when the stimuli are three-dimensional. The mechanisms mediating the visual control of object-oriented actions are thought to operate in egocentric coordinates. We would therefore like to know whether this effect is maintained when reaching for the illusion with a virtual arm, where there is an indirect pairing of visual and proprioceptive feedback, a process essential for pairing the external visual scene onto egocentric coordinates. Our research shows that while the two stream effect is maintained in a real world, it is lost out in a virtual world where there is a lack of haptic feedback. It is also seen that participants underestimate depth unless given an external feedback, in our case, a change of colour in the virtual arm within a virtual environment with a depth grid.</dc:abstract><ual:supervisor>Jeremy Cooperstock</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/sj139552r.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/2514np76t</ual:fedora3Handle><dc:subject>Engineering - Electronics and Electrical</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Afj236576k"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Mechanical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Optimization of steel production: ladle furnace slag and caster productivity</dcterms:title><ual:dissertant>Bathy Vodeyar Math, Kailash</ual:dissertant><dc:abstract>Un modèle d'optimisation de laitier est le premier objectif de cette thèse. L'importance de laitier dans la qualité et la rentabilité de l'acier a été très bien comprise par l'industrie sidérurgique. En effet, la phase de laitier est devenue une partie essentielle du processus de production d'acier. La composition et les propriétés du laitier jouent un rôle important dans la protection des réfractaires de four. La recherche s'est portée sur le développement d'un modèle de laitier afin d'avoir le laitier optimal, saturé en MgO, pour allonger la vie de réfractaire. Un modèle informatique a été développé pour calculer la quantité de MgO minimale requise lors du processus de l'affinage en poche. L'effet de la désulfuration sur la basicité optique et l'exigence de MgO est discuté. Les données de l'usine Arcelormittal Contrecoeur-Ouest ont été utilisées pour comparer les résultats générés par le modèle pour l'utilisation de MgO et CaO. L'application du modèle de laitier dans l'installation de métallurgie en poche peut augmenter la durée de vie du réfractaire et peut réduire la quantité d'additifs utilisée pour générer suffisamment de MgO et de CaO.Le deuxième objectif de la thèse est d'augmenter le débit de coulée d'une machine de coulée continue afin d'améliorer la capacité de production de l'usine. Une étude expérimentale du flux de chaleur lors de la production de billettes d'acier a été entreprise. Cette recherche a mesuré la vitesse de refroidissement de l'acier en fusion dans l'installation de coulée par la mesure systématique de la température de l'acier à travers un pyromètre sur plusieurs points pendant le processus de coulée. Un modèle de simulation à 2D de transfert de chaleur à l'état d'équilibre thermique a été développé pour produire des données sur la répartition de la température de phase à des vitesses de coulée différentes. Les données de modèle concernant la température de surface de la billette a été comparée à la température de surface mesurée. La comparaison entre les températures de surface mesurées et calculées était raisonnable et les deux ensembles de données ont été à l'intérieur de ± 30-40 ° C. Les données modèles peuvent être utilisées pour prédire la vitesse de coulée optimale en fonction de la position de fermeture du puits et sa température de surface correspondante. Ce paramètre prédit peut être suivi en utilisant des capteurs et la vitesse de coulée peut être contrôlée par un système de rétroaction.</dc:abstract><dc:abstract>A slag optimization model is the first objective of this thesis. The importance of slag has been very well understood by the steelmaking industry to produce cost effective, quality steel, where the slag phase has become an essential part of steel making process. The composition and properties of slag play an important role in protecting furnace refractories.  The research focused on the development of a slag model to have optimum slag saturated with MgO for better refractory life. A computer model was developed to calculate minimum MgO required during the ladle refining process. The effect of the desulfurization process on optical basicity and MgO requirement is discussed. The plant data at Arcelormittal Contrecoeur West were used to compare the results generated by the model for usage of MgO and CaO. The application of the slag model at the ladle metallurgical facility can increase the life of the refractory and can result in reduced usage of additives to generate sufficient MgO and CaO. The second objective of the thesis is to increase the casting throughput of a continuous caster to improve the factory throughput. An experimental investigation of heat flow during the production of steel billets was undertaken. This research measured the cooling rate of the molten steel at the casting facility by systematic measurement of the steel temperature at several points during the casting process by the use of a pyrometer. A 2D steady state heat transfer simulation model was developed to produce data on temperature and phase distributions for different casting rates. The model data for billet surface temperatures were compared to measured surface temperatures. The comparison between measured and calculated surface temperatures was reasonable and the two sets of data were within ± 30-40 °C. The model data can be used to predict optimum casting speed based on the liquid well closure position and its corresponding surface temperature. This predicted parameter can be monitored by using sensors, and the casting rate can be controlled through a feedback system.</dc:abstract><ual:supervisor>Vincent Thomson</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/9c67wr230.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/fj236576k</ual:fedora3Handle><dc:subject>Engineering - Mechanical</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Axk81jq162"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Civil Engineering and Applied Mechanics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Multisite statistical downscaling of daily temperature extremes for climate-related impact assessment studies</dcterms:title><ual:dissertant>Kim, Ju Eun</ual:dissertant><dc:abstract>Global climate change has been considered in many engineering studies due to its drastic impacts on the design and planning of various infrastructures. In order to reduce the risks of those impacts, the present study focuses on accurate prediction of daily temperature extremes for future periods under different climate change scenarios. The main objectives of this study are therefore: (a) to detect the evidences of climate change from the statistical analysis of existing observed daily extreme temperature data; (b) to assess the performance of single-site and multi-site statistical downscaling (SD) approaches in order to identify the best SD model that could describe accurately the linkage between global scale climate variables and the observed statistical properties of daily temperature extremes at a given local site; and (c) to provide a prediction of daily temperature extremes for future periods based on the best SD model identified under different climate change scenarios.  Firstly, a detailed statistical analysis of daily extreme temperature data available during the 1973-2009 period from a network of 25 weather stations located in South Korea was carried out to identify the possible trends in 18 different temperature characteristics. Results of this data analysis have indicated significant changes in the characteristics of daily maximum temperature (Tmax) and daily minimum temperature (Tmin) during this period. In particular, the positive trends in annual means of Tmax and Tmin were found statistically significant. In addition, the number of cold events tends to decrease while the number of warm events tends to increase at most of the stations considered. Secondly, statistical downscaling methods were used to describe the linkage between the coarse resolution of General Circulation Model (GCM) climate variables and the daily extreme temperature characteristics at a local site for impact assessments. Most previous studies have been dealing with downscaling of daily temperature extremes at a single site. However, more recent studies have been conducted to develop improved downscaling methods for many sites concurrently. This study was carried out to assess the performance of the multi-site SD method based on the Singular Value Decomposition (SVD) method as compared with the performance of the popular SDSM for single-site downscaling. The application of the multi-site and single-site SD methods was performed using the observed daily Tmax and Tmin data from the 25 stations in South Korea and the corresponding NCEP re-analysis data for the 1973-2001 period. It was found that the multi-site SD method and the single-site SDSM could accurately reproduce basic properties of Tmax and Tmin at each local site. However, the multi-site SD method could describe more accurately the temporal and spatial correlations of daily temperature extremes than the SDSM. Overall, the multi-site SD method was found to be more accurate than the SDSM. Finally, future prediction of daily extreme temperatures was accomplished based on the multi-site SD method under the A1B and A2 climate scenarios provided by the third version of the Canadian Global Climate Model (CGCM3). The increasing trends were found in the  monthly means of Tmax and Tmin, the monthly90th percentiles of Tmax, and the monthly10th percentiles of Tmin for the future 2010-2100 period over South Korea. </dc:abstract><dc:abstract>Le changement climatique global a été introduit dans les études d'ingénierie en raison de ses impacts importants sur la conception et la planification des infrastructures. Afin de réduire ces impacts, la présente étude se concentre sur la possibilité d'obtenir des prévisions précises des températures extrêmes pour les périodes futures sous divers scénarios de changement climatique. Les objectifs principaux de cette étude sont alors (a) de détecter les éléments reliés au changement climatique à partir de l'analyse statistique des données disponible de températures extrêmes journalières; (b) d'évaluer la performance des techniques de mise en échelle statistique (SD : Statistical Downscaling) en un site et en plusieurs sites pour identifier le meilleur modèle SD qui est capable décrire correctement le lien entre les variables climatiques globales et les propriétés statistiques observées des températures extrêmes journalières en un site choisi; et (c) de fournir une prévision des températures extrêmes pour le futur en se basant sur le meilleur modèle SD identifié pour divers scénarios de changement climatique. Premièrement, une analyse statistique détaillée des données de températures extrêmes journalières disponibles pour la période de 1973-2009 d'un réseau de 25 stations météorologiques situé en la Corée du Sud a été effectuée pour identifier les tendances possibles dans les 18 propriétés de température. Les résultats de cette analyse des données ont indiqué des changements significatifs sur les caractéristiques de température maximale journalière (Tmax) et de température minimale journalière (Tmin) pendant cette période. En particulier, des tendances positives statistiquement significatives dans les moyennes annuelles de Tmax et Tmin ont été identifiées. De plus, le nombre d'événements froids a eu une tendance de diminution tandis que le nombre d'événements chauds a eu une tendance d'augmentation pour la plupart de stations considérées. Deuxièmement, les méthodes SD ont été utilisées pour établir le lien entre la résolution grossière des variables climatiques du modèle de circulation générale (MCG) et les propriétés de températures extrêmes journalières en un site pour les évaluations d'impact. La plupart des études antérieures ont été effectuées sur la mise en échelle des températures extrêmes journalières en un seul site. Cependant, des études plus récentes ont été réalisées pour élaborer des méthodes de mise en échelle en plusieurs sites simultanément. Cette étude a été effectuée pour évaluer la performance de la méthode SD en multi-sites basée sur la technique de décomposition en valeurs singulières (SVD) en comparant avec celle de la méthode de mise en échelle statistique populaire SDSM en un site. L'application de ces deux méthodes a été réalisée en utilisant les données observées de températures extrêmes journalières Tmax et Tmin de 25 stations météorologiques en Corée du Sud et les données de NCEP correspondantes pour la période de 1973 à 2001. On a trouvé que les méthodes de mise en échelle multi-sites et en un site SDSM sont capables de reproduire correctement les caractéristiques statistiques de base de Tmax et Tmin en chaque site. Toutefois, l'approche multi-site peut reproduire d'une façon plus précise les corrélations temporelle et spatiale que la méthode SDSM. En général, l'approche multi-site peut fournir des estimations plus précises des caractéristiques Tmax et Tmin que celles données par la méthode SDSM. Enfin, la prévision des températures extrêmes quotidiennes est faite en appliquant l'approche multi-sites SD pour les scénarios de changement climatique A1B et A2 fournis par le modèle climatique global canadien (MCCG3). Les résultats de cette prévision ont indiqué une tendance croissante dans les valeurs moyennes mensuelles de Tmax et Tmin, la 90e percentile de Tmax et la 10e percentile de Tmin pour la période de 2010 à 2100 à travers de la Corée du Sud.   </dc:abstract><ual:supervisor>Van-Thanh-Van Nguyen</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/ws859k134.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/xk81jq162</ual:fedora3Handle><dc:subject>Engineering - Civil</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A2514np773"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Chemistry</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Contactless liquid flow control for miniaturised analytical techniques on continually rotating centrifugal microfluidic platforms</dcterms:title><ual:dissertant>Kong, Cher Rong Matthew</ual:dissertant><dc:abstract>In an industrial society it is critical that techniques be developed for the measurement of chemical species in the environment, in humans and as both intended and unintended products of manufacturing. Initially, these techniques were developed around sophisticated instruments and often involved complex procedures. It is obviously advantageous if the cost of analyses can be reduced and the experimental procedures simplified, while still maintaining the quality of the data collected. Furthermore, it is often desirable to have measurements performed rapidly, with on-site measurement sometimes deemed useful or even essential. All of these desirable outcomes may, in some cases, be obtained by miniaturisation. The interest in miniaturisation has led to rapid growth of the field of microfluidics, an area of study which involves using small volumes of liquids, often with detection systems specifically tailored to these reduced volumes. Microfluidic systems must have some way of moving liquids through various stages of chemical or physical processes. One particularly interesting pumping method involves the use of centrifugal force, which eliminates the need for pumps and minimises connections to the platform on which the analysis is done. Up to this point, centrifugal systems have generally been constrained to a limited number of sequential analytical steps as liquid could only flow in the direction demanded by the applied centrifugal force.In this thesis, a variety of liquid manipulation techniques on centrifugal microfluidic platforms were developed and characterised. These techniques were used to miniaturise standard classical analytical methods and implement them on centrifugal microfluidic platforms with the goal of monitoring environmentally important compounds such as aqueous sulfide. A two-phase liquid displacement pumping technique and a pneumatic-centrifugal pumping technique are demonstrated and presented. The developed pneumatic-centrifugal system was used to significantly increase the toolbox of capabilities for centrifugal microfluidic platforms, simultaneously enabling critical microfluidic operations such as valveless liquid transfer, metering, liquid flow switching, agitative micromixing, and liquid recirculation. This technique is based on contactless implementation of pneumatic pressure using compressed air on a continually rotating centrifugal microfluidic platform, thereby enabling complete liquid flow control by combining the effects of pneumatic pressure and centrifugal force.This new type of pneumatically enhanced centrifugal microfluidic platform greatly simplifies the fabrication process by minimising valving requirements, as well as improving efficiency by performing analyses in a highly automated manner. The pneumatic approach was applied to an on-disk calibration and spectrophotometric measurement using the method of standard additions. Similarly, another pneumatically enhanced platform was developed for performing liquid-liquid extractions between an aqueous phase and an organic phase, demonstrating that these centrifugal platforms are not only capable of performing complex multi-step reactions, but also multi-cycle reactions and processes. Finally, an application-specific pneumatically enhanced centrifugal platform was developed for the spectrophotometric determination of aqueous hydrogen sulfide.All of the developed analytical methods only required small sample and reagent volumes, are highly automated and convenient, and have the potential to be performed in a field environment without the need for highly trained personnel.</dc:abstract><dc:abstract>Dans notre société industrielle, la conception de techniques pour la quantification  d'espèces chimiques dans l'environnement, les humains et les dérivés de la production manufacturière est primordiale. Au départ, ces techniques avaient été élaborées à partir d'instruments sophistiqués et se basaient sur des procédures complexes. Il serait donc avantageux de pouvoir réduire les coûts d'analyse et simplifier les procédures expérimentales, tout en maintenant un niveau élevé de la qualité des données recueillies. De plus, il est souvent souhaitable de pouvoir effectuer ces mesures rapidement, et si possible sur le site où l'échantillon à analyser est recueilli. Toutes ces caractéristiques bénéfiques des méthodes analytiques peuvent être obtenues, dans certains cas, à travers la miniaturisation. L'intérêt pour la miniaturisation a mené à une croissance rapide des systèmes microfluidiques, un domaine d'études qui se concentre sur l'utilisation de petits volumes de liquide et des systèmes de détection spécialement adaptés à ces volumes réduits. Tout système microfluidique doit intégrer une méthode de transfert des liquides à travers différentes étapes de traitements chimiques ou physiques. Une méthode de pompage particulièrement intéressante utilise la force centrifuge, ce qui permet d'éliminer l'utilisation de pompes ou connections externes au système où s'effectue l'analyse chimique. Jusqu'à présent, les systèmes employant la force centrifuge ont été limités par le nombre d'étapes analytiques consécutives, le liquide ne pouvant se déplacer que dans une seule direction définie par la force centrifuge appliquée.Pour cette thèse, plusieurs techniques de manipulation des liquides sur un système microfluidique à base de force centrifuge ont été dévelopées et caractérisées. Ces techniques ont été utilisées pour miniaturiser les méthodes analytiques classiques pour ensuite les intégrer à des plateformes microfluidiques à base de force centrifuge, l'objectif final étant la surveillance d'espèces chimiques dans l'environnement. Une technique de pompage par déplacement de deux phases liquides et une technique de pompage pneumatique à base de force centrifuge sont démontrées. La technique pneumatique à base de force centrifuge qui a été développée augmente de façon significative les capacités de la boîte à outils des systèmes microfluidiques à base de force centrifuge. Ce nouveau système permet d'effectuer simultanément des opérations essentielles dans les systèmes microfluidiques telles que le transfert de liquides sans valves, les dosages, la commutation du débit des liquides, les micromélanges par agitation ainsi que la recirculation des liquides. Cette technique se base sur l'application sans contact d'une pression pneumatique en utilisant de l'air comprimé sur un système microfluidique à base de force centrifuge en rotation constante. Ceci permet un contrôle complet du débit des liquides en combinant les effets de la pression pneumatique et de la force centrifuge. Le processus de fabrication de ce nouveau système est grandement simplifié par l'ajout du système pneumatique car cela diminue le nombre de valves à intégrer dans le système. De plus, son efficacité est accrue grâce à la possibilité d'effectuer des analyses de façon automatisée. Cette approche pneumatique a été appliquée à des mesures spectrophotométriques par la méthode des additions connues effectuées directement sur le disque. Dans le même ordre d'idées, un autre système employant la fonction pneumatique a été développé pour effectuer des extractions liquide-liquide entre une phase liquide et une phase organique. Ceci a démontré que la plateforme centrifuge est capable non seulement d'effectuer des réactions chimiques complexes en plusieurs étapes, mais aussi de répéter les cycles de réactions et autres processus.</dc:abstract><ual:supervisor>Eric Dunbar Salin</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/47429d82t.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/2514np773</ual:fedora3Handle><dc:subject>Chemistry - Analytical</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A6w924g119"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Mining and Materials</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>The dynamic transformation of deformed Austenite at temperatures above the Ae3</dcterms:title><ual:dissertant>Ghosh, Chiradeep</ual:dissertant><dc:abstract>Le comportement de la transformation dynamique de l'austénite lors de sa déformation a été étudié dans quatre aciers, dont les teneurs en carbone sont croissantes, déformés à des températures allant de 743 à 917°C. Ces expériences ont été réalisées par torsion sous une atmosphère contrôlée (mélange argon et 5% H2) et les températures de déformation étaient au-dessus des températures d'ortho et para-équilibre Ae3 pour chaque acier. Des taux de déformation de 0,15 à 5 ont été utilisés avec des vitesses de déformation allant de 0,4 à 4,5 s-1. Les paramètres expérimentaux ont été modifiés afin de déterminer les effets du taux de déformation et de la température sur la formation de ferrite et de cémentite induite par déformation. Les structures observées sont de type Widmanstätten et semblent avoir nucléées de façon displacive. Les départs de la transformation dynamique et de la recrystallization dynamique ont été détectés pour les quatre aciers en utilisant la méthode de double différenciation. Deux ensembles de minima sur les dérivés secondes se trouvent être associés à toutes les courbes d'écoulement. Il est montré qu'un double minimum ne peut être obtenu que lorsque l'ordre du polynôme utilisé dans la procédure d'ajustement de l'intégralité de la courbe découlement est supérieur ou égale à 7. Le premier ensemble de minima correspond à l'initialisation de la transformation dynamique. Le second ensemble est associé à la nucléation de la recrystallization dynamique. Le taux de déformation critique de la transformation dynamique est toujours inférieur à celui de la recrystallization dynamique, dans la gamme de température étudiée, et augmente légèrement avec la température. A l'inverse, le taux de déformation critique de la recrystallization dynamique diminue, de manière connue, avec la température. Les contraintes d'écoulement moyennes relatives à chaque condition expérimentale sont calculées à partir de l'intégration des courbes d'écoulement. Celles-ci sont représentées en fonction de l'inverse de la température absolue sous la forme de diagrammes de Boratto. Les températures  auxquelles la chute de contrainte se produit, normalement définie comme étant la température critique supérieure Ar3*, sont déterminées à partir de ces diagrammes. Celles-ci sont d'environ 40°C au-dessus de la température critique supérieure de para-équilibre et d'environ 20 à 30°C au-dessus de celle d'ortho-équilibre. L'effet de la déformation sur l'énergie de Gibbs de l'austénite dans ces aciers est estimé en supposant que l'austénite continue de s'écrouir après l'initiation de la transformation et que sa contrainte d'écoulement et sa densité de dislocations peuvent être dérivées à partir des courbes d'écoulement expérimentales en émettant des hypothèses appropriées sur l'écoulement conjoint de deux phases. En prenant en outre en compte l'hétérogénéité de la densité de dislocation, les contributions à l'énergie de Gibbs obtenues (forces motrices) sont suffisantes pour promouvoir une transformation jusqu'à 100°C au-dessus de la température Ae3. Le temps de diffusion du carbone requis pour la formation des plaques de ferrite observées est calculé; les résultats obtenus sont cohérents avec l'apparition de diffusion interstitielle  au cours de la déformation. Des calculs similaires indiquent que la diffusion substitutionnelle ne joue aucun rôle lors de la transformation dynamique. Les calculs de l'énergie de Gibbs suggèrent que la croissance de la ferrite de Widmanstätten est suivie de la diffusion du carbone dans le cas des plus faibles teneurs en carbone tandis qu'elle est accompagnée par celle-ci pour les teneurs les plus fortes.</dc:abstract><dc:abstract>The dynamic transformation behavior of deformed austenite was studied in four steels of increasing carbon contents that had been deformed over the temperature range 743 – 917°C. These experiments were carried out in torsion under an atmosphere of argon and 5% H2 and the experimental temperatures were above the ortho and para-equilibrium Ae3 temperatures of the steels. Strains of 0.15 – 5 were applied at strain rates of 0.4 - 4.5 s-1. The experimental parameters were varied in order to determine the effects of strain and temperature on the formation of strain-induced ferrite and cementite. The structures observed are Widmanstätten in form and appear to have nucleated displacively. The onsets of dynamic transformation and dynamic recrystallization were detected in the four steels using the double-differentiation method. Two sets of second derivative minima were found to be associated with all the flow curves. It is shown that double minima can only be obtained when the polynomial order is at least 7. The first set of minima corresponds to the initiation of dynamic transformation (DT). The second set is associated with the nucleation of dynamic recrystallization (DRX). The critical strain for DT is always lower than for DRX in this range and increases slightly with temperature. Conversely, the critical strain for DRX decreases with temperature in the usual way.The mean flow stresses (MFS's) pertaining to each experimental condition were calculated from the flow curves by integration. These are plotted against the inverse absolute temperature in the form of Boratto diagrams. The stress drop temperatures, normally defined as the upper critical temperature Ar3*, were determined from these diagrams. These are shown to be about 40°C above the paraequilibrium and about 20 - 30°C above the orthoequilibrium upper critical transformation temperatures. This type of behavior is ascribed to the occurrence of the dynamic transformation of austenite to ferrite during deformation. The effect of deformation on the Gibbs energy of austenite in these steels was estimated by assuming that the austenite continues to work harden after initiation of the transformation and that its flow stress and dislocation density can be derived from the experimental flow curve by making suitable assumptions about two-phase flow. By further taking into account the inhomogeneity of the dislocation density, Gibbs energy contributions (driving forces) are derived that are sufficient to promote transformation as much as 100°C above the Ae3. The carbon diffusion times required for formation of the observed ferrite plates and cementite particles are calculated; these are consistent with the occurrence of interstitial diffusion during deformation. Similar calculations indicate that substitutional diffusion does not play a role during dynamic transformation. The Gibbs energy calculations suggest that growth of the Widmanstätten ferrite is followed by C diffusion at the lower carbon contents, while it is accompanied by C diffusion at the higher carbon levels.</dc:abstract><ual:supervisor>Stephen Yue</ual:supervisor><ual:supervisor>John Joseph Jonas</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/j098zf60j.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/6w924g119</ual:fedora3Handle><dc:subject>Engineering - Metallurgy</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Axd07gx142"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Earth and Planetary Sciences</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Localized metasomatism of Grenvillian marble leading to its melting, autoroute 5 near Old Chelsea, Québec</dcterms:title><ual:dissertant>Sinaei-Esfahani, Fahimeh</ual:dissertant><dc:abstract>La construction récente (2009) d'un nouveau tronçon de l'Autoroute 5 au nord de Old Chelsea, Québec, a produit des coupes imposantes sur une longueur de plus de 2 km, révélant ainsi une grande variété de types de roches et une juxtaposition surprenante d'assemblages de minéraux  ignés, métamorphiques, et métasomatiques. Cette thèse porte surtout sur la minéralogie du marbre blanc "regional", ainsi que d'échantillons de roches carbonatées orange, rose, jaune, et bleu. Les roches à calcite orange ou rose se présentent en filons avec phénocristaux, et ceux-ci ont un liseré de cristaux idiomorphes de diopside le long de leur contact. La pargasite, la phlogopite, la titanite et la bétafite sont les phénocristaux prédominants. La calcite orange dans ces filons [δ13C ≈  –1‰, δ18O ≈  16‰] est isotopiquement intermédiaire entre la calcite du marbre blanc "régional" [δ13C ≈ 3‰, δ18O ≈ 24‰] et la calcite typique d'une carbonatite mantellique [δ13C ≈ –5‰, δ18O ≈ 6‰]. D'après les données nouvelles, le marbre régional a aurait subi les effets d'une métasomatose locale par une phase fluide alcaline de dérivation mixte (croûte + manteau), et a aurait ensuite fondu, possiblement à la fin de la phase orogénique Ottawa, à environ 1020 millions d'années, ou la phase orogénique Rigolet, à environ 980 millions d'années. Le pigment orange dans la calcite est possiblement la bastnäsite-(Ce) ou l'hydroxylbastnäsite-(Ce), et la couleur de la calcite rose pourrait bien être due aux micro-inclusions de dolomite ferrifère, attribuées à l'exsolution. Au contact supérieur des filons de carbonate se trouvent des zones diffuses de transformation rougeâtre du gneiss gris, distribuées le long de fractures. Ces zones transformées contiennent un matériau "syénitique" à dominance de feldspath potassique, dû au rhéomorphisme des fénites créées aux dépens du gneiss gris. Les affleurements démontrent les produits de la fusion du marbre dans la croûte, et donc la formation de silicocarbonatite crustale. Le phénomène est répandu mais localisé dans la Ceinture Métasédimentaire Centrale de la Province du Grenville.</dc:abstract><dc:abstract>The recent (2009) opening of an extension of Autoroute 5 north of Old Chelsea, Quebec, has produced striking road cuts over a length of 2 km, with a wide variety of rock types and a very complex and bewildering juxtaposition of igneous, metamorphic, and metasomatic assemblages of minerals.  The focus here is on the mineralogy of the "regional" white marble; it is compared to calcite-dominant rocks, orange, pink, yellow, and blue in color. The orange to pink calcite is dominant  in phenocryst-bearing dikes with a selvage of euhedral crystals of diopside. pargasite, phlogopite, titanite and betafite are the dominant phenocrysts.  The orange calcite in those dikes [δ13C ≈  –1‰, δ18O ≈  16‰] is isotopically intermediate between the regionally developed white marble [δ13C ≈ 3‰, δ18O ≈ 24‰] and a typical mantle-derived carbonatite [δ13C ≈ –5‰, δ18O ≈ 6‰]. The evidence points to the local metasomatism of regional marble by an alkaline fluid of mixed crust + mantle derivation, then melted, possibly at the end of the Ottawan orogenic phase, at approximately 1020 m.y., or the Rigolet orogenic phase, at approximately 980 m.y. The orange pigment in the calcite is possibly bastnäsite-(Ce) or hydroxylbastnäsite-(Ce), and the pink calcite may well be due to exsolution-induced blebs of ferroan dolomite. Above the dikes are diffuse zones of fracture-controlled reddening of the gray gneiss, in which the original mineralogy is replaced by a K-feldspar-dominant "syenitic" material. There are signs of rheomorphism of fenites developed at the expense of the gray gneiss.  The road cut displays the products of melting of marble in the crust, leading to a crustal silicocarbonatite. The phenomenon is widespread but localized in the Central Metasedimentary Belt of the Grenville Province.</dc:abstract><ual:supervisor>Hojatollah Vali</ual:supervisor><ual:supervisor>Robert F. Martin</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/44558h59s.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/xd07gx142</ual:fedora3Handle><dc:subject>Earth Sciences - Geology</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Agb19f950t"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Psychiatry</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Perspectives of illness and resilience in the Peruvian highlands: a cross-sectional follow-up study</dcterms:title><ual:dissertant>D'souza, Nicole</ual:dissertant><dc:abstract>Les conflits armés, la guérilla, et la violence politique ont contribué à les repensions de fléaux, la morbidité au niveau de pertes en vies humaines et les incapacités, surtout parmi les populations civiles du Pérou. Les effets de la guerre et de la violence politique peuvent languir et permet de déterminer la capacité des gens à reconstruire leur vie longtemps après la fin des guerres. Le projet en cours est une étude de suivi, transversale, qualitative chez les populations quechua des hautes terres de South Central Pérou qui ont été exposées à vingt ans de violence entre 1980-2000. Le but de l'étude était d'obtenir des récits sur les expériences de détresses, la maladie mentale, l'adaptation et la résilience des personnes quechua de cette région montagneuse. L'étude a été menée à Ayacucho, au Pérou dans quatre communautés rurales ainsi que d'un milieu urbain. Des entrevues semi-structurées ont été menées par 17 informateurs qui ont rencontré la compatibilité de stress post-traumatique en 2000, dont la moitié ont continué à avoir des symptômes de PTSD. Les résultats indiquent que les individus expriment plus de détresse due aux énormes difficultés de survie a l'époque actuelle contrairement aux symptômes de traumatisme de la guerre. Les résultats suggèrent que, bien que les informateurs ont continué à avoir des symptômes de détresse, ils ont trouvé un support morale aux niveau des ressources communautaires, sociales, culturelles et économiques mis à leur disposition. Les données révèlent que la sante psychosociale d'après-guerre ne peut pas être séparée des structures politiques et économiques.</dc:abstract><dc:abstract>Armed conflict, guerrilla warfare, and political violence have contributed to the burden of disease and disability, especially among civilian populations of Peru. The effects of war and political violence can be long lasting and can determine the capacity of people to reconstruct their lives long after wars have ended. The current project is a cross-sectional, qualitative, follow-up study among Quechua populations of the South Central Peruvian highlands who were exposed to twenty years of protracted violence between1980-2000.  The previous study was conducted by Pedersen et al (2008) and revealed that of all respondents who had been exposed to violence, one in four (N=92) reported symptoms compatible with the DSM-III-R diagnosis of PTSD. However, due to the absence of mental health services in the province, it was virtually impossible to refer those cases for treatment and follow-up. It has been ten years since the first survey, and a subsample of the number of PTSD positive cases that were detected in 2000, were relocated and interviewed to elicit narratives on the experiences of distress, mental illness, coping and resilience for Quechua individuals of this highland region. The study was conducted in Ayacucho, Peru in four rural communities as well as one urban setting. Semi-structured interviews were carried out with 17 informants who met the compatibility of PTSD in 2000, half of whom continued to have PTSD symptoms in 2011. The findings indicate that individuals express more distress about the tremendous difficulties of surviving in the present day than about the trauma symptoms of the war. Findings suggest that although informants continued to have symptoms of distress, they found resilience in certain community resources, including social, cultural and economic resources. The data reveals that postwar psychosocial health cannot be separated from the broader political and economic structures.</dc:abstract><ual:supervisor>Duncan Pedersen</ual:supervisor><ual:supervisor>Laurence J. Kirmayer</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/47429d833.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/gb19f950t</ual:fedora3Handle><dc:subject>Health Sciences - Mental Health</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Aff3658531"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Medicine</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Insights on the role of the protein hemojuvelin in the maintenance of systemic iron homeostasis</dcterms:title><ual:dissertant>Gkouvatsos, Konstantinos</ual:dissertant><dc:abstract>Iron is an essential nutrient, involved in a wide range of biochemical activities. However, its flexible coordination chemistry and favorable redox potential may render this element potentially toxic. Thus, tight and accurate regulation of iron absorption in humans is critical to prevent systemic excess or deficiency. This complex task is accomplished by hepcidin, a liver-derived peptide hormone that binds to the iron transporter ferroportin and promotes its degradation. This results in a decrease of the iron efflux from duodenal enterocytes, macrophages and hepatocytes into the blood stream. Severalmolecules, such as HFE, TfRs, BMP6 and HJV, are being implicated in the regulation of hepcidin expression. HJV is encoded by the HFE2 gene and functions as a BMP co-receptor, activating hepcidin expression through the BMP/SMAD pathway. It is predominantly expressed in the skeletal muscles and at lower levels in the heartand the liver. Furthermore, a putative muscle-derived soluble Hjv is supposed to circulate in the plasma. Humans bearing pathogenic mutations of the HfE2 gene develop juvenile hemochromatosis, a disease characterized by profound hepcidindeficiency and early-onset severe iron overload. Mouse models with ubiquitous disruption of the expression of HJV recapitulate the main features of the disease. Previous studies have proposed an essential role for HJV in iron sensing, however, the implicated mechanisms have not been elucidated thus far. In this work we study the function of HJV within the iron metabolism regulatory mechanisms. In chapter II we investigate the role of HJV, expressed in different tissues, in the maintenance of iron homeostasis. We generate two novelmouse models with targeted disruption of the expression of Hjv in liver hepatocytes or skeletal muscle cells and we analyze their phenotype. We show that hepatic HJV suffices to regulate the expression of hepcidin and to maintainsystemic iron homeostasis whereas skeletal muscle HJV is dispensable for systemic iron metabolism. Furthermore, we do not observe any significant iron regulatory function of a putative muscle-derived soluble Hjv.In chapter III we focus our interest on the role of hepatic HJV in iron sensing to hepcidin. To this end, we analyze the molecular responses of HJV-/- and HJV+/+ mice to dietary iron manipulations. We demonstrate that HJV is not essential for iron sensing and it rather functions as an enhancer of the primary iron signal. Furthermore, we provide evidence of iron-dependent regulation of duodenal DMT1 and tissue specific function of hepcidin in the spleen and the duodenum of the studied HJV-/- mice.</dc:abstract><dc:abstract>Le fer est un nutriment essentiel impliqué dans une vaste gamme d'activités biochimiques. Cependant, sa coordination chimique flexible et son potentiel redox favorable rendent cet élément potentiellement toxique. Ainsi, une régulation stricte et précise de l'absorption du fer chez l'homme est essentielle pour prévenir un excès ou une insuffisance systémique. Cette tâche complexe est réalisée par l'hepcidine, une hormone peptidique dérivée du foie qui s'attache au transporteur du fer ferroportine et favorise sa dégradation. Ceci mène à une diminution de l'efflux du fer des entérocytes duodénaux, des macrophages et des hépatocytes dans le flux sanguin. Plusieurs molécules, comme le HFE, le TfR2, leBMP6 et l'HJV, sont impliquées dans la régulation de l'expression de l'hepcidine. HJV est codée par le gène HFE2 et fonctionne comme un co-récepteur de BMP, en activant l'expression d'hepcidine par la voie BMP/SMAD. Elle est principalement exprimée dans les muscles squelettiques et à des niveaux inférieurs dans le coeur et le foie. En outre, un putatif HJV soluble dérivé des muscles est supposé circuler dans le plasma. Les humains portant des mutations pathogènes du gène HFE2 développent l'hémochromatose juvénile, une maladie caractérisée par une carence profonde en hepcidine et une surcharge sévère et précoce en fer. Des modèles de souris avec une perturbation omniprésente de l'expression de l'HJV récapitulent les principales caractéristiques de la maladie. Des études antérieures ont proposé un rôle essentiel pour HJV dans la détection du fer, cependant, les mécanismes impliqués n'ont pas été élucidés à ce jour. Dans ce travail, nous étudions la fonction de HJV dans les mécanismes de régulation du métabolisme du fer. Dans le chapitre II, nous étudions le rôle de HJV, exprimé dans différents tissus, dans le maintien de l'homéostasie du fer.Nous générons deux nouveaux modèles murins avec une perturbation ciblée de l'expression de HJV dans les hépatocytes ou des cellules musculaires squelettiques et nous analysons leur phénotype. Nous montrons que l'HJV hépatique est suffisante pour réguler l'expression de l'hepcidine et de maintenir l'homéostasie du fer systémique alors que l'HJV musculaire est non essentiel pour le métabolisme du fer systémique. De plus, nous n'avons pas observé une fonction significative d'une HJV soluble musculaire hypothétique liée à la régulation du fer.Dans le chapitre III, nous nous intéressons au rôle de l'HJV hépatique dans la détection des altérations du niveau de fer et la transmission subséquente de ce signal sur l'expression de l'hepcidine. À cette fin, nous analysons les réponsesmoléculaires des souris HJV-/- et HJV+/+ à des manipulations alimentaires de fer. Nous démontrons que HJV n'est pas essentielle pour la détection des variations des niveaux ferriques mais qu'elle fonctionne plutôt comme un amplificateur dusignal primaire de fer. En outre, nous fournissons des preuves d'une régulation du DMT1 dépendante du fer et une fonction de l'hepcidine spécifique au tissu, dans le duodénum et la rate des souris HJV-/ - étudiées.</dc:abstract><ual:supervisor>Konstantinos Pantopoulos</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/mw22v915p.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/ff3658531</ual:fedora3Handle><dc:subject>Health Sciences - Medicine and Surgery</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Afx719q576"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>School of Computer Science</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Flux graphs for 2D shape analysis</dcterms:title><ual:dissertant>Rezanejad, Morteza</ual:dissertant><dc:abstract>Ce mémoire propose une méthode pour calculer des représentations squelettiques en fonction du flux moyen décrit par le gradient de la fonction de distance Euclidienne aux limites d'un objet 2D qui rétrécit. La méthode originale développée par Dimitrov et al. [17] est ensuite optimisée afin de calculer des invariants de flux plus rapidement. Une relation entre l'AOF et l'angle de l'objet aux extrémités (aux points de branches et des points réguliers du squelette) est exploitée afin d'obtenir une reconstruction plus précises des limites de l'objet par rapport aux travaux précédents. En utilisant cette implémentation optimisée, de nouvelles mesures de simplification de squelettes sont proposées selon deux critères: l'unicité d'un disque inscrit comme un outil permettant de définir la saillance, et la limitation de la moyenne du flux à l'extérieur. Il est démontré que le squelette simplifié, abstrait par un graphe orienté, est beaucoup moins complexe que des graphes squelettiques conventionnels mentionnés dans la littérature, tel que le graphe de choc. Les mesures de complexité de graphe comprennent le nombre de nuds, le nombre de bords, la profondeur du graphe, le nombre de points du squelette et la somme des valeurs du vecteur des signes topologiques (TSV). La thèse se finit en appliquant le graphe simplifié au problème de reconnaissance d'objets basée sur la vue, préalablement adapté pour l'utilisation de graphes de choc. Les résultats suggèrent que notre nouveau graphe simplifié atteint des performances similaires à celles des graphes de choc, mais avec moins de nuds, de bords et de points du squelette plus rapide.</dc:abstract><dc:abstract>This thesis considers a method for computing skeletal representations based on the average outward flux (AOF) of the gradient of the Euclidean distance function to the boundary of a 2D object through the boundary of a region that is shrunk. It then shows how the original method, developed by Dimitrov et al. [17] can be optimized and made more efficient and proposes an algorithm for computing flux invariants which is a number of times faster. It further exploits a relationship between the AOF and the object angle at endpoints, branch points and regular points of the skeleton to obtain more complete boundary reconstruction results than those demonstrated in prior work. Using this optimized implementation, new measures for skeletal simplification are proposed based on two criteria: the uniqueness of an inscribed disk as a tool for defining salience, and the limiting average outward flux value. The simplified skeleton when abstracted as a directed graph is shown to be far less complex than popular skeletal graphs in the literature, such as the shock graph, by a number of graph complexity measures including: number of nodes, number of edges, depth of the graph, number of skeletal points, and the sum of topological signature vector (TSV) values. We conclude the thesis by applying the simplified graph to a view-based object recognition experiment previously arranged for shock graphs. The results suggest that our new simplified graph yields recognition scores very close to those obtained using shock graphs but with a smaller number of nodes, edges, and skeletal points.</dc:abstract><ual:supervisor>Kaleem Siddiqi</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/bc386n969.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/fx719q576</ual:fedora3Handle><dc:subject>Applied Sciences - Computer Science</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ams35tc65f"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Anti-counterfeiting method using synthesized nanocrystalline cellulose taggants</dcterms:title><ual:dissertant>Zhang, Yu Ping</ual:dissertant><dc:abstract>Depuis que l'économie et le commerce existent, des gens ont tenté de créer des imitations de marchandises de valeur pour leur profit personnel. La contrefaçon engendre des pertes substantielles, coûtant entre 200 et 250 milliards de dollars annuellement à l'économie des États-Unis ainsi que des pertes de milliards de dollars à l'économie canadienne. L'augmentation de la contrefaçon souligne les limites des technologies présentement utilisées pour la sécurité et indique le besoin grandissant pour le développement d'une nouvelle technologie d'authentification. Dans cette contribution, nous synthétisons la nanocellulose cristalline (NCC), nous étudions les propriétés optiques de ce nouveau matériau, et nous proposons l'utilisation de la cellule nanocristalline (NCC) comme marqueur anti-contrefaçon sophistiqué. Nous suggérons que la NCC traceurs de sécurité possèdent plusieurs fonctions de sécurité: une irisation manifeste, une sélection de réflexions masquées, une fluorescence ultraviolette, une morphologie unique masquée et un motif de diffraction de la lumière blanche. L'origine de l'irisation de la NCC vient à la fois de la réflexion de Bragg sur de multiples interfaces et du relief sur la surface du réseau de diffraction, alors que la sélection de réflexions masquées vient de la structure chirale formée lors du moulage par autoassemblage du NCC. Afin d'inclure une autre caractéristique de sécurité masquée, la fluorescence ultraviolette, un agent azurant, est ajoutée au NCC en suspension ce qui lui apporte la fluorescence et l'irisation. Finalement, la morphologie du marqueur NCC et le motif de diffraction de la lumière blanche fournissent des éléments de sécurité masqués supplémentaires.La méthode proposée possède de multiples avantages par rapport aux méthodes d'anti-contrefaçon conventionnelles: un système de sécurité à multiples niveaux, incluant des caractéristiques manifestes et masquées. Ces caractéristiques sont très difficiles à reproduire mais peuvent être authentifiées grâce à des outils à faible coût ainsi qu'avec un système optique simple lorsque de plus amples tests seront nécessaires.</dc:abstract><dc:abstract>For as long as economies and trade have existed, there have been people who have attempted to produce imitations of valuable goods for personal gain. Counterfeiting is a substantial drain on business, costing the U.S. economy between $200-250 billion annually, as well as billions of dollars in losses to the Canadian economy. The increased in counterfeiting attests to the limitation of present security techniques and indicates a strong need to develop more secure ones. In this contribution, we synthesize Nanocrystalline Cellulose (NCC), study the optical properties of this novel material, and propose that NCC can be used as a sophisticated anti-counterfeiting taggant.    We suggest that NCC security taggants possess multiple security features: overt iridescence, covert selective reflection, ultraviolet fluorescence, covert unique morphology, a white light diffraction pattern, and a water induced color variation. The origin of the iridescence of NCC comes from both the Bragg multilayer reflection and surface relief grating diffraction, while the covert selective reflection security feature comes from the chiral structure formed during the casting by self-assembly of NCC. In order to add another covert security feature, ultraviolet fluorescence, an Optical Brightening Agents (OBA) was incorporated into the NCC suspension, and the result is a fluorescent and iridescent NCC material. The white light diffraction pattern which arises from the morphology of the NCC taggant provides further covert security. We also show that this NCC material displays water induced color variation which may also be used as security feature.    Compared to conventional anti-counterfeiting techniques, the proposed method has several advantages: one system supports multi-level security, including overt and covert features. These features are very difficult to copy, but can be authenticated using low-cost tools, as well as a simple optical set-up when further lab tests are needed. </dc:abstract><ual:supervisor>Vamsy Chodavarapu</ual:supervisor><ual:supervisor>Andrew G. Kirk</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/bg257j249.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/ms35tc65f</ual:fedora3Handle><dc:subject>Engineering - Materials Science</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A4x51hn86r"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Integrated Program in Neuroscience</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Cocaine cue-induced dopamine release in Amygdala and Hippocampus: a high-resolution PET [18F] Fallypride study in cocaine dependent participants</dcterms:title><ual:dissertant>Fotros, Aryandokht</ual:dissertant><dc:abstract>Background: Drug related cues are potent triggers for relapse in people with cocaine dependence. Dopamine release within a limbic network of striatum, amygdala and hippocampus has been implicated in animal studies, but in humans it has been possible to measure effects in the striatum only. The objective here was to measure dopamine release in the amygdala and hippocampus using high-resolution PET with [18F]fallypride. Methods: Twelve cocaine dependent volunteers (mean age: 39.6±8.0; years of cocaine use: 15.9±7.4) underwent two [18F]fallypride HRRT PET scans, one with exposure to neutral cues and one with cocaine cues. [18F]Fallypride non-displaceable binding potential (BPND) values were derived for five regions of interest (ROI) (amygdala, hippocampus, ventral limbic striatum, associative striatum, and sensorimotor striatum,). Subjective responses to the cues were measured with visual analog scales and grouped using principal component analysis. Results: Drug cue exposure significantly decreased BPND values in all five ROI in subjects who had a high but not low craving response (limbic striatum: p=0.019, associative striatum: p=0.008, sensorimotor striatum: p=0.004, amygdala: p=0.040, and right hippocampus: p=0.025). Individual differences in the cue-induced craving response predicted the magnitude of [18F]fallypride responses within the striatum (ventral limbic: r=0.581, p=0.048; associative: r=0.589, p=0.044; sensorimotor: r=0.675, p=0.016). Conclusions: To our knowledge this study provides the first evidence of drug cue-induced dopamine release in the amygdala and hippocampus in humans. The preferential induction of dopamine release among high craving responders suggests that these aspects of the limbic reward network might contribute to drug seeking behavior.</dc:abstract><dc:abstract>ABRÉGÉHistorique:  L'indice lié à la drogue est un puissant élément déclencheur pour une rechute chez les gens avec une dépendance à la cocaïne.  La libération de la Dopamine dans le réseau limbique du striatum, les amygdales et les hippocampes a été démontrée dans les études animales, mais avec l'humain, il a été possible de mesurer les effets spécifiques au striatum.  Notre objectif est de quantifier le relâchement de dopamine dans les amygdales et hippocampes en utilisant la TEP à haute résolution avec injection de [18F]fallypride. Méthode :  Douze bénévoles dépendants de la cocaïne (moyenne d'âge :  39.6±8.0; nombre d'années d'utilisation de la cocaïne :  15.9±7.4) ont subi deux scans  HRRT TEP avec [18F]fallypride: Une avec exposition de l'indice neutre et l'autre avec l'indice de la cocaïne.  Les valeurs du potentiel de fixation (BPND) du [18F]fallypride sont tirées de cinq régions d'intérêt (RDI) (striatum limbique ventral, cortex associatif, striatum sensorimoteur, amygdales et hippocampes).  Les réponses subjectives de l'indice déclencheur sont mesurées avec des échelles analogues visuelles et groupées à l'aide d'analyses en composantes principales.Résultats : L'exposition de l'élément déclencheur de la drogue diminue significativement les valeurs  BPND d  aux cinq RDI des sujets qui ont eu un désir élevé de consommer (striatum limbique p=0.019, cortex associatif : p=0.008, striatum sensorimoteur : p=0.004, amygdales : p=0.040  et l'hippocampe droit : p=0.025).  A l'intérieur du striatum, les différences individuelles dans la réponse à la provocation de l'élément déclencheur prédisait l'ampleur des réponses [18F]fallypride (limbique ventral: r=0.581, p=0.048; cortex associatif:  r=0.589, p=0.044; sensorimoteur: r=0.675, p=0.016). Conclusion:  À notre connaissance, cette étude apporte la première preuve que l'élément déclencheur provoque le relâchement de la dopamine dans les amygdales et hippocampes chez les humains.  L'induction préférentielle du relâchement de la dopamine parmi les répondants aux indices de la drogue suggère que ces aspects du réseau limbique pourraient contribuer aux comportements de recherche de la drogue.</dc:abstract><ual:supervisor>Marco Leyton</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/0c483n61f.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/4x51hn86r</ual:fedora3Handle><dc:subject>Health Sciences - Medicine and Surgery</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Avx021j57m"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Mathematics and Statistics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>On the p-adic variation of Heegner points</dcterms:title><ual:dissertant>Castellà Cabello, Francisco</ual:dissertant><dc:abstract>Cette thèse est consacrée aux "points de Heegner en famille" introduits par Ben Howard. Par définition, ce sont des classes de cohomologie globales à valeurs dans la représentation Galoisienne associée à une famille de Hida, interpolant en poids 2 les images de points CM par l'application de Kummer. La première partie de cette thèse relie les spècialisations de la classe de Howard en poids k&gt;2 aux images de certains cycles de Heegner par l'application d'Abel-Jacobi p-adique. Notre démonstration de cette relation repose sur une formule de Gross-Zagier p-adique obtenue dans les travaux récents [BDP] de Bertolini-Darmon-Prasanna, et que nous étendons ici à un cadre permettant de travailler avec des formes modulaires de niveau divisible par p. On déduit de nos résultats une interpolation de la formule de Gross-Zagier p-adique de Nekovar sur une famille de Hida. La deuxième partie étend la définition de la classe de Howard "le long de la droite anticyclotomique", pour obtenir une classe de cohohomologie à deux variables. On montre que la fonction L p-adique de Hida-Rankin, telle que décrite dans [BDP], est l'image de cette classe par une généralisation de l'isomorphisme de Coleman. La méthode des systèmes d'Euler de Kolyvagin, telle que réinventée par Kato et Perrin-Riou, permet d'en déduire certains nouveaux cas de la conjecture de Bloch-Kato pour la convolution de Rankin-Selberg d'une forme parabolique avec une série thêta de poids supérieur, et une divisibilité dans la conjecture principale de la théorie d'Iwasawa associée à cette famille de motifs.</dc:abstract><dc:abstract>In this thesis we study the so-called ``big Heegner points'' introduced and first studied by Ben Howard. By construction these are global cohomology classes, with values in the Galois representation  associated to a twisted Hida family, interpolating in weight 2 the twisted Kummer images of CM points.In the first part, we relate the higher weight specializations of the big Heegner point of conductor one to the p-adic etale Abel-Jacobi images of Heegner cycles. This is based on a new p-adic limit formula of Gross-Zagier type obtained in the recent work [BDP] of Bertolini-Darmon-Prasanna, a formula that we extend to a setting allowing arbitrary ramification at p. As a first consequence of the aforementioned relation, we deduce an interpolation of the p-adic Gross-Zagier formula of Nekovar over a Hida family.In the second part, we extend some of these formulas in the anticyclotomic direction, and find that the p-adic L-function introduced in [BDP] can be obtained as the image of a compatible sequence of big Heegner points of p-power conductor via a generalization of the Coleman power series map. By an application of Kolyvagin's method of Euler systems, we then exploit this alternate construction of the p-adic L-function to establish certain new cases of the Bloch-Kato conjecture for theRankin-Selberg convolution of a cusp form with a theta series of higher weight, and deduce one divisibility in the associated anticyclotomic Iwasawa main conjecture.</dc:abstract><ual:supervisor>Henri Darmon</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/wp988p366.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/vx021j57m</ual:fedora3Handle><dc:subject>Pure Sciences - Mathematics</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Asx61dq62t"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Natural Resource Sciences</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>The functional role of earthworms in carbon and nitrogen dynamics in riparian areas under different land use in Southern Québec</dcterms:title><ual:dissertant>Kernecker, Maria</ual:dissertant><dc:abstract>Les bandes riveraines se situent à l'interface des écosystèmes aquatiques et terrestres. Les événements hydrologiques ainsi que la composition de la végétation influence la décomposition et le cycle des nutriments dans ces zones et ultimement déterminent si les bandes riveraines sont des puits de carbone (C) et d'azote (N) ou bien des sources pour l'environnement. Les vers de terre jouent un rôle crucial dans la décomposition et le cycle des nutriments en fragmentant les résidus végétaux et par leur interaction avec les microorganismes du sol. Durant ces procédés,les vers de terre augmentent la production et les flux de CO2 et N2O tout en augmentant la quantité de composés solubles tels que le C organique dissout et le N minérale. L'objectif de cette recherche était de décrire la communauté de vers de terre établie dans les bandes riveraine au long de le rivière Pike dans le sud du Québec, d'indentifier les facteurs environnementaux qui influencent la structure des communautés de vers de terre, et de déterminer comment les vers de terres affectent la dynamique du C et de N avec différentes gestions du sol. La communauté de vers de terre était plus abondante (p &lt;.0001) et plus diversifiée dans les bande riveraine comparé particulièrement ceux qui étaient sous exploitation agricole. L'humidité du sol, la diversité de la végétation, et les propriétés chimiques du sol (NH4 et P) contrôlent l'assemblage des communautés de vers de terre adultes à travers les sites (p &lt;.005). Une expérience en microcosme a été réalisée en laboratoire sur deux espèces de vers de terre venant de bande riveraines, soit une espèce anécique et une espèce endogéique. L'objectif était de tester comment ces deux espèces affectent la perte de C et de N des sols avec leurs effets sur la décomposition dela litière composée soit de résidus de soya (Glycine max.), de feuilles d'essence forestière feuillue (Acer saccharum, Fagus grandifolia, Betula alleghaniensis) ou de baldingère faux-roseau (Phalaris arundinacea). Avec des résidus soya, les vers de terre ont augmenté la perte de CO2 de 14% (p &lt; .0001) et les émissions de N2O de 700% (p &lt; .0001). Avec la litière de baldingère faux-roseau, les vers de terre ont réduit la perte de CO2 de 18% (p &lt; .0001) et les émissions de N2O de 250% (p &lt; .0001). La quantité de C et de N soluble dans les percolats et dans le sol dépend de l'interaction entre l'espèce de vers de terre et le type de litière. Microcosmes avec les vers de terre ont augmenté C gazeux et les pertes d'azote par rapport aux pertes solubles par rapport aux microcosmes sans vers de terre. Dans une autre expérience en microcosme, la présence de vers de terre a fait augmenter le taux brut de production du CH4 de 365 à 509 μg CH4 g-1 sol d-1. Par contre, la consommation cumulative nette de CH4 dans le sol avec les vers était de 489 μg CH4 g-1 d-1, et dans les sols sans vers de 318 μg CH4 g-1 d-1. Une expérience sur le terrain dans les bandes riveraines a testé l'effet de la manipulation des populations de vers sur les émissions printanières de CO2, N2O et CH4. Dans tous les sites, la moyenne du flux de CO2 variait entre 33.5 to 171.4 mg CO2-C m-2 h-1, la moyenne du flux de N2O variait entre 1.2 to 51.6  μg N2O-N m-2 h-1, et la moyenne du flux de CH4 était entre -44.2 et 3.1 μg CH4-C m-2 h-1. Même si le taux d'humidité du sol, le couvert végétal et les variables des vers de terres corrélaient tous avec les flux de CO2, N2O, and CH4, seul le couvert végétal et le taux d'humidité du sol ont pu prédire de manière significative les flux de CO2 (R2=0.245, p = 0.0007) et de N2O (R2=0.188, p = .0049).  En dépit de l'influence importante des vers de terres sur les émissions de C et de N gazeux  en laboratoire, cette influence n'était pas détectable sur le terrain. La gestion du couvert végétale plutôt que celle de la population des vers de terre serait une stratégie plus efficace pour minimiser la perte de C et de N gazeux dans les bandes riveraines du sud du Québec.  </dc:abstract><dc:abstract>Riparian areas are located at the interface between terrestrial and aquatic ecosystems. Hydrological events and vegetation patterns drive decomposition and nutrient cycling occurring in these areas, ultimately determining whether riparian areas are a carbon (C) and nitrogen (N) sink or source to the environment. Earthworms play a central role in decomposition and nutrient cycling by fragmenting plant material and interacting with soil microorganisms. During this process, earthworms are assumed to increase CO2 and N2O production and fluxes, while increasing soluble compounds such as dissolved organic C and mineral N that may either be substrates for microbial activity and plants (i.e., plant N uptake) or lost from soil when leached through earthworm burrows (macropores). The objective of this research was to describe the earthworm community inhabiting riparian areas along the Pike River in southern Québec, identify the environmental factors driving earthworm community assemblage, and determine how earthworms in this area affected C and N dynamics under different land use. A field study of earthworms, soil, and vegetation showed that earthworm communities were larger (p &lt;.0001) and more diverse in riparian sites compared to upland sites that cultivated with crops. Canonical correspondence analysis showed that soil moisture, vegetation, microbial biomass carbon (MBC) and soil parameters including ammonium (NH4) and phosphorus (P) were the main factors driving the separation of earthworm assemblages and associated plots (p &lt; .005). A 5-month long microcosm experiment tested the effect of two earthworm species from riparian areas, the anecic Lumbricus terrestris and endogeic Aporrectodea turgida, on C and N losses from riparian soils via their effect on litter decomposition. Litter consisted of soybean residue (Glycine max), deciduous forest mix (Acer saccharum, Fagus grandifolia, Betula alleghaniensis) and reed canarygrass (Phalaris arundinacea). Earthworms increased CO2 and N2O losses from microcosms with soybean litter, by 14% (p &lt; .0001) and 700% (p &lt; .0001), respectively, but reduced CO2 and N2O losses by 18% (p &lt; .0001) and 250% (p &lt; .0001), respectively, when fed with reed canarygrass. The amount of soluble C and N in leachate and soil extracts depended on the interaction between earthworm species and litter type. Microcosms with earthworms increased gaseous C and N losses relative to soluble losses compared to microcosms without earthworms.  The effect of earthworm presence and soil moisture on methanogenic and methanotrophic activity was tested in another laboratory microcosm experiment lasting 24 hours. Earthworm presence increased cumulative gross CH4 production from 365 μg CH4 g-1 d-1 soil (without earthworms) to 509 μg CH4 g-1 d-1 soil. Cumulative net CH4 consumption in soils with earthworms was 489 μg CH4 g-1 d-1, whereas in soils without earthworms it was 318 μg CH4 g-1 d-1. A field experiment in riparian areas along the Pike River tested the effects of manipulated earthworm populations on gas (CO2, N2O, and CH4) fluxes in spring. Throughout sites, mean CO2, CH4, and N2O fluxes ranged from 33.5 to 171.4 mg CO2-C, -44.2 and 3.1 μg CH4-C, and 1.2 to 51.6 μg N2O-N m-2 h-1, respectively. While soil moisture, vegetation cover, and earthworm variables were all correlated with CO2, N2O, and CH4 fluxes, only vegetation cover and soil moisture significantly predicted CO2 (R2=0.245, p = .0007) and N2O (R2=0.188, p = .0049) fluxes.  Despite the important earthworm influence on C and N gas fluxes from riparian soils in the laboratory, it is not detectable at the field scale. I conclude that management of vegetation cover rather than earthworm populations would be a more effective way to minimize C and N gaseous and leachate losses in riparian areas in southern Québec. </dc:abstract><ual:supervisor>Robert Lionel Bradley</ual:supervisor><ual:supervisor>Joann Karen Whalen</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/9306t280t.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/sx61dq62t</ual:fedora3Handle><dc:subject>Health And Environmental Sciences - Environmental Sciences</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Aw6634708p"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Laws</schema:inSupportOf><dc:contributor>Faculty of Law</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Sustainable development of international arbitration: rethinking subject-matter arbitrability</dcterms:title><ual:dissertant>Bahmany, Leyla</ual:dissertant><dc:abstract>The discussion pertaining to the inarbitrability of public policy disputes has a long-standing position in arbitration law. To protect public interests, domestic legal systems imposed a general ban on the arbitration of public policy disputes. In 1985, however, the United States Supreme Court in Mitsubishi Motors Corp. v. Soler Chrysler-Plymouth, Inc. removed antitrust disputes from the category of inarbitrable matters and marked a new phase in the history of inarbitrability. The general nature of Mitsubishi's reasoning affected other Western jurisdictions to remove the inarbitrability of public policy disputes in order to develop international arbitration. Mitsubishi's rationale and holding, therefore, can be considered to be pillars of the new approach to inarbitrability. This thesis critically analyzes Mitsubishi's reasoning and the record of the past three decades in light of case law and the views of prominent scholars. It draws a picture of the current situation of arbitrability in the United States, Canada, France and Belgium. The discussion explains that the removal of inarbitrability has resulted in an ineffective protection for public interests, which has caused dissatisfaction in certain sectors of society and may amount to formation of a radical view hostile to arbitration. The situation raises concerns as to whether the current development of arbitration will endure. This thesis borrows the term "sustainable development" from environmental law and economy, and applies it to international arbitration law. By redefining "sustainable development" according to the needs of international arbitration, this thesis provides a solution for developing arbitration without jeopardizing public policy interests. The solution balances private and public interests to achieve sustainable development in international arbitration.</dc:abstract><dc:abstract>La discussion relative à l'inarbitrabilité des différends portant sur l'ordre public occupe une position de longue date en droit de l'arbitrage. Afin de protéger les intérêts du public, les systèmes juridiques nationaux interdisaient généralement l'arbitrage de différends portant sur des questions d'ordre public. En 1985, cependant, la Cour suprême américaine dans l'affaire Mitsubishi Motors Corp. v. Soler Chrysler-Plymouth, Inc. retira les différends pourtant sur le droit de la concurrence de la catégorie des questions inarbitrables, et marqua une nouvelle phase dans l'histoire de inarbitrabilité. Le caractère général des arguments soulevés dans l'affaire Mitsubishi a influencé d'autres pays occidentaux et ils retirèrent les différends portant sur l'ordre public des matières inarbitrables afin de développer l'arbitrage international. Par conséquent, les arguments formulés et la décision prise dans l'affaire Mitsubishi peuvent être considérés comme les piliers de la nouvelle approche de inarbitrabilité. Ce mémoire analyse l'argumentaire de l'affaire Mitsubishi et le bilan des trois dernières décennies, à la lumière de la jurisprudence et des points de vue d'éminents chercheurs. Il dresse un tableau de la situation actuelle de l'arbitrabilité aux Etats-Unis, au Canada, en France et en Belgique. L'exposé explique que la suppression de l'inarbitrabilité a donné lieu à une protection inefficace de l'ordre public, ce qui a provoqué l'insatisfaction dans certains secteurs de la société et pourrait résulter dans la formation d'un point de vue radical, hostile à l'arbitrage. La situation soulève des préoccupations quant à savoir si l'évolution actuelle de l'arbitrage durera longtemps. Ce mémoire emprunte le terme  "développement durable" au droit de l'environnement et de l'économie, et il l'applique au droit de l'arbitrage international. En redéfinissant le terme "développement durable" en fonction des besoins de l'arbitrage international, ce mémoire propose une solution pour développer l'arbitrage sans mettre en péril les intérêts d'ordre public. Cette solution équilibre les intérêts privés et publics pour parvenir à un développement durable dans l'arbitrage international. </dc:abstract><ual:supervisor>Fabien Gélinas</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/g732dd46q.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/w6634708p</ual:fedora3Handle><dc:subject>Social Sciences - Law</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ad217qt30x"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Arts</schema:inSupportOf><dc:contributor>Department of Integrated Studies in Education</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Counterbalanced instruction in practice: integrating a focus on content into a foreign language classroom</dcterms:title><ual:dissertant>Morgan, Joy</ual:dissertant><dc:abstract>Cette étude examine la faisabilité et l'efficacité de l'intégration d'une concentration sur le contenu/le sujet dans un contexte principalement concentré sur la forme/la langue.  Le contexte choisi pour cette étude est une classe de français langue étrangère dans un lycée d'une petite ville rurale du nord-ouest de l'État de New York. Une intervention dans la salle de classe a été conduite avec 27 participants-étudiants et leur professeur de français. Cette intervention mettait en pratique un module (« une situation d'apprentissage et d'évaluation ») en français sur les problèmes environnementaux. L'étude a adopté des méthodes mixtes pour rassembler et analyser les données. Ces dernières ont été analysées au regard du contenu qualitatif aussi bien que par des analyses statistiques quantitatives. Les résultats ont indiqué que la mise en pratique d'un module basé sur l'instruction contrepoids dans une salle de classe de langue étrangère qui se concentre sur la langue est faisable, même s'il y a plusieurs défis.  En outre, cette approche peut soutenir le progrès des étudiants tant dans le contenu que dans la langue, en créant une connexion significative et profonde avec les étudiants. Mots-clés: l'approche du « contrepoids », l'enseignement des langues par le contenu (CBLT), l'instruction par le contenu (CBI), l'intégration d'une langue étrangère et une discipline non linguistique (DNL), l'enseignement de matières par intégration d'une langue étrangère (EMILE/CLIL en anglais), le français, la langue étrangère, l'enseignement des sciences, le contexte de salle de classe.</dc:abstract><dc:abstract>The present study examines the feasibility and effectiveness of integrating a focus on content/meaning into a predominantly form/language-focused French foreign language high school classroom context in rural, upstate New York. A classroom intervention was conducted with 27 student participants and their French teacher, implementing a French content-based unit on environmental issues.  The study used a mixed-methods approach for data collection and data analysis. Data were analyzed using both qualitative content-analyses and quantitative statistical analyses. Results indicate that implementing a counterbalanced content-based unit into a traditional form-focused foreign language classroom, while challenging on many levels, is feasible and has the added benefit of helping students progress in both content and language, while making a meaningful and deep connection with students. Keywords: counterbalanced instruction, content-based language teaching (CBLT), content-based instruction (CBI), content and language integrated learning (CLIL), French, foreign language, science education, classroom context.</dc:abstract><ual:supervisor>Roy Lyster</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/3b591c549.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/d217qt30x</ual:fedora3Handle><dc:subject>Education - Language and Literature</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Awp988p37g"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Distribution feeder reduction for dispersed generation applications</dcterms:title><ual:dissertant>George, Michael</ual:dissertant><dc:abstract>Electric power systems today are undergoing a paradigm shift in operational and market philosophy through technologies like distributed generation and the "smart grid." Decentralizing the power system and allowing users to inject power into the grid, however, introduces a wide array of problems, and much research has gone towards implementing a growing number of small generation sources throughout the existing electric power network infrastructure. This thesis describes the issues involved in reducing a typical rural distribution feeder to a model that can be used for distributed generation interconnection studies, particularly for islanding studies.</dc:abstract><dc:abstract>Nos systèmes de puissance électrique procèdent présentement à un changement de paradigme autant dans leurs philosophies opérationnelles que dans celles du marché grâce à des technologies telles que la génération distribuée et la plateforme «smart grid». Décentraliser le système d'énergie et permettre aux usagers d'injecter de l'énergie dans le réseau présente néanmoins de nombreux problèmes, et beaucoup de nouvelles études cherchent à établir un nombre croissant de petites sources de génération dans le cadre du réseau d'infrastructure d'énergie électrique existant présentement. Cette thèse décrit les questions liées à la réduction d'une artère de distribution rurale typique d'un modèle qui peut être utilisé pour des études d'interconnexion distribués génération, en particulier pour les études îlotage.</dc:abstract><ual:supervisor>Geza Joos</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/gt54kr494.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/wp988p37g</ual:fedora3Handle><dc:subject>Engineering - Electronics and Electrical</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A5h73q058c"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Chemical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Granular polymer nanocomposites</dcterms:title><ual:dissertant>Mohaddes pour, Ahmad</ual:dissertant><dc:abstract>Contrairement aux théories classiques, les nanoparticules ont été utilisées pour diminuerla viscosité de volume lorsqu'elles sont dispersées dans un mélange de polymère, et pour augmenter la perméabilité de la membrane et la sélectivité lorsqu'elles sont incorporées dans certains verres polymères amorphes. Cependant, les effets sur la concentration des particules, sur la taille des particules et sur la configuration des polymères à particules inter faciales ne sont pas bien compris. Afin de comprendre comment la taille des particules, la longueur de la chaîne, et les différentes compositions influencent l'assemblage des chaines de polymères et, par conséquent, le volume libre — qui est connu principalement pour agir sur les propriétés rhéologiques et d'infiltration despolymères nanocomposites—le volume de sphères acryliques (représentant les nanoparticules) couplé avec les chaînes de billes d'aluminium (ce qui représente des chaînes de polymère) a été mesurée, et le volume molaire partiel des sphères a été calculée à partir depetit volume fini . Les résultats montrent que le rayon de la sphère par rapport à la taille dela boucle de la chaîne minimum est le paramètre qui affecte principalement la dimensiondu volume de mélange libre. De plus, le volume libre est maximale—jusqu'à deux fois levolume de l'inclusion intrinsèque par particule—lorsque le rayon de la sphère et la taille minimum de la boucle de la chaîne sont comparables, ce qui est d à l'augmentation des interactions dans la chaîne de la sphère, alors que les interactions sphère-sphère diminuent le volume du mélange libre lorsque les particules sont grandes. Il a également été déterminé que, en présence de nanoparticules, le volume libre et l'architecture de la chaîne du polymère jouent un rôle déterminant en influençant la température de transition vitreuse des polymères nano composites. La raison ostensible pour la diminution dela température de transition vitreuse des polymères nano composites est connue pour tre la répulsion entre les chaînes des nanoparticules. Toutefois, en l'absence d'interactions enthalpiques, c'est encore élusif de comment et pourquoi la température de transition vitreuse baisse avec le chargement des nanoparticules. Pour étudier l'influence des nanoparticules sur la dynamique de relaxation de la chaîne et, par conséquent, la température de transition de verre nanocomposite, le temps de relaxation (le temps d'atteindre l'état bloqué) de la chaine du mélange de granulés a été mesurée en changeant systématiquement la taille et la longueur de la sphère et le mélange de la composition. D'avoir mesurer la dynamique de compactage révèle que les inclusions sphériques influencent profondément le temps de relaxation de la chaîne lors de la séparation des nanoparticules caractéristiques ainsi que la taille des nanoparticules est comparable à la taille de la boucle de chaîne. Cette étude nous éclaire sur l'architecture des polymères en présence de nanoparticules, en particulier lorsque les chaînes sont très longues et par conséquent, au-delà de la capacité des simulations informatiques actuels pour être explorées à fond. Ce modèle macroscopique granulaire peut aussi être utilisé pour optimiser la conception de polymères nanocomposites par un choix judicieux de la taille des nanoparticules, de la longueur de la chaîne et la composition du mélange pour des applications industrielles et biomédicales.</dc:abstract><dc:abstract>Contrary to classical theories, nanoparticle dispersion in polymer melt has been shown to decrease the bulk viscosity, and to increase the membrane permeability and selectivity when incorporated into certain amorphous polymer glasses. However, the effects of particle concentration, particle size, and polymer configuration at particle interfaces are not well understood. To elucidate how the particle size, chain length, and mixture composition influence polymer-chain packing and, thus, free volume---which is known to primarily influence rheological and permeation properties of polymer nanocomposites---the volume of acrylic spheres (representing nanoparticles) mixed with aluminum ball chains (representing polymer chains) was measured, and the partial molar sphere volume at small but finite sphere volume fractions was calculated. The results show that the sphere radius with respect to the minimum chain loop size is the primary dimensionless parameter that affects mixture free volume. Moreover, free volume is maximal---up to twice the intrinsic inclusion volume per particle---when the sphere radius and the minimum chain loop size are comparable, which is because of the increase in sphere-chain interactions, whereas sphere-sphere interactions decrease the mixture free volume when particles are large. It was further determined that, in the presence of nanoparticles, free volume and polymer chain architecture play a determinative role in influencing the glass transition temperature of polymer nanocomposites. The reason for the decrease in the glass transition temperature of polymer nanocomposites is known to be the repulsive chain-nanoparticle interactions. However, in the absence of enthalpic interactions, it is still elusive how and why the glass transition temperature declines with nanoparticle loading. To examine the nanoparticle influence on chain relaxation dynamics and, thus, nanocomposite glass transition temperature, the relaxation time (the time to reach the close-packed, jammed state) of granular chain-sphere mixtures was measured by systematically changing the sphere size, chain length, and mixture composition. Measuring the compaction dynamics reveals that spherical inclusions profoundly influence the chain relaxation time when the characteristic nanoparticle separation and nanoparticle size are comparable to the chain loop size. This study can shed light on polymer architecture in the presence of nanoparticles, especially when chains are very long and, thus, beyond the capability of current computer simulations. This macroscopic, granular model can also be used to optimize the design of polymer nanocomposites by a judicious choice of nanoparticle size, chain length, and mixture composition for industrial and biomedical applications.</dc:abstract><ual:supervisor>Reghan James Hill</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/08612s037.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/5h73q058c</ual:fedora3Handle><dc:subject>Engineering - Chemical</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Axd07gx15b"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Parallel vector fitting of systems characterised by measured or simulated data</dcterms:title><ual:dissertant>Song, Yidi</ual:dissertant><dc:abstract>During the past decade, technology in the electronics industry has advanced considerably. The integrated circuits we are using today are becoming more and more complex. As a result, modeling those complex systems has become a difficult task. The vector fitting method is a very efficient tool for building a model based on measured or simulated data. However, for large scale systems, the vector fitting method runs slowly or even fails to converge at the end. One of the solutions to the problem is the parallel vector fitting which was introduced a few years ago. Recently, the parallel computing and cloud computing have become more popular. It would be much more efficient if we can use the concept of parallel computing to do the vector fitting. Since each column in the admittance matrix Y is independent from each other. Calculations on one column will not affect the results of another column. Thus, we can do multiple column vector fittings at the same time. This concept leads to the idea of doing the vector fitting in a parallel way. During the algorithm, many columns are being vector fitted at the same time. There is one small model for each column. After all columns are done, an extra routine will be executed to combine all sub-models into one complete model. In this way, we can achieve a descent speedup factor which leads to less total computing time. The final model is verified so that it is as accurate as the one generated by the traditional vector fitting. In this thesis, detailed concepts will be presented. Methods will be explained step by step and examples will be tested and analyzed.</dc:abstract><dc:abstract>Au cours des dix dernières années, la technologie dans l'industrie d'électronique a avancé fortement. Le circuit intégré que nous utilisons aujourd'hui est devenu de plus en plus complexe. En conséquence, la modélisation de ces systèmes complexes est devenue une tâche difficile. Le vector fitting est un outil très efficace pour la construction d'un modèle basé sur des données mesurées ou simulées. Cependant, pour le système sur une grande échelle, le montage vecteur fonctionne lentement ou n'arrive même pas à obtenir de résultat à la fin. Une des solutions à ce problème est le vector fitting parallèle qui a été introduit il ya quelques années. Récemment, le calcul parallèle et le cloud computing sont devenus plus populaires. Il serait beaucoup plus efficace si nous pouvons utiliser le concept de calcul parallèle pour faire le vector fitting. Étant donné que chaque colonne de la matrice admittance Y est indépendante de l'autre. Travailler sur une colonne n'affectera pas les résultats d'une autre colonne. Ainsi, nous pouvons faire plusieurs de vector fitting de colonne en même temps. Ce concept conduit à l'idée de vector fitting parallèle. Au cours de l'algorithme, de nombreuses colonnes sont muni vecteur en même temps. Il y a un petit modèle pour chaque colonne. Après toutes les colonnes sont faites, une routine supplémentaire sera exécuté à combiner tous les sous-modèles dans un modèle complet. De cette façon, nous pouvons parvenir à une application plus rapide et il y aura moins de temps d'exécution. Le modèle final est vérifié pour être sûr qu'il soit aussi précise que la seule tradition. Dans cette thèse, les concepts détaillés seront présentés. Le méthode sera expliquée étape par étape et les exemples seront testés et analysés.</dc:abstract><ual:supervisor>Roni Khazaka</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/ms35tc66q.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/xd07gx15b</ual:fedora3Handle><dc:subject>Engineering - Electronics and Electrical</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Apn89d991f"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Integrated Program in Neuroscience</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Brain regions involved in heading estimation and steering control in a virtual environment</dcterms:title><ual:dissertant>Liu, Anita</ual:dissertant><dc:abstract>L'indentification des régions du cerveau humain, requises pour juger la direction choisie et s'orienter activement vers notre but, pourrait aider à comprendre le fait que ceux qui ont eu un AVC ont des difficultés avec la locomotion orientée vers un but.  Des études antérieures ont démontré que lorsque nous marchons dans un environnement avec des textures riches, nous utilisons principalement le flux optique, un modèle de mouvement d'expansion radiale, pour discerner avec précision la direction choisie et de se diriger vers une cible. Le but de cette étude était d'investiguer quelles régions du cerveau sont impliquées dans la discrimination et dans le contrôle de la direction (pilotage) en utilisant un environnement virtuel écologique qui ressemble à la plupart des environnements dans lesquels nous évoluons dans la vie quotidienne. Quatorze personnes (7 hommes, 7 femmes) ont participé à une étude de IRMf où leurs réponses BOLD ont été mesurées pendant qu'ils complétaient une tâche de discrimination et une tâche active de pilotage à l'aide d'une manette de commande, en réponse à des flux optiques de différentes directions. Une inférence de groupe a été réalisée et ceux statistiquement significatifs au-dessus d'un seuil de Z=4  (p&lt;0.01) ont été identifiés. Cette étude portait sur les régions du cerveau qui ont affiché des réponses BOLD plus élevées dans les tâches de discrimination de la direction et de pilotage, indépendamment des réponses motrices associées aux mouvements de la manette de commande. Le sillon interpariétal (divisions antérieure et postérieure) a été impliqué bilatéralement dans la tâche de discrimination et une activation bilatérale du cervelet postérieur a été observée dans la tâche pilotage. D'autres analyses ont démontré que le complexe hMT+ et V2, des régions impliquées dans le traitement du flux optique, des régions bilatérales dans le cervelet, le cortex prémoteur et l'aire motrice supplémentaire présentaient des réponses BOLD plus élevées dans la tâche de pilotage que dans la tâche de discrimination. Ces résultats suggèrent que même si la discrimination de la direction implique un certain degré d'intégration sensorimotrice et de traitement du flux optique, le pilotage est une tâche plus exigeante nécessitant davantage de régions du cerveau pour transformer les informations dynamiques du flux optique en réponses motrices adaptées aux exigences contextuelles.</dc:abstract><dc:abstract>The brain regions required for judging heading direction and actively steering towards a goal could be damaged by stroke. Identifying the neural correlates responsible for goal-directed locomotion is important for the understanding of the mechanism underlying neuroplasticity and functional recovery. Past research shows that when we are walking through a texture-rich environment, we primarily use optic flow, a radially expanding pattern of motion, to accurately discriminate our heading direction and steer towards a goal. The purpose of this study was to investigate the different brain regions involved in heading discrimination and steering using an ecological virtual environment, mimicking most environments we walk through in everyday life. Fourteen participants (7 males, 7 females) took part in an fMRI study where their BOLD responses were measured while they completed a heading discrimination and active steering tasks using a joystick. A cluster level inference was conducted and clusters that were statistically significant above a threshold of Z=4 (p&lt;0.01) were identified. This study investigated which brain regions display higher BOLD responses in the heading discrimination and steering task, independent of motor movements from joystick input. Consistent with previous studies, the bilateral intraparietal sulcus is involved in heading discrimination and bilateral posterior cerebellum was observed in the steering task. Further analysis revealed that the hMT+ and V2, the bilateral cerebellum, supplementary eye fields, premotor cortex, and supplementary motor area, displayed higher BOLD responses in the steering task than in the heading discrimination task. These results suggest that although heading discrimination involves a certain degree of sensorimotor integration and optic flow processing, steering is a more demanding task, requiring more brain regions to transform dynamic optic flow information into context-adapted motor responses. </dc:abstract><ual:supervisor>Anouk Lamontagne</ual:supervisor><ual:supervisor>Richard Hoge</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/r781wk49n.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/pn89d991f</ual:fedora3Handle><dc:subject>Biology - Neuroscience</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A9593tz661"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>School of Information Studies</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Preserving the intelligibility of digital archives of contemporary music with live electronics: a theoretical and practical framework</dcterms:title><ual:dissertant>Boutard, Guillaume</ual:dissertant><dc:abstract>Cette recherche a pour objectif de fournir un cadre théorique et pratique de préservation des artéfacts numériques tout spécialement orienté vers la pérennité du répertoire de musique contemporaine avec électronique en temps réel. La pérennité de la musique instrumentale repose sur l'organologie des instruments de musique, l'enseignement de la pratique instrumentale, et la notation musicale, qui dans notre contexte sont remis en cause par plusieurs facteurs : l'obsolescence rapide des logiciels idiosyncratiques de traitement du signal en temps réel, le contexte social complexe de production de ces artéfacts numériques, et la difficulté à fournir une notation prescriptive. Cette recherche questionne l'impact de ces problématiques sur la théorie et les modèles des archives numériques autour d'un intérêt particulier pour le contexte socialde création des objets numériques. La première étude élabore un cadre conceptuel pour la préservation de l'intelligibilité des artéfacts numériques. Pour ce faire, elle part de la notion de propriétés significatives pour l'étendre à la notion de connaissances tacites à travers la proposition de définition et d'opérationnalisation des connaissances significatives impliquées dans la production des artéfacts numériques. Cette étude a donc fourni une opérationnalisation d'un modèle de gestion des connaissances en vue du processus de documentation. Un questionnaire en ligne a été disséminé auprès de la communauté des compositeurs en musique électroacoustique et mixte afin de recueillir des données relatives à cette opérationnalisation. Des méthodes statistiques non-paramétriques ont été utilisées afin d'évaluer la pertinence du modèle. Nos résultats mettent en lumière les bénéfices de l'utilisation du modèle pour la préservation du répertoire et le potentiel d'expansion de cette opérationnalisation à d'autres contextes artistiques. La deuxième étude propose une formalisation du processus créatif soutenant la production des objets numériques dans le contexte des oeuvres de musique contemporaine avec électronique en temps réel. L'analyse des données repose sur la théorie ancrée, appliquée à des données secondaires de type ethnographique (entrevues, enregistrement vidéo des séances de travail et rapports écrits) d'un processus créatif multi-agents. Les résultats de cette étude montre un riche réseau de concepts catégorisant le processus créatif des oeuvres de musique contemporaine avec électronique en temps réel qui montre les faiblesses potentielles d'une documentation basée sur les théories musicales courantes. Cette étude permet d'étendre les limites de la notion d'artéfacts numériques à un contexte social plus large qui implique plusieurs agents, humains et non-humains, impliqués dans les processus créatifs. La troisième étude modélise l'impact des deux précédentes études en termes de modèles d'archives numériques. Plus spécifiquement, elle modélise l'impact sur le modèle OAIS (Open Archival Information System). Le résultat est un cadre pratique centré sur la relation entre les processus créatifs et les objets numériques pendant leur cycle de vie d'archives. Ce cadre pratique contribue à la formalisation du lien entre producteuret archives numériques afin de mieux spécifier des politiques d'acquisition et d'évaluation dans le contexte des archives de musique contemporaine avec électronique en temps réel. De par l'utilisation récente des technologies de traitement du signal en temps réel dans d'autres domaines artistiques, comme la danse, le théâtre, et les installations, les résultats, en termes de méthodologie et de modélisation, sont susceptibles d'avoir un impact plus large que le contexte de cette recherche. Sur la base de ces études, nous proposons une extension de la notion archivistique de performance des archives numériques, qui inclue un réseau social multi-agent, qu'ils soient humains ou non-humains, et qui se répercute sur la préservation de l'intelligibilité des objets numériques.</dc:abstract><dc:abstract>This research provides a theoretical and practical framework for the preservation of digital artifacts with a focus on the sustainability of the repertoire of contemporary music with live electronics. The sustainability of instrumental music relies on the organology of musical instruments, the teaching of instrumental practices, and musical notation. In the context of music with live electronics, these three principles are challenged by several factors: the rapid obsolescence of idiosyncratic software for live electronics, the complex social context of the production of these digital artifacts, and the difficulty in providing a prescriptive notation. This thesis investigates the impact of these issues on digital archives theory and models and further conceptualises the notion of performance of digital archives with a focus on the sociological context of digital object creation. This research is divided into three complementary studies at the intersection of three research fields: digital archives, knowledge management, music research. The first study provides a conceptual framework for preserving the intelligibility of digital artifacts. It builds on the notion of significant properties and proposes a framework for significant knowledge, which accounts for the tacit dimension of the knowledge involved in the production of these artifacts. A knowledge management model was selected and operationalised in the context of documentation process of electroacoustic and mixed music. We invited composers to respond to an online survey to test the operationalisation of the model and relied on non-parametric statistics to evaluate its relevance. Our findings highlight the benefits of using this model for contemporary music preservation and the potential for expanding this operationalisation to other artistic contexts. The second study focusses on the specification of the creative process underlying the production of digital artifacts. We applied grounded theory to secondary ethnographic data (including interviews, video recordings of work sessions and written reports) of a 2-year creative process of a string quartet with live electronics. The actors included the composer, the computer music designer, performers, researchers and engineers. The outcome of this study is a rich multi-level categorisation of the creative process of a contemporary work with live electronics, which stresses the limits of standard a posteriori documentation and shows the potential lacks in a documentation based on current music theories. This study provides an extension of the notion of digital artifacts to a broader sociological context accounting for both human and non-human agents involved in the creative process. The third study models the main findings of both previous studies in terms of digital archives, specifically extending the OAIS (Open Archival Information System). We propose a practical framework accounting for the relationship between creative processes and digital objects during their archival lifecycle. This framework contributes to formalising the link between data producers and digital archives, in order to better relate to ingestion and appraisal policies in the context of archives of contemporary music with live electronics. The methodological, theoretical and practical outcomes of this research may benefit other contexts, as live electronics have garnered increased interest in a wide range of artistic domains including dance, theatre and art installations. We further conceptualise the archival notion of performance of digital archives with a social extent involving both human and non-human agents, which has an impact on maintaining the intelligibility of digital objects.</dc:abstract><ual:supervisor>James M. Turner</ual:supervisor><ual:supervisor>Catherine Guastavino</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/qj72pb81j.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/9593tz661</ual:fedora3Handle><dc:subject>Communications And The Arts - Information Science</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ax059cb85z"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Engineering</schema:inSupportOf><dc:contributor>Department of Mechanical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Machining and characterization of structural components of a Rankine micro-turbine</dcterms:title><ual:dissertant>Neill, Denten</ual:dissertant><dc:abstract>La microturbine Rankine est un microsystème de récupération d'énergie qui convertie un surplus de chaleur en énergie mécanique et électrique à l'aide d'un cycle fermé Rankine qui utilise de l'eau comme fluide. L'appareille est une structure rectangulaire à 5 couches, les dimensions de l'ensemble  sont de 1.5 cm x 1.5cm x 1.75 mm. La couche centrale contient deux structures : un rotor qui a un diamètre de 4 mm  et un isolant thermique. L'alliage de titan Ti-6Al-4V a été identifié comme un matériel idéal pour les deux composantes. À l'aide d'une revue de la littérature et des essais d'usinages il peut être conclu que l'usinage par laser ne permet pas d'atteindre les géométries, dimensions et tolérances requises.  De son côté, l'usinage 5-axes CNC a été capable d'usiner un isolant thermique provenant d'une plaque de Ti-6Al-4V avec une épaisseur de 0.4 mm. En parallèle, une station de test thermique a été conceptualisée et bâtie pour maintenir des gradients de température de l'ordre de 100 oC/mm. Des cartouches chauffantes encrées dans un bloc de cuivre on servies comme plaque chauffante et une plaque refroidissante à base de cuivre a permis de maintenir les gradients de température élevés. Ce mécanisme peut être intégré au système existant qui permet de caractériser les pompes, les joints d'étanchéité et le rotor de la microturbine. Le tout de cette thèse réussit à contribuer à l'avancement de l'usinage et de la caractérisation structurale des composantes de la microturbine.</dc:abstract><dc:abstract>The Rankine micro-turbine is a miniaturized energy harvester for converting waste heat into mechanical and electrical energy by implementing the closed-loop Rankine cycle with water as the working fluid. The device is a five-layer structurewith the geometry of a rectangular cuboid with overall dimensions of 1.5cm x 1.5cm x 1.75mm. The central layer contains two critical components, namely, a disc-shaped rotor with a diameter of 4mm and a thermal insulator. The titanium alloy Ti-6Al-4V has been identified as the optimal material for both components. By combining a detailed literature survey with experimental studies, it was concluded that laser micro-machining is unsuitable for achieving the size, geometry, and tolerance required for these components. In contrast, a 5-axis CNC micro-machining station was able to machine the thermal insulator using a 4mm thick plate of the titanium alloy. In parallel, a thermal test station was designed and assembled to establish a large temperature gradient on the order of 100◦Cmm−1across the Rankine micro-turbine. During testing, the hot side of the micro-turbine is placed in contact with a copper block containing embedded cartridge heaters, and the cold side with a water-cooled cold plate. This station can enable detailed experimental characterization of the rotor, pumps and seals during the operation of the device. Taken together, this thesis makes a contribution to the machining and characterization of the structural components of the Rankine micro-turbine.</dc:abstract><ual:supervisor>Srikar Vengallatore</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/dz010t48m.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/x059cb85z</ual:fedora3Handle><dc:subject>Engineering - Mechanical</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ax346d756r"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Chemistry</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Photophysical properties of single and double stranded DNA containing 6-phenylpyrrolocytosine (PHPC)</dcterms:title><ual:dissertant>Azizi, Fereshteh</ual:dissertant><dc:abstract>La spectroscopie de fluorescence s'est avérée une technique précieuse pour étudier la structure et la fonction des acides nucléiques et d'autres molécules essentielles en biologie cellulaire. À cet égard, les analogues de nucléoside fluorescentes intrinsèques sont largement utilisés pour sonder les propriétés structurales et dynamiques des acides nucléiques. À cause de ses propriétés émissives uniques, 6-phénylpyrrolo-2'-déoxycytosine (dPhpC), un nouvel analogue fluorescent de la déoxycytosine, est un reporter fluorescent approprié qui a été exploitée pour étudier la structure, la dynamique et la localisation des acides nucléiques. dPhpC possède plusieurs propriétés souhaitables, notamment le rendement quantique élevé et une sensibilité à des changements dans le micro-environnement environnant. Compte tenu de la demande croissante de discrètes sondes fluorescentes pour utilisation dans des études biochimiques, dPhpC est un fluorophore attrayant qui imite la cytosine par rapport au couplage d'acide nucléique de base et les interactions enzymatiques. Pour utiliser cette sonde moléculaire à son plein potentiel, il est essentiel d'élucider les interactions entre dPhpC et ses nucléotides voisins inter- et intra-brin, et l'effet de ces interactions sur les propriétés fluorescentes de dPhpC. Avec cette information, dPhpC peut être utilisé comme une sonde moléculaire très sensible pour l'étude d'une grande variété des systèmes à base de acides nucléiques, et les oligonucléotides fluorescentes contenant du PhpC peuvent être facilement optimisé à des fins spécifiques. Dans cette thèse, nous avons synthétisé 6-phénylpyrrolo-2'-désoxycytidine (dPhpC) et l'ont incorporé dans l'ADN simple et double brin. Ce travail démontre que la nature et l'orientation des voisins nucléosidiques entourant dPhpC affecter de manière significative ses propriétés fluorescentes. Selon les résultats présentés dans ce travail, les rendements quantiques de fluorescence moyenne pour dPhpC contenant des simples brins est supérieure à celles de leurs doubles brins correspondants. Plusieurs règles pour la prédiction et l'optimisation des propriétés des oligonucléotides contenant dPhpC sont également identifiées: l'adénine voisin entraîne une augmentation significative de l'intensité de fluorescence de dPhpC, la guanine plus efficacement étanche fluorescence, et l'orientation des voisins autour dPhpC affecte de manière significative le rendement quantique de dPhpC (par exemple l'effet d'extinction de la guanine est plus élevée lorsqu'il est placé à l'extrémité 3 'du côté dPhpC). Dans l'ensemble, nos études permettez-nous de prévoir mieux les changements de fluorescence de dPhpC sur l'incorporation en structures d'ADN, ce qui facilite grandement la conception d'optimisation dPhpC contenant des sondes d'acides nucléiques pour utilisation dans une grande variété d'études de fluorescence.</dc:abstract><dc:abstract>Fluorescence spectroscopy has proven a valuable technique for studying the structure and function of nucleic acids and other essential molecules in cellular biology. In this regard, intrinsic fluorescent nucleobase analogues are widely used to probe structural and dynamic properties of nucleic acids. Due to its unique emissive properties, 6-Phenylpyrrolo-2'-deoxycytosine (dPhpC), a novel fluorescent deoxycytosine analog, is a suitable fluorescent reporter that has been exploited to study the structure, dynamics and localization of nucleic acids. dPhpC possesses several desirable properties, including high quantum yield and sensitivity to changes in the surrounding microenvironment. Given the increasing demand for unobtrusive fluorescent probes for use in biochemical studies, dPhpC is an attractive fluorophore that mimics cytosine with respect to nucleic acid base pairing and enzyme interactions. To use this molecular probe to its full potential, it is essential to elucidate the interactions between dPhpC and its inter- and intra-strand neighbouring nucleotides, and the effect of these interactions on the fluorescent properties of dPhpC. With this information in hand, dPhpC can be employed as a highly sensitive molecular probe for studying a wide variety of nucleic acid-based systems, and fluorescent PhpC-containing oligonucleotides can be readily optimized for specific purposes.In this thesis, we synthesized 6-phenylpyrrolo-2'-deoxycytidine (dPhpC) and incorporated it into single and double stranded DNA. This work demonstrates that the nature and orientation of nucleoside neighbours surrounding dPhpC significantly affect its fluorescent properties.  According to the results presented in this work, the average fluorescence quantum yields for dPhpC-containing single strands is greater than those of their corresponding double-strands. Several rules for predicting and optimizing the properties of dPhpC-containing oligonucleotides are also identified: neighboring adenine causes a significant increase in dPhpC fluorescent intensity, guanine most effectively quenches fluorescence, and the orientation of neighbors around dPhpC significantly affects dPhpC quantum yield (e.g. the quenching effect of guanine is higher when it is placed at the 3'-side of dPhpC). Overall, our studies allow us to better predict dPhpC fluorescence changes upon incorporation in DNA structures, greatly facilitating the design of optimized dPhpC-containing nucleic acid probes for use in a wide variety of fluorescence studies.</dc:abstract><ual:supervisor>Masad J. Damha</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/ht24wn79h.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/x346d756r</ual:fedora3Handle><dc:subject>Chemistry - Organic</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ac821gp33c"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Mechanical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Dynamic analysis of rovers and mobile robots</dcterms:title><ual:dissertant>Hirschkorn, Martin</ual:dissertant><dc:abstract>Beaucoup de techniques ont été développées pour l'analyse et l'étude des  systèmes mécaniques. Puisque la modélisation des interactions entre les roues et le sol est essentielle pour la modélisation du comportement des robots mobiles, les travaux portant sur des systèmes fixes ne sont pas a priori applicables aux robots mobiles.  Cette thèse porte sur des concepts importants pour l'analyse de robots mobiles. Les premières évaluations des techniques actuelles de simulation numériques ont montré que, si elles pouvaient modéliser précisément des robots mobiles, elles ne pouvaient souvent que simuler la dynamique et étaient insuffisantes pour des analyses plus poussées. Les recherches ont ensuite montré que les modèles utilisant la dynamique des sols étaient les mieux adaptés pour la modélisation des interactions entre les roues et le sol. Après avoir étudié plusieurs concepts utilisés pour caractériser la mobilité, deux nouvelles mesures ont été proposées (la force maximale nette de traction, et le potentiel d'accélération) qui se sont révélés utiles pour fournir en temps réel des indications sur les capacités d'un robot mobile. Une nouvelle méthode a été proposée pour l'analyse de la matrice des masses d'un système mécanique ainsi que quatre concepts apportant des renseignements sur les masses effectives et le couplage dynamique d'un mécanisme: l'inertie effective verrouillée, le couplage de forces, l'inertie effective libre, et le couplage de l'accélération. Enfin, la formulation de l'espace opérationnel, qui est principalement utilisé dans le domaine des manipulateurs, a été étudié et étendu au domaine de la robotique mobile. Il a été constaté l'utilité de représentations appropriées et spécifiques de l'espace opérationnel pour le contrôle et l'estimation du mouvement de robots mobiles.</dc:abstract><dc:abstract>Many techniques have been developed for the purpose of analyzing and evaluating mechanical systems for the purpose of improving design and control. Such work is not necessarily applicable to mobile rovers, since the wheel-ground contact, which does not exist for fixed-base systems, plays a critical role in the behaviour. This thesis investigates important concepts related to analyzing rovers. In initial investigations of existing methods, it was found that current numerical simulation tools can efficiently model rovers, but are often limited to forward dynamics simulations, and are not suitable for more in-depth analyses. Additional investigations were performed to determine which contact models could be used, and it was found that wheel--ground behaviour was best captured using terramechanics-based models. Several concepts relating to defining mobility were investigated, and two new measures were proposed (maximum net traction force, and accelerability), which were found to provide useful, real-time indications of a rover's capability. A novel method was proposed for analyzing the mass matrix of a mechanical system and four concepts were presented that provide information relating to the effective masses and dynamic coupling of a mechanism: locked effective inertia, force coupling, free effective inertia, and acceleration coupling. Finally, the operational space formulation, an important concept primarily used in the field of manipulators, was investigated and extended to be used with rovers. It was found to be a useful method of evaluating and controlling rovers with the appropriate selection of the operational space representation.</dc:abstract><ual:supervisor>Jozsef Kovecses</ual:supervisor><ual:supervisor>Marek Teichmann</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/8p58ph35x.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/c821gp33c</ual:fedora3Handle><dc:subject>Engineering - Mechanical</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ap8418r737"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Animal Science</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>A proposed framework for analytical processing of information in the dairy industry using multidimensional data models</dcterms:title><ual:dissertant>Ghaffar, Aisha</ual:dissertant><dc:abstract>In the dairy industry, datasets pertaining to the milk recording of cows can be extremely large and complex, especially in the Province of Quebec where management and feed information are also collected for on-farm advising. Any subsequent analysis of these data for strategic (or even tactical) decision making is often impeded by the transactional nature of the existing databases, whose main purpose is often to produce regular and routine reports. Since conventional database management systems mostly support simple and short queries and flat views of data, they are less than ideal for the analysis of large datasets, particularly those which contain data of varying dimensions. In recent years, the high value of multidimensional data has been recognized as an important resource in both the academic and business communities. The wider recognition of data warehousing and On-Line Analytical Processing (OLAP) applications has highlighted their importance. The dairy industry is an excellent example of an area where the analysis of its data, and the subsequent decision-making process, could significantly benefit from the implementation of data warehousing and OLAP techniques. While these technologies have already been used to good advantage for the analysis of business data, the unusual nature of dairy data poses certain challenges which are addressed in this study. These include selection of a data model which best suits the hierarchical nature of the data, selection of the highest and lowest hierarchy for data aggregation, and the definition of functions (pre-aggregation) to improve query performance. In order to investigate the use of an OLAP system for Quebec milk-recording data, a number of multidimensional data models were compared. The star, snowflake and fact-constellation schemes each displayed advantages and disadvantages for the particular data (and their structure) in this study. The star schema did not support many-to-many relationships between fact and dimension tables, and creating combination dimensions (e.g., herd_cow) with a key (such as herd_cow_testdate), resulted in an unmanageable record length in the dimension table, thus rendering the model impractical. Many-to-many relationships were captured by a snowflake schema, by normalizing herd, cow and test day dimensions. In order to achieve an exact aggregation of milk components on each test day and for each cow, a herd_cow bridge dimension was implemented within a snowflake model which had a composite key of herd and cow. The lowest granularity level was test day and the highest was herd, but data could also be rolled up to regions. Queries could subsequently be directly executed on a cube structure, since data were stored in a multidimensional online analytical processing (MOLAP) server. All of the pre-aggregation was typically based on the milk-production test date, but could also support analysis at the individual cow level. The cube structure supports "drill down", "roll up", and "slice and dice" operations as an aid to the data analyses. Data could also be exported to Excel pivot tables as a means of simple overview reporting. It is felt that the examination of these technologies, and their future implementation, may lead to increased value for the dairy industry as their large quantities of data are explored for better management and strategic decision making.</dc:abstract><dc:abstract>Les ensembles de données de contrôle laitier peuvent être extrêmement vastes et complexes, en particulier dans la province de Québec où des données d'alimentation sont également collectées pour le service conseil. Une fois ces données collectées, leur analyse pour la prise de décision est souvent entravée par la nature transactionnelle des bases de données existantes, dont le principal objectif est de produire des rapports routiners. Puisque les systèmes classiques de gestion de bases de données servent principalement à des requêtes simples et courtes et à des vues simplifiées de données, ils sont loin d'être idéaux pour l'analyse de grands ensembles de données, en particulier ceux qui contiennent des données avec de multiples dimensions. Dans les dernières années, les données multidimensionnelles ont été reconnues comme une ressource importante tant dans les divers milieux d'affaires. Une plus large reconnaissance de l'entreposage de données et de techniques d'analyse comme le traitement analytique en ligne  (traduction de On-Line Analytical Processing ou OLAP) a aussi mis en évidence l'importance de ces données. L'industrie laitière est un excellent exemple d'un domaine où l'analyse de ses données et les prises de décision qui en découlent pourraient grandement bénéficier de la mise en œuvre d'entrepôts de données et de techniques OLAP. Bien que ces technologies aient déjà été utilisées pour l'analyse de données dans certaines autres industries, la nature des données laitières pose certains défis qui sont abordés dans cette étude. Ceux-ci comprennent la sélection d'un modèle de données qui convient le mieux à la nature hiérarchique des données, la sélection des niveaux hiérarchiques les plus élevés et les plus bas pour l'agrégation des données, et la définition des fonctions de pré-agrégation pour améliorer les performances des requêtes. Afin d'étudier l'utilisation d'un système OLAP pour les données de contrôle laitier, un certain nombre de modèles de données multidimensionnelles ont été comparés. Les modèles en étoile, flocon de neige et constellation ont chacun démontré des avantages et des inconvénients pour afficher les données (et leur structure) dans cette étude. Le schéma en étoile n'a pas supporté les relations plusieurs-à-plusieurs entre les tables de faits et de dimension, et la création de dimensions combinées (e.g., troupeau_vache_date-de-test) avec une clé a entraîné une longueur d'enregistrement dans la table de dimension qui était très difficile à gérer, rendant ainsi le modèle impraticable. Les relations plusieurs-à-plusieurs ont été capturées par un schéma en flocon, en normalisant les dimensions troupeau, vache et date de test. Afin de réaliser une agrégation exacte des composants du lait à chaque jour de test et pour chaque vache, une dimension pont troupeau_vache a été développée au sein d'un modèle en flocon de neige qui avait une clé composée troupeau-vache. Le plus bas niveau de granularité était la date de test et le niveau le plus élevé était le troupeau, mais les données pouvaient également être agrégées au niveau de la région. Une fois le modèle implanté et les données stockées sur le serveur suivant une approche multidimensionnelle OLAP (MOLAP), les requêtes pouvaient ensuite être exécutées directement sur la structure de cube. Toutes les pré-agrégations ont été généralement fondées sur la date de test, mais elles pouvaient également supporter l'analyse au niveau de chaque vache. La structure du cube permettait les opérations d'analyse par désagrégation (drill-down), agrégation (drill-up) et blocs de données (slicing). Les données pouvaient également être analysées dans des tableaux croisés dynamiques à l'intérieur d'un chiffrier électronique. L'utilisation éventuelle de ces technologies par l'industrie laitière pourrait accroître la valeur du grand volume de données disponibles et augmenter leur utilisation pour améliorer la gestion et la prise de décision stratégique.</dc:abstract><ual:supervisor>Kevin Wade</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/3n204256k.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/p8418r737</ual:fedora3Handle><dc:subject>Agriculture - General</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A3b591c55k"><ual:graduationDate>2013</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Chemistry</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Synthesis and biological evaluation of 2- aminothiophene and benzothiazole derivatives as isoprenoid biosynthesis inhibitors</dcterms:title><ual:dissertant>Langille, Adrienne</ual:dissertant><dc:abstract>The condensation of stable 2-(1-(trimethylsilyl)ethylidene)malononitrile with elemental sulfur was explored in the parallel-synthesis of a small library of structurallydiverse2-aminothiophenesandthieno[2,3-d]pyrimidines. Bromination and ipso-iododesilylation of these heterocyclic scaffolds provided synthetic methods to efficiently generate key intermediates, allowing for great versatility. Bisphosphonic acid derivatives of thieno[2,3-d]pyrimidine and benzothiazole scaffolds, with favourable physicochemical properties, were evaluated for their ability to inhibit isoprenoid biosynthesis and potentially modulate the function of small G-proteins implicated in a range of human diseases. Preliminary biological activities and selectivity will be presented.</dc:abstract><dc:abstract>La condensation de 2-(1-(trimethylsilyl)ethylidene)malononitrile avec du soufre élémentaire a été explorée dans le parallèle synthèse d'une petite group de structures diverses de 2-aminothiophenes et thieno[2,3-d]pyrimidines. Bromation et ipso-iododesilylation de ces échafaudages hétérocyclique fourni des méthodes de synthèse pour générer efficacement des intermédiaires clés, ce qui permet une grande polyvalence. Dérivés d'acide bisphosphonique de thieno[2,3-d]pyrimidines et échafaudages benzothiazole, avec de bonnes propriétés physico-chimiques, ont été évalués pour leur capacité à inhiber la biosynthèse des isoprénoïdes et potentiellement moduler la fonction des petites protéines G impliquées dans un assortiment de maladies humaines. Les activités préliminaires biologiques et la sélectivité sera présenté.</dc:abstract><ual:supervisor>Youla S. Tsantrizos</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/bv73c406k.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/3b591c55k</ual:fedora3Handle><dc:subject>Chemistry - Organic</dc:subject></rdf:Description></rdf:RDF>