<?xml version="1.0" encoding="UTF-8"?><rdf:RDF xmlns:oai="http://www.openarchives.org/OAI/2.0/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:ual="http://terms.library.ualberta.ca/" xmlns:bibo="http://purl.org/ontology/bibo/" xmlns:dcterms="http://purl.org/dc/terms/" xmlns:schema="https://schema.org/" xmlns:etdms="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ajs956j488"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Physics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Evolving networks as coupled differential equations: a phenotypic model of Dipterans during embryogenesis</dcterms:title><ual:dissertant>Rothschild, Jeremy</ual:dissertant><dc:abstract>An elaborate network of genes defines the genetic profile along the anteroposterioraxis of certain individuals in the Diptera family, establishing a robust pattern that differsslightly between species. Differences in the segmentation gene pattern of Drosophilaand Anopheles suggest that the parameters defining their networks evolved differentlyfrom the last common ancestor onwards. The study of the evolution of thenetwork, defined by a set of differential equations, using our genetic algorithm revealsa phenotypic pathway that explains these dissimilarities while conserving thenecessary conditions for viable species. This computational search through a modeland parameter "hyperspace" using the genetic algorithm predicts homologies betweendifferent stripe modules for the invariant target gene, eve. Additionally, anetwork model is further developed to explain the polarity of the pair-rule gene patternexpressed in the embryo, which suggests that ancestral Dipteran exploited adynamic network to establish a proper periodic pattern of the other segmentationgenes with respect to eve.</dc:abstract><dc:abstract>Un réseau complexe de gènes définit le profil génétique selon l'axe antéro-postérieurde certains individus de la famille des diptères et établit un modèle robuste qui diffèrelégèrement entre les espèces. Les différences dans la configuration spatiale desgènes de segmentation de Drosophila et Anopheles suggèrent que les paramètresdéfinissant leurs réseaux ont évolué différemment à partir de leur dernier ancêtre commun. L'étude du réseau, défini par un ensemble d'équations différentielles, en utilisantnotre algorithme génétique révèle une trajectoire phénotypique qui explique cesdifférences tout en conservant des conditions nécessaires pour garder des espèces viablespendant l'évolution. Cette recherche à travers un "hyperespace" de paramètresen utilisant l'algorithme génétique prédit des homologies entre les différents modulescontrôlant les bandes de gène cible invariant eve. De plus, un modèle de réseau estdéveloppé pour expliquer la polarité du motif de gènes de segmentation exprimés dansl'embryon, ce qui suggère que cette éspèce ancestrale exploitait un réseau dynamiquepour établir un motif périodique des autres gènes de segmentation par rapport à eve.</dc:abstract><ual:supervisor>Paul Francois</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/sf268787d.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/js956j488</ual:fedora3Handle><dc:subject>Physics</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ac247dv756"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Geography</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>The change of ecosystem carbon fluxes with permafrost thaw: dominant factors and biogeochemical mechanisms in a subarctic peatland</dcterms:title><ual:dissertant>Wang, Zheng</ual:dissertant><dc:abstract>La fonte du pergélisol s'accentue dans toute la région subarctique en raison du réchauffement climatique. Les rétroactions entre les flux de carbone des tourbières et la fonte du pergélisol ont changé le bilan de carbone dans cette région et potentiellement accéléré le réchauffement climatique. Cependant, les mécanismes biogéochimiques liés aux changements environnementaux qui régulent les flux de carbone dans ces écosystèmes subarctiques demeurent mal compris. La présente recherche combine des mesures in situ de flux de carbone, de δ13C, de communautés végétales, de bio-indicateurs de labilité du carbone, d'éléments nutritifs et des facteurs environnementaux dans le but d'étudier les changements des flux de dioxyde de carbone (CO2), de méthane (CH4) et les mécanismes biogéochimiques sur un gradient de dégel du pergélisol dans une tourbière à palses subarctique. La biomasse et l'abondance végétales ont augmenté de manière significative de la zone de pergélisol à la zone de dégel humide; les plantes dominantes passant des lichens et arbustes à feuilles caduques aux carex et sphaignes. La masse et la biodégradabilité de la litière ont augmenté significativement avec la fonte du pergélisol, ce qui est crucial afin de déterminer l'importance de la décomposition de matière organique totale en réaction à la fonte du pergélisol. La production brute et la respiration de l'écosystème ont augmenté de manière significative avec le dégel du pergélisol, mais la production nette de l'écosystème n'a pas changé de manière significative. L'analyse des acides gras montre que les substrats carbonés passent du matériel plus vieux au matériel plus jeune avec la fonte du pergélisol. L'analyse des δ13C démontre que le carbone organique nouvellement assimilé, particulièrement la litière et la rhizosphère, domine l'augmentation de la respiration hétérotrophe et de la respiration souterraine dans les zones de dégel. Ainsi, une plus grande absorption photosynthétique stimule une plus grande respiration dans les zones de dégel plus humides, réduisant la capacité de stockage du carbone dans les zones de dégel. Les émissions de CH4 augmentaient de manière significative passant des palses aux zones de dégel. L'augmentation du δ13C du CH4 émis et la diminution du facteur de fractionnement des gaz dissous montrent que le CH4 produit par méthanogenèse acétoclastique augmente des secteurs secs aux secteurs de dégel humides. Les co-relations entre la production brute de l'écosystème, le CH4 et SUVA254 ont indiqué qu'une plus grande production de carex dans les zones de dégel humides produisait plus de carbone labile et était associée à des émissions de CH4 plus élevées.</dc:abstract><dc:abstract>With a warming climate, permafrost thaw is widespread across subarctic regions. Feedbacks of peatland carbon fluxes to permafrost thaw have changed the ecosystem carbon (C) balance in this region, potentially accelerating global warming. However, biogeochemical mechanisms of how environmental changes regulate ecosystem C fluxes with permafrost thaw in subarctic peatlands remain poorly understood. In this research, I combined in situ measurements of C fluxes, natural abundance of δ13C, plant community structure, bio-indicators of C lability, nutrients, and other environmental factors to assess and explain changes in ecosystem C dioxide (CO2) flux, methane (CH4) exchange, and related biogeochemistry mechanisms across a permafrost thaw transect in a subarctic palsa mire. Plant biomass and abundance significantly increased from palsa to wet thawed areas, with dominant plants changing from lichens and deciduous shrubs to sedges and Sphagnum. Plant litter mass and biodegradability also significantly increased with permafrost thaw, which are crucial factors to determine feedback strengths of overall organic matter decomposition to permafrost thaw. The gross ecosystem production and ecosystem respiration increased significantly with thaw, but net ecosystem production did not change significantly. Analysis of fatty acids shows that main C substrates changed from older peat to newer plant material with permafrost thaw. δ13C analysis demonstrates that newly assimilated organic C, especially litter and rhizosphere, dominated increased heterotrophic respiration and belowground respiration in thaw areas. Thus, greater photosynthetic uptake with changes in plants stimulated greater respiration in wet thawed areas, reducing the potential for an increased C sink with thaw. CH4 emissions significantly increased from palsa to thawed areas. Increased δ13C of emitted CH4 and decreased fractionation factors of dissolved gases both show that acetoclastic methanogenesis produced CH4 increased from dry to wet thaw sites. The relationships among gross ecosystem production, CH4 emission, and specific UV absorbance of DOC (SUVA254) indicate that greater production of sedges in wet thaw areas produced more labile C, and was associated with higher CH4 emissions. </dc:abstract><ual:supervisor>Nigel Thomas Roulet</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/t435gg48k.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/c247dv756</ual:fedora3Handle><dc:subject>Geography</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A2v23vw58h"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Medicine</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Elucidating the mechanisms of HIV-1 antiviral activity by SERINC5</dcterms:title><ual:dissertant>Moumneh, Khaled</ual:dissertant><dc:abstract>The serine incorporators (SERINC) are a highly conserved transmembrane protein family in eukaryotes that are known to play an important role in stimulating lipid biosynthesis in a variety of cells. As their name suggests, they activate phosphatidylserine synthase and palmitoyltransferase via the incorporation of the amino acid serine to drive the synthesis of phosphatidylserine and sphingolipids, respectively. In 2015, two groups independently discovered that in the absence of HIV-1 Nef, SERINC5 and to a lesser extent SERINC3 incorporated into the virion and prevented proper viral pore expansion thus preventing viral core deposition and decreasing infectivity. These findings identified SERINC5 as a host restriction factor and finally solved the mystery behind the mechanism of Nef-mediated up-regulation of HIV-1 infectivity.Little is known about the SERINC5 protein itself and the specifics of its downregulation of HIV-1 and its downregulation by Nef. In our study, SERINC5 post-translational modification by ubiquitin was explored via co-immunoprecipitation. We discovered that SERINC5 is ubiquitinated, and that this ubiquitination most likely does not correspond to its counteraction either by Nef or proteasomal degradation. Next, we set out to find a Nef binding motif on SERINC5 through the use of a novel CD4-SERINC5 chimera internalization assay. Lastly, the SERINC5 region or motif required for antiviral activity against HIV-1 was investigated through the use of two sets of SERINC5 and non-antiviral SERINC1 region-swapped chimeras. Through these experiments, a central region of SERINC5 encompassing amino acids 176-311 was found to be required for its anti-HIV-1 activity. These observations pave the way for future studies to find specific motifs required for SERINC5-HIV-1 and SERINC5-Nef interaction and elucidate a more detailed antiviral mechanism.</dc:abstract><dc:abstract>Les incorporateurs de sérine (SERINC) constituent une famille de protéines transmembranaires hautement conservée chez les eucaryotes et qui sont connues pour jouer un rôle important dans la stimulation de la biosynthèse des lipides dans de nombreux types cellulaires. Comme leur nom le suggère, ils activent la phosphatidylsérine synthase et la palmitoyltransférase via l'incorporation de l'acide aminé sérine afin de faciliter la synthèse de la phosphatidylsérine et des sphingolipides, respectivement. En 2015, deux groupes ont indépendamment découvert qu'en l'absence de Nef du VIH-1, SERINC5 et, dans une moindre mesure, SERINC3, sont alors incorporés dans le virion et préviennent l'expansion adéquate des pores viraux, permettant donc de prévenir la déposition du noyau viral et réduire l'infectiosité. Ces résultats ont identifié SERINC5 comme étant un facteur de restriction de l'hôte et a finalement résolu le mystère se cachant derrière le mécanisme de la régulation positive de l'infectiosité du VIH-1 médiée par Nef. Peu de choses sont connues à propos de la protéine SERINC5 elle-même et les spécificités de sa régulation négative du VIH-1 et de sa régulation négative par Nef. Dans notre étude, des modifications post-traductionnelles de SERINC5 par de l'ubiquitine ont été explorées via co-immunoprécipitation. Nous avons découvert que SERINC5 était en effet ubiquitinée, et que cette ubiquitination ne correspond probablement pas à sa régulation négative par Nef ou à la dégradation protéasomale. Nous avons ensuite recherché un motif de liaison de Nef sur SERINC5 grâce à l'utilisation d'un nouveau test d'internalisation de CD4-SERINC5 chimérique. Finalement, le motif ou la région SERINC5 requise pour l'activité antivirale contre le VIH-1 a été examinée en utilisant deux ensembles de protéines chimériques par échange de régions entre SERINC5 et la protéine non-antivirale SERINC1. À travers ces expériences, une région centrale de SERINC5, englobant les acides aminés 176 et 311, a été découverte comme étant requise pour ses activités anti-VIH-1.  Ces observations permettent de préparer la voie pour de futures études ayant pour but de trouver des motifs spécifiques requis pour l'interaction entre SERINC5-HIV-1 et SERINC5-Nef et élucider un mécanisme antiviral plus détaillé.</dc:abstract><ual:supervisor>Chen Liang</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/0v838321q.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/2v23vw58h</ual:fedora3Handle><dc:subject>Medicine</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Amc87pt16g"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Desautels Faculty of Management</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Two essays on charitable behaviour</dcterms:title><ual:dissertant>Mendenhall, Zachary</ual:dissertant><dc:abstract>Cette dissertation est composée de deux essais sur le comportement de bienfaisance. Le premier essai est une revue intégrative de la recherche contemporaine sur le comportement caritatif. Cette revue couvre des articles séminaires publiés dans des revues majeures en psychologie sociale et commercialisation, organise cette littérature dans un cadre d'antécédents et de conséquences du comportement caritatif et identifie des directions prometteuses pour la recherche future. Le deuxième essai met l'accent sur la croyance dans le libre arbitre comme un antécédent clé du comportement charitable. Des recherches antérieures semblent indiquer que la croyance en le libre arbitre est susceptible d'avoir un effet positif sur le comportement de bienfaisance. L'Essai 2 contribue à cette littérature en proposant que la croyance en libre arbitre peut avoir un effet positif ou négatif sur le comportement caritatif, selon le niveau d'origine de la dotation. Cet essai propose également un mécanisme basé sur la perception de la propriété de l'argent qui sous-tend l'effet de la croyance en libre arbitre et l'origine de la dotation sur le comportement de bienfaisance. Le modèle développé dans l'essai 2 est testé dans quatre études, en utilisant différentes manipulations et mesures de la croyance dans le libre arbitre, ainsi que des mesures différentes de comportement de bienfaisance.</dc:abstract><dc:abstract>This dissertation is comprised of two essays on charitable behavior. The first essay is an integrative review of contemporary research on charitable behavior. This review covers seminal articles published in major journals in both marketing and social psychology, organizes this literature into a framework of antecedents and consequences of charitable behavior, and identifies promising directions for future research. The second essay focuses on belief in free will as a key antecedent of charitable behavior. Previous research suggests that belief in free will is likely to have a positive effect on charitable behavior. Essay 2 contributes to this literature by proposing that belief in free will can have either a positive or a negative effect on charitable behavior, depending on the level of endowment origin. This essay also proposes a mechanism based on perceived ownership of money that underlies the effect of belief in free will and endowment origin on charitable behavior. The model developed in essay 2 is tested in four studies, using different manipulations and measures of belief in free will, as well as different measures of charitable behavior. </dc:abstract><ual:supervisor>Ashesh Mukherjee</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/hd76s277w.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/mc87pt16g</ual:fedora3Handle><dc:subject>Management</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A0v8383220"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Mechanical Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Nonlinear behaviour of carbon nanotube resonators with applications in mass-sensors</dcterms:title><ual:dissertant>Farokhi, Hamed</ual:dissertant><dc:abstract>Recent technological advances have facilitated the development and fabrication of nanoelectromechanical systems (NEMS). NEMS are nano-scale devices consisting of integrated mechanical and electrical components designed to work in different environments for various purposes. A special class of NEMS devices are nanomechanical resonators which have received considerable attention from researchers around the world. Due to their small mass and size, nano resonators are capable of detecting the presence of even one very small particle, since the addition of the particle  mass causes a shift in the resonance frequency of such devices. Carbon nanotubes (CNTs) have been considered as suitable candidates to be implemented in nano resonators,  due to their small mass, high stiffness, small cross-section, and unique electrical properties. The performance of a nano resonator is directly related to its dynamical behaviour. The objective of this thesis is to perform a comprehensive investigation on the nonlinear behaviour of CNT resonators and to examine their applications in mass detection.  To this end, new nonlinear size-dependent continuum models are developed for doubly clamped and cantilevered CNT resonators taking into account the effects of small size, initial curvature, geometric imperfection, nonlinear damping, and geometrical and inertial nonlinearities; for a special case, the size-dependent continuum model is validated via molecular dynamics simulations. On the electrical part, new nonlinear models are proposed for the electrostatic load distribution in doubly clamped and cantilevered CNT resonators, taking into account the end effects caused due to the finite length; the proposed models are validated employing 3D finite element simulations.Solving the complete nonlinear model developed for each case is a significantly complicated and challenging task, due to presence of various nonlinearities associated with the large-amplitude motion of the CNT resonator as well as the strong nonlinear coupling between the electrostatic load and the motion of the system. In this thesis, highly optimized and efficient discretization schemes as well as advanced numerical techniques are employed to investigate the nonlinear behaviour of the CNT resonator. The nonlinear static and dynamic responses of the CNT resonator are examined thoroughly, investigating the effect of various parameters, such as DC and AC voltages, length-scale parameter, nonlinear intrinsic damping, number of degrees of freedom, initial curvature, and geometric imperfections; it is shown that the DC voltage acts as a tuning parameter for the nonlinear behaviour of the system. More importantly, it is shown that when a realistic model is employed for the electrostatic load, via taking into account the end effects, the response of the system, in both static and dynamic regimes, changes significantly compared to the model available in the literature. Furthermore,   the mass detection sensitivity of the cantilevered CNT resonator is examined in detail and methods are proposed for its enhancement. </dc:abstract><dc:abstract>De récentes avancées technologiques ont facilité le développement et la fabrication de systèmes nano-électromécaniques (SNEM). Les SNEM sont des dispositifs nanométriques constitués de composants mécaniques et électroniques conçus pour fonctionner dans des environnements différents, pour divers usages. Une classe spéciale de dispositifs SNEM est constituée des résonateurs nano-mécaniques qui ont été particulièrement étudiés par des chercheurs du monde entier. Grâce à leur faible masse et à leur petite taille, les nano-résonateurs sont ainsi capables de détecter la présence d'une toute petite particule, l'ajout de la masse de la particule causant un décalage de la fréquence de résonnance de tels dispositifs. Les nanotubes de carbones (NTC) ont été considérés, grâce à leur faible masse, leur grande raideur, leur faible section et leurs propriétés électriques uniques, comme des candidats appropriés pour être implémentés dans les nano-résonateurs.La performance d'un nano-résonateur est directement liée à son comportement dynamique. L'objectif de cette thèse est de réaliser un examen complet du comportement non linéaire des résonateurs NTC et d'examiner leurs applications en détection de masse. À ces fins, des nouveaux modèles continus non linéaires dépendant de l'échelle sont développés pour des résonateurs NTC avec des conditions aux limites encastré – encastré ou encastré - libre, prenant en compte les effets de petite échelle, de courbure initiale, d'imperfections géométriques, d'amortissement intrinsèque non linéaire, et de non linéarités géométriques et inertielles ; pour un cas spécifique, le modèle continu dépendant de l'échelle est validé grâce à des simulations dynamiques moléculaires. Quant à l'aspect électrique, de nouveaux modèles non linéaires sont proposés pour la distribution de charge électrostatique pour des résonateurs NTC soumis aux conditions aux limites mentionnées précédemment, prenant en considération les effets de bord dus à la longueur finie du résonateur. Les modèles proposés sont validés par la réalisation de simulations par éléments finis en 3D.Résoudre le modèle non linéaire complet développé pour chaque cas est particulièrement compliqué et exigeant, tant à cause de la présence de diverses non linéarités liées aux larges déplacements du résonateur NTC que du fort couplage non linéaire entre le chargement électrostatique et le déplacement du système. Dans cette thèse, aussi bien des schémas de discrétisation efficaces et optimisés que des techniques numériques avancées ont été employés pour étudier le comportement non linéaire du résonateur NTC. Les réponses statique et dynamique du résonateur NTC ont été examinées minutieusement en étudiant les effets de divers paramètres, tels que les tensions continues (DC) et alternées (AC) appliquées, le paramètre d'échelle, l'amortissement intrinsèque non linéaire, le nombre de degrés de liberté, la courbure initiale et les imperfections géométriques ; il est montré que la tension continue (DC) est un paramètre influent pour le comportement non linéaire du système. De surcroît, il est remarqué, en particulier, que, lorsqu'un modèle réaliste est employé pour le chargement électrostatique, grâce à la prise en compte des effets de bord, la réponse du système, en régimes statique et dynamique, change considérablement en comparaison avec celle obtenue grâce au modèle disponible dans la littérature. En outre, la sensibilité de détection de masse du résonateur NTC est examinée en détail et des méthodes sont proposées pour l'améliorer.</dc:abstract><ual:supervisor>Michael P. Paidoussis</ual:supervisor><ual:supervisor>Arun K. Misra</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/6m311r955.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/0v8383220</ual:fedora3Handle><dc:subject>Mechanical Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ad791sj873"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of History and Classical Studies</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Transplantation of Asian spices in the Spanish empire 1518-1640: entrepreneurship, empiricism, and the crown</dcterms:title><ual:dissertant>Bassewitch Frenkel, Omri</ual:dissertant><dc:abstract>Cette thèse examine la manière dont la transplantation et domestication des épices asiatiques ayant une valeur commerciale dans l'empire espagnol a contribué à la production, circulation et institutionnalisation de connaissances empiriques à travers les colonies impériales de l'Espagne Couronne-parrainée. Bien qu'éventuellement échoués, les projets de transplantation d'épices étaient perçus par les Espagnols comme étant une composante importante de l'expansion impériale au cours des XVIe et XVIIe siècles. Les entreprises d'introduction ou de domestication des épices ont souvent été initiées et gérées par des réseaux de colons, entrepreneurs, fonctionnaires, moines et historiens naturels, qui, par l'observation empirique et l'expérimentation acquéraient une expertise dans le domaine impliqué. Les projets de transplantations d'épices réussis ont attiré l'attention des établissements impériaux de l'Espagne, notamment, le Conseil des Indes et la Casa de Contratación, qui à leur tour, ont engagé les administrateurs des colonies de l'Amérique espagnole et des Philippines à faire appel aux experts compétents dans le domaine de la culture et du développement des épices. Par conséquent, des expérimentations dans l'introduction et la culture des épices ont été menées dans les propriétés privées et les propriétés de la Couronne espagnole dans l'Amérique, les Philippines et l'Espagne, et les résultats de celles-ci ont aidé à formuler les politiques de la Couronne régissant la culture et le commerce des épices. Il est proposé ici que les projets de la transplantation des épices reflètent une culture organisationnelle où les stratégies gouvernementales étaient basées sur les opinions des experts dérivés des observations empiriques et des expérimentations. En essentiel, la Couronne a adopté une approche scientifique pour guider ces politiques. Par conséquent, cette étude soutient que, dès les années 1570, les établissements de la Couronne espagnole évaluaient et analysaient les données empiriques complexes sous des contextes économiques, politiques, et diplomatiques variables, pour former les décisions aux conséquences perçues critiques pour l'économie de l'Espagne et pour son expansion impériale.</dc:abstract><dc:abstract>This dissertation focuses on the way in which Crown-sponsored attempts to transplant or domesticate commercially valuable Asian spices throughout the Spanish empire generated production, circulation and institutionalization of empirical knowledge throughout Spain's imperial domains. Although largely unsuccessful, Spaniards perceived spice transplantations as an important component of Spain's imperial expansion during the sixteenth and seventeenth centuries. Ventures for the introduction or domestication of spices were often initiated and run by networks of settlers, entrepreneurs, officials, friars, and natural historians, who, through empirical observation and experimentation, acquired specific expertise in that field. Successful spice transplantations attracted the attention of Spain's imperial establishments, namely the Council of the Indies and the Casa de Contratación [known also as the "House of Trade"], which, in turn, engaged colonial administrators in Spanish America and the Philippines to call upon relevant experts for information regarding spice cultivation and processing. Consequently, experiments in the introduction and cultivation of spices were conducted in private and Crown estates in Spanish America, the Philippines and Spain, and the results thereof helped formulate Crown policies regulating spice cultivation and trade. It is maintained here that spice transplantation projects reflect an organizational culture in which policies were formed and decisions were made based on expert opinions obtained through empirical observations and experiments. Essentially, the Crown has adopted a scientific approach to direct its policies. Therefore, this study argues that as early as the 1570s, Crown establishments assessed and analyzed complex empirical evidence in variable economic, political, and diplomatic contexts, to form decisions which were perceived to bear critical consequences to Spain's economy and its imperial expansion.</dc:abstract><ual:supervisor>Gwyn Campbell</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/8g84mq05f.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/d791sj873</ual:fedora3Handle><dc:subject>History and Classical Studies</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Asx61dp93m"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Political Science</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Strengthening electoral integrity through election management</dcterms:title><ual:dissertant>Garnett, Holly</ual:dissertant><dc:abstract>Planifier et mettre en place une élection représente une entreprise titanesque qui implique plusieurs tâches techniques et administratives telles que l'inscription des électeurs, la transmission d'informations, la mise en place de bureaux de vote, le décompte des votes et l'annonce des résultats. La plupart de ces tâches sont effectuées par des organismes de gestion électorale (OGE), des agences et départements gouvernementaux qui s'occupent de l'administration technique des élections. Cette dissertation se penche sur la question suivante : comment les organismes de gestion électorale influencent-ils l'intégrité des élections ? Cette dissertation aborde d'abord deux phases du cycle électoral qui visent à augmenter la participation électorale : l'inscription des électeurs et la diffusion d'information sur les élections. Ensuite, cette dissertation analyse l'efficacité des organismes de gestion électorale. La première étude de cette dissertation se penche sur l'impact de trois innovations en matière d'enregistrement des électeurs- l'inscription le jour de l'élection, l'inscription en ligne et la préinscription des jeunes- sur l'inscription et la participation électorale dans 49 états américains sur une période de six élections. En codifiant la mise en place de ces innovations à travers le temps et en utilisant trois stratégies de modélisation différentes, cette étude souligne l'importance de considérer les problèmes d'endogénéité et de l'implantation non aléatoire de lois électorales lorsque l'on évalue l'efficacité des innovations en matière d'inscription électorale. La deuxième étude se penche sur les effets du vote anticipé à travers plusieurs élections dans quatre pays : le vote anticipé plusieurs jours à l'avance au Canada, le vote anticipé d'une semaine en Finlande, le vote par la poste sur demande en Allemagne et le vote postal automatique en Suisse. Cette étude démontre que le vote anticipé a peu de chances d'améliorer la participation électorale des groupes qui ont généralement une participation plus faible. Les personnes âgées sont celles qui risquent le plus de se prévaloir du vote anticipé. La dernière étude présente une nouvelle approche pour comparer les organismes de gestion électorale à travers le monde. À l'aide d'une analyse de contenu des sites web des OGE de 99 pays qui compare la diffusion d'information, la communication avec les parties prenantes et la transparence envers le public, cette étude mesure la capacité et l'efficacité des OGE. Ensuite, cette étude évalue la validité de la mesure proposée en effectuant des tests à petite échelle pour vérifier si les OGE communiquent efficacement avec leurs citoyens. Puis, l'étude démontre que cette nouvelle mesure de capacité des OGE est en mesure de prédire l'intégrité électorale d'un pays, ce qui révèle son utilité pour des recherches futures. Cette dissertation démontre l'importance de trois différentes facettes de la gestion électorale pour l'intégrité électorale et propose quelques conclusions. Tout d'abord, nos postulats concernant la gestion des élections et les lois électorales sont parfois faux et doivent donc être testés empiriquement. Deuxièmement, la capacité des OGE et le contexte a plus d'impact sur l'intégrité électorale que les lois et structures formelles. Troisièmement, les pratiques de gestion électorale peuvent avoir des impacts qui diffèrent selon les pays et peuvent avoir plus d'effet sur certains groupes de citoyens que d'autres. Finalement, cette dissertation suggère qu'il importe d'avoir de meilleures données et de d'améliorer nos partenariats avec des parties prenantes en vue d'améliorer l'étude de la gestion et de l'intégrité électorale.</dc:abstract><dc:abstract>Planning and executing an election is an enormous undertaking that is comprised of a variety of technical and administrative tasks, including registering and educating voters, setting up polling places, counting ballots, and announcing results. Many of these tasks fall under the umbrella of election management, and are executed by election management bodies (EMBs), the government agencies and departments that are tasked with the technical administration of elections. This dissertation asks: how does election management impact electoral integrity? It first considers two stages of the electoral cycle where convenience registration and voting procedures are aimed at improving participation. It then considers the capacity of the election management bodies that implement these procedures. The first study in this dissertation considers the impact of three registration innovations – election day registration, online registration and pre-registration of youth – on individual registration and turnout in 49 American states across six election years. By tracking the implementation of these registration opportunities over time, and using three modelling strategies, this study emphasizes the need for scholars to be aware of potential issues of endogeneity and the non-random implementation of election laws when evaluating the effectiveness of registration innovations. The second study considers the socio-demographic and attitudinal correlates of early voting across a number of elections in four jurisdictions: days-long advance voting in Canada, week-long advance voting in Finland, on-demand postal voting in Germany and automatic postal voting in Switzerland. This study finds that early voting is unlikely to mobilize commonly under-represented population groups, with the exception of the elderly, who are often quite likely to take advantage of early voting opportunities. The final study presents a new approach to comparing election management bodies in cross-national perspective. It measures their capacity to perform their functions through a content analysis of EMB websites in 99 countries, capturing their provision of information, communication with stakeholders, and transparency with the public. This study then assesses the measurement validity of this new measure of capacity, and conducts a small-scale test to determine whether EMBs that score high do actively communicate with their citizens. An application of this new measure of EMB capacity demonstrates its importance in predicting overall electoral integrity, indicating its importance for future scholarly and policy research.  This dissertation demonstrates the importance of three different components of election management for electoral integrity and draws a number of conclusions: first, that our common assumptions about election management and election laws may be mistaken and must therefore be empirically tested; second, that capacity and context often matter more for electoral integrity than formal laws and structures; third, that election management practices may have differential impacts in different countries or for different population groups; and finally that better data sources and partnerships are needed to improve the study of election management and electoral integrity around the globe. </dc:abstract><ual:supervisor>Elisabeth Gidengil</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/1n79h702w.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/sx61dp93m</ual:fedora3Handle><dc:subject>Political Science</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3At435gg49v"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Seamless dual-brake transmission for electric vehicles: design, modeling, estimation, and control</dcterms:title><ual:dissertant>Rahimi Mousavi, Mir Saman</ual:dissertant><dc:abstract>In automotive applications, a transmission is a mechanical device that delivers the power of the traction unit to the wheels in different combinations of torque and speed.Various transmissions have been suggested and developed for internal combustion engine vehicles (ICEVs) to meet the above-mentioned objective. Moreover, complex gear shift techniques have also been introduced in order to meet certain characteristics such as efficiency, drivability, and lifetime of the system. However, increasing fuel cost and environmental concerns have pushed the automotive industry to gradually replace ICEVs with hybrid electric vehicles (HEVs) and fully electric vehicles (EVs). The migration from ICEVs to EVs has a considerable number of hurdles. One of the main challenges is the lower energy density of electric batteries in comparison with fossil fuels. Thus, by changing the traction unit from internal combustion engines to electric motors, it is required to minimize losses in the driveline in order to maximize the range of EVs and more importantly make them competitive with ICEVs. Transmission, in particular, has a considerable impact not only on dynamic performance but also on the overall efficiency of the driveline, and therefore, its mechanical design and gear shift algorithms have to be revised.In recent years, multi-speed transmissions for EVs have been studied and developed in two different directions. In one direction, based on the characteristics of electric motors, transmissions initially designed for ICEVs were modified in order to be retrofitted to HEVs and EVs. In the other direction, novel transmissions have been developed for EVs from the ground up considering effective controllability of electric motors as well as their wide range of efficient operation.In this thesis, a special attention is given to the second direction in which a novel seamless two-speed transmission particularly designed for EVs is proposed. In this system, clutches and torque converters are eliminated from the powertrain, and instead, the transmission is perpetually connected to the powertrain. This is done not only because of the high controllability of electric motors, but also for efficiency and drivability improvements. Further, the hydraulic gear shift actuators are replaced with electromechanical ones in order to improve efficiency and reliability and reduce the weight and volume of the overall system.Kinematic analysis of the introduced transmission is performed to provide achievable gear ratios of the system that are beneficial for gear ratio optimization purposes. Further, various modeling techniques are fused together in order to provide a detailed dynamical model of an EV powertrain equipped with the proposed transmission.The derived model is validated by means of a down-scaled proof-of-concept experimental prototype as well as simulation models built in MATLAB/Simulink using SimDriveLine library. Based on the dynamical model of the system, in order to reduce the number of sensors and transducers on the powertrain, a stochastic observer is designed to estimate the unmeasured state variables and the unknown input imparted on the system. The observer mitigates the process and measurement noises and provides a smooth estimation of unmeasured states and the unknown input. By considering all state variables and disturbances available for feedback, two optimal control problems minimizing shifting time and energy dissipation during the gear shift processes are solved using the Pontryagin minimum principle (PMP) while eliminating the power interruption at the output. The solutions to these optimal control problems shed light on novel gear shift algorithms. Finally, a closed-loop controller is designed to track the optimal control inputs and trajectories while coping with actuators limitations. The performance of the designed observers and controllers are verified by experiments and simulation analyses.</dc:abstract><dc:abstract>Dans les applications automobiles, une transmission est un dispositif mécanique qui fournit la puissance de l'unité de traction aux roues dans différentes combinaisons de couple et de vitesse.Diverses transmissions ont été proposées et développées pour les véhicules à moteur à combustion internes (VMCIs) afin d'atteindre l'objectif mentionné ci-dessus. De plus, des techniques de changement de vitesses complexes ont également été proposées afin de répondre à certaines caractéristiques telles que l'efficacité, la maniabilité et la durée de vie du système. Cependant, l'augmentation du coût du carburant et des préoccupations environnementales ont poussé l'industrie automobile à remplacer progressivement les VMCIs par des véhicules électriques hybrides (VÉHs) et des véhicules entièrement électriques (VÉs). La migration technologique des VMCIs aux VÉs présente un nombre considérable d'obstacles. L'un des principaux défis est la plus faible densité énergétique des batteries électriques par rapport aux combustibles fossiles. Ainsi, en changeant le moteur à combustion interne par un moteur électrique dans l'unité de traction, il est nécessaire de minimiser les pertes dans la transmission afin de maximiser l'autonomie des véhicules électriques et ainsi les rendre plus compétitifs. La transmission a donc un impact considérable non seulement sur la performance dynamique, mais aussi sur l'efficacité globale de la chaîne cinématique. Au cours des dernières années, les transmissions multi-vitesses pour les véhicules électriques ont été étudiées et mises au point selon deux axes différents. Dans le premier axe, des transmissions initialement conçues pour VMCIs ont été modifiées afin d'être adaptées aux VÉHs et VÉs. Dans l'autre axe, de nouvelles transmissions ont été développées pour les véhicules électriques à partir de principes fondamentaux considérant l'excellente gouvernabilité des moteurs électriques ainsi que leur grande plage de fonctionnement efficace.Dans cette thèse, une attention particulière est accordée aux deuxième axe. Dans ce système, les embrayages et les convertisseurs de couple sont éliminés du groupe motopropulseur, et au lieu, la transmission est perpétuellement connectée au groupe motopropulseur. En outre, les actionneurs de changement de vitesse hydrauliques sont remplacés par des actionneurs électromécaniques afin d'améliorer l'efficacité et la fiabilité et de réduire le poids et le volume de l'ensemble du système. L'analyse cinématique de la transmission est effectuée pour fournir des rapports de vitesse réalisables qui sont bénéfiques à des fins d'optimisation du rapport d'engrenage. En outre, diverses techniques de modélisation sont fusionnées afin de fournir un modèle dynamique du groupe motopropulseur détaillé d'un véhicule électrique équipé de la transmission proposée.Le modèle proposé est validé au moyen d'un prototype expérimental réduit à l'échelle, ainsi que de modèles de simulation créés dans MATLAB/Simulink en utilisant la bibliothèque SimDriveline. Basé sur le modèle dynamique du système un observateur stochastique est conçu pour estimer les variables d'état non mesurées et l'entrée inconnue transmise dans le système. L'observateur atténue les bruits de processus et de mesure et fournit une estimation lisse des états non mesurés et de l'entrée inconnue. En tenant compte de toutes les variables d'état et des perturbations disponibles pour la rétroaction, deux problèmes de contrôle optimal minimisant le temps et la dissipation d'énergie pendant les opérations de changement de vitesse sont résolus en utilisant le Principe du Minimum de Pontryagin, tout en éliminant l'interruption de couple à la sortie. Enfin, un contrôleur en boucle fermée est conçu pour asservir le système aux entrées et aux trajectoires de contrôle optimales tout en faisant face aux limitations des actionneurs. La performance des observateurs et des contrôleurs conçus est vérifiée par des expériences et des analyses de simulation. </dc:abstract><ual:supervisor>Benoit Boulet</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/bv73c315b.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/t435gg49v</ual:fedora3Handle><dc:subject>Electrical and Computer Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A6t053j75f"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Biology</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>The source and nature of adaptive variation for the evolution of dark growth in «Chlamydomonas reinhardtii»</dcterms:title><ual:dissertant>Anderson-Trocmé, Luke</ual:dissertant><dc:abstract>Dans cette thèse, j'applique des nouvelles méthodes de séquençage et des techniques analytiques développées pour étudier la source et la nature de la variation adaptative dans le contexte d'une expérience d'évolution à long terme utilisant Chlamydomonas reinhardtii. Je me concentre sur deux mesures distinctes de la dynamique évolutive et utilisons une variété de méthodes bioinformatiques pour traiter et analyser les données génomiques pour répondre à ces questions. Le premier chapitre aborde la question de savoir si la variation génétique permanente ou les nouvelles mutations sont la source de variations adaptatives. En comparant l'ascendance locale de chaque région génomique pour chaque échantillon, j'ai été en mesure de déterminer que la variation permanente est toujours présente dans chaque population. Donc, prouvant qu'un « balayage sélectif » n'a pas eu lieu.Le deuxième chapitre tente de décrire la fonction des gènes qui ont été touchés par des mutations biologiquement significatives qui ont été activement sélectionnées au cours de l'expérience. J'ai effectué une annotation des variantes en utilisant un programme qui classe l'impact de chaque variante, suivie d'une estimation du coefficient de sélection par changement de fréquence d'allèle au cours de l'expérience. La combinaison de ces deux étapes me permet de limiter notre analyse d'enrichissement à des gènes qui ont été activement sélectionnés au cours de cette expérience. Mes résultats suggèrent que les gènes en cours de sélection dans cette expérience sont enrichis en voies de signalisation et la régulation des gènes.Ensemble, ces deux analyses commencent à dévoiler comment les populations sexuelles de taille modérée s'adaptent à des environnements nouveaux.</dc:abstract><dc:abstract>In this thesis, I apply newly developed sequencing methods and analytical techniques to study the source and nature of adaptive variation in the context of a long term evolution experiment with Chlamydomonas reinhardtii as a model. I focus on two distinct measures of evolutionary dynamics and use a variety of bioinformatic methods to process and analyze the genomic data to answer such questions. The first chapter addresses the question of whether standing genetic variation or novel mutations are the source of adaptive variation. By comparing the local ancestry of each genomic region for each sample, I have been able to determine that standing variation is still present in each population. Thus proving that a "hard sweep" has not occurred. The second chapter attempts to describe the function of the genes that have been impacted by biologically significant mutations that have been actively under selection over the course of the experiment. I performed a variant annotation which categorizes the impact of each variant, followed by an estimation of selection coefficient via allele frequency change over the course of the experiment. The combination of these two steps allowed me to limit my enrichment analysis to genes that have been actively under selection. My results suggest that the genes under selection in this experiment are enriched in signaling pathways and gene regulation.Together, these two analyses begin to unveil how sexual populations of moderate size adapt to novel environments.</dc:abstract><ual:supervisor>Graham Bell</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/gx41mm46b.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/6t053j75f</ual:fedora3Handle><dc:subject>Biology</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A3b591b917"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Food Science and Agricultural Chemistry</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Soil quality fertility determination in precision agriculture and bitumen residue determination in oil sand tailings by fourier transform infrared spectroscopy coupled with chemometrics</dcterms:title><ual:dissertant>Gan, Qianjun</ual:dissertant><dc:abstract>La nécessité de techniques rapides et peu coûteuses pour la détermination de la fertilité des sols a excité à l'étude des technologies modernes. La spectroscopie infrarouge dans le proche infrarouge a été beaucoup utilisée, tandis que l'infrarouge moyen (4000-400 cm-1) a été moins étudiée. Dans cette étude, on a étudié la faisabilité de l'utilisation de la réflectance totale atténuée infrarouge moyen (ATR-FTIR) dans la détermination de la fertilité du sol. La fertilité du sol de 278 échantillons en provenant des quatre provinces canadiennes a été évaluée par measure de 10 propriétés du sol sélectionnées: Le carbone total (TC), l'azote total (TN), le rapport carbone-azote (C / N), l'ammonium (NH4+), le nitrate (NO3-), le sable, le limon, l'argile, l'absorption de N et le rendement. La régression des moindres carrés partielle (PLSR) a été utilisée pour construire des modèles d'étalonnage pour la prédiction de ces propriétés à partir des spectres ATR-FTIR des sols. Sur la base de l'évaluation du coefficient de détermination (r2) et de l'écart prédictif résiduel (RPD), On a constaté que les modèles pour TC, TN, C / N, sable, limon et argile présentaient des performances très fiables (r2 &gt; 0,90, RPD &gt; 2,00). Des résultats similaires ont été trouvés lorsque le même ensemble d'échantillons a été analysé en utilisant la spectroscopie infrarouge à transformée de Fourier proche infrarouge (DRIFT-NIR) de réflectance diffuse à infrarouge. La comparaison des résultats de prédiction obtenus par spectroscopie ATR-FTIR et DRIFT-NIR a démontré que les modèles ATR-FTIR ont montré une meilleure précision de prédiction que les modèles DRIFT-NIR.Dans la deuxième partie de la recherche, la cible d'étude est passée des sols agricoles aux sols de résidus contaminés par le bitume, où la teneur et la qualité des résidus bitumineux dans un processus d'assainissement des résidus ont été déterminées par FTIR spectroscopie. Dans cet étude, les résidus bitumineux ont été déterminés directement dans des échantillons purs sans aucune séparation ou extraction chimique. La spectroscopie ATR-FTIR combine avec PLS a donné le meilleur étalonnage, avec un r2 de 0,99 et un RMSEC de 1,76% en poids depasse la limite de bitume entre 0,70 et 40,70 %m. Ces méthodes étaient reproductibles avec une différence moyenne de 0,91%m parmi les analyses en triple. On a étudié la classification des sols de résidus non réadaptés et traités par l'analyse en composantes principales (PCA) de leurs spectres ATR-FTIR. Les sols ont été classés avec succès en fonction de leur teneur en bitume, mais la classification fondée sur la discrimination entre les sols non remis en état et les sols remis en état n'a pas été couronnée de succès. Ce résultat implique l'absence d'une relation directe entre la teneur en bitume et le processus d'assainissement, ce qui a été attribué à la teneur variable en bitume des charges d'alimentation et à l'utilisation d'un processus d'assainissement non optimisé. Par conséquent, la classification MIR-PCA en ligne ainsi que la quantification MIR-PLS sont nécessaires pour la catégorisation des matières premières basée sur le bitume afin d'optimiser le processus d'assainissement et d'évaluer ultérieurement le processus d'assainissement pour s'assurer que l'objectif d'assainissement a été atteint. Dans l'extension de ce travail, on a évalué l'utilisation du solvant vert 2-méthyltétrahydrofurane (2-MeTHF) pour l'extraction de bitume dans les sols de résidus. Sur la base de la détermination gravimétrique du rendement de récupération du bitume, on a constaté que 89%m du bitume total ont été récupérés par une extraction à 2-MeTHF à une étape à température ambiante. La qualité du bitume extrait par les trois solvants a été analysée par spectroscopie FTIR, ce qui a indiqué qu'une moindre migration de minéraux argileux dans le bitume produit s'est produite lors de l'extraction avec du 2-MeTHF. </dc:abstract><dc:abstract>The need for rapid and inexpensive techniques for soil quality determination has led to the investigation of modern technologies. Infrared spectroscopy in the near-infrared region has been traditionally used, while the mid-infrared region (4000 – 400 cm-1) has been less studied. In this research, the feasibility of employing attenuated total reflectance mid-infrared (ATR-FTIR) spectroscopy in soil quality determination was studied. The soil quality of 278 soil samples from four Canadian provinces was evaluated by measurement of 10 selected soil properties: total carbon (TC), total nitrogen (TN), carbon-to-nitrogen ratio (C/N), ammonium (NH4+), nitrate (NO3-), sand, silt, clay, N uptake, and yield. Partial least-squares regression (PLSR) was used to build calibration models for the prediction of these properties from ATR-FTIR spectra of soils. Based on evaluation of the coefficient of determination (r2) and the residual; predictive deviation (RPD), it was found that the models for TC, TN, C/N, sand, silt, and clay showed very reliable performance (r2 &gt; 0.90, RPD &gt; 2.00). Similar results were found when the same set of samples were analyzed using diffuse reflectance infrared Fourier transform near-infrared (DRIFT-NIR) spectroscopy. Comparison of the prediction results obtained by ATR- MIR and DRIFT-NIR spectroscopy demonstrated that the ATR-FTIR models showed better prediction accuracy than the DRIFT-NIR models, with an RPD increment between 12% and 36%. This result indicates that ATR-FTIR spectroscopy coupled with PLSR has the potential to model and predict certain important soil properties and therefore may assist in achieving large-scale precision farming. In the second part of the research, the target of study moved from agricultural soils to bitumen-contaminated tailing soils, where the content and quality of bitumen residues in a tailings remediation process were determined by FTIR spectroscopy. The application of ATR-FTIR and DRIFT-NIR spectroscopy as rapid tools for determination of bitumen residues in tailings and remediated tailings was investigated. In this work, bitumen residues were directly determined in neat samples without any chemical separations or extractions. ATR-FTIR spectroscopy coupled with PLSR yielded the best calibration, with a r2 of 0.99 and a 1.76 wt% RMSEC over the bitumen range between 0.70 and 40.70 wt%. These methods were reproducible with an average 0.91 wt% difference among triplicate analyses. The classification of unremediated and remediated tailing soils by principal component analysis (PCA) of their ATR-FTIR spectra was investigated. Soils were successfully classified according to their level of bitumen content, but classification based on discrimination between unremediated and remediated soils was not successful. This result implied the lack of a direct relationship between bitumen content and the remediation process, which was attributed to the variable bitumen content of the feedstocks and the use of an un-optimized remediation process. Therefore, the on-line MIR-PCA classification as well as the MIR-PLS quantification is necessary for feedstock categorization based on bitumen level in order to optimize the remediation process and for subsequent evaluation of the remediation process to ensure the remediation goal has been met. In an extension of this work, the use of the green solvent 2-methyltetrahydrofuran (2-MeTHF) for extraction of bitumen from tailing soils was evaluated. Based on gravimetric determination of the bitumen recovery yield, it was found that 89 wt% of the total bitumen was recovered by a room-temperature single-stage 2-MeTHF extraction, which was 9% and 14% higher than the recovery obtained with the traditionally used organic solvents toluene and DCM under the same conditions. The quality of the bitumen extracted by the three solvents was analyzed by FTIR spectroscopy, which indicated that less migration of clay minerals into the bitumen.</dc:abstract><ual:supervisor>Ashraf A. Ismail</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/s7526f79z.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/3b591b917</ual:fedora3Handle><dc:subject>Food Science and Agricultural Chemistry</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3An583xx56b"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>School of Computer Science</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Stippling with quadrotors</dcterms:title><ual:dissertant>Galea, Brendan</ual:dissertant><dc:abstract>Nous décrivons une méthode pour créer des impressions pointillées en utilisant un robot quadrirotor volant. À un niveau bas, nous utilisons la capture de mouvement pour mesurer la position du robot et la toile, et un algorithme de commande robuste pour com- mander le robot de voler à différentes positions pointillées pour prendre contact avec la toile à l'aide d'une éponge d'encre trempée. Nous décrivons une collection de détails im- portants et les défis qui doivent être relevés pour le contrôle avec succès dans notre mise en oeuvre, y compris le modèle de robot estimation, filtrage de Kalman pour l'estimation de l'état, la latence entre la capture de mouvement et de contrôle, des interférences de com- munication radio, et le paramètre de commande de réglage. Nous utilisons un diagramme de Voronoi centroïde pour générer des dessins pointillées, et calculer une approximation gourmande du problème du voyageur de commerce pour attirer autant de pointillés par vol que possible, tout en tenant compte de la taille de stipple souhaitée et en ajustant dy- namiquement pointillés futurs basés sur les erreurs du passé. Un des modèles de fonctions exponentielles la désintégration naturelle des tailles pointillées que l'encre est utilisée dans un vol. Pointillés par seconde et de la variance du placement de stipple sont présentés pour évaluer nos impressions physiques et les performances de contrôle du robot. Pour le vol entièrement Autonome en nous alimenter nos quadrirotor en utilisant une attache filaire. On compense pour l'ancrage dans la commande du robot, en supposant une courbe caté- naire statique de longueur fixe entre le robot et la source d'alimentation. Nous évaluons la précision de vol stationnaire et vol sur des chemins simples, et comparer les résultats à vol untethered.</dc:abstract><dc:abstract>We describe a method for creating stippled prints using a quadrotor flying robot. At a low level, we use motion capture to measure the position of the robot and the canvas, and a robust control algorithm to command the robot to fly to different stipple positions to make contact with the canvas using an ink soaked sponge. We describe a collection of important details and challenges that must be addressed for successful control in our implementation, including robot model estimation, Kalman filtering for state estimation, latency between motion capture and control, radio communication interference, and control parameter tuning. We use a centroidal Voronoi diagram to generate stipple drawings, and compute a greedy approximation of the traveling salesman problem to draw as many stipples per flight as possible, while accounting for desired stipple size and dynamically adjusting future stipples based on past errors. An exponential function models the natural decay of stipple sizes as ink is used in a flight. Stipples per second and variance of stipple placement are presented to evaluate our physical prints and robot control performance. For fully autonmous flight we power our quadrotor using a wired tether. We compensate for the tether in our control of the robot by assuming a static catenary curve of fixed length between the robot and the power source. We evaluate accuracy of hovering and flight on simple paths, and compare the results to untethered flight.</dc:abstract><ual:supervisor>Paul Kry</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/pv63g266c.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/n583xx56b</ual:fedora3Handle><dc:subject>Computer Science</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A2f75rb431"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Kinesiology and Physical Education</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Examining the feasibility of prescribing a 12 week exercise intervention for advanced chronic kidney disease patients: a pilot study</dcterms:title><ual:dissertant>Yan, Xin Wei</ual:dissertant><dc:abstract>Background: Frailty is a common comorbid condition in elderly patients with advanced chronic kidney disease (CKD). Despite a significant and increasing prevalence, there is a lack of interventions for this population, especially in those patients who are pre-dialysis. Objectives: The purpose of this study was to investigate the feasibility of prescribing a 12 week home based exercise intervention that combined aerobic and resistance components. Methodology: Five patients, aged ≥ 65 years were recruited for this study. Inclusion criteria required a glomerular filtration rate of ≤45 mL/min/1.73m2 and demonstrating 3 out the 5 frailty criteria, as defined by Fried. Patients completed 12 weeks of home-based, individualized exercise, prescribed by a kinesiologist. Weekly telephone calls ensured patient adherence, safety and addressed any concerns with program. Results: Significant increases (p &lt; 0.05) were detected in maximum dominant hand grip strength, 4 meter walk speed, and total body weight. Conclusions: Given that 5 patients were able to complete this exercise program and achieve detectable improvements, this study shows that it is feasible for this patient population to successfully embark on a 12 week exercise intervention. However, there are challenges in gaining interest and adherence. Given the promising results shown here in our pilot data, an intervention such as this merits a greater preventative role in the CKD population, and should include a patient pool that includes less advanced disease states.</dc:abstract><dc:abstract>Contexte: La fragilité est une comorbidité fréquente chez les personnes âgées atteintes d'insuffisance rénale chronique (IRC). Malgré une augmentation considérable de la prévalence de l'IRC, il manque d'interventions pour cette population, en particulier pour les patients en prédialyse. Objectifs: Le but de cette étude est d'examiner la faisabilité de prescrire des exercices d'aérobie et de résistance à domicile pendant une durée de 12 semaines. Méthode : 5 patients, âgés ≥ 65 ans, ont complété l'étude. Les critères d'inclusion exigeaient que les patients aient un débit de filtration glomérulaire de ≤45 mL/min/1.73m2 et aient rencontré 3 des 5 critères de fragilité, définis par Fried. Les patients ont complété 12 semaines d'exercices individualisés à domicile, prescrits par un kinésiologue. Les patients ont été appelés de manière hebdomadaire afin d'assurer leur adhésion, leur sécurité, et répondre à toutes questions qu'ils avaient concernant le programme. Résultats: Une augmentation significative (p &lt; 0.05) a été obtenue dans la force de poignée maximale de la main droite, la vitesse de marche sur 4m et le poids total des patients. Conclusions: Étant donné que 5 patients ont été en mesure de compléter ce programme d'exercices et ont démontré des améliorations marquées, cette étude démontre la faisabilité pour cette population de patients d'entreprendre un programme d'exercice de 12 semaines. Toutefois, il existe des défis en ce qui à trait à l'intérêt suscité par le programme et son taux d'adhésion. En raison des résultats prometteurs de cette étude pilote, une intervention de la sorte joue un rôle préventif chez les individus atteints d'IRC et devrait être effectuée avec une cohorte incluant des patients à un stade moins avancé de la maladie</dc:abstract><ual:supervisor>Celena Scheede</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/1n79h7035.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/2f75rb431</ual:fedora3Handle><dc:subject>Kinesiology and Physical Education</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A1v53k0602"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Mining and Materials</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Solid-state recycling of aerospace aluminum components</dcterms:title><ual:dissertant>Hendrickx, Philippe</ual:dissertant><dc:abstract>Nowadays, aerospace manufacturing companies are facing major challenges in the management of end-of-life (EoL) aircrafts. In fact, the structures of decommissioned aircrafts, mainly composed of aluminum alloys (AA) from the 2xxx and 7xxx series, are stored in graveyards and downgraded into low-end applications using conventional Al recycling processes. This lack of revalorization processes offers the opportunity to improve the sustainability of the aerospace industry by recycling structural components of EoL aircrafts into valuable AA products. In that context, the present thesis examines the recyclability of aerospace AA scrap into bulk components by successive comminution and spark plasma sintering (SPS) processing. Specifically, the solid-state processing of Al 7075 scrap is investigated to assess the viability of EoL aircrafts recycling.Initially, pure Al scraps were processed using a patented industrial comminution line to gain insight on the in-process response of scrap materials and establish its process-structure-property relationships. The comminution process was found to be a viable technique to prepare suitable powders for the powder metallurgy (PM) industry from different types of Al scraps (chips, turnings and plates), provided the accumulation of exogenous contamination within the scrap was controlled. The comminution of Al chips under different processing conditions further evidenced the ability of this process to control the properties of the pulverized powders by tailoring its operating parameters. The morphology, composition and passivation layer of the pulverized powders were hence governed by the sets of circumferential velocity of the hammers and ventilation power selected for comminution. Subsequently, the pulverized powders were effectively recycled into bulk compacts by SPS processing. The major findings were that, for the pulverized powders of Al chips, the thickness of the passivation layer constituted the main barrier to their usage within the PM supply chain, while, for the pulverized powders of Al turnings and plates, the presence of exogenous contamination reduced drastically the strength of the recycled compacts.Ultimately, the comminution of Al 7075 scrap coming from EoL aircrafts yielded suitable powders for subsequent PM processing. The recyclability of pulverized Al 7075 powders was however limited by their thick composite passivation layer and high content of contaminants. The solid-state recycling route proposed for processing aerospace Al components was thus deemed as currently non-viable.</dc:abstract><dc:abstract>De nos jours, les entreprises manufacturières du secteur aérospatial font face à des défis majeurs dans la gestion d'aéronefs en fin de vie (FdV). En effet, les structures d'avions hors service, composées principalement d'alliages d'aluminium des séries 2xxx et 7xxx, sont stockées dans des cimetières d'avions et sont dévalorisées en applications bas de gamme à l'aide de procédés conventionnellement utilisés pour le recyclage d'Al. Ce manque de processus de revalorisation offre ainsi l'opportunité d'améliorer la durabilité du développement de l'industrie aérospatiale par le recyclage des composants structurels d'avions en FdV en nouveaux produits d'alliage d'aluminium valorisables. Dans ce contexte, cette thèse examine la capacité à recycler des rebuts d'alliages d'Al utilisés dans le secteur aérospatial en composants massifs par le biais de traitements successifs de broyage et de frittage par décharge plasma (FDP). En particulier, le traitement par voie solide de rebuts d'Al 7075 est étudié afin d'évaluer la viabilité du recyclage d'avions en FdV.Initialement, des rebuts d'Al pur ont été traités à l'aide d'une ligne de broyage industrielle brevetée afin de mieux comprendre le comportement des matériaux de rebut pendant le traitement et d'en établir les relations procédé-structure-propriété. Le procédé de broyage s'est révélé être une technique viable pour préparer des poudres acceptables pour l'industrie de la métallurgie des poudres (MP) à partir de différents types de rebuts d'Al (copeaux fins, copeaux grossiers et plaques), à condition que l'accumulation de contamination exogène au sein des rebuts soit contrôlée. En opérant sous différentes conditions de traitement, le broyage de copeaux fins d'Al a notamment mis en évidence la capacité de ce procédé à contrôler les propriétés des poudres broyées en adaptant ses paramètres de fonctionnement. La morphologie, composition et couche de passivation des poudres broyées étaient ainsi régies par les couples de vitesse circonférentielle des marteaux et de puissance de ventilation sélectionnés pour le broyage. Par la suite, les poudres broyées ont pu être efficacement recyclées en compacts massifs par un traitement de FDP. Les principaux résultats étaient que, pour les poudres broyées de copeaux fins d'Al, l'épaisseur de la couche de passivation constituait le principal obstacle à leur utilisation au sein de la chaine d'approvisionnement de la MP, tandis que, pour les poudres broyées de copeaux grossiers et de plaques d'Al, la présence de contamination exogène diminuait drastiquement la résistance mécanique des compacts recyclés.Finalement, le broyage de rebuts d'Al 7075 provenant d'avions en FdV a permis de générer des poudres acceptables pour un traitement ultérieur par MP. La recyclabilité de poudres broyées d'Al 7075 était cependant limitée par leur épaisse couche de passivation à structure composite et leur haute teneur en contaminants. L'approche de recyclage par voie solide proposée pour le traitement de composants aérospatiaux en Al a donc été considérée comme étant non viable à l'heure actuelle.</dc:abstract><ual:supervisor>Mathieu Brochu</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/x920g023g.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/1v53k0602</ual:fedora3Handle><dc:subject>Mining and Materials</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A2r36v104b"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Medicine</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>The role of semaphorin 4C in B cells during allergic airways disease</dcterms:title><ual:dissertant>Xue, Di</ual:dissertant><dc:abstract>La pathologie allergique des voies aériennes (PAA) est une maladie inflammatoire des voies respiratoires conductrices associée à l'hyperréactivité bronchique et au remodelage des voies aériennes. Elle est caractérisée par l'amincissement des voies aériennes, l'éosinophilie pulmonaire et l'augmentation de cytokines Th2 et d'IgE périphérique. Les cellules productrices d'IgE – les lymphocytes B – sont essentielles pour la pathogenèse de PAA. Suite à l'exposition à un allergène, les cellules B subissent une commutation isotypique en présence des cytokines IL-4 et IL-13. Notre laboratoire a détecté une augmentation significative des niveaux d'ARNm de Sémaphorine 4C (Sema4C) dans des cellules B isolées d'amygdales, qui ont été stimulées avec un agoniste CD40 et IL-4/IL-13. Les sémaphorines de classe 4 jouent un rôle crucial dans les réponses immunitaires; cependant, la fonction de Sema4C n'est pas encore déterminée. Le but global de nos études était de définir la fonction de Sema4C dans les cellules B pendant des maladies immunitaires liées aux cytokines Th2.Les marquages immunofluorescents montrent que Sema4C est fortement induite dans le compartiment des cellules B mémoire par la stimulation des cytokines Th2. Sema4C colocalise avec son ligand, Plexin B2, à un pôle synaptique des cellules B activées. Les cellules B déficientes en Sema4C (Sema4c-/-) n'organisent pas les fibres d'actine et ne font pas de synapses quand elles sont stimulées. Le tout est associé à une diminution de signalisation du récepteur des cellules B et un blocage de la production des immunoglobulines. Ces résultats suggèrent que Sema4C est nécessaire pour la formation de synapses immunitaires, qui contribuent à la différentiation des cellules B.En utilisant un modèle murin de PAA dirigé par l'ovalbumine, nous avons déterminé que la délétion spécifique de Sema4C des cellules B (souris S4C-B) induit une inflammation pulmonaire exacerbée, une augmentation des niveaux de cytokines IL-4 et IL-5 dans le fluide de lavage broncho-alvéolaire et un taux d'IgE sérique élevé. Les analyses suivantes ont démontré que dans le compartiment CD138+ de cellules B mémoire, les cellules B Sema4c-/- produisent plus d'IL-4 et mois d'IL-10, comparé aux cellules B de type sauvage (WT). Le transfert adoptif des cellules B Sema4c-/- CD19+CD138+ dans des récipients WT a montré une reproduction de l'augmentation de l'inflammation observée chez les souris S4C-B. Nous avons aussi démontré que le transfert de cellules WT CD19+CD138+IL10+ est capable de bloquer l'inflammation Th2 dans une modèle PAA contrôlé par antigène. Ceci indique que Sema4C est nécessaire à la différentiation d'une population nouvelle de cellules B régulatrices, les CD19+CD138+IL10+, dans la PAA.En résumé, nous avons identifié Sema4C comme étant une protéine critique pour la formation des synapses immunitaires dans des cellules B activées. Sema4C est nécessaire pour la production de cytokines régulatrices des cellules CD19+CD138+. Nos études soulignent l'importance des lymphocytes B comme cellules régulatrices dans l'inflammation allergique. Nous fournissons aussi de l'évidence que le développement des cellules B régulatrices requiert la formation de synapses immunitaires fonctionnelles.</dc:abstract><dc:abstract>Allergic airways disease (AAD) is an inflammatory disorder of the airways that is associated with airway hyperresponsiveness (AHR) and airway remodeling. It is characterized by narrowed airways with marked pulmonary eosinophilia, elevated Th2 cytokines and increased peripheral IgE. IgE-producing cells – B lymphocytes – are considered important for AAD progression. Upon allergen exposure, B cells undergo IgE class switching in the presence of Th2 cytokines IL-4 and IL-13. Our laboratory detected a significant increase in Semaphorin 4C (Sema4C) mRNA levels in isolated human tonsillar B cells that were stimulated with anti-CD40 antibodies and IL-4r or L-13. Class 4 semaphorins are of particular importance in immune responses, however, the function of Sema4C in the immune system has never been studied. Our  aim was to delineate the function of Sema4C in B cells during Th2 immune responses.Immunofluorescent staining revealed that Sema4C expression was induced by Th2 cytokine stimulation on human activated memory B cells. Sema4C co-localized with its binding partner, Plexin B2, at a synapse-like pole of activated B cells. Sema4c-deficient (Sema4c-/-) B cells failed to polarize and form a synapse-like structure when stimulated in vitro. The decreased polarization was associated with decreased B cell receptor (BCR) signaling and impaired immunoglobulin production. These results suggest that Sema4C is required for polarization and potentialy immune synapse formation, which contributes to B cell differentiation.Using a murine ovalbumin (OVA)-driven AAD model, we determined using both Sema4C deficient mice (Sema4C-/-) as well as chimeric mice with Sema4C deleted specifically in B cells (S4C-B mice) demonstrated exacerbated pulmonary eosinophilia, elevated IL-4 and IL-5 in bronchial alveolar lavage fluid (BAL), and increased peripheral OVA-specific IgE. Further analysis showed that in CD138+ B cells, Sema4c-/- B cells exhibited increased IL-4 and decreased IL-10 production, as compared to wild-type (WT) B cells. Transferring Sema4c-/- CD19+CD138+ cells to WT recipients reproduced the increased Th2 inflammation in S4C-B mice. We also showed that transfer of WT CD19+CD138+IL-10+ cells to Sema4C deficient mice suppressed Th2 inflammation in the antigen-driven AAD model. We therefore concluded that Sema4C is required for the differentiation of a novel regulatory B cell population, CD19+CD138+IL-10+, in AAD.In summary, we identified Sema4C as a critical protein for polarization and immune synapse formation in activated B cells. It is required for regulatory cytokine production from CD19+CD138+ cells. Our studies highlight the importance of B-lymphocytes as regulatory cells in allergic inflammation, as well as providing evidence that regulatory B cell development requires functional immune synapse formation.</dc:abstract><ual:supervisor>Bruce Mazer</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/8336h433k.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/2r36v104b</ual:fedora3Handle><dc:subject>Medicine</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Adn39x400r"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Electrical and Computer Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Advanced digital signal processing for next-generation coherent optical communication systems</dcterms:title><ual:dissertant>Qiu, Meng</ual:dissertant><dc:abstract>Coherent detection combined with digital signal processing (DSP) has been widely adopted in modern fiber-optic transport for long-haul and medium reach applications. Compared with direct detection systems, coherent communication systems can significantly improve the receiver sensitivity and increase the transmission capacity. The ever-increasing demand for greater transport network capacity necessitates continuous upgrade of future fiber transmission systems. In such context, novel advanced DSP schemes are necessary to satisfy the requirements of next-generation coherent optical communication systems.In this thesis, we present several advanced DSP techniques to cope with both linear and nonlinear impairments in coherent optical communication systems with data rates of 100 Gb/s and beyond. First, two effective low-complexity algorithms for carrier recovery in single carrier coherent systems are presented. Specifically, we describe a frequency offset (FO) tracking algorithm that can dynamically compensate the FO in intradyne coherent systems to avoid potential performance degradation caused by stochastic frequency drift of lasers. In addition, we demonstrate a format-transparent carrier phase recovery (CPR) algorithm based on interleaved superscalar parallelization, which can be economically implemented in practice because it can minimize the required pilot symbol overhead and buffer size in the superscalar parallelization structure. Second, we explore the digital subcarrier multiplexing (SCM) technique and discuss its benefits. Specifically, we employ SCM signals in a long-haul transmission scenario to demonstrate the improved tolerance to both fiber nonlinearity and laser linewidth when the number of subcarriers is optimized. Furthermore, we explore the enhanced flexibility of the DSP design in SCM systems and propose a novel joint CPR algorithm for the correction of cycle slips (CS). Finally, we conduct studies on a low-cost solution for medium reach transmission, namely the Stokes-vector direct detection (SV-DD) systems. We demonstrate that the laser linewidth tolerance of SV-DD systems is limited by equalization-enhanced phase noise (EEPN) and verify that the EEPN induced performance degradation can be mitigated by a simple maximum likelihood (ML) phase recovery stage. All the aforementioned DSP techniques have been demonstrated by simulations and experiments based on our leading-edge coherent optical transmission testbed.</dc:abstract><dc:abstract>La détection cohérente avec traitement de signaux numériques (TSN) est largement adoptée dans les transports modernes par fibre optique pour les applications de longue et moyenne portée. Comparé aux systèmes en détection directe, les systèmes de communication cohérents peuvent significativement améliorer la sensitivité du receveur et augmenter la capacité de transmission. La demande croissante incessante pour une plus grande capacité des réseaux de transport nécessite des améliorations continues sur les systèmes de transmission par fibre. Dans un tel contexte, de nouveaux algorithmes de TSN avancés sont nécessaire pour satisfaire aux exigences des systèmes de communication optique cohérent de prochaine génération.Dans cette thèse, nous présentons plusieurs techniques de TSN avancé pour faire face aux détériorations linéaires et non-linéaire des systèmes cohérents de communications optique avec taux de transfert de 100 Gb/s et plus. Premièrement, nous présentons deux algorithmes de recouvrement de la porteuse efficaces et à faible complexité pour les systèmes cohérent à porteuse unique. Plus spécifiquement, nous décrivons un algorithme pour traquer le décalage en fréquence (DF) qui peut dynamiquement compenser pour le DF des systèmes cohérents intradynes permettant d'éviter une potentielle dégradation de la performance causée par la dérive fréquentiel stochastique des lasers. De plus, nous démontrons un algorithme de recouvrement de phase de la porteuse (RPP) transparent aux formats de modulation basé sur la parallélisation super-scalaire interfoliée, qui peut être économiquement implémenté en pratique car il peut minimiser la surcharge de symboles pilotes et la largeur du tampon dans les structures à parallélisation super-scalaire. Deuxièmement, nous explorons la technique de multiplexage de sous-porteuses (MSP) numérique et discutons de ses bénéfices. Plus spécifiquement, nous employons des signaux en MSP dans un scénario de transmission à longue portée pour démontrer une tolérance améliorée de ceux-ci aux non-linéarités de la fibre ainsi qu'à la largeur spectrale du laser quand le nombre de sous-porteuse est optimisé. En outre, nous explorons la flexibilité rehaussée du design des TSN pour les systèmes à MSP et proposons un nouvel algorithme à RPP permettant conjointement la correction des glissements de cycle (GS). Finalement, nous menons des études sur une solution à faible coût pour les transmissions à portée moyenne, nommément, sur les systèmes en détection directe de vecteurs-Stokes (DDVS). Nous démontrons que la tolérance à la largeur spectrale des systèmes en DDVS est limitée par le bruit de phase rehaussé par l'égalisation (BPRE) et vérifions que la dégradation induite par le BPRE peut être atténué à l'aide d'une simple étape de recouvrement de phase à vraisemblance maximale (VR). Toutes les techniques de TSN mentionnées ci-haut furent démontrées à l'aide de simulations et d'expérimentations basées sur notre banc d'essai de transmission optique cohérente de dernier cri.</dc:abstract><ual:supervisor>David V. Plant</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/6q182n713.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/dn39x400r</ual:fedora3Handle><dc:subject>Electrical and Computer Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Aqv33s010c"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Kinesiology and Physical Education</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Ice hockey helmet fit using 3D modeling</dcterms:title><ual:dissertant>Greencorn, David</ual:dissertant><dc:abstract>Ice hockey helmets must pass rigorous standardized impact tests to become certified for sale. However, these tests are performed with the helmet attached to a headform with the exact same shape from which they are designed. Human head shapes are not uniform, and very few standards exist for helmet fitting for the common user. The goal of this study was to create a 3D acquisition protocol to assess the geometric fit of ice hockey helmets with the proper head-helmet interface and orientation. The following study recruited 30 participants who wore 5 ice hockey helmet models in an attempt to quantify ice hockey helmet fit using 3D modeling, and analyzing fit parameters in two ways. First, by comparing geometric fit measures (dimensional differences or DD) in a cross-sectional plane of the head to the perception of fit scores. Second, by using principal component analysis (PCA) to determine the largest components of fit. Significant differences were noted between helmet models for both perception of fit scores as well as the DD (i.e. overlaps or gaps between the head surface and the helmet liner). However, in most cases the helmets that were perceived to be significantly tighter than another showed no significant difference in DD. The principal components of fit that were calculated included the overall uniformity of helmet-head contours emphasizing the differential between the DD of the front and back regions of the head, the lateral DD magnitudes, the front-back DD magnitudes, and the uniformity of the DD for the absolute back of the head and the rear lateral boss. PCA shows promise as a future method to investigate fit for a variety of purposes and fields.</dc:abstract><dc:abstract>Les casques de hockey sur glace doivent passer des tests d'impacts rigoureux and respectant des standards pour devenir certifié pour la vente magasin. Par contre, ces tests sont performés avec le casque attaché à une tête de mannequin qui est de la même forme que celle qui a été utilisé pour la fabrication. La forme de la tête des humains ne sont pas uniformes et très peu de standards existent pour la convenance du casque pour le consommateur régulier. Le but de cette étude est de créer un protocole d'acquisition 3D pour évaluer la convenance des casques de hockey et l'évaluation réelle de l'orientation. Cette étude a recruté 30 participants qui ont porté 5 différent model de casques de hockey dans le but de quantifier la convenance utilisant un modélisation 3D et analyser les paramètres de convenance de deux façons. Premièrement, en comparant la convenance des mesures géométriques (différences dimensionnels ou DD) dans un plan cross-sectionnelle de la tête aux scores sur la perception de convenance. Deuxièmement, en utilisant les principales composantes d'analyses (PCA) pour déterminer la composante de convenance la plus important. Signifiantes différences a été noté entre les modèles de casques pour la perception de convenance et aussi la DD (chevauchements ou un espace entre la surface de la tête et le liner du casque). Par contre, dans la plupart des cas les casques qui étaient perçus comme plus serré que les autres démontraient aucune différence signifiante dans la DD. Les principales composantes de convenance qui ont été retenus sont l'uniformité du contour tête-casque en général ce qui emphase la différence entre la DD des régions du devant et du derrière de la tête, en plus des magnitudes des DD latérales, avant-arrières et de l'uniformité de la DD du derrière de la tête et des bosses arrière latérales. PCA démontre un potentiel pour être une méthode dans le futur pour rechercher sur la convenance dans une variété de buts and champs d'expertises.</dc:abstract><ual:supervisor>David J. Pearsall</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/xg94hs26v.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/qv33s010c</ual:fedora3Handle><dc:subject>Kinesiology and Physical Education</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3As4655k097"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Chemistry</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Toward alternative routes to access functionalized arenes</dcterms:title><ual:dissertant>Girard, Simon</ual:dissertant><dc:abstract>Cette thèse décrit le développement de nouvelles méthodes de synthèse de molécules complexes et de matériaux avancés. Un bref récapitulatif des diverses stratégies de synthèse à la disposition des chimistes pour la construction de cycles aromatiques hautement décorés est présenté dans le chapitre 1. Le concept de synthèse de « l'hydrogène chapardé » pour la synthèse directe d'arènes fonctionnalisées à partir de phénols est introduit dans le chapitre 2. La première étape dans la réalisation de cet objectif a mené au développement d'une nouvelle approche pour la synthèse d'éther aromatique. Cette réaction catalysée par des complexes de cuivre, permet la condensation oxydante d'alcools aliphatiques avec des dérives de la cyclohexenone pour la génération in situ du cycle aromatique par aromatisation aérobie. De surcroit, la quantité du catalyseur de cuivre peut être réduit et l'oxygène moléculaire utilisé comme oxydant terminal.Le chapitre 3 présente de plus amples explorations de la déshydrogénation aromatique des dérivés de la cyclohexenones pour accéder aux arènes fonctionnalisés. Le développement d'un nouveau catalyseur au palladium est décrit pour l'arylation sélective de diverses amines secondaires à partir de précurseurs non-aromatiques.Dans le chapitre 4, les récents développements dans le domaine de la déshydrogénation aromatique et ses applications à la synthèse d'hétérocylces seront présentés ainsi que la récente application du concept de « l'hydrogène chapardé » pour le couplage direct entre phénols et amines. Enfin, le chapitre 5 présente les résultats préliminaires dans l'exploration du dioxyde de carbone supercritique comme milieu réactionnel pour la synthèse de squelettes organométalliques poreux cristallins. Plus particulièrement, de la synthèse de squelettes d'imidazolate zéolitique à partir d'oxydes métalliques.</dc:abstract><dc:abstract>This thesis describes the development of novel methods and processes to efficiently access complex molecules and advanced materials.After a brief overview of the various synthetic strategies available to chemists for the construction of highly decorated aromatic rings in chapter 1, the "borrowing hydrogen" synthetic concept for the direct synthesis of functionalized arenes from phenols is presented in chapter 2. As a first step towards this goal; a direct, versatile and original approach for the synthesis of functionalized aryl ethers is introduced. This reaction, catalyzed by copper complexes, allows the oxidative condensation of aliphatic alcohols and 2-cyclohexenone derivatives to generate in situ the aromatic ring through aerobic aromatization. In addition, the amount of copper catalyst can be reduced and molecular oxygen used as the terminal oxidant.Next, further exploration of the dehydrogenative aromatization of cyclohexenone derivatives to access decorated arenes is presented in chapter 3. The development of a new palladium catalyst is introduced for the atom-economic and waste-minimized selective arylation of various secondary amines from non-aromatic precursors.In chapter 4, the recent advances in the field of dehydrogenative aromatization and its application to the synthesis of heterocycles is discussed along with the successful application of the "borrowing hydrogen" strategy for formal direct cross coupling of phenols with amines. Finally, chapter 5 presents preliminary results on the exploration of supercritical carbon dioxide as medium for the synthesis of metal-organic frameworks. In particular, the synthesis of porous and non-porous zeolitic imidazolate frameworks from metal oxide is introduced.</dc:abstract><ual:supervisor>Chaojun Li</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/xd07gw26n.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/s4655k097</ual:fedora3Handle><dc:subject>Chemistry</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3As4655k100"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Chemistry</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>From drug design to drug metabolism and biocatalysis: exploring the realm of proteins for pharmaceutical applications</dcterms:title><ual:dissertant>Schiavini, Paolo</ual:dissertant><dc:abstract>Despite the tremendous progress of the last decades, many efforts are still being directed towards a better understanding of how proteins work at the atomic level. The relationship between structure and function of proteins remains an important subject of investigations from research groups all around the world. Advances in the methodologies for the determination of the three dimensional structure of proteins have contributed enormously to the field, but they still cannot provide scientists with all the desired answers. In fact, proteins are dynamic entities whose properties change depending on several variable including temperature, pH, presence of ions, type of solvent and interaction with other molecules. As a result, much emphasis has been placed on the development of computational tools to simulate protein systems and predict their behavior based on a set of given conditions. In the end, full understanding of a biochemical process is often achievable only through a combination of approaches at the interface of chemistry, physics, biochemistry and computer science. This doctorate thesis describes a series of studies where diverse strategies, from the use of small molecule as probes to investigate conformational dynamics, to computer-assisted protein engineering, were used to investigate different protein systems. Organic synthesis, an array of analytical procedures, computational tools and site-directed mutagenesis include some of the many techniques that were combined to tackle projects relevant to the pharmaceutical field.In chapter 1, the topic of protein science is introduced. Protein structure, dynamics and protein engineering are discussed. Two types of protein families, kainate receptor (KAR) and cytochrome P450 (P450s), are presented. In chapter 2, a study on kainate receptor GluK2, a glutamate-type receptor involved in neurodegenerative diseases, is described. Analogues of L-glutamate were designed and used as molecular probes to investigate the conformational flexibility of the receptor. The findings shed light on the importance of a tyrosine residue, in the receptor binding site, in inducing receptor inhibition. In chapter 3, the focus is shifted to cytochromes P450s and their potential for biocatalytic application. In particular, P450 3A4, a human enzyme responsible for metabolizing &gt; 50 % of current drugs, was chosen as a starting point for the development of a versatile biocatalyst for hydroxylation reactions. Computer-aided protein engineering was used in the attempt to develop a chemo-enzymatic synthesis for the preparation of latanaprost, a prostaglandin analogue widely used for the treatment of glaucoma. In chapter 4, a semi-rational enzyme engineering approach was used to investigate the effect of "active site crowding" of P450 3A4 on its regio- and stereoselectivity, with the final goal of developing a biocatalyst for the preparation of useful hydroxylated products. General guidelines for the remodelling of the enzyme active site were established, and a biochemical assay for the screening of several mutants was developed. The strategy was applied for the total synthesis of (R)-lisofylline, a compound under investigation for its antinflammatory properties, and the functionalization of the steroid sex hormone progesterone. In chapter 5, a complex case of P450-mediated metabolism is presented. A series of prolyl oligopeptidase (POP) inhibitors were found to undergo a series of unexpected chemical transformation following enzymatic sulphur oxidation. Through a combination of LC–MS analysis, synthetic work, deuterium exchange studies, and computational predictions, a mixture of interconverting stereoisomers was characterized. </dc:abstract><dc:abstract>Malgré le progrès des dernières décennies, chimistes at biochimistes aspirent toujours à mieux comprendre le fonctionnement des protéines au niveau moléculaire. La relationentre la structure and la fonction des protéines reste un sujet important des investigations de plusieurs groupes de recherche dans le monde. Les avancées dans la méthodologie pour la détermination de la structure tridimensionnelle des protéines ont beaucoup contribué au domaine, mais nombreuses questions restent sans réponse. En fait, les protéines sont des entités dynamiques avec des propriétés qui changent à l'effet de plusieurs variables comme la température, le pH, la présence d'ions, le type de solvant et l'interaction avec d'autre molécules. Par conséquent, beaucoup d'efforts sont actuellement dédiés au développement d'outils de calcul pour simuler et prévoir in silico le comportement des protéines. En effet, la compréhension complète d'un processus biochimique est possible seulement à travers une combinaison d'approches à l'interface de la chimie, la physique, la biochimie et les sciences informatiques. Cette thèse de doctorat décrit une série d'études de différentes protéines. Pour ce faire, une variété de stratégies comprenant l'utilisation de petites molécules comme sondes pour enquêter la dynamique conformationnelle, ou l'ingénierie des protéines aidée par l'informatique, ont été utilisées. La synthèse organique, un assortiment de procédures analytiques, la chimie informatique et la mutagénèse contrôlée sont quelques unes des techniques qui ont été combinées pour faire face à des projets pertinents dans le domaine pharmaceutique.Dans le chapitre 1, le sujet de la science des protéines est introduit. La structure, la dynamique et l'ingénierie des protéines sont discutés. Deux familles de protéines, le récepteurs kaïnate (KAR) et les cytochromes P450 (P450s) sont présentés. Dans le chapitre 2, GluK2, un récepteur kaïnate impliqué dans les maladies neurodégénératives, est étudié. Des analogues de L-glutamate ont été conçus et utilisés comme sondes moléculaires pour examiner la flexibilité conformationnelle du récepteur. Les découvertes ont révélé l'importance d'une tyrosine dans le site actif pour l'inhibition du récepteur. Dans le chapitre 3, l'attention est tournée vers les cytochromes P450s et leur potentiel dansdes applications biocatalytiques. En particulier, P450 3A4, une enzyme humaine responsable du métabolisme de plus de 50% des médicaments sur le marché, a été choisi comme point de départ pour le développement d'un biocatalyseur de réactions d'hydroxylation. L'ingénierie de protéines a été utilisé pour développer une synthèse chimio-enzymatique du latanoprost, un analogue des prostaglandines communément utilisé pour le traitement du glaucome. Dans le chapitre 4, une stratégie semi-rationnelle pour l'ingénierie des protéines a été utilisée pour examiner l'effet de « l'encombrement du site actif » de P450 3A4 sur sa régio- et stéreosélectivité, afin de développer un biocatalyseur pour la production d'intéressants composés hydroxylés. Des lignes directrices générales ont été établies pour le criblage de mutants. La stratégie a été appliquée à la synthèse de (R)-lisofylline, un composé étudié pour ses propriétés antiinflammatoires, et pour la fonctionnalisation de la progestérone, une hormone sexuelle stéroïdienne. Dans le chapitre 5, une étude du métabolisme d'inhibiteurs de la prolyl oligopeptidase (POP) est décrite. Les investigations ont révélé une chaine de transformations chimiques inattendues à la suite de l'oxydation enzymatique d'un atome de soufre catalysé par les P450s humaines. En combinant des analyses de chromatographie couplée à la spectrométrie de masse, de la synthèse organique, des études d'échange hydrogène/deutérium et des modélisations moléculaires, un mélange de stéréoisomères en équilibre a été caractérisé.</dc:abstract><ual:supervisor>Nicolas Moitessier</ual:supervisor><ual:supervisor>Karine Auclair</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/r494vn52h.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/s4655k100</ual:fedora3Handle><dc:subject>Chemistry</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A12579v877"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Epidemiology and Biostatistics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>A methodological framework for environmental public health surveillance with a practical example in wildfire smoke</dcterms:title><ual:dissertant>Morrison, Kathryn</ual:dissertant><dc:abstract>Wildfire smoke is considered a globally important cause of mortality by the World Health Organization, with an estimated 339,000 deaths from landscape fire smoke each year. The health effects from wildfire smoke are expected to intensify as changes in land use and climate are increasing the frequency and severity of wildfires, exposing more individuals to the harmful effects of smoke each year. The objective of an environmental public health surveillance (EPHS) system is to detect potential changes in the health status of the population, and to provide timely evidence for public health intervention during periods of hazardous exposure. However, the methodological and conceptual frameworks for surveillance are generally designed for infectious disease. EPHS poses some unique challenges, as exposures like air pollution are difficult to accurately measure and there are many indicators of health impact. Public health officials in environmental health have called for better decision-making surveillance tools. To address these challenges, in Chapter 3 I proposed a methodological framework for forecasting two health indicators against a common imperfectly measured exposure. My objectives were to identify a statistical approach that would be appropriate EPHS, be flexible so that changes to data characteristics could be accommodated (e.g., additional indicators or changes in exposure metrics), and address the computational constraints of requiring an "online" daily surveillance system. I demonstrated how the proposed model could be implemented using integrated nested Laplace approximations (INLA), a cutting-edge approach to approximate Bayesian inference. In Chapter 4, I explored the challenges of using the proposed EPHS system across an entire state or province with data aggregated by administrative boundaries, where some communities may have very small absolute populations. As an alternative to aggregating administrative units, I added spatial smoothing to the previously proposed model. The spatial smoothing stabilized the prediction variance in smaller regions, in exchange for a small loss of accuracy. In regions with larger populations, the smoothing was generally not found to be beneficial or necessary. The decision of whether to include spatial smoothing can be made within context of characteristics of the regions. Finally, I demonstrated how the model proposed in Chapter 3 could be used for surveillance. I used the severe wildfire smoke event in July 2015 in southern British Columbia as a case study, where smoky conditions resulted in PM2.5 concentrations up to ten times higher than baseline levels. Based on the theoretical intervention assessment, I found that simple, early interventions with lower effectiveness, such as public health messaging about steps to reduce exposure, were preferable to delayed interventions with higher effectiveness, such as evacuation. This work provides a flexible methodological approach that can be extended and improved as related research advances, such as improvements in exposure estimation and availability of additional real-time surveillance health data. The methods developed and evaluated in the first two manuscripts and implemented in the third are currently being integrated into the existing public health surveillance system at the BC Centre for Disease Control, and will be used during the wildfire season of 2017.</dc:abstract><dc:abstract>La fumée des feux de forêt est considérée comme une cause de mortalité importante à travers le monde, avec 339 000 décès causés par la fumée de feux de paysage chaque année. On s'attend à ce que les effets sur la santé de la fumée de feux de forêt s'intensifient, à mesure que les changements dans l'utilisation des terres et le climat augmentent la fréquence et la gravité des feux de forêt, exposant plus d'individus aux effets nocifs de la fumée chaque année. L'objectif d'un système de surveillance de la santé publique environnementale (EPHS) est de détecter les changements potentiels dans l'état de santé de la population et de fournir des preuves en temps opportuns pour le choix d'intervention de santé publique pendant les périodes d'exposition dangereuse. Cependant, les cadres méthodologiques et conceptuels de la surveillance sont généralement conçus pour les maladies infectieuses. L'EPHS pose des défis uniques, car les expositions comme la pollution de l'air sont Mesurer avec précision et il ya de nombreux indicateurs de l'impact sur la santé. Les responsables de la santé publique en matière de santé environnementale ont réclamé de meilleurs outils de surveillance pour la prise de décisions. Pour répondre à ces défis, nous avons proposé dans au chapitre 3 un cadre méthodologique pour la prévision de deux indicateurs de santé contre une exposition commune et imparfaitement mesurée. Nos objectifs étaient d'identifier une approche statistique qui ferait de l'EPHS appropriée, qui serait suffisamment souple pour permettre de tenir compte des changements apportés aux caractéristiques des données (par exemple, des indicateurs supplémentaires ou des changements dans les paramètres d'exposition), et qui permettrait de résoudre les contraintes informatiques liées aux besoins d'un système de surveillance quotidienne «en ligne». Nous avons démontré comment le modèle proposé pourrait être mis en œuvre en utilisant des approximations intégrées de Laplace (INLA), une approche de pointe pour l'approximation de l'inférence bayésienne. Au chapitre 4, nous avons exploré les défis liés à l'utilisation du système EPHS proposé dans l'ensemble d'un état ou d'une province, avec des données agrégées par des territoires administratifs, où certaines communautés peuvent avoir de très petites populations absolues. Comme alternative à l'agrégation des territoires administratifs, nous avons ajouté le lissage spatial au modèle proposé précédemment. Le lissage spatial a stabilisé la variance de prédiction dans les régions plus petites, en échange d'une petite perte de précision. Dans les régions où la population est plus importante, le lissage n'a généralement pas été jugé bénéfique ou nécessaire. La décision d'inclure le lissage spatial peut être prise dans le contexte des caractéristiques des données d'un ensemble de régions administratives. Enfin, nous avons décrit comment le modèle proposé au chapitre 3 peut être utilisé dans un système de surveillance en temps réel. Nous avons utilisé l'événement de la fumée de feu de forêt de juillet 2015, dans le sud de la Colombie-Britannique, où les concentrations de PM2,5 étaient jusqu'à dix fois plus élevées que les niveaux de référence. D'après notre évaluation théorique de l'intervention, nous avons constaté que des interventions simples et précoces à plus faible efficacité, comme la messagerie de santé publique sur les mesures à prendre pour réduire l'exposition, étaient préférables aux interventions plus tardives mais avec une efficacité plus élevée, comme l'évacuation. Les méthodes développées et évaluées dans les deux premiers manuscrits et mises en œuvre dans le troisième sont actuellement intégrées dans le système existant de surveillance de la santé publique au Centre for Disease Control de la Colombie-Britannique et seront utilisées pendant la saison des feux de forêt de 2017.</dc:abstract><ual:supervisor>Sarah Henderson</ual:supervisor><ual:supervisor>David Buckeridge</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/3t945t49h.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/12579v877</ual:fedora3Handle><dc:subject>Epidemiology and Biostatistics</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Axw42nb428"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Educational and Counselling Psychology</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Treating depression with cognitive behavioural therapy: exploring therapist technique</dcterms:title><ual:dissertant>Antunes-Alves, Sara</ual:dissertant><dc:abstract>A seriously debilitating condition, major depressive disorder (MDD) is the most common psychiatric illness (Kleine-Budde et al., 2013) said to become the foremost contributor to disease burden in high income countries like Canada by 2030 (Mathers &amp; Loncar, 2006). Cognitive behavioural therapy (CBT) is a widely used treatment with ample support for its efficacy in treating depression. It is based on the notion that depression is maintained chiefly by dysfunctional beliefs that influence motivation, behaviour, and affect (Beck, Rush, Shaw, &amp; Emery, 1979). As such, it is known for its abundance of goal-oriented, systematic interventions aimed at modifying everyday thoughts, behaviours, and emotions to alleviate symptoms of depression (Keshi, Basavarajappa, &amp; Nik, 2013). Decades of outcome studies demonstrate CBT's effectiveness in treating depression (Butler, Chapman, Forman, &amp; Beck, 2006). However, researchers remain confused about the specific elements responsible for its success (Webb, Auerbach, &amp; DeRubeis, 2012). While there have been numerous efforts toward better understanding the mechanisms of change in CBT, much of this body of research has been criticised for its methodological or conceptual limitations (Drapeau, 2014). This dissertation presents two distinct studies that serve to address some of these limitations to better our understanding of the specific therapist behaviours that contribute to patient improvement. The first examines specific interventions that occur in CBT with depressed patients and assesses their individual relationships with symptoms of depression, and late therapy cognitive errors and overall coping functioning. Addressing the persistent common vs. specific factor debate in the psychotherapy community, it identifies both interventions specific to CBT, as well as some common to all therapies related to the alliance. The second study is an extension of the first, exploring the focus of therapist interventions on two pivotal concepts in CBT: cognitive errors and coping strategies. Inspired by methods used in psychodynamic research, it presents a method to gauge therapist accuracy in CBT based on therapist-patient interaction on these concepts. The relationships between therapist accuracy conceptualized in this way and the same three dependent variables are investigated. Practical clinical and research implications of both studies are discussed throughout the dissertation. </dc:abstract><dc:abstract>Le trouble dépressif majeur (TDM), une pathologie débilitante sévère, constitue le trouble psychiatrique le plus répandu (Kleine-Budde et al., 2013) et est en voie de devenir, d'ici 2030, l'élément qui alourdira le plus le fardeau des maladies qui touchent les pays à revenu élevé comme le Canada (Mathers &amp; Loncar, 2006). La thérapie cognitivo-comportementale (TCC) repose sur la notion selon laquelle la dépression est causée principalement par des croyances dysfonctionnelles qui influent sur la motivation, le comportement, et les affects (Beck, Rush, Shaw, &amp; Emery, 1979). À cet égard, cette thérapie est reconnue pour son abondance d'interventions systématiques orientées vers un but, soit modifier les pensées, émotions, et comportements quotidiens pour soulager les symptômes de la dépression (Keshi, Basavarajappa, &amp; Nik, 2013). Les études axées sur les résultats menées au cours des dernières décennies ont démontré que la TCC était efficace dans le traitement de la dépression (Butler, Chapman, Forman, &amp; Beck, 2006). Toutefois, les chercheurs s'interrogent sur les éléments précis qui ont contribué à ce succès (Webb, Auerbach, &amp; DeRubeis, 2012). Malgré tous les efforts visant à mieux comprendre les mécanismes de changements apportés par la TCC, ce domaine de recherches a, dans une grande mesure, fait l'objet de critiques en raison de ses limites méthodologiques ou conceptuels (Drapeau, 2014). La présente thèse présente deux études distinctes qui traitent de certaines de ces limites dans le but d'accroître notre compréhension des approches spécifiques des thérapeutes pour améliorer la condition des patients. La première décrit des interventions précises réalisées dans le cadre de la TCC avec des patients souffrant de dépression afin de déterminer leurs effects sur les symptômes de la dépression, les erreurs cognitives, et le fonctionnement global du coping. Dans le cadre du débat qui persiste au sein de la communauté des psychothérapeutes, divisés sur la question des facteurs communs et des facteurs spécifiques, cette étude décrit les deux types d'intervention propres à la TCC, ainsi que certaines interventions communes à toutes les thérapies liées à l'alliance thérapeutique. La deuxième étude constitue une prolongation de la première en ce qu'elle explore les interventions thérapeutiques à l'aide de deux concepts clés en TCC: les erreurs cognitives et les stratégies de coping. S'inspirant des méthodes utilisées en recherche psychodynamique, cette étude offre une méthode qui permet d'évaluer le degré de précision des thérapeutes qui pratiquent la TCC en fonction de l'interaction thérapeute-patient basée sur ces concepts. Elle se penche aussi sur le rapport entre le degré de précision des thérapeutes ainsi conceptualisé et les trois mêmes variables dépendantes. Les implications des deux études sur le plan de la recherche et de la pratique sont également analysées tout au long de la thèse.</dc:abstract><ual:supervisor>Martin Drapeau</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/vd66w227f.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/xw42nb428</ual:fedora3Handle><dc:subject>Educational and Counselling Psychology</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Apv63g267n"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Master of Science</schema:inSupportOf><dc:contributor>Department of Family Medicine</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Accessibility of adolescent care in the context of primary care reforms: a retrospective population-based cohort study in Québec, Canada</dcterms:title><ual:dissertant>Ohm, Hyejee</ual:dissertant><dc:abstract>Introduction: Les groupes de médecine de famille (GMF) ont été mis en place au Québec il y a plus de dix ans. Ce nouveau modèle de soins primaires multidisciplinaires vise à améliorer le milieu médical. Les soins primaires sont essentiels pour les adolescents, car les comportements malsains tels que le tabagisme, l'abus d'alcool et l'inactivité physique qui sont adoptés pendant cette période deviennent des facteurs de risque des maladies chroniques à l'âge adulte. Un accès facilité aux soins primaires peut aider les adolescents à maintenir leur état de santé, à modifier les comportements malsains et à recevoir des traitements au temps opportun. Au Québec, les adolescents reçoivent principalement des soins primaires de la part des médecins de famille (GMF et non-GMF) ou des pédiatres. Aucune étude publiée n'a étudié l'impact des nouveaux modèles de réforme de soins primaires sur l'accès des adolescents aux soins.Objectifs: Évaluer si les GMF sont associés à un accès accru aux soins et à une diminution des inégalités de santé chez les adolescents.Méthodes: Étude de cohorte populationnelle rétrospective utilisant les données administratives de santé au Québec pour les adolescents entre 2010-2013 (n = 574 964). Nous avons effectué des analyses de régression multivariée pour examiner les associations entre 4 modèles de soins primaires (GMF, médecins de famille non-GMF, pédiatres ou sans soins primaires) et deux résultats: visites à l'urgence (résultat principal), et visites de soins primaires (résultat secondaire). Les modèles ont été ajustés pour les facteurs de confusion: âge, sexe, co-morbidités, ruralité, statut socioéconomique (SSE). Les raisons des visites aux urgences ont été examinées à l'aide des codes de diagnostic de la CIM-9CA selon les facturations des médecins. L'analyse secondaire a évalué la modification des effets, examinant l'interaction entre le SSE et le modèle de soins primaires.Résultats: La répartition des adolescents selon les modèles de soins primaires était la suivante: 19,7% dans les GMF, 13,7% dans les soins pédiatriques, 10,1% dans les non-GMF et 56,5% dans les soins primaires. Comparativement aux adolescents recevant des soins de FMG, moins de visites ont été effectuées lors de la prise en charge de pédiatres (rapport de taux d'incidence, RTI 0,90, IC 95% 0,87-0,93) ou sans soins primaires (RTI 0,89, IC 95%: 0,87-0,91). Aucune différence significative dans les taux d'utilisation de l'urgence n'a été remarquée entre GMF et non GMF (RTI 0,98, IC 95% 0,95-1,02). Les adolescents en milieu pédiatrique (rapport de taux 1,29, IC 95% 1,28-1,31) et les modèles non GMF (rapport de taux 1,12, IC 95% 1,11-1,13) étaient plus susceptibles de recevoir une visite de soins primaires que ceux des GMF. Le terme d'interaction entre le SSE et le modèle de soins primaires n'a été significatif que pour le résultat secondaire. Les non-GMF ont le plus grand écart dans l'accès aux visites de soins primaires entre les groupes SES les plus bas et les plus élevés, tandis que les modèles pédiatriques et GMF ont des gradients comparables.Conclusion: La majorité des adolescents n'utilisaient pas les soins primaires et les GMF n'étaient pas associés à un meilleur accès pour les adolescents. Bien que les GMF n'aient pas eu d'incidence significative sur les inégalités en santé pour les visites aux urgences, les GMF ont réduit l'inégalité des visites de soins primaires entre les groupes SES les plus bas et les plus élevés par rapport aux non GMF. Chez les adultes, les GMF ont été liés à des améliorations mineures dans l'accès. Nos résultats suggèrent que le même avantage ne s'étend pas à la population adolescent. La présente étude identifie les lacunes dans les soins primaires chez les adolescents - les études futures devraient déterminer et éliminer les obstacles et les facilitateurs de l'accessibilité des soins primaires.</dc:abstract><dc:abstract>Introduction: Family medicine groups (FMGs) were implemented in Québec over a decade ago as a new model of multidisciplinary primary care intended to improve the medical home. Primary care is crucial for adolescents, since unhealthy behaviours such as smoking, alcohol abuse, and physical inactivity that arise during this period translate into risk factors for chronic diseases in adulthood. Proper access to primary care may help adolescents maintain health, modify unhealthy behaviors, and receive timely treatments. In Québec, adolescents primarily receive primary care from family physicians (FMG and non-FMG) or pediatricians. No published studies have investigated the impact of the new reform models on adolescent access to care.Objectives: To assess the extent to which FMGs are associated with increased access to care and decreased health inequalities for adolescents. Methods: Population-based retrospective cohort study linking province-wide health administrative data in Québec for adolescents between 2010-2013 (n=574,964). Multivariate regression analyses were performed to test associations between 4 primary care models (FMGs, family physicians not part of FMGs, pediatricians, or no primary care) and two outcomes: emergency department (ED) visits (main outcome; proxy for primary care accessibility) and primary care visits (secondary outcome). Models were adjusted for confounders: age, sex, co-morbidities, rurality, socioeconomic status (SES), and previous ED visits. Reasons for ED visits was examined through the ICD-9CA diagnostic codes on physician claims. Secondary analysis assessed for effect modification, testing the interaction between SES and primary care model.Results: The distribution of adolescents across primary care models was the following: 19.7% in FMGs, 13.7% in pediatric care, 10.1% in non-FMGs, and 56.5% in no primary care. Compared to adolescents receiving care from FMGs, fewer ED visits were made when receiving care from pediatricians (incidence rate ratio [IRR] 0.90, 95% CI 0.87-0.93) or with no primary care (IRR 0.89, 95% CI 0.87-0.91). No significant differences in rates of ED use were found between FMGs and non-FMGs (IRR 0.98, 95% CI 0.95-1.02). Adolescents in pediatric (RR 1.29, 95% CI 1.28-1.31) and non-FMG models (RR 1.12, 95% CI 1.11-1.13) were more likely to receive a primary care visit than those in FMGs. The interaction term between SES and primary care model was only significant for the secondary outcome. Non-FMGs had the greatest gap in access to primary care visits between the lowest and the highest SES groups, whereas the pediatric and FMG models had comparable gradients. Conclusion: The majority of adolescents did not utilize primary care and FMGs were not associated with improved access for adolescents. Although FMGs did not significantly impact health inequalities for ED visits, FMGs reduced inequality in primary care visits between the lowest and highest SES groups compared to non-FMGs. Among adults, FMGs have been linked to minor improvements in access. Our findings suggest the same benefit does not extend to the adolescent population. The current study identifies gaps in adolescent primary care – future studies should ascertain and address the barriers and enablers of primary care accessibility.</dc:abstract><ual:supervisor>Isabelle Vedel</ual:supervisor><ual:supervisor>Patricia Li</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/gh93h2103.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/pv63g267n</ual:fedora3Handle><dc:subject>Family Medicine</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ah415pd129"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Integrated Program in Neuroscience</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Causal evidence for the role of REM sleep in memory formation</dcterms:title><ual:dissertant>Boyce, Richard</ual:dissertant><dc:abstract>Le sommeil paradoxal (SP) est une phase déterminante du sommeil des mammifères. Cependant sa fonction physiologique précise reste obscure. Plusieurs éléments de preuves liant le SP à différents aspects de l'apprentissage et de la mémoire chez l'homme et autres mammifères ont été obtenus principalement par le biais d'études corrélatives, d'approches pharmacologiques visant des populations de neurones actives pendant le SP ou encore par des études de privation de SP. Toutefois, le rôle spécifique du SP dans l'apprentissage et la mémoire reste un sujet de débat considérable puisque les approches corrélatives n'apportent pas de preuves définitives. En effet, le SP suit un pattern d'apparition transitoire au cours du cycle veille-sommeil, ce qui empêche la manipulation pharmacologique spécifique à cette phase de sommeil. De plus, les méthodes disponibles de privation de SP engendrent de nombreux problèmes notamment du stress, des dérèglements hormonaux et une perte de poids, ce qui est difficilement contrôlables. Par conséquent, la démonstration directe et causale du rôle du SP dans la mémoire est encore manquante. Le but du travail effectué durant cette thèse a été de surmonter ce problème en exploitant le contrôle temporel précis d'une population spécifique de neurones offert par l'optogénétique. En effet, nous avons ciblé une population de neurones exprimant γ-aminobutyric acid (GABA) dans le septum median de souris (SMGABA) qui est largement impliquée dans la genèse des ondes de 7 Hz associée à la mémoire: le rythme theta. Ce rythme a la particularité d'être prédominant pendant le SP sans être pour autant impliqué dans la régulation du sommeil.L'objectif principal de notre expérience était de tester si l'activité neuronale de SMGABA pendant le SP est déterminante pour la consolidation de la mémoire. Suite à un apprentissage lors d'un test visant à reconnaitre le changement de place d'un nouvel objet ou un test standard de conditionnement de peur, l'activité de SMGABA a été inhibée spécifiquement pendant les épisodes de SP apparaissant durant les 4h qui succèdent le test. Suite à l'inhibition de SMGABA pendant le SP, la puissance du rythme theta dans l'hippocampe pendant le SP a été significativement réduite sans affecter le comportement au cours du sommeil. Le jour suivant, les souris ont présenté des troubles de mémoire concernant la reconnaissance de la place du nouvel objet ainsi que du conditionnement de peur au contexte. Le SP joue un rôle critique dans ces résultats puisque l'inhibition de SMGABA pendant des durées similaires et de manière non spécifique pendant le SL ou l'éveil n'a aucun effet sur la mémoire. Ce résultat démontre que l'activité de SMGABA spécifiquement pendant le SP est essentiel pour la formation normale de mémoire spatiale et contextuelle. Dans l'ensemble, cette étude est la première à démontrer que l'activité neuronale de SMGABA sélectivement pendant le SP joue un rôle critique dans la formation de la mémoire. Le mécanisme visant à comprendre comment le SP peut contribuer à la formation de la mémoire dépasse la portée de ce travail de thèse et des études supplémentaires sont requises pour clarifier ce lien. Compte tenu de ces résultats, il est très probable que l'altération de la mémoire observée soit une conséquence directe de la perturbation du rythme theta pendant le SP qui suit immédiatement l'apprentissage. Cependant, d'autres mécanismes, incluant l'altération de l'homéostasie synaptique peuvent aussi être impliqués.</dc:abstract><dc:abstract>Rapid-eye movement sleep (REMs) is a major component of mammalian sleep, however the precise physiological function of REMs remains unclear.  Several lines of evidence linking REMs to various aspects of learning and memory in humans and non-human mammals has been obtained from correlation based studies, pharmacological approaches that target neural populations during REMs as well as studies using REMs deprivation techniques.  However, whether REMs has a direct role in learning and memory remains a topic of considerable debate; correlative studies do not provide definitive answers, REMs has a transient pattern of occurrence that prevents REMs-selective pharmacological manipulation and the available methods to selectively deprive animals of REMs have critical caveats – including stress, hormone imbalance and weight loss - that are difficult to fully control for.  Therefore, direct causal evidence for the role of REMs in memory is still lacking.  This thesis work sought to overcome these issues by taking advantage of the temporally precise control of specific neural circuits enabled by the use of optogenetic techniques.  Specifically, we sought to target a population of γ-aminobutyric acid (GABA) -containing neurons within the medial septum of mice (MSGABA) which are heavily implicated in the generation of the memory-associated ~7 Hz theta rhythm that is prominent during REMs, yet not implicated in the regulation of sleep itself.    The primary experimental goal was to test whether MSGABA neural activity specifically during REMs is critical for normal memory consolidation.  Following a training session for a spatial novel object place recognition test or completion of a standard fear conditioning paradigm, MSGABA neural activity was optogenetically silenced selectively during REMs for the subsequent 4 h.  Hippocampal theta power during REMs was found to be significantly reduced by REMs-specific MSGABA neural inhibition yet sleeping behavior was unaltered.  The following day, mice demonstrated impaired novel object place recognition memory and fear-conditioned contextual memory.  REMs was a critical factor in these results as MSGABA inhibition for similar durations non-specifically during non-REMs and wakefulness did not result in any memory impairment.  Thus, these results demonstrates that MSGABA activity selectively during REMs is critical for normal spatial and contextual memory formation. Cumulatively, this work is the first to demonstrate that neural (MSGABA) activity selectively during REMs is critical for normal memory formation.  A precise mechanistic understanding of exactly how REMs contributes to memory formation was beyond the scope of this thesis work and will require future research to clarify.  Considering the results, it is a distinct possibility that the memory impairment observed was a direct result of the disruption of theta oscillations during REMs immediately following learning, although other mechanisms, including disturbed synaptic homeostasis, may also be involved.   </dc:abstract><ual:supervisor>Sylvain Williams</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/4x51hm83q.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/h415pd129</ual:fedora3Handle><dc:subject>Neuroscience</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3A4t64gq826"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Human Genetics</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Genetic risk factors of childhood onset schizophrenia</dcterms:title><ual:dissertant>Ambalavanan, Amirthagowri</ual:dissertant><dc:abstract>Schizophrenia is a severe psychiatric disorder that affects approximately 1% of the general population. Childhood Onset Schizophrenia (COS) is a rare form of schizophrenia diagnosed during childhood (i.e. 6 to 13 years of age). The signs and symptoms of this early form of schizophrenia are continuous with those observed for adult schizophrenia and as such they equally impair the ability of those who are affected. Relatives who are genetically closer to a schizophrenic patient are more likely to develop the disorder themselves, and there is considerable interest in specific genetic mechanisms involved in its transmission. To this day the number of studies that examined the genetic risk associated to COS remains limited and only a few of those studies were focused on the identification of causative genes. With the advent of high-throughput sequencing instruments and whole exome capture arrays, genetic studies of schizophrenia recently tested the implication of de novo variants (variant not inherited from one of the two parents). The first chapter of this thesis describes an investigation of de novo variants across the entire coding regions (whole exome) of individuals diagnosed with COS. Our results showed such COS cases appear to present an increased number of missense variants that are predicted to have deleterious impact suggesting that de novo variants could represent an important aspect of the genetic architecture that underlies the development of COS. The following chapter describes a reexamination of the same whole exome sequencing (WES) data to identify inherited recessive variants. This analysis revealed an enrichment of disease related variants across the X-linked genes of male patients. Interestingly, human brain transcriptome data derived from the general population shows those X-linked genes are highly expressed in the brain. Overall these results represent the first published reports linking COS to single nucleotide variants identified using a tandem high throughput sequencing and genome wide approach (exome). The genes identified in our two studies represent a list of potential genetic risk factors linked to COS, which in turn provide clues about the pathogenicity of this complex disorder. </dc:abstract><dc:abstract>La schizophrénie est un trouble psychiatrique sévère qui touche approximativement 1% de la population générale. La schizophrénie à début précoce est une forme rare de schizophrénie qui se manifeste pendant l'enfance (entre 6 à 13 ans). Des études antérieures ont démontré que les symptômes de cette forme de schizophrénie de l'enfance sont en continuité avec ceux observés chez les adolescents et adultes qui souffrent de la schizophrénie. Peu d'études génétiques ont été réalisées pour la schizophrénie de l'enfance et encore moins ont été axés sur l'identification de gènes causatifs. Avec l'avènement des technologies de séquençage à haut débit et le développement de systèmes permettant de capturer l'ensemble des séquences codantes (exome), les études génétiques portant sur la schizophrénie ont testé la contribution des variations de novo (variations non transmises par l'un des deux parents). Le premier chapitre de la thèse décrit l'identification de variations de novo dans l'ensemble des séquences codantes du génome (exome) de cas ayant reçu un diagnostic de schizophrénie de l'enfance. Nous avons observé une augmentation du nombre de variations faux-sens pour lesquels les outils de prédictions indiquent un impact délétère important. Nos résultats suggèrent que les variations de novo pourraient représenter une part importante de l'architecture génétique de la schizophrénie de l'enfance. La seconde partie de la thèse décrit une étude (faites à partir des mêmes données d'exomes) visant à identifier les variations récessives transmise. Les résultats de cette seconde analyse révèlent un enrichissement des variations au niveau de gènes liés   au chromosome X chez les garçons masculins. Fait intéressant, les bases de données transcriptomiques humaine révèlent que ces gènes liés au chromosome X sont fortement exprimés au niveau du cerveau. En résumé, ces résultats sont les premiers à lier la schizophrénie de l'enfance à des variations nucléotidiques simples qui ont été identifiés grâce à une utilisation combinée de séquençage à haut débit au niveau de l'ensemble des séquences codantes du génome (exome). Les gènes identifiés par nos deux études représentent une liste de facteurs de risque génétiques pour la schizophrénie de l'enfance, par la même occasion ceux-ci offrent des indices sur pathogénèse de ce trouble complexe.</dc:abstract><ual:supervisor>Guy Rouleau</ual:supervisor><ual:supervisor>Ridha Joober</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/gq67jt830.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/4t64gq826</ual:fedora3Handle><dc:subject>Human Genetics</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Atx31qm38d"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Bioresource Engineering</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>Deep-fat frying charactersitcs of blends of palm and canola oils</dcterms:title><ual:dissertant>Mba, Ogan</ual:dissertant><dc:abstract>Selecting an appropriate oil for deep-fat frying can be challenging since oils undergo irreversible thermo-degradation as frying progresses. Highly-saturated and trans-fat oils have adverse public health consequences. Virgin palm oil (VPO) has a balanced fatty acid composition and is rich in phytonutrients that possess health-promoting functions. This study investigated the stability of these phytonutrients and their migration into fried products when VPO either alone or as the major portion in blends of oils is used in deep-fat frying. Refined canola oil (RCO) was the second oil sample in the binary blends. Firstly, Fourier transform near-infrared spectroscopy (FTNIRS) was used to characterize the palm, canola, and their blends oil samples. Partial Least Squares (PLS) regression was used to correlate spectral data with iodine value (IV), free fatty acid (FFA) and peroxide value (PV) data of the oil samples obtained by reference methods. First derivative and first derivative + straight line subtraction spectra pre-processing methods gave the most reproducible and robust predictions of the PLS-NIR models developed. The study simultaneously characterized the essential quality parameters of VPO, RCO and their blends using the FTNIRS. The VPO, RCO and blend samples were used in deep-fat frying of ripe and unripe plantain crisps at 180 °C for different times. Significant differences (p &lt; 0.05) were observed in the oil uptake and color properties of the crisps. The unripe and ripe plantain crisps absorbed 14% and 26% less oil, respectively, when fried in VPO than RCO. The browning index showed that the VPO crisps had greater color changes than the crisps fried using RCO. The VPO: RCO blends also improved the qualities of the crisps better than RCO alone. The deterioration of VPO, RCO and VPO: RCO (1:1 w/w) blend during 20 h of successive deep-fat frying at 170, 180 and 190 oC was investigated. Kinetics results showed that FFA and PV accumulation followed the first order reaction model, while anisidine value (p-AV), total polar compounds (TPC) and color index (CI) followed the zero-order reaction model. The deterioration rate constants were modeled by the Arrhenius equation. The overall activation energy (Ea) values showed that during thermo-oxidation, the PV build-up was the fastest while the blend oil sample was the most stable. Frying potato slices at 170 oC for different times was used to assess the migration and retention of the endogenous phytonutrients from VPO, RCO and blend (VPO: RCO 1:1 w/w). The French fries produced using VPO and the blend was significantly enriched with phytonutrient (over 50% of total carotenoids, 40 – 45% of tocotrienols and 3 – 16% of tocopherols), absorbed less oil and showed more pronounced color changes. The biphasic first order model was applied as a predictor model of changes in the concentration of the phytonutrients in the French fries.The thermostability of the tocopherols, tocotrienols and carotenoids in VPO, RCO and their blends used in deep-fat frying at 170 to 190 oC for 20 h was evaluated. The deterioration kinetic rate of each homolog followed a reaction order &gt;1. The Arrhenius relationship adequately modeled the deterioration rates. The Ea showed that the least stable homologs were γ-tocopherol and γ-tocotrienol while δ-tocotrienol and carotenoids were the most stable. The rate for α-tocopherol, α-tocotrienol and δ-tocopherol were similar and intermediate. The carotenoids were more retained in VPO (Ea of 71±5 kJ/mol), while the tocopherols and tocotrienols were more stable in the blend oil samples.This work further broadened the scientific knowledge on the behavior of VPO alone or in blend with other unsaturated oils during deep-fat frying. The blended oil samples were the most stable. The fried products were enriched with bioactive phytonutrients. VPO and blends offer great advantages as choice frying oils and can be adopted in domestic and commercial deep-fat frying protocols.</dc:abstract><dc:abstract>La sélection d'une huile appropriée pour la friture commerciale peut être difficile puisque lors du procédé de friture, l'huile subit des réactions de thermo-oxydation menant à sa dégradation. Les graisses animales très saturées et les acides gras trans ont des effets néfastes sur la santé. L'huile de palme vierge (HPV) a une composition balancée en acides gras et elle est très riche en phytonutriments ayant des propriétés bénéfiques sur la santé. Cette étude a examiné la stabilité de ces phytonutriments et la migration des phytonutriments vers les produits frits lorsque HPV est utilisée seule ou en mélange avec une l'huile de canola (HCO).Tout d'abord, la spectroscopie dans le proche infrarouge à transformée de Fourier (FT-NIR) fut utilisée pour caractériser l'huile de palme et l'huile de canola seuls ou en combinaison.  Les effets des différentes méthodes de prétraitement des spectres ont été étudiés afin de prédire la reproductibilité et la robustesse des modèles développés. Dans l'ensemble, les résultats de cette étude ont démontré la pertinence de la spectroscopie FT-NIR pour la caractérisation simultanée des paramètres essentiels des huiles végétales et des mélanges utilisés. L'HPV, l'HCO et leurs mélanges ont été utilisés pour la friture, à 180 °C, de tranches de plantains mûrs et immatures. Aucune différence significative (p &gt; 0,05) du taux de perte de l'humidité ou de la croustillance des échantillons ne fut observée. Des différences significatives (p &lt; 0,05) ont été observées dans les propriétés d'absorption et de la couleur. Les tranches de plantains mûrs et immatures frites dans l'HPV ont absorbé 14 % moins et 26 % moins d'huile, respectivement, que lorsqu'elles étaient frites dans l'HCO. Il a été observé que les tranches de plantain ont subi un changement de couleur plus prononcé lorsque frites dans l'HPV. Les mélanges HPV : HCO ont aussi amélioré la qualité des chips par rapport à l'utilisation de l'HCO seule. Une étude a permis d'évaluer la dégradation des HPV, HCO, et d'un mélange HPV:HCO (1:1 w/w) sur une période de 20 h de friture consécutives à 170, 180 et 190 oC Les résultats ont révélé que l'accumulation des acides gras libres (FFA) et que l'indice de peroxydes (PV)  ont suivi un modèle cinétique de premier ordre alors que L'indice d'anisidine (p-AV), les composés polaires totaux (TPC) et l'indice de couleur (CI) ont suivi un modèle cinétique d'ordre zéro. Les constantes de la vitesse de détérioration ont augmenté avec l'augmentation de la température et furent modélisées avec l'équation d'Arrhenius. L'accumulation de PV était la plus rapide pendant la thermo-oxydation. Les valeurs d'énergie d'activation (Ea) ont démontré que la stabilité du mélange HPV :HCO était supérieure.Des pommes de terre frites furent cuites à 170 °C en utilisant soit l'HPV, l'HCO ou le mélange de HPV : HCO (1:1 w/w). Les frites produites dans l'HPV ou dans le mélange ont été enrichies de phyto-nutriments (50 % des caroténoïdes, 40 à 45 % des tocotriénols et 3 à 16 % des tocophérol), ont absorbé moins d'huile et avaient un changement de couleur plus prononcé. Le modèle bi-phasique de premier ordre a été utilisé avec succès pour prédire les changements dans la concentration des phyto-nutriments dans les frites. La thermo-stabilité des tocophérols, tocotriénols et caroténoïdes dans l'HPV, l'HCO et dans un mélange de ces deux huiles a été évalué sur une période de 20 h de friture consécutives à des températures allant 170 à 190 °C. La cinétique de dégradation de chaque homologue a suivi une réaction d'ordre  &gt;1. Les homologues les moins stables étaient le γ-tocophérols et le γ-tocotrienol tandis que le δ-tocotrienol et les caroténoïdes ont été les plus stables. Les tocochromanols ont été plus stables dans le mélange HPV : HCO. Cette étude a démontré que l'HPV, seule ou en mélange, offre de grands avantages comme huile de friture et qu'elle peut être facilement adoptées aux procédés de friture domestiques et commerciaux.</dc:abstract><ual:supervisor>Marie-Josee Dumont</ual:supervisor><ual:supervisor>Michael O. Ngadi</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/0p096979p.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/tx31qm38d</ual:fedora3Handle><dc:subject>Bioresource Engineering</dc:subject></rdf:Description><rdf:Description rdf:about="http://example.org/oai%3Aescholarship.mcgill.ca%3Ajq085n82c"><ual:graduationDate>2017</ual:graduationDate><dcterms:language>eng</dcterms:language><schema:inSupportOf>Doctor of Philosophy</schema:inSupportOf><dc:contributor>Department of Anatomy and Cell Biology</dc:contributor><dcterms:publisher rdf:resource="http://dbpedia.org/resource/McGill_University"/><dcterms:title>From golgi to lipid droplet— understanding of organelle homeostasis</dcterms:title><ual:dissertant>Lee, EunJoo</ual:dissertant><dc:abstract>Les organelles dans les cellules eucaryotes sont des compartiments membranaires qui assurent le contrôle localisé des activités cellulaires spécifiques. Les organelles sont essentielles pour l'organisation et la fonction des cellules eucaryotes. Il est donc important de comprendre l'homéostasie des organelles : comment sont-elles créées et entretenues dans des conditions stables. Chaque organelle diffère dans sa fonction cellulaire et son homéostasie. L'appareil de Golgi est une organelle d'auto-organisation qui conserve son intégrité face à l'énorme afflux de lipides et de protéines. Grand nombre de protéines et de processus ont été cernés afin de maintenir les structures hautement dynamiques et l'équilibre de l'appareil de Golgi. Toutefois, le mécanisme par lequel les protéines biosynthétiques et les enzymes qi résident dans l'appareil de Golgi et qi le traversent est débattu depuis de nombreuses décennies. Afin d'élucider la manière dont les protéines et enzymes sont transportées à travers l'appareil de Golgi, nous avons conçu et entièrement caractérisé une nouvelle sonde fondée sur les anticorps qui peut mettre en lumière des enzymes de Golgi endogène in vivo. 'les anticorps de fusion' construits de cette façon sont considérablement plus petites que les anticorps conventionnels, et ils peuvent être conçus pour mettre en évidence les événements cellulaires. En outre, l'anticorps de fusion purifié par l'affinité conserve sa spécificité d'antigène. Avec les anticorps de fusion et la microscopie corrélative, les traits dynamiques des enzymes résidentes dans le Golgi endogènes peuvent être surveillées, et les résultats de cette étude contribueront à trouver des mécanismes de la rétention et du recyclage des enzymes qui résident dans la voie sécrétoire précoce de l'appareils de Golgi.</dc:abstract><dc:abstract>Organelles within eukaryotic cells are membrane-bound compartments that ensure the localized control of specific cellular activities. Organelles are essential to the organization and function of eukaryotic cells; therefore, it is important to understand organelle homeostasis— how organelles are formed and maintained in steady-state conditions. Organelles are unique in that they differ in their cellular function and homeostasis.The Golgi apparatus is a self-organizing organelle that maintains its structural integrity in the face of an enormous flux of lipid and proteins. A large number of proteins and processes have been identified in order to maintain the Golgi's highly dynamic structural equilibrium. However, the mechanisms by which biosynthetic proteins and Golgi-resident enzymes traverse the Golgi have been debated for many decades. To elucidate how proteins and enzymes are transported through the Golgi, we have designed and fully characterized a novel antibody-based probe able to highlight endogenous Golgi enzymes in vivo. 'Fusion antibodies' constructed this way are significantly smaller than conventional antibodies, and they can be engineered to highlight cellular events. Furthermore, affinity purified fusion antibodies retain their characteristics of antigen recognition. Together with fusion antibodies and correlative microscopy, dynamic trafficking of endogenous Golgi-resident enzymes can be monitored. Results from this study will contribute to finding mechanisms of retention and recycling of Golgi-resident enzymes in the early secretory pathway.  The lipid droplet (LD) is known for its function in excessive lipid storage. However, the LD is a highly dynamic and regulated organelle with many more functions such as cholesterol regulation and prevention of lipotoxicity. Formation and breakdown of lipid droplets are crucial for the cell and body as a whole because the abnormal accumulation of lipids may contribute to the development of metabolic diseases such as Non-Alcoholic Fatty Liver Disease (NAFLD). For this reason, it is crucial to understand how lipids are broken down and released from lipid droplets. In this thesis, we uncovered a novel lipid droplet protein, endophilin B1, which contributes to lipid droplet breakdown via non-canonical lipophagy. The results presented may further provide a novel therapeutic approach for the treatment of NAFLD. </dc:abstract><ual:supervisor>Tommy Nilsson</ual:supervisor><dc:identifier>https://escholarship.mcgill.ca/downloads/1831cn413.pdf</dc:identifier><ual:fedora3Handle>https://escholarship.mcgill.ca/concern/theses/jq085n82c</ual:fedora3Handle><dc:subject>Anatomy and Cell Biology</dc:subject></rdf:Description></rdf:RDF>