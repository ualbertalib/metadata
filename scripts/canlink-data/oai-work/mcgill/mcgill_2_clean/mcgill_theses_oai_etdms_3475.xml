<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/assets/blacklight_oai_provider/oai2-b0e501cadd287c203b27cfd4f4e2d266048ec6ca2151d595f4c1495108e36b88.xsl"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd"><responseDate>2020-07-24T23:03:21Z</responseDate><request resumptionToken="oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):3475" verb="ListRecords">https://escholarship.mcgill.ca/catalog/oai</request><ListRecords><record><header><identifier>oai:escholarship.mcgill.ca:zg64tp22d</identifier><datestamp>2020-03-21T05:01:54Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>This thesis is composed of two sections: a fiction and a critical analysis. In Les violences internes, I adopt the short story composite genre in order to take advantage of its plasticity and to free my writing of the principals of linearity, continuity and unity. I attempted to unify five short stories through two recurrent protagonists, Dorothy and Linda.The second section, Le Composite de récits brefs dans le cycle manitobain de Gabrielle Roy, offers a study of this genre in three of Gabrielle Roy's books: Rue Deschambault, La Route d'Altamont and Ces enfants de ma vie. I analyse the structural ellipses and the narrative voice, that is, how the narrator appears as two different voices in each of these works.</description><description>Ce mémoire s'articule en deux parties : un texte de création et une analyse critique. Dans Les Violences internes, j'adopte la forme du composite de récits brefs afin de profiter de sa plasticité et libérer mon écriture des principes de linéarité, de continuité et d'unité. J'ai cherché à unifier les cinq récits par le retour des mêmes protagonistes, Dorothy et Linda. La deuxième section, Le Composite de récits brefs dans le cycle manitobain de Gabrielle Roy, propose plutôt une étude de cette forme dans trois œuvres de Gabrielle Roy : Rue Deschambault, La Route d'Altamont et Ces enfants de ma vie. J'ai analysé l'utilisation de l'ellipse entre les récits et la voix narrative, ou plutôt comment la narratrice se dédouble dans chacune de ces œuvres.</description><creator>Hénault, René-Philippe</creator><contributor>Jane Everett (Internal/Supervisor)</contributor><date>2019</date><subject>French Language and Literature</subject><title>Les violences internes suivi de le composite de récits brefs dans le cycle Manitobain de Gabrielle Roy</title><language>fre</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/ms35tb66h.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/zg64tp22d</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of French Language and Literature</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:m326m412k</identifier><datestamp>2020-03-21T05:01:55Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Aerosols interact with clouds and affect climate through absorption and scattering of radiation. However, aerosol-cloud interactions are complex, making radiative forcing predictions hard to calculate accurately. The most important uncertainty is the role of aerosols in the formation and dissipation of clouds, which are controlled by nucleation processes. In the lower troposphere, ice and mix-phase clouds are common. In these types of clouds, ice formation is primarily catalyzed by aerosols through heterogeneous ice nucleation. The conditions at which this process occurs depends on the properties of aerosols. Some aerosols are more efficient than other, but due to the complexity of aerosol-cloud interactions, models only focus on the contribution of aerosols that are efficient and abundant in the atmosphere. Even if an aerosol is very efficient, if its abundance in the atmosphere is low, its relevance as a global ice nucleating particle is minimal. This thesis presents the particle size distributions in snow from four different locations as well as their physical and chemical properties to find which particles sizes are the most abundant. It also presents their ice nucleation behavior to determine their potential as relevant ice nucleating particles. Sampling was done in two remote locations, one urban, and one highly contaminated by oil sands activities. The remote locations were Barrow in Alaska, USA and Alert in Nunavut, Canada. The urban location was Montreal, Quebec, Canada and the highly polluted area was the Athabasca Oil Sands Region (AOSR) in Alberta, Canada. The first part of the thesis presents the development of a system for the real-time measurement of aerosol size distributions in melted snow. This system brings particles suspended in melted snow into the airborne state. Collection of the generated particles onto electron microscopy grids is also possible. Samples are dialyzed before analysis to remove interferences from salts and other dissolved substances. Analysis of snow samples revealed that particles of 30 nm dominated the particle size distribution in Montreal snow and particles of 15 nm dominated the distribution in Alert and Barrow snow. Results suggest low particle size aggregation during the aerosolization process when compared to similar techniques. This developed technique had a high resolution of particle size in the range of 10-100 nm. Using this technique, it was also found that nanosized particles (&lt;200 nm) are the most abundant (38-71 %) in the snow sampled from Alert, Barrow and Montreal. It was also found that nanoparticles represent 11-19% of all particles. Nanosized particles also exhibited high ice nucleation efficiencies, with average freezing temperatures of  19.6 ± 2.4 to  8.1 ± 2.6 °C. Chemical analysis of this size fraction revealed that these particles are composed by biological material such as amino acids and possibly cell debris as well as inorganic materials such as mineral dust.In snow from the AOSR, nanosized particles dominated the size distributions as well, but their concentrations were as high as 2 orders of magnitude higher than Montreal. Additionally, these particles were much more efficient at nucleating ice with average freezing temperatures of -7.1 ± 1.8 °C. Analysis of these particles (even for samples collected 7-25 km away from major bitumen upgrading facilities) revealed the presence of anthropogenic nanostructures such as carbon nanotubes and trace metals with concentration up to 72 mg/L.This thesis contributes to the understanding of the distribution of environmental particles and nanoparticles in northern locations and provided results that will help understand their effect on climate.  With an increase in the release of chemicals by anthropogenic sources, understanding the properties of particles will help to predict atmospheric phenomena more accurately.</description><description>Les aérosols interagissent avec les nuages et affectent le climat par l'absorption et la diffusion des rayonnements. Les interactions aérosols-nuages sont complexes, ce qui rend les prévisions de forçage radiatif difficiles à calculer. L'incertitude la plus importante est le rôle des aérosols dans la formation et la dissipation des nuages qui sont contrôlés par les processus de nucléation. Dans la basse troposphère, les nuages de glace et de phase mixte sont fréquents. Dans ce type de nuages, la formation de la glace est principalement catalysée par les aérosols grâce à la nucléation hétérogène de la glace. Les conditions dans lesquelles ce processus se produit dépendent des propriétés des aérosols. Certains aérosols sont plus efficaces que d'autres, mais en raison de la complexité des interactions aérosols-nuages, les modèles portent seulement sur les interactions pertinentes. Même si un aérosol est très efficace pour la nucléation de la glace, si son abondance dans l'atmosphère est faible, sa contribution sera minimale. Cette thèse présente les distributions granulométriques dans des échantillons de neige provenant de quatre endroits différents ainsi que leurs propriétés physiques et chimiques qui servent à trouver les particules les plus abondantes. Elle présente également leur comportement de nucléation de la glace pour déterminer leur potentiel d'être des particules de nucléation de la glace pertinentes. L'échantillonnage a été effectué dans (1) deux sites de prélèvement éloignés: Barrow en Alaska, États-Unis et Alert au Nunavut, Canada; (2) un sites de prélèvement en milieu urbain: Montréal, Québec, Canada; (3)  et le dernier dans un endroit hautement contaminé par les activités d'exploitation des sables bitumineux: La Région des Sables Bitumineux de l'Athabasca (AOSR) en Alberta, Canada. Un système de mesure en temps réel des distributions de la taille des aérosols a été développé. Ce système amène les particules en suspension dans la neige fondue à l'état aéroporté. La collecte des particules générées sur des grilles de microscopie électronique est également possible comme une technique alternative. Les échantillons sont dialysés avant l'analyse pour éliminer les interférences des sels et autres substances dissoutes. L'analyse des échantillons de neige a révélé que les particules de 30 nm dominaient la distribution granulométrique dans la neige de Montréal et que les particules de 15 nm dominaient la distribution dans la neige Alert et Barrow. Les résultats suggèrent une faible agrégation de la taille des particules prélève du processus d'aérosolisation par rapport à des techniques similaires. Cette technique développée a eu une haute résolution de la taille des particules dans la gamme de 10-100 nm.En utilisant cette technique, on a également constaté que les particules nanométriques (&lt;200 nm) sont les plus abondantes (38-71%) dans la neige échantillonnée à Alert, Barrow et Montréal. C'était également constaté que les nanoparticules représentent 11-19% de toutes les particules. Les particules nanométriques présentaient également des propensions levées de nucléation de la glace, avec des moyennes de températures de germination entre 19,6 ± 2,4 - 8,1 ± 2,6 ° C. L'analyse chimique de cette fraction de taille a révélé que ces particules sont composées de matériaux biologiques tel que des acides aminés et probablement des débris cellulaires, ainsi que des matériaux inorganiques comme la poussière minérale.Dans la neige de l'AOSR, les particules nanométriques dominaient aussi les distributions de taille, mais leurs concentrations atteignaient 2 ordres de grandeur plus levés que Montréal. Ces particules étaient beaucoup plus efficaces pour la nucléation de la glace avec des moyennes de températures de germination de -7,1 ± 1,8 ° C. L'analyse de ces particules a révélé la présence de nanostructures d'origine anthropique telles que les nanotubes de carbone et de métaux traces avec des concentrations allant jusqu'à 72 mg / L.</description><creator>Rangel-Alvarado, Rodrigo</creator><contributor>Parisa A Ariya (Supervisor)</contributor><date>2019</date><subject>Chemistry</subject><title>Nanosized particles in North American snow: physicochemical properties of efficient ice nucleating particles</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/c821gn289.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/m326m412k</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Chemistry</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:wd375z71m</identifier><datestamp>2020-03-21T05:01:56Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les faisceaux Euler-Bernoulli vibrant avec une courbure uniforme sont sujets à une dilatation de leur matériel. En conséquence, cette dilatation cause des gradients de déformation à apparaitre à travers l'axe neutre. Le couplage thermoélastique transforme ces gradients de déformation en gradients de température qui provoque la conduction thermique irréversible, suivi par la génération d'entropie. Ce type de dissipation est nommé l'amortissement thermoélastique.L'étude de l'amortissement thermoélastique exige une solution à l'équation de conduction thermique. Pour les matières thermoélastiques, cela prend la forme d'une équation différentielle partielle non-linéaire. Les modèles linéaires sont déjà bien établis dans la littérature, pourtant les modèles non-linéaires nécessitent encore des recherches plus approfondies.Cette thèse présente un cadre d'analyses pour calculer l'amortissement thermoélastique non-linéaire. Un nouveau modèle linéaire d'amortissement thermoélastique a été établi, ainsi qu'une résolution numérique non-linéaire qui suit une procédure de solution similaire. La résolution numérique tient compte d'une source de non-linéarité intrinsèque qui s'appelle la « non-linéarité dissipative ». En faisant la comparaison entre ces deux modèles, c'est possible d'évaluer le comportement de la réponse non-linéaire. A cet égard, la relation entre l'amortissement thermoélastique et la fréquence des oscillations a été évaluée en calculant la valeur maximale de la dissipation à la fois des modèles linéaires et non-linéaires.  Pour 16 matériaux communs en génie, cette crête se produit à une fréquence normalisée d'environ 10 qui indique la fréquence des oscillations normalisée par le temps de relaxation thermique du faisceau. De plus, une analyse paramétrique de l'équation de conduction thermique non-linéaire avait révélé un paramètre, nommé le « coefficient de non-linéarité », qui contrôle la puissance de la non-linéarité dissipative. Des résultats sont présentés qui démontre la dépendance de la non-linéarité dissipative sur le coefficient de non-linéarité, ainsi que les propriétés matérielles. Selon les cas traités dans cette étude, la différence entre les modèles linéaires et non-linéaires d'amortissement thermoélastique ne dépassait pas 0.2%. Ces nouvelles techniques de modélisation sont parmi les premiers qui adressent la non-linéarité dissipative.</description><description>Bending-mode vibrations of Euler-Bernoulli beams create oscillating strain gradients which form across the neutral axis of the structure. Due to the thermoelastic coupling between the strain and temperature ﬁelds within an elastic material, these strain gradients engender oscillating temperature gradients. In turn, the temperature gradients lead to irreversible heat conduction and entropy generation. This mode of dissipation is referred to as thermoelastic damping.To model thermoelastic damping, the governing heat equation must ﬁrst be solved. For a thermoelastic solid, this takes the form of a nonlinear, partial diﬀerential equation. While linearized thermoelastic damping models are readily available in literature, developing models to accurately solve the heat equation in its full nonlinear form remains an ongoing research eﬀort.This thesis presents a framework to study nonlinear thermoelastic damping. A new analytical model for linear thermoelastic damping was derived, along with a nonlinear solver which follows a similar conceptual structure numerically. The nonlinear solver accounts for an intrinsic type of nonlinearity referred to as 'dissipative nonlinearity'. These linear and nonlinear models were compared to one another to study the behaviour of the nonlinear response. To this end, the frequency dependence of thermoelastic damping was examined by calculating the peak value for the dissipation in both the linear and nonlinear cases. Across 16 common engineering materials, this peak occurred consistently at a normalized frequency of approximately 10, which is the operating frequency normalized by the thermal relaxation time of the beam. Furthermore, a parametric analysis of the nonlinear heat equation revealed a dimensionless number, referred to as the 'nonlinearity coeﬃcient', related to the strength of the dissipative nonlinearity. Results showing how the dissipative nonlinearity evolves as a function of both the nonlinearity coeﬃcient and the material properties are presented. For the cases considered here, the maximum diﬀerence between the linear and nonlinear models did not exceed 0.2%. These new modelling tools are among the ﬁrst to address the impact of the dissipative nonlinearity on thermoelastic damping modelling.</description><creator>Agellon, Christopher</creator><contributor>Srikar Vengallatore (Internal/Supervisor)</contributor><date>2019</date><subject>Mechanical Engineering</subject><title>Nonlinear thermoelastic damping in Euler-Bernoulli beams</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/h989r534v.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/wd375z71m</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Mechanical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:qf85nd44z</identifier><datestamp>2020-03-21T05:01:57Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Un coup de terrain peut être définie comme une rupture soudaine et violente du sol souvent associée à un événement sismique. Les coups de terrain constituent un danger pour les travailleurs des mines souterraines et compromettent les opérations minières. Pour les éviter, de nombreuses techniques ont été développées telles que le pré-conditionnement du sol (réduction des contraintes de la roche et promotion de la fracturation de la roche par forage et dynamitage), support de terrain (câbles, boulons d'ancrage à haute résistance, grillage). Cette recherche se concentre sur le pré-conditionnement du sol. Le pré-conditionnement du sol, également connu sous le nom de « tir de relaxation », n'est efficace que lorsqu'il est appliqué correctement, au bon moment et au bon endroit, avec la juste quantité d'explosifs et de trous de forage. Des recherches supplémentaires sont nécessaires dans ce domaine car le processus de dynamitage avec de l'énergie explosive pour créer des fractures impose des mesures de sécurité rigoureuses sur le site. Cette thèse est le prolongement des travaux antérieurs du laboratoire de conception minière de l'Université McGill (Musunuri &amp; Mitri, 2009) (Dessouki &amp; Mitri, 2011) sur la rupture des roches sans explosifs. Cette thèse explore, en outre, l'efficacité de l'encochage des trous pour améliorer le processus de fracture des roches. Ce nouveau concept vise à trouver des avantages à induire moins de sismicité dans un système et à générer suffisamment de fractures pour éviter les coups de terrain.L'objectif principal de cette étude est de mettre en place un programme expérimental au sein du laboratoire de soutènement de la roche de l'Université McGill afin de réaliser des tests personnalisés liés au pré-conditionnement du sol, à la fracturation discrète, au ciment expansif et aux encoches. Le deuxième objectif de cette étude est d'évaluer la compétence du ciment expansif sous chargement axial. Le troisième objectif de cette étude est d'évaluer l'efficacité de l'encoche des trous pour améliorer le processus de fracture des roches. Une expérience de pression uniaxiale constante (CUP) a été adoptée pour simuler des conditions de stress in situ. Basé sur les travaux réalisés dans cette étude, il est montré que les encoches et le ciment expansif pourraient être efficaces pour fracturer des échantillons de roche granitique sous charge axiale. Des suggestions pour améliorer la procédure d'expérimentation, ainsi que des recommandations pour des tests supplémentaires sont faites.</description><description>A rockburst can be defined as a sudden and violent ground failure often associated with a seismic event. Rockbursts are a danger to underground mine workers and jeopardize smooth mining operations. To avoid rockbursts, multiple techniques have been developed such as ground preconditioning (relieving stress of the rock and promoting fracturing of the rock mass via drilling and blasting), ground support (cables, high endurance rock bolts, meshes) or alternative mining sequences. The current research focuses on ground pre-conditioning.Ground preconditioning, which is a type of ''destress blasting'', is only optimally effective when applied correctly on time and at the right place, with the right quantity of explosives. Further research is needed in this field as the process of blasting with explosives energy to create fractures imposes rigorous safety measures on site. This thesis is the extension of previous work of the Mine Design Laboratory  (Musunuri &amp; Mitri, 2009) (Dessouki &amp; Mitri, 2011) on explosive-free rock breakage. This thesis further explores the efficiency of hole notching to enhance the rock fracturing process. This new concept aims to find advantages into inducing less seismicity into the rockmass and generating sufficient fractures to prevent rockbursts.The primary goal of this study is to set up an experimental program in the Rockbolting Lab of the Mine Design Laboratory to conduct customized testing related to ground pre-conditioning, discrete fracturing, expansive cement and hole notching. The second goal of this study is to evaluate the competency of expansive cement under axial loading. The third goal of this study is to evaluate the effectiveness of hole notching to enhance the rock fracturing process. A constant uniaxial pressure (CUP) experiment was adopted to simulate in-situ stress conditions. Based on the work done in this study, it is shown that expensive cement and hole notching could be effective to fracture granite rock samples under axial load. Suggestions to improve the experiment procedure, as well as recommendations for further testing are made.</description><creator>Arseneau, Flavie</creator><contributor>Hani Mitri (Internal/Supervisor)</contributor><date>2019</date><subject>Mining and Materials</subject><title>Laboratory investigation into fracturing of uniaxially loaded hard rock with expansive cement</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/pg15bh33t.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/qf85nd44z</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Mining and Materials</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:0c483m39q</identifier><datestamp>2020-03-21T05:01:58Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The first phase of the research involved analyses of a linked database of a large sample of Canadians surveyed in 2001 as part of the Canadian Community Health Survey (CCHS) 1.1 and followed up with recorded death events to December 31, 2011 and hospitalizations to March 31, 2004. Analyses were stratified by two age groups, 55 – 64 (n=6,822) and 65 and older (n=8,966), owing to differing patterns of mortality and health care utilization for these age divisions. Social support measures operationalized several support constructs of interest, including tangible support, affection, emotional and informational support, positive social interactions, living alone, and sense of belonging. Key covariates included sex, age, income, smoking, and a frailty index. In adjusted analyses, compared to adults with the highest levels of support, adults 55 – 64 with low levels of affection had elevated mortality risk (Hazard Ratio (HR) of 1.37 (1.07, 1.75 95% CI)). Effect estimates were similar for low positive social interactions (HR of 1.36 (1.06, 1.75 95% CI)), and low emotional/informational support (HR of 1.36 (1.06, 1.74 95% CI)). Adults 65 and older also had increased mortality risk with low levels of affection (HR of 1.17 (104, 1.31 95% CI)), low positive social interactions (HR of 1.20 (1.07, 1.34 95% CI)), and low emotional/ informational support (HR of 1.19 (1.06, 1.33 95% CI)). Tangible support and living alone were not consistently associated with mortality risk in adjusted analyses which is in keeping with past studies suggesting that tangible support might increase in response to very poor health, and living alone may not inherently put older individuals at risk for mortality. More than one third of respondents 55 – 64 (36.86%) were admitted to hospital over the morbidity follow-up period, and more than half of respondents 65 and older had admissions (54.52%). Hospitalization is not infrequent in older Canadians, especially those over 65. There was a modest signal for elevated odds of hospital admission for adults 65 and older with a weak sense of belonging (Odds Ratio of 1.14 (1.02, 1.28 95% CI)), but otherwise social support variables were not generally associated with an increased risk of admission.Low positive social interactions and living alone were associated with the number of hospital admissions in the younger age group (Incidence Rate Ratio (IRR) of 1.46 (1.08, 1.97 95% CI) and IRR of 1.22 (1.01, 1.48 95% CI) respectively). Respondents reporting low positive social interactions had a predicted number of admissions nearly one and a half times that of respondents reporting the highest positive social interactions. Those living alone had a predicted number of admissions nearly one and a quarter times those living with others. Tangible support, affection, and emotional/informational support were not generally associated with an increased number of admissions in either age group. Low positive social interactions (IRR of 1.73 (1.21, 2.51 95% CI)), low emotional/ informational support (IRR of 1.45 (1.01, 2,05 95% CI)) and living alone (IRR of 1.32 (1.06, 1.65 95% CI)) were all associated with length of stay in hospital in fully adjusted models among the younger cohort. Low levels of affection (IRR of 1.31 (1.08, 1.58 95% CI)), low positive social interactions (IRR of 1.31 (1.07, 1.57 95% CI)), low emotional/informational support (IRR of 1.34 (1.09, 1.61 95% CI)), and a weak sense of belonging (IRR of 1.13 (1,01, 1.27 95% CI)) were all associated with length of stay among the older cohort. Indeed it was length of stay that was the hospitalization measure that was particularly sensitive to multiple social support constructs, suggesting that low social support is implicated in discharge decisions and readmissions. </description><description>La première phase de cette étude portait sur l'analyse de données liées sur un vaste échantillon de Canadiens ayant répondu à un sondage en 2001 dans le cadre de l'Enquête sur la santé dans les collectivités canadiennes (ESCC) 1.1, suivie d'une analyse des décès enregistrés jusqu'au 31 décembre 2011 et des hospitalisations survenues jusqu'au 31 mars 2004.  Les covariables clés comprenaient le sexe, l'âge, le revenu, le tabagisme et l'indice de fragilité. Les analyses corrigées ont révélé que les adultes âgés de 55 à 64 ans qui recevaient peu de marques d'affection présentaient un risque de mortalité plus élevé (rapport de risques [RR] de 1,37 [IC à 95 %, de 1,07 à 1,75]) que les adultes qui recevaient le plus de soutien. Les estimations de l'effet étaient semblables chez les répondants qui avaient peu d'interactions sociales positives (RR de 1,36 [IC à 95 %, de 1,06 à 1,75]) et ceux qui recevaient peu de soutien affectif ou informatif (RR de 1,36 [IC à 95 %, de 1,06 à 1,74]). On a également observé un risque accru de mortalité chez les adultes de 65 ans et plus qui recevaient peu de marques d'affection (RR de 1,17 [IC à 95 %, de 1,04 à 1,31]), qui avaient peu d'interactions sociales positives (RR de 1,20 [IC à 95 %, de 1,07 à 1,34]), et qui recevaient peu de soutien affectif ou informatif (RR de 1,19 [IC à 95 %, de 1,06 à 1,33]). Plus du tiers des répondants âgés de 55 à 64 ans (36,86 %) ont été admis à l'hôpital au cours de la période de suivi de la morbidité, et plus de la moitié des répondants âgés de 65 ans et plus ont été hospitalisés (54,52 %). Les hospitalisations ne sont pas rares chez les Canadiens âgés, particulièrement chez les personnes de plus de 65 ans. On a observé une légère tendance vers une augmentation du risque d'hospitalisation chez les adultes de 65 ans et plus ayant un faible sentiment d'appartenance (rapport de cotes de 1,14 [IC à 95 %, de 1,02 à 1,28]), mais, par ailleurs, les autres variables du soutien social n'ont généralement pas été associées à une augmentation du risque d'hospitalisation.Chez les répondants âgés de 55 à 64 ans, on a observé un lien entre la fréquence des interactions sociales positives et la vie dans la solitude, d'une part, et le nombre d'hospitalisations, d'autre part (rapport des taux d'incidence [RTI] de 1,46 [IC à 95 %, de 1,08 à 1,97] et de 1,22 [IC à 95 %, de 1,01 à 1,48], respectivement). Chez les répondants qui avaient peu d'interactions sociales positives, le nombre prévu d'hospitalisations était près d'une fois et demie celui des répondants qui avaient le plus d'interactions sociales positives. Le nombre prévu d'hospitalisations chez les répondants vivant seuls était près d'une fois et quart celui des répondants vivant avec d'autres personnes. L'aide tangible, l'affection et le soutien affectif et informatif n'étaient généralement pas associés à une augmentation du nombre d'hospitalisations, quel que soit le groupe d'âge.Dans la cohorte plus jeune, la faible fréquence des interactions sociales positives (RTI de 1,73 [IC à 95 %, de 1,21 à 2,51]), le faible niveau de soutien affectif et informatif (RTI de 1,45 [IC à 95 %, de 1,01 à 2,05]) et la vie dans la solitude (RTI de 1,32 [IC à 95 %, de 1,06 à 1,65]) ont tous été associés à la durée de l'hospitalisation dans les modèles entièrement corrigés. Dans la cohorte plus âgée, le peu d'affection (RTI de 1,31 [IC à 95 %, de 1,08 à 1,58]), le peu d'interactions sociales positives (RTI de 1,31 [IC à 95 %, de 1,07 à 1,57]), le peu de soutien affectif et informatif (RTI de 1,34 [IC à 95 %, de 1,09 à 1,61]), et un faible sentiment d'appartenance (RTI de 1,13 [IC à 95 %, de 1,01 à 1,27]) ont tous été associés à la durée de l'hospitalisation. La durée du séjour est le paramètre lié à l'hospitalisation qui s'est révélé particulièrement sensible aux multiples volets du soutien social, ce qui porte à croire qu'un faible soutien social influe sur les décisions relatives aux congés accordés aux patients et sur les réadmissions. </description><creator>Renwick, Kelly</creator><contributor>Nancy Ross (Supervisor)</contributor><date>2019</date><subject>Geography</subject><title>The influence of low social support and living alone on premature mortality and hospital utilization among aging Canadians</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/3484zj92m.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/0c483m39q</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Geography</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:ff365747p</identifier><datestamp>2020-03-21T05:01:59Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Copper (Cu) is one of about ten known essential metals required for phytoplankton growth and a limiting resource in parts of the open sea.  It functions primarily as a cofactor in key enzymes and redox proteins in photosynthesis and respiration and is involved in high affinity Fe uptake.  Growth of marine diatoms is limited by Cu at environmentally-relevant concentrations, suggesting diatom production in the Cu-depleted ocean may be compromised.  The molecular mechanisms of how diatoms respond to Cu deficiency and maintain cellular Cu homeostasis are not well known.  This thesis examines molecular and physiological responses of an oceanic diatom, Thalassiosira oceanica 1005, to Cu deficiency and characterizes a Cu(I)-dependent uptake pathway.  Proteomic analysis of T. oceanica identified Cu-regulated proteins involved in light harvesting, photosynthetic electron transport, carbon and nitrogen assimilation, fatty acid oxidation, and a putative Cu-binding transcription factor.  Using RNAseq to explore the transcriptome of the same species, I validated the proteomic results and identified metabolic processes that were regulated by Cu.  These included down-regulation of photosynthesis, nitrate assimilation and glycolysis and up-regulation of ammonium assimilation, pentose phosphate pathways, fatty acid metabolism and oxidative stress defense pathways.  Acclimation to low Cu resulted in a slowing down of most cellular metabolic processes and an increase in stress defense systems to combat oxidative damage.  A major finding of the thesis was that T. oceanica contains a Cu(I)-dependent uptake system that functions at limiting Cu concentrations and proceeds through a two-step reaction: extracellular Cu(II) reduction followed by Cu(I) internalization.  Four CTR-type Cu(I) transporters were identified; two of which complemented a yeast Cu transport mutant and increased uptake rates of both Cu(II) and Cu(I).  Two putative Cu reductase (FRE-type) genes were identified and shown to catalyze Cu(II) reduction.  Inhibition of Cu(II) reduction and trapping Cu(I) produced by the reductase with a Cu(I)-complexing agent reduced Cu uptake rate and inhibited cell growth.  Thus, the results provide the first experimental evidence for a Cu(I)-dependent Cu uptake pathway in Thalassiosira oceanica and show that Cu(II) reduction is a necessary first step in Cu uptake.  </description><description>Le cuivre (Cu) fait partie d'une dizaine de métaux essentiels qui sont requis pour la croissance de phytoplancton. Ce métal est aussi une ressource limitante dans certaines parties de l'océan. Il fonctionne principalement comme cofacteur à l'intérieur d'enzymes clés, ainsi que dans les protéines oxydo-réductrices, de la photosynthèse et de la respiration. De plus, il est impliqué dans l'assimilation du fer. La croissance de diatomées marines est limitée par le Cu retrouvé à des concentrations environnementales actuelles. Cela suggère que la production de diatomée dans un océan pauvre en Cu pourrait être compromise. Cependant, les mécanismes moléculaires de diatomées en réponse à des déficiences de Cu, ainsi qu'au maintien de leur homéostase cellulaire en Cu, sont mal compris. Ma thèse examine les réponses moléculaires et physiologiques de la diatomée océanique Thalassiosira oceanica 1005 à des déficiences de Cu, et caractérise une assimilation Cu(I)-dépendante. L'analyse protéomique de T. oceanica a identifié des protéines régulées par le Cu et impliquées dans le captage de lumière, le transport photosynthétique d'électrons, l'assimilation de carbone et d'azote, l'oxydation d'acides gras, ainsi que dans un facteur de transcription putatif qui lie le Cu. Utilisant RNAseq pour explorer le transcriptome de la même espèce, j'ai validé les résultats protéomiques et identifié les processus métaboliques régulés par le Cu. Ceux-ci incluent des inhibiteurs de photosynthèse, d'assimilation de nitrates et de glycolyse, ainsi que des activateurs d'assimilation d'ammonium, de voies de pentose phosphates, de métabolisme d'acide gras, et de voies de défense de stress oxydatif. Lorsque la diatomée s'acclimatait à des faibles concentrations de Cu, la majorité de ses processus métaboliques ralentissaient et les systèmes de défense du stress augmentaient pour combattre des dommages oxydatifs. Ma thèse a permis de découvrir la présence d'un système d'assimilation Cu(I)-dépendant chez T. oceanica qui fonctionne à des faibles concentrations de Cu. Ce système procède avec une réaction en deux temps : une réduction de Cu(II) extracellulaire suivie de l'assimilation du Cu(I). Quatre transporteurs de Cu(I) de type CTR furent identifiés; deux desquels complémentaient une levure mutante de transport du Cu, ainsi qu'augmentaient des taux d'assimilation du Cu(II) et Cu(I). J'ai identifié deux gènes réductases putatifs de Cu (type FRE) qui catalysent la réduction de Cu(II). La réductase qui utilise l'agent de complexation du Cu(I) trappe le Cu(I) et inhibe la réduction de Cu(II), menant à une réduction dans le taux d'assimilation du Cu ainsi qu'à une inhibition du développement cellulaire. Ainsi, ces résultats repoussent les limites de la frontière en recherche, car ils constituent la première évidence expérimentale de la voie assimilatrice du Cu Cu(I)-dépendante chez Thalassiosira oceanica et montrent que la réduction de Cu(II) est la première étape nécessaire dans l'assimilation du Cu. </description><creator>Kong, Liangliang</creator><contributor>Neil Price (Supervisor)</contributor><date>2019</date><subject>Biology</subject><title>Molecular and physiological responses of an oceanic diatom to copper deficiency</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/kp78gj685.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/ff365747p</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Biology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:c247dv42n</identifier><datestamp>2020-03-21T05:01:59Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>L'abondance de données a joué un rôle majeur dans le récent boom de l'apprentissage automatique. Mais, la disponibilité de ces larges ensembles de données, bien qu'utile, ne s'est pas directement traduite à des applications réussies en robotique. Cette thèse présente des moyens de pallier le manque de données dans les applications robotiques grâce à des méthodes d'adaptation de domaine. Nous proposons et étudions la performance d'algorithmes conçus pour deux applications en robotiques dans des situations de manque de données: le suivi visuel et l'apprentissage à partir de démonstrations. Nous présentons d'abord une approche robuste de convoi à robots multiples qui repose sur la détection visuelle de l'agent principal. Notre méthode est basée sur l'idée de suivi par détection, qui couple la détection d'objet avec le filtrage temporel de l'estimation de la boîte englobante de l'objet dans l'image. À l'aide d'un ensemble de données constitué d'images d'un robot sous-marin annotées de boîtes englobantes, nous comparons plusieurs variantes d'algorithmes de suivi visuel, dont plusieurs réseaux neuronaux convolutifs avec et sans connexions récurrentes, ainsi que des algorithmes de suivi visuels par fréquence. Nous étudions la capacité d'adaptation de domaine de notre architecture la plus prometteuse à partir d'un entrainement sur données synthétiques, générées grâce à un moteur de jeu réaliste. Pour démontrer la praticité de cette stratégie de suivi par détection dans des scénarios réels nous contrôlons avec succès un robot sous-marin à nageoires, capable de cinq degrés de liberté, pour suivre le mouvement d'un autre robot indépendant. Nous nous concentrons ensuite sur l'impact des pénuries de données lors de l'apprentissage par démonstration. L'on étend le cadre des options en Apprentissage par Renforcement (AR) avec la notion d'options de récompense, développons une méthode d'apprentissage des options de politiques et récompenses conjointe dans le contexte de l'AR inverse génératif et adversairial, et montrons que les méthodes dans ce contexte souffrent dans les cas de manque de démonstrations. Nous étudions ensuite les capacités d'adaptation de domaine en un coup de notre approche. C'est-à-dire que, étant donné des démonstrations expertes provenant d'un mélange d'environnements avec des dynamiques variées, l'agent peut-il apprendre à effectuer correctement une tâche dans un environnement inconnu avec des dynamiques différentes. Nos résultats montrent que notre méthode est capable d'apprendre une tâche avec succès dans ces scénarios d'adaptation de domaine et surpasse significativement l'AR inverse sans options.</description><description>The abundance of data has played a major role in the recent machine learning boom. The availability of large datasets however, while useful, hasn't directly translated to successful applications in robotics. This thesis attempts to present ways to overcome the lack of data in robotics applications through domain adaptation methods. We propose and study the performance in data-poor scenarios of algorithms designed for two Robotics applications: visual tracking and learning from demonstrations. We first present a robust multi-robot convoying approach that relies on visual detection of the leading agent. Our method is based on the idea of tracking-by-detection, which interleaves efficient object detection with temporal filtering of image-based bounding box estimation. Using a bounding box annotated dataset of images extracted from footage of an underwater robot in ocean settings, we compare multiple tracker variants, including several convolutional neural networks with and without recurrent connections and frequency-based model-free trackers. We investigate the domain adaptation ability of our most applicable architecture through training on synthetic data, generated from a realistic game engine. To demonstrate the practicality of this tracking- by-detection strategy in real-world scenarios, we successfully control a 5-DOF legged underwater robot to follow another robot's independent motion. We then focus on the impact of data shortages when learning from demonstration. Extending the options framework with the notion of reward options, we develop a method for learning joint reward-policy options in the context of generative adversarial inverse RL and show that methods in this context suffer in demonstration data-poor scenarios. We then study the one shot domain adaptation abilities of our approach. That is, given expert demonstrations from a mixture of environments with different dynamics, can the agent learn to properly complete a task in a previously unseen environment with different dynamics. Our results show that our method is able to successfully learn a task in these domain adaptation scenarios, and significantly outperforms inverse RL without options.</description><creator>Chang, Wei-Di</creator><contributor>Michael Rabbat (Internal/Supervisor)</contributor><contributor>Gregory L Dudek (Internal/Cosupervisor2)</contributor><date>2019</date><subject>Electrical and Computer Engineering</subject><title>Overcoming data shortages in robotic applications</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/kk91fp006.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/c247dv42n</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:zg64tp23p</identifier><datestamp>2020-03-21T05:02:00Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>This project takes the idea of the "twilight zone" as a central organizing principle to examine ambiguous public and private spaces in popular representations of gender, the home, and the family in the postwar period. I argue that the intimate address of new media technologies—movies and radio, in their own ways, as well as television—creates an uncanny virtual space between the public sphere of commerce and entertainment and the private sphere of the home, reflecting a larger experience of social and spatial liminality for women. Through close readings of the science-fiction anthology TV program The Twilight Zone (1959-1964) and other popular texts, I position the evolving experience of narrative media—of being a subject of mediated entertainment and advertising—as emblematic of an in-between state that was the middle-class trauma of the postwar period. Formally and thematically, these texts dramatize social anxieties over the ambiguous position of women as uncompensated laborers in the developing consumer economy. This project initiates a historical poetics of television by tracing the development of formal conventions, their queer deviations, and systems of representation. My method of textual analysis aims to gain an understanding of the experience of narrative media as part of the everyday texture of an era.</description><description>Ce projet prend l'idée de la «zone crépusculaire» comme principe organisateur central pour examiner les espaces publics et privés ambigus dans les représentations populaires du genre, du foyer et de la famille dans l'après-guerre. Je soutiens que l'adresse intime des nouvelles technologies médiatiques—les films et la radio, à leur manière, ainsi que la télévision—crée un espace virtuel étrange entre la sphère publique du commerce et du divertissement et la sphère privée de la maison, reflétant une expérience plus large de liminalité sociale et spatiale pour les femmes. Grâce à des lectures approfondies de l'émission télévisée d'anthologie de science-fiction The Twilight Zone (1959-1964) et d'autres textes populaires, je positionne l'expérience évolutive des médias narratifs—d'être un sujet de divertissement médiatisé et de publicité—comme emblématique d'un état intermédiaire c'était le traumatisme de la classe moyenne de l'aprèsguerre. D'un point de vue formel et thématique, ces textes dramatisent les angoisses sociales faceà la position ambiguë des femmes en tant qu'ouvrières non compensées dans l'économie de consommation en développement. Ce projet initie une poétique historique de la télévision entraçant le développement des conventions formelles, de leurs déviations queer et des systèmes de représentation. Ma méthode d'analyse textuelle vise à acquérir une compréhension de l'expérience des médias narratifs dans le cadre de la texture quotidienne d'une époque.</description><creator>Barth, Josie</creator><contributor>Edward Schantz (Supervisor)</contributor><date>2019</date><subject>English</subject><title>Twilight zones: Women between the public and private spheres in postwar U.S. television, film, and radio</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/2j62s7110.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/zg64tp23p</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of English</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:5h73pz245</identifier><datestamp>2020-03-21T05:02:01Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La Commande à Horizon Fuyant (CHF) est une méthode de contrôle très efficace qui aété utilisée dans une large gamme d'applications industrielles. La stabilité des systèmescontrôllés par la CHF revêt une grande importance pour son application et a été abondamment étudiée. Cependant, la plupart des résultats de stabilité impliquent des coûts finaux ou des contraintes parfois coûteuses en temps de calculs. De récentes études considèrent la stabilité des systèmes contrôllés par la CHF sans ces désavantages. Dans ce travail, il est montré que la fonction de valeur doit être suffisament lisse pour assurer la stabilité des contrôleurs affines des systèmes asservis, par les lois CHF, sans coûts finaux. De plus, la stabilité est prouvée pour les contraintes de contrôle bornées, s'il existe un contrôleur ayant un horizon infini pouvant stabiliser le système sous la même contrainte. Afin de trouver l'infimum pour tous les horizons stabilisants, une simple Équation Diffrentielle Ordinaire (ÉDO) basé sur le système linéarisé est développée. Elle fournit l'ensemble des horizons stabilisants ou déstabilisants. Ce travail démontre que l'infimum des horizons stabilisants peut être estimé sans qu'il soit nécessaire de résoudre le problème non linéaire du contrôle optimal et que, sous certaines conditions, l'infimum exact peut être obtenu. Des simulations ont été effectuées pour illustrer l'application de ces méthodes à des systèmes non linéaires spécifiques. Les résultats sont ensuite généralisés pour les Systàmes Hybrides Régionaux qui n'ont généralement pas de fonctions de valeur lisses. Il est démontré que pour ces Systèmes Hybrides Régionaux et sous certaines hypothèses, il existe un horizon spécifique pour lequelle système est stable avec des horizons plus larges. Ces hypothèses incluent la convergence des gradients de deux fonctions de valeur, une avec un horizon fini et l'autre avec un horizon infini.</description><description>Receding Horizon Control (RHC) is a very effective control methodology which has been employed in an extensive range of industrial applications such as process industry and power systems. The stability of systems under RHC is of great importance for its application and has been abundantly studied. However, most of the stability results involve terminal costs or constraints which are sometimes not computationally desirable. Recent studies consider the stability of systems under RHC without such terminal costs or constraints. In this work, it is shown that the smoothness of the value function is sufficient to ensure stability for control affine systems under RHC laws with no terminal cost. In addition, the stability is proved subject to bounded control constraints if a stabilizing infinite horizon controller exists under the same constraints. In order to find the infimum for all stabilizing horizons, a simple ODE problem based on the linearized system is developed that provides the set of stabilizing and destabilizing horizons. It is shown that the infimum of stabilizing horizons can be estimated without the need to solve the nonlinear optimal control problem, and that subject to certain conditions the exact infimum can be obtained. Simulations are provided to illustrate the application of these methods to some nonlinear systems. The results are then generalized for Regional Hybrid Systems which do not have smooth value functions in general. It is shown for the Regional Hybrid Systems that under certain assumptions, which particularly includes the convergence of the gradients of the infinite and finite horizon value functions, there exists a specfiic horizon so that the system is stable under RHC with larger horizons.</description><creator>Layeghi, Hamed</creator><contributor>Peter Edwin Caines (Supervisor)</contributor><date>2019</date><subject>Electrical and Computer Engineering</subject><title>A Hamilton-Jacobi-Bellman methodology for the stability of receding horizon control</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/v979v512k.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/5h73pz245</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:gh93h185z</identifier><datestamp>2020-03-21T05:02:02Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Capacity design principles have reduced the earthquake-induced collapse risk in steel frame buildings designed in seismic regions. Experiments suggest that the steel column behaviour may be significantly compromised due to member and local geometric instabilities, thereby increasing the associated collapse risk and likelihood of building demolition due to residual deformations. The High Yield Point (HYP400) steel is a steel material that has a higher yield stress and notch toughness but less strain hardening than conventional mild steels. HYP400 steel could enhance capacity design principles, such as the strong-column-weak-beam (SCWB) ratio when they are utilized in steel columns and potentially increase the collapse capacity of steel moment resisting frames (MRFs) under earthquake shaking. This thesis advances the state-of-knowledge through a multi-scale (from material to system) level study to assess the potential use of high-performance steel materials in minimizing earthquake-induced collapse of steel MRFs. The primary focus is on the characterization of the collapse behaviour of HYP400 and conventional steel hollow square section (HSS) columns by means of experimental testing and corroborating numerical simulations. Dual-parameter collapse-consistent loading histories (i.e., axial load and lateral drift demands) are developed to better quantify the flexural and axial demands in both interior and end columns in steel MRFs. These protocols reflect the asymmetric drifting of a building in one primary loading direction prior to dynamic instability ("ratcheting"). They also reflect the seismic demands imposed into steel columns within a steel MRF subjected to near-fault and long-duration ground motions. A landmark experimental program is conducted that characterizes the collapse behaviour of wide-flange and HSS steel columns under cyclic loading. The experimental program highlights the differences in the seismic demands and failure modes observed in steel columns depending on the imposed lateral and axial loading history, expected ground motion characteristics and building topology. It is shown that column axial shortening dominates the steel column stability. The hysteretic behaviour of HSS steel columns is further evaluated through corroborating finite element (FE) simulations. The steel column pre- and post-buckling behaviour is fully characterized depending on the type of steel material including the HYP400 steel. The FE results provide insight on the main differences of the lateral and axial damage progression between interior and end columns within the same steel MRF bay. The experimental data and corroborating finite element studies provide the basis for the development of a versatile steel column deterioration model that can explicitly simulate the axial-bending interaction, the column axial shortening due to local buckling induced softening and the cyclic deterioration in the column's strength and stiffness. Local buckling-induced softening is modeled through the development of an equivalent stress-strain formulation that includes a softening branch and can be fully characterized through conventional stub column tests. System level dynamic collapse simulation studies are conducted with over 80 archetype buildings with steel MRF systems ranging from 2 to 12-stories. Emphasis is placed on the importance of column axial shortening on the seismic performance of steel MRFs. It is shown that depending on the ground motion type, column axial shortening may result into slab tilting and catenary action prior to collapse. It is also shown that the use of the HYP400 steel columns can potentially enhance the collapse capacity of steel MRFs and reduce the expected residual lateral and vertical deformations in the aftermath of earthquakes.</description><description>Les principes de conception parasismique des bâtiments basés sur la capacité ont réduit le risque d'effondrement des structures en acier. Les études expérimentales suggèrent que le comportement des colonnes peut être grandement affecté par les instabilités globales et le flambement local, ce qui augmente le risque d'effondrement et le besoin de procéder à la démolition des bâtiments qui ont subi des déformations résiduelles excessives. L'acier "High Yield Point" (HYP400) est un matériau avec une limite d'élasticité élevée et une résilience accrue (résistance aux chocs mesurée à l'entaille - test Charpy), ainsi qu'un écrouissage moins marqué.  Ces propriétés des aciers haute performance pourraient permettre d'améliorer les principes de conception parasismique basés sur la capacité qui prônent le modèle de séquence préférentielle de ruine des poutres d'abord (colonnes fortes – poutres faibles -SCWB) dans les cadres d'acier. Cette thèse fait progresser l'état des connaissances avec des études multi-échelles pour quantifier les bénéfices des aciers haute performance pour la prévention des effondrements des bâtiments avec ossatures à cadres.  L'objectif principal est de caractériser et comparer le  comportement à  l'effondrement des colonnes en HYP400 et de celles en acier conventionnel, au moyen d'essais en laboratoire et de simulations numériques avancées. Les demandes sismiques axiales et flexionnelles des colonnes intérieures et extérieures sont quantifiées avec de nouveaux protocoles de chargement pour simuler les conditions d'effondrement. Ces protocoles reflètent la dérive latérale asymétrique des structures avant l'instabilité dynamique (ratcheting), et sont représentatifs de deux types de tremblements de terre sévères, avec chocs à proximité des failles et avec secousses de longue durée. Un programme expérimental unique a été réalisé pour quantifier le comportement à l'effondrement des colonnes en forme de I et des sections tubulaires carrées. Les résultats d'essais  suggèrent que les demandes sismiques des colonnes intérieures et extérieures sont très  différentes. Ces différences dépendent des protocoles de chargement, des caractéristiques des tremblements de terre et de la topologie de la structure. Le raccourcissement de la colonne suite aux déformations plastiques induites par flambage local est une grande problématique pour la stabilité des colonnes. Le comportement des colonnes tubulaires à section carrée est également évalué avec la simulation par éléments finis. La validité de ces simulations dépend entre autres facteurs du modèle constitutif et des paramètres des matériaux de l'acier utilisé. Les simulations numériques révèlent des différences significatives dans  la  progression de l'endommagement axial et latéral des colonnes intérieures et extérieures d'un même étage du cadre d'acier. Les résultats des expériences en laboratoire et des simulations numériques sont utilisés pour développer un nouveau modèle constitutif pour la modélisation des colonnes d'acier. Ce modèle  permet de simuler l'interaction axiale et flexionnelle de la réponse, le raccourcissement dû aux déformations importantes résultant du flambage local, et la dégradation cyclique de la résistance et de la rigidité des colonnes endommagées. Finalement, plus de 80 bâtiments avec cadres en acier (archétypes de 2 à 12 étages) sont analysés dans leur régime non linéaire. Pour fins de comparaison, les archétypes utilisent les colonnes conventionnelles et les colonnes faites d'acier HYP400. Les résultats des simulations numériques indiquent qu'en fonction du type de tremblement de terre, le raccourcissement de la colonne endommagée impose par compatibilité une inclinaison de la dalle et l'action caténaire se produit avant que le point d'instabilité dynamique des cadres ne soit atteint. L' utilisation d'acier HYP400 peut réduire ces problèmes et augmenter la capacité des cadres à l'effondrement. </description><creator>Suzuki, Yusuke</creator><contributor>Colin Andrew Rogers (Supervisor1)</contributor><contributor>Dimitrios Lignos (Supervisor2)</contributor><date>2019</date><subject>Civil Engineering &amp; Applied Mechanics</subject><title>Earthquake-induced collapse of steel moment resisting frames with conventional and high performance steel columns</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/d791sj57c.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/gh93h185z</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Civil Engineering and Applied Mechanics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:s7526f497</identifier><datestamp>2020-03-21T05:02:03Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The aim of this paper is to investigate why, despite experiencing the longest civil conflicts in the Middle East and Africa, Lebanon and Sudan continue to exemplify durable traditional clientelistic regimes based on sectarianism. This research, based on literature on domination theory in a post-colonial framework, examines the creation and reformulation of nationalist discourse in the years prior to independence found in two primary indigenous publications: La Révue Phénicienne in Lebanon and The Sudan Notes and Records in Sudan. These publications show the political elite's agency, with the colonial authorities' endorsement, to write the national history along the lines of sectarian-based identities in Lebanon and Sudan. In the contemporary period, these political elites promoted more particularistic sectarian-based ideologies, deftly reformulated when challenged by wide-scale civil wars, in order to sustain situating their own sectarian group at a higher level in the country's political and discursive hierarchy. This thesis concludes that in both Lebanon and Sudan sectarianism is the by-product of the deliberate hegemonic strategies employed by the political elite, originally empowered during the colonial era, to perpetuate and legitimise their position at the top of the power hierarchy in their respective countries.</description><description>L'objet de cette étude est de mener une recherche sur les causes qui font que le Liban et le Soudan continuent, malgré leur expérience de longue guerre civile, la plus longue d'ailleurs au Moyen Orient et en Afrique, d'illustrer des régimes clientélistes traditionnels se manifestant sous la forme d'un système sectaire. Cette recherche, basée sur la littérature de la théorie de domination dans un cadre postcolonial, étudie la création et la formulation du discours nationaliste dans les années précédant l'accès à l'indépendance, respectivement au Liban et au Soudan dans deux importantes publications indigènes : La Révue Phénicienne au Liban et les Notes et Registres Soudanais (The Sudan Notes and Records) au Soudan. Ces publications démontrent la volonté de l'élite politique, avec l'aval de l'autorité coloniale, à rédiger l'histoire nationale définit autours des identités à caractère sectaire au Liban et au Soudan.  Dans la période contemporaine, cette même élite politique a encouragé de plus en plus les idéologies reposant sur le sectarisme et les a habilement reformulées quand elle a dû faire face à des guerres civiles de grande ampleur ; ceci afin de continuer à placer leur propre groupe sectaire en haut de la hiérarchie politique et discursive du pays. Cette recherche conclut qu'au Liban comme au Soudan, le sectarisme est le résultat délibéré de stratégies hégémoniques utilisées par l'élite politique dans leurs pays respectifs. De cette façon, ces élites, précédemment soutenu par le pouvoir coloniale, ont perpétué et légitimé leurs positions supérieures dans la hiérarchie du pouvoir.</description><creator>Roussel-Hemery, Morgane</creator><contributor>Khalid Medani (Internal/Supervisor)</contributor><date>2019</date><subject>Islamic Studies</subject><title>The reformulation of sectarianism in independent Lebanon and Sudan</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/3484zj93w.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/s7526f497</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Institute of Islamic Studies</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:pg15bh343</identifier><datestamp>2020-03-21T05:02:04Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Ces travaux de doctorat ont utilisé l'électroencéphalographie (EEG), l'imagerie par résonance magnétique (IRM) et des mesures comportementales dans un échantillon vaste et bien caractérisé de personnes vieillissants avec le VIH, dans le but de mieux comprendre les mécanismes du cerveau impliqués dans le dysfonctionnement cognitif au sein de cette population. Les participants sont issus de la cohorte « Pour un cerveau en santé », une étude canadienne longitudinale portant sur la santé du cerveau chez les personnes VIH+ traitées avec cART. Cette thèse débute avec une revue systématique et critique de la littérature existante utilisant des méthodes électrophysiologiques chez des personnes ayant le VIH depuis que cART est largement disponible. Cette revue démontre qu'il y a des différences électrophysiologiques entre les individus VIH+ et des participants contrôles en bonne santé, mais que la relation entre ces mesures d'activité cérébrale et le dysfonctionnement cognitif demeure incertaine. De plus, la majorité des travaux sur ce sujet implique des échantillons de taille modique, et souffre d'autres contraintes méthodologiques. Les deuxième et troisième études présentées dans cette thèse visent à déterminer si les mesures d'activité cérébrale d'EEG à l'état de repos et évoqués par des tâches cognitives sont systématiquement liés à la capacité cognitive au sein d'un vaste échantillon (N=89) d'hommes âgés vivant avec le VIH, et dont la capacité cognitive varie de normale à légèrement déficiente. La première étude empirique examine les réponses EEG évoquées par deux différentes tâches, à différentes étapes du traitement cognitif. Nous avons trouvé que les potentiels évoqués tardifs (P300), mais pas précoces, sont liés à la capacité cognitive, et ce pour les deux tâches. Nous avons aussi trouvé des indications préliminaires que cet effet serait lié au volume du thalamus, suggérant que la sévérité de l'infection au VIH avant traitement affecte certains circuits neuronaux de manière sélective. L'étude finale se concentre sur l'EEG à l'état de repos, examinant les relations entre la capacité cognitive et l'activité oscillatoire alpha, delta et thêta à l'état de repos. Les données d'imagerie par résonance magnétique structurelle étaient aussi disponibles pour un sous-groupe de participants, permettant l'évaluation préliminaire des bénéfices relatifs à chacune de ces approches complémentaires d'imagerie fonctionnelle et structurelle pour comprendre les effets du VIH sur le cerveau. Nous avons trouvé que la puissance relative des fréquences alpha et delta au repos était liée de façon significative à la capacité cognitive, alors que les mesures structurelles du cerveau, tel que l'épaisseur du cortex et le volume de régions du cerveau, ne l'étaient pas. La sévérité antérieure de l'immunosuppression liée au VIH n'était pas associée à ces mesures structurelles ou fonctionnelles à l'état de repos. Mises ensemble, ces découvertes supportent l'idée que la déficience cognitive chez les personnes vivant avec le VIH reflète un dysfonctionnement de plusieurs circuits cérébraux, possiblement affectés par différentes pathophysiologies. Certains circuits seraient potentiellement plus vulnérables à la sévérité de l'infection au VIH pré-traitement, alors que d'autres seraient affectés par des facteurs additionnels comme les comorbidités, qui ont aussi des effets néfastes sur la santé du cerveau. De plus amples recherches sont nécessaires afin de mieux comprendre les multiples facteurs qui contribuent à la déficience cognitive accompagnant l'infection chronique au VIH. Les études présentées ici mettent de l'avant l'EEG en tant qu'outil particulièrement utile à l'avancement de notre compréhension des mécanismes du cerveau impliqués dans cette déficience cognitive. De plus, l'utilisation de l'EEG est prometteuse dans une visée clinique, pouvant permettre de mieux caractériser cette complication commune, méconnue et potentiellement traitable de l'infection au VIH.</description><description>This doctoral work applied electroencephalography (EEG), magnetic resonance imaging (MRI), and behavioral methods in the same large, well-characterized sample of older persons living with HIV to better understand the brain mechanisms underlying cognitive dysfunction in this population. Participants were drawn from the Positive Brain Health Now cohort, a Canadian longitudinal study of brain health in people with cART-treated HIV. This thesis begins with a systematic and critical review of the existing literature using electrophysiological methods in persons with HIV since the widespread availability of cART. That review showed that there are electrophysiological differences between HIV+ individuals and healthy controls but that the relationship of these measures with cognitive impairment remains uncertain. Furthermore, much of the work on this topic involved small samples, and suffered from other methodological limitations. The second and third studies reported in this thesis thus aimed to provide evidence that task-evoked and resting state electroencephalography (EEG) measures systematically related to cognitive ability across the normal to mild cognitively impaired range in a large sample (N=89) of older men with HIV. The first empirical study examined EEG responses evoked by two different tasks, and across early and later processing stages. We found that late (P300), but not early evoked potentials related to cognitive ability in both tasks. We also found preliminary evidence of selective neural circuit vulnerability to the severity of HIV infection, prior to treatment, and suggest that "legacy" effects of HIV on the thalamus may explain this observation. The final empirical study focused on resting state EEG, examining the relationships of cognitive ability with alpha, delta and theta oscillatory activity at rest. Structural magnetic resonance imaging was available in a sub-sample, allowing preliminary assessment of the relative merits of these complementary functional and structural neuroimaging approaches in HIV. We found that relative alpha and delta power at rest were significantly related to cognitive ability, while structural brain measures such as cortical thickness and regional brain volumes were not. The historical severity of HIV-related immunosuppression was not associated with these resting-state functional or structural markers of brain health. Taken together, these findings argue that cognitive impairment in people living with HIV likely reflects dysfunction in multiple brain circuits, the underlying pathophysiology may vary. That is, some circuits may be more vulnerable to the severity of HIV infection prior to effective treatment, while others might be affected by additional factors, such as co-morbidities that also have a negative impact on brain health. More work is needed to fully understand the likely multifactorial contributors to cognitive impairment in chronic HIV infection. The studies presented here argue that EEG may be a particularly useful tool for advancing our understanding of the brain mechanisms underlying this cognitive impairment. EEG also holds promise for clinical use in characterizing this common, under-recognized and potentially treatable complication of HIV infection.</description><creator>Fernandez Cruz, Ana Lucia</creator><contributor>Lesley K Fellows (Supervisor)</contributor><date>2019</date><subject>Neuroscience</subject><title>Brain mechanisms underlying cognitive dysfunction in HIV</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/h702q853k.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/pg15bh343</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Integrated Program in Neuroscience</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:n296x1461</identifier><datestamp>2020-03-21T05:02:05Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>In the current agricultural context, sustainable crops such as perennial grains have the potential to further secure the world's demand in cereals. Under northern climates, perennial grains are as vulnerable as annual grains to early and late frost events that cause important damages and economic losses. Therefore, the understanding of cold-acclimation in perennials grasses, that is the process by which temperate plants prime their defence against freezing stress, is necessary to cultivate them at their full potential under northern latitudes. Here, we tested the newly developed perennial grasses model B. sylvaticum in its capacity to facilitate the study of cold-acclimation and freezing tolerance in perennial grasses. Accordingly, our hypothesis is that B. sylvaticum can cold-acclimate in response to low temperatures and increase its freezing tolerance level, and that a phenotypic range in the capacity to cold-acclimate will be observed across different accessions. To verify this, we first determined the survival of non-acclimated and cold-acclimated live plants to freezing stress. We observed an increase of 2°C in the freezing tolerance of cold-acclimated plants in nine tested accessions, themselves differentiated by a diversity in cold-acclimation capacity. This was followed by the determination of cold-responsive genes transcript accumulation profiles in B. sylvaticum. Consequently, we determined that three cold-responsive genes BsCOR413, BsCOR410 and BsCBF2.1 were differentially regulated in response to cold in nine accessions of B. sylvaticum, which indicates that this plant most likely possesses the molecular mechanisms that allow cold-acclimation and the subsequent increase in its freezing tolerance. In addition, we tested a high-efficiency transformation protocol for B. sylvaticum under our laboratory conditions. We report the transformation of a B. sylvaticum plant that overexpresses by thirtyfold the acetyltransferase GCN5, an epigenetic modifier that was previously linked to cold response in plants. Therefore, B. sylvaticum's capacity to cold-acclimate through the observed underlying molecular mechanisms as well as its ability to be transformed under laboratory conditions highlights its potential in being used as a model to study cold response in perennial grasses. Findings made in B. sylvaticum could thus be transferred and applied to economically important perennial grains crop in order to increase their freezing tolerance.</description><description>Dans le contexte agricole actuel, les cultures durables telles que les céréales vivaces ont le potentiel de mieux sécuriser la demande mondiale en céréales. Sous les climats nordiques, les céréales vivaces sont aussi vulnérables que les céréales annuelles aux gelées hâtives et tardives qui créent d'importants dommages et pertes économiques. Ainsi, la compréhension de l'acclimatation au froid chez les herbacées vivaces, soit le procédé par lequel les plantes tempérées activent leurs défenses pour contrer le stress causé par le gel, est nécessaire afin de tirer le plein potentiel de leur culture sous les latitudes nordiques. Nous testons ici la nouvelle plante modèle Brachypodium sylvaticum dans sa capacité à faciliter l'étude de l'acclimatation au froid et de la tolérance au gel chez les herbacées vivaces. En conséquence, notre hypothèse est que B. sylvaticum peut s'acclimater en réponse à de basses températures et augmenter sa tolérance au gel, et qu'une gamme phénotypique de capacité d'acclimatation devrait être observée à travers plusieurs accessions. Dans le but de tester ceci, nous avons d'abord déterminé la survie de plantes vivantes soumises à des températures sous zéro; nous observons une augmentation de la tolérance au gel d'environ 2°C chez les plantes acclimatées de neuf accessions testées, elles-mêmes étant diversifiées par leur capacité à s'acclimater. Nous avons ensuite caractérisé l'accumulation de transcrits pour des gènes de réponse au froid en réponse à des conditions d'acclimations. Conséquemment, nous avons déterminé que trois gènes de réponse au froid, soit BsCOR413, BsCOR410 et BsCBF2.1 sont régulés de façon différentielle en réponse au froid chez neuf accessions de B. sylvaticum. Ceci nous indique que cette plante possède des mécanismes moléculaires qui lui permettent une acclimatation au froid ainsi que l'augmentation subséquente de sa tolérance au gel. En plus, nous avons testé et adapté sous nos conditions de laboratoire un protocole de transformation à haute-efficacité chez B. sylvaticum. Ainsi, nous rapportons la transformation d'une plante B. sylvaticum qui sur-exprime par trente fois l'acetyltransférase GCN5, soit un modificateur épigénétique dont l'action est liée à la réponse au froid chez les plantes. De ce fait, la capacité qu'a B. sylvaticum de s'acclimater au froid en vertu des mécanismes moléculaires sous-jacents qui ont été observés, ainsi que son aptitude à être transformé sous des conditions de laboratoire lui assure d'être utilisé en tant que plante modèle pour étudier la réponse au froid chez les herbacées vivaces. Les découvertes faites chez B. sylvaticum pourraient être transférées et appliquées chez des céréales vivaces d'importance économique dans le but d'améliorer leur tolérance au gel.</description><creator>Lambert-Rivest, Gabriel</creator><contributor>Jean-Benoit Charron (Internal/Supervisor)</contributor><date>2019</date><subject>Plant Science</subject><title>«Brachypodium sylvaticum»: developing a new model to study freezing tolerance in temperate perennial grasses</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/2z10ws63m.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/n296x1461</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Plant Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:sn00b112t</identifier><datestamp>2020-03-21T05:02:06Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Contexte: Les caroténoïdes sont des pigments végétaux jaune-rouge obtenus à partir de fruits et de légumes (FL), qui se déposent en grande partie dans la peau et servent de biomarqueur à l'apport en FL. Les méthodes actuelles d'évaluation des caroténoïdes (évaluation du régime alimentaire, analyse sanguine par CLHP, spectrophotométrie cutanée) peuvent être biaisées, longues, complexes et coûteuses. Objectif: Nous avions pour objectif d'évaluer la faisabilité de l'analyse numérique de la couleur de la peau contre l'analyse spectrophotométrique pour l'estimation du contenu en caroténoïdes de la peau et d'étudier l'impact de la coloration de la peau du visage induite par les caroténoïdes sur les mesures de la santé perçue et de l'attractivité physique.Méthodes: Un essai en ouvert de deux semaines de supplémentation en jus à base de carottes a été mené auprès de vingt-cinq participants, avec mesures de suivi toutes les deux semaines pendant quatre semaines. Des images de trois régions de la peau (paume, revers de la main, joue) ont été prises sous différentes conditions d'éclairage (standard, flash, incandescent) et avec différents appareils (appareil photo Canon et deux téléphones intelligents) ainsi qu'une évaluation alimentaire (questionnaire de fréquence de consommation alimentaire et journal alimentaire) et mesures spectrophotométriques.Résultats: La coloration de la peau de la paume médiée par les caroténoïdes a considérablement augmenté suivant la supplémentation (semaine 2) et pendant le suivi (semaines 4 et 6). L'analyse numérique de la couleur de la peau de la paume est étroitement corrélée aux changements de coloration évalués par spectrophotométrie, la corrélation la plus forte étant observée pour les images prises avec un flash. Aucun changement significatif n'a été noté pour les évaluations de la santé perçue et de l'attractivité physique.Digital Photo Analysis for Tissue Carotenoid Status Assessment ROLDOS vi Conclusion: Nous concluons que l'analyse numérique des images peut servir d'estimation rapide du contenu en caroténoïdes de la peau lorsque les images sont prises avec le flash de l'appareil, mais des modifications de la santé perçue et de l'attractivité pourraient nécessiter plus de deux semaines de supplémentation en caroténoïdes.</description><description>Background: Carotenoids are yellow-red plant pigments obtained from fruits and vegetables (FV) that are largely deposited into skin and serve as a biomarker for FV intake. Current methods of carotenoid assessment (dietary assessment, HPLC blood analysis, skin spectrophotometry) can bebiased, time consuming, complex, and expensive. Objective: We aimed to assess the feasibility of digital image skin color analysis for skin carotenoid content estimation against spectrophotometric analysis and study the impact of carotenoid-mediated facial skin coloration on measures of perceived health and attractiveness. Methods: Twenty-five participants completed a two-week open label carrot-based juice supplementation trial with bi-weekly follow up measurements for four weeks. Images of three skin regions (palm, top hand, cheek) were taken under various lighting conditions (standardized, device-flash, incandescent) and with different devices (Canon camera, and two smartphones) along with dietary (FFQ &amp; diet diary) and spectrophotometric measurements. Images were rated for perceived health and attractiveness by trained evaluators that exhibited high inter-rater reliability. Results: Palm carotenoid-mediated skin coloration increased significantly following supplementation (Week 2) and throughout follow up (Weeks 4 &amp; 6). Digital image skin color analysis of the palm correlated strongly with spectrophotometer changes in palm skin coloration, with the strongest correlation noted for images taken with a device's flash. No significant changes were noted for perceived health and attractiveness ratings. Conclusion: We conclude that digital image analysis can serve as a rapid estimate for skin carotenoid content when images are taken with the device's flash, but changes in perceived health and attractiveness may require more than two weeks of carotenoid supplementation.</description><creator>Roldos Saibene, Lucas</creator><contributor>Stan Kubow (Internal/Supervisor)</contributor><date>2019</date><subject>Human Nutrition</subject><title>Digital photo analysis for tissue carotenoid status assessment</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/3t945t18h.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/sn00b112t</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Human Nutrition</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:mk61rk34p</identifier><datestamp>2020-03-21T05:02:07Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>This work presents novel architectures for improving the performance of capacitive-based micromachined thermal detectors, ultrasonic transducers, and multiplexers. The proposed designs are implemented in a pure-play commercial process, which is known for its reliability and cost-eﬀectiveness. In addition, several performance-limitation issues are tackled. Furthermore, a novel approach is proposed for implementing standalone MEMS arrays, to avoid the complicated and expensive post-processing of complementary metal-oxide-semiconductor (CMOS) wafers.The first part of this work presents a novel dual-level capacitive bimorphous thermal detector architecture that is prototyped in the commercial PolyMUMPs by MEMSCAP. The dual-level design exhibits a 6.5 fF/°C sensitivity which is over 3 times higher than traditional single-level designs and it has a base capacitance that is over twice as large. The proposed architecture mitigates an inherent trade-oﬀ between thermal sensitivity and base capacitance. Other challenges facing bimorphous thermal detectors are addressed as well. This work also presents, a compensation mechanism for shocks and the ambient temperature. In addition, a material selection study for the bimorph layers concluded a significant performance enhancement of using silicon-carbide (SiC) with polyimide. Moreover, a method was developed for utilizing a positive photoresist as a sacrificial layer that alleviates the restrictions on material-selection for the layers of the bimorphs.The second part of this study presents a reduced-gap implementation of a 3.33-MHz capacitive micromachined ultrasonic transducer (CMUT) in the PolyMUMPs technology. The design provides a bias voltage supply reduction that is four times less compared to the traditional architecture to achieve a sufficient acoustic pressure. Also, a novel operation mechanism is demonstrated for ultrasonic testing underwater, and this mechanism employs the surface-tension forces between the surfaces of the water and the ultrasonic probe. The proposed meniscus-mode mechanism amplifies the ultrasonic signal more than the traditional fully-immersed setup by a factor of 2.6; this is demonstrated experimentally in the study.The final part proposes a novel switching design for multiplexing, and it targets low-frequency applications. The inline torsional electrostatic MEMS multiplexer (ITEM2) architecture is presented. In the study, a theoretical analysis of the structure's snap-down voltage is derived. By combining the novel architectures for thermal detectors and CMUTs presented with the proposed ITEM2 design, a stand-alone MEMS array solution can be a low-cost alternative to the traditional monolithic and hybrid integration with the electronics. The study presents an implementation of an 8 × 8 thermal detectors array that is routed using micromachined bypass-bridges and MEMS multiplexers.</description><description>Ce travail présente de nouvelles architectures pour améliorer les performances des d´détecteurs thermiques micro-usinés à base capacitive, des transducteurs à ultrasons et des multiplexeurs. Les conceptions proposées sont mises en œuvre dans un processus commercial pur, connu pour sa fiabilité et son rapport coût-efficacité. En outre, plusieurs problèmes de limitation des performances sont abordés. De plus, une nouvelle approche est proposée pour la mise en œuvre d'une matrice MEMS autonome afin d'éviter le post-traitement compliqué et coûteux de tranches de métal-oxyde-semiconducteur complémentaires (CMOS). La première partie de ce travail présente une nouvelle architecture de d´détecteur thermique bimorphe capacitif à deux niveaux qui est prototypée dans les PolyMUMPs commercialisés par MEMSCAP. La conception à deux niveaux présente une sensibilité de 6,5 fF/°C qui est plus élevée de plus de 3 fois que les conceptions traditionnelles à un seul niveau, et qui a une capacité de base deux fois plus grande. L'architecture proposée atténue un compromis inhérent entre la sensibilité thermique et la capacité de base. D'autres défis auxquels sont confrontés les détecteurs thermiques bimorphes sont également abordés. Ce travail présente un mécanisme de compensation des chocs et de la température ambiante. De plus, une étude de sélection des matériaux pour les couches de bimorphe a emmené à une amélioration significative des performances de l'utilisation du carbure de silicium (SiC) avec le Polyimide. Par ailleurs, une méthode a été développée pour utiliser une résine photosensible positive en tant que couche sacrificielle qui allège les restrictions sur la sélection de matériaux pour les couches des bimorphes.La deuxième partie de cette étude présente une mise en œuvre réduite des transducteurs ultrasoniques micro-usinés capacitifs de 3,33-MHz (CMUT) dans la technologie PolyMUMPs. La conception fournit une réduction de la tension de l'alimentation qui est quatre fois supérieure à l'architecture traditionnelle pour obtenir une pression acoustique suffisante. En outre, un nouveau mécanisme de fonctionnement est démontré pour les tests par ultrasons sous l'eau, et ce mécanisme utilise les forces de tension de surface entre les surfaces de l'eau et la sonde ultrasons. Le mécanisme en mode ménisque proposé amplifie le signal ultrasonore plus que la configuration traditionnelle entièrement immergée par un facteur de 2,6; ceci est démontré expérimentalement dans l'étude.La dernière partie propose une nouvelle conception de commutation pour le multiplexage et cible les applications à basse fréquence. L'architecture du multiplexeur MEMS électrostatique en torsion en ligne (ITEM2) est présentée. Dans l'étude, une analyse théorique de la tension d'enclenchement de la structure est dérivée. En combinant les nouvelles architectures pour les détecteurs thermiques et les CMUT représentées par la conception ITEM2 proposée, une solution MEMS autonome peut être une alternative économique à l'intégration traditionnelle monolithique et hybride avec l'électronique. L'étude présente une mise en œuvre d'un réseau de détecteurs thermiques de 8 × 8 qui est acheminé à l'aide de ponts de dérivation micro-usinés et de multiplexeurs MEMS.</description><creator>Tawfik, Hani</creator><contributor>Mourad N El-Gamal (Supervisor)</contributor><date>2019</date><subject>Electrical and Computer Engineering</subject><title>Novel architectures for capacitive micromachined sensors and actuators</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/ng451k835.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/mk61rk34p</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:0k225d34t</identifier><datestamp>2020-03-21T05:02:08Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Urban growth is a highly relevant challenge to development in the northern Vietnamese uplands. In this region, state and private enterprises are dramatically transforming rural landscapes for natural resource exploitation and 'development' potential. As a result, the region's small cities are steadily growing in population as lowland migrants are attracted by new employment opportunities. Despite such rapid urbanization occurring in northern Vietnam, there is little written on the dynamics of urban space use in the region's small upland cities. This research project seeks to fill the gap in the literature concerning urbanization dynamics in small upland cities in Vietnam. The particular research site is Cao Bằng city, the capital city of Cao Bằng province in northeastern Vietnam. The aim of my project is to investigate how the interactions between everyday activities of citizens and state urban planning co-create urban space in Cao Bằng city. To conceptualize my research, I draw upon social spatialization theory, debates from the urban space literature, and the theories behind everyday politics and resistance. During six weeks of fieldwork in Cao Bằng city, I collected data from local residents and state officials through semi-structured interviews, oral histories, and participant observation. From the analysis of these data I find that state development initiatives consider small cities like Cao Bằng as focal points for instigating a regime of industrialization and modernization in the remote upland northern region at-large. As such, Cao Bằng city's built form and spatial arrangement are undergoing dramatic transformations. I find that residents in Cao Bằng negotiate and adapt their everyday spatial practices in response to these urban transformations, especially the city's most marginalized residents who face grave threats to their livelihoods as a result of contemporary urban governance practices. </description><description>La croissance urbaine pose un défi brûlant au développement durable des hauteurs du nord du Vietnam. L'État et les entreprises privées transforment radicalement le paysage rural de ces régions, notamment avec l'exploitation des ressources naturelles et des projets de développement. Ainsi, on assiste à la croissance soutenue de la population des villes de petite taille, suite aux nouvelles perspectives d'emploi qui entrainent l'arrivée considérable de migrants en provenance des plaines. Malgré la manifeste rapidité de l'urbanisation au nord du Vietnam, très peu reste écrit sur les dynamiques qui façonnent l'usage de l'espace urbain dans ces villes de petite taille situées dans les hauteurs de la région. Ce projet de recherche a donc pour but de combler en partie les lacunes qui existent actuellement dans l'étude des dynamiques d'urbanisation opérant au nord du Vietnam. Le site sur lequel la recherche est axée est la ville de Cao Bằng, la capitale de la province de Cao Bằng au nord-est du Vietnam. Mon projet cherche à élucider la manière dont les activités quotidiennes des résidents ainsi que l'aménagement urbain par l'État sont imbriqués, et ensemble tissent l'espace urbain de la ville de Cao Bằng. D'un point de vue conceptuel, ma recherche est fondée sur la théorie de spatialisation sociale, des débats issus de la littérature de l'espace urbain, ainsi que sur différentes théories de politique quotidienne et de resistance. Mon projet est basé sur des donnés recueillies à partir de résidents locaux et de fonctionnaires d'État durant six semaines d'enquête de terrain à Cao Bằng, à travers des entretiens semi-structurés, des histoires orales ainsi que de l'observation participante. L'analyse de ces donnés confirme le statut de Cao Bằng comme plaque tournante des initiatives de développement de l'État vis-à-vis de l'industrialisation et de la modernisation des régions reculées du pays. À la suite de ces initiatives, il devient clair que la forme construite et l'organisation spatiale de la ville de Cao Bằng subissent présentement un bouleversement majeur. Les résidents de la ville, tout particulièrement les groupes les plus marginalisés dont les modes de vies sont largement menacés par les pratiques de gouvernance urbaine actuelles, se retrouvent à devoir adapter leur pratiques spatiales quotidiennes en réponse à ces transformations urbaines.</description><creator>Adenwala, Ammar</creator><contributor>Sarah Turner (Internal/Supervisor)</contributor><date>2019</date><subject>Geography</subject><title>Alternative realities: negotiating urban space production in the small town of Cao Bang City, upland northern Vietnam</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/bc386m67n.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/0k225d34t</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of Geography</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:1831cn19k</identifier><datestamp>2020-03-21T05:02:09Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Ecological communities are complex, and this complexity can obscure their underlying patterns and natural laws. One way to understand communities is to summarize their most important characteristics using consistent measures. Community structure is a set of measures of composition, abundance, distribution, and interaction that describe an ecological community over space and time. Trophic structure is an important aspect of community structure, and relates to energy and nutrient flow, especially the distribution of organisms across trophic levels. Trophic level is the energetic distance of an organism from the base of production – its average position in the food chains to which it belongs. Due to energetic inefficiencies, we generally predict that organisms decrease in number and biomass with trophic level, forming trophic pyramids (known as "pyramids of numbers" and "pyramids of biomass", respectively). Other, non-pyramidal trophic structures are also common, and trophic structure is affected by variables at multiple ecological scales. The objective of this thesis is to investigate determinants of trophic and community structure, including latitude, ecosystem type, biome transition, community composition, and body size. While pyramids of numbers and pyramids of biomass are well-studied, few have investigated the trophic distribution of diversity. Using a meta-analysis approach, I found that, on average, large published food webs form pyramids of species richness, with a decrease in number of species as trophic level increased. Trophic diversity structure was correlated to centrality, latitude, ecosystem type, and study identity.Community structure varies spatially, as can be seen even by a casual observer at interfaces between biomes. I studied how macroinvertebrate and soil prokaryote communities changed latitudinally along the forest-tundra biome transition in the Yukon, and how the communities responded to other environmental variables. I found that the communities differed between sites, changed along the latitudinal transect, and responded to environmental variables at multiple scales, including active layer depth, lichen cover, and road proximity. Loss of predators can have profound effects on community structure. I used an experimental approach to investigate the effect of spider assemblage composition and diversity on prey consumption. I hypothesized that diverse assemblages would consume more prey due to niche complementarity and sampling effects. I found, however, that the spiders were generalist and intraguild predators, and that the one-species assemblage consumed the most prey. Spider body size affects its trophic niche, energy requirements, and interspecific interactions, and as a result, body size mediates the relationship between spider assemblage composition and prey consumption. The body size of an organism affects how it interacts with other organisms and its biological rates. I used a meta-analytic approach to test several prediction regarding the relationship between body mass and trophic properties of terrestrial vertebrate predators: Accipitridae (hawks, eagles, and their relatives), Felidae (cats), and Serpentes (snakes). I found that the predators chose prey smaller than themselves, within a predictable mass range. Prey taxonomic diversity increased with Serpentes mass. Counter to theory, Felidae trophic level decreased with body mass, and Felidae and Accipitridae predator-prey body mass ratio increased with trophic level. We currently live in the Anthropocene, an epoch characterized by anthropogenic geological, atmospheric, and biological change. These changes are affecting community structure, which in turn is affecting human access to the benefits provided by nature. Therefore, it is important that we continue to study community structure and the variables that affect it, so that we can predict and respond to ecological change in the Anthropocene. </description><description>Les communautés écologiques sont complexes, et cette complexité peut masquer leurs modèles et leurs lois naturelles. Il possible de tenter de comprendre les communautés en résumant leurs caractéristiques les plus importantes avec des mesures reproductibles. La structure communautaire consiste en l'ensemble des mesures de la composition, de l'abondance, de la distribution et des interactions qui décrivent une communauté écologique dans l'espace et dans le temps. La structure trophique est un aspect important de la structure communautaire et concerne la circulation de l'énergie et des nutriments, en particulier la distribution des organismes entre les niveaux trophiques. Le niveau trophique est la distance énergétique entre un organisme et la base de la production - sa position moyenne dans les chaînes alimentaires auxquelles il appartient. En raison des inefficiences énergétiques, nous prédisons généralement que le nombre et la biomasse des organismes diminuent avec le niveau trophique, formant des pyramides trophiques (appelées respectivement « pyramides des nombres » et « pyramides des biomasses »). D'autres structures trophiques non-pyramidales sont également fréquentes, et la structure trophique est affectée par de multiples variables à différentes échelles écologiques. L'objectif de cette thèse est d'étudier les déterminants de la structure trophique et communautaire, incluant la latitude, le type d'écosystème, la transition du biome, la composition de la communauté et la taille du corps. En utilisant une méta-analyse, j'ai constaté qu'en moyenne, les grands réseaux trophiques publiés forment des pyramides de la richesse spécifique; le nombre d'espèces diminue avec le niveau trophique. La structure de diversité trophique corrélait à la centralité, la latitude, le type d'écosystème et l'identité de l'étude. J'ai étudié comment les communautés de macroinvertébrés et de procaryotes du sol changeaient le long de l'écotone entre la toundra et la forêt au Yukon, et comment les communautés réagissaient à d'autres variables environnementales. J'ai constaté que les communautés étaient différentes entre les sites, qu'elles changeaient le long du transect latitudinal et réagissaient aux variables environnementales à de multiples échelles. J'ai utilisé une approche expérimentale pour étudier l'effet de la diversité et de la composition d'assemblages d'araignées sur la consommation de proies. J'ai posé l'hypothèse que les assemblages les plus divers consommeraient plus de proies en raison de la complémentarité des niches et des effets d'échantillonnage. La taille du corps de l'araignée affecte sa niche trophique, ses besoins en énergie et ses interactions interspécifiques et, par conséquent, la taille du corps sert de médiateur entre la composition de l'assemblage d'araignées et la consommation de proies. J'ai utilisé une approche méta-analytique pour tester plusieurs hypothèses concernant la relation entre la masse corporelle et les propriétés trophiques des prédateurs vertébrés terrestres : Accipitridae (faucons, aigles et leurs parents), Felidae (chats) et Serpentes (serpents). J'ai découvert que les prédateurs choisissaient des proies plus petites qu'eux, dans une fourchette de masse prévisible. Contrairement à la théorie, le niveau trophique de Felidae diminuait avec la masse corporelle, et le ratio des masses prédateurs-proies de Felidae et Accipitridae augmentait avec le niveau trophique. Nous vivons actuellement dans l'Anthropocène, une époque caractérisée par des changements géologiques, atmosphériques et biologiques anthropiques. Ces changements affectent la structure de la communauté, qui à son tour affecte l'accès humain aux richesses fournies par la nature. Il est donc important que nous continuions à étudier la structure des communautés et les variables qui l'affectent, afin de pouvoir prédire et répondre aux changements écologiques de l'Anthropocène.</description><creator>Turney, Shaun</creator><contributor>Gregor Fussmann (Supervisor2)</contributor><contributor>Christopher Buddle (Supervisor1)</contributor><date>2019</date><subject>Natural Resource Sciences</subject><title>Determinants of trophic structure in ecological communities</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/rj4306971.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/1831cn19k</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Natural Resource Sciences</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:w66345975</identifier><datestamp>2020-03-21T05:02:10Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Software interfaces shape the way we create, consume, and experience cultural goods. They reflect the cultural, social, and political systems, in which they are embedded and they embody and transmit the sensibilities of their designers and the overarching context of economic interests. This dissertation project uncovers these embedded interests and sensibilities through a comparative historical study of the production and design of touchscreens for music production. By focusing on the history of touchscreens in music production, the central assumption is that changes in music technology presage changes in culture. It argues that many of the ideas and cultural discourses that presently encircle Apple's iOS platform and app format are derived from past iterations of touchscreens for music production. From Iannis Xenakis's Unité Polyagogique Informatique CEMAMu (UPIC) in 1977 to the contemporary commercialized format in apps for smartphones, music touchscreens express cultural and technological aspirations of universality. Based on interviews and archival research, the work provides empirical evidence for a sensory design analysis of user interfaces in order to understand how social and political processes circulate and infiltrate design practices among developers and the users of touchscreens for music production. Although touchscreens are widely advertised as ushering in a more inclusive and "natural" form of musical practice, this study reveals the biases embedded in the interface design and their cultural, social, and aesthetic consequences. Specifically, the dissertation questions the paradigms of efficient design found in music apps and the consequences of designing out the possibility for failure and reflection in user interfaces. In so doing, it addresses how the interfaces uphold traditional normative conceptualizations of human and technological perfectability. The main goal of this project is to identify how technology and cultural discourse can be informed by more politically progressive values.</description><description>Les interfaces logicielles façonnent la manière dont nous créons, utilisons et expérimentons les biens culturels. Elles reflètent les systèmes culturels, sociaux et politiques dans lesquels elles sont ancrées et elles incarnent et transmettent les sensibilités de leurs concepteurs et le contexte général des intérêts économiques. Ce projet de thèse dévoile ces intérêts et sensibilités à travers une étude historique comparative de la production et de la conception des écrans tactiles pour la production musicale. En focalisant sur l'histoire des écrans tactiles en production musicale, l'hypothèse centrale est que les changements dans la technologie musicale présagent des changements dans la culture. Bon nombre des idées et discours culturels qui entourent présentement la plateforme Apple iOS et le format des applications sont dérivés d'itérations passées d'écrans tactiles pour la production musicale. De l'Unité Polyagogique Informatique CEMAmu (UPIC) de Iannis Xenakis en 1977 au format commercialisé contemporain des applications pour téléphones intelligents, les écrans tactiles expriment des aspirations technologiques et culturelles d'universalité. Reposant sur des interviews et des recherches archivistiques, ce travail offre une démonstration empirique pour une analyse sensorielle des interfaces utilisateur dans le but de comprendre comment les processus sociaux et politiques circulent et infiltrent les pratiques de conception parmi les développeurs et les utilisateurs d'écrans tactiles pour la production musicale. Bien que les écrans tactiles soient largement célébrés comme menant à une forme plus inclusive et « naturelle » de la pratique musicale, cette étude révèle les biais inhérents à la conception de l'interface et leurs conséquences culturelles, sociales et esthétiques. Plus précisément, la thèse interroge les paradigmes de la conception efficiente que l'on retrouve dans les applications musicales et les conséquences de concevoir la possibilité d'échec et de reflet dans les interfaces utilisateur. Ce faisant, elle adresse comment les interfaces maintiennent les conceptualisations normatives traditionnelles de la perfectibilité humaine et technologique. L'objectif principal de ce projet est d'identifier comment la technologie et le discours culturel peuvent être informés par des valeurs politiques plus progressistes. </description><creator>Simon, Victoria</creator><contributor>Sterne, Jonathan (Supervisor)</contributor><date>2019</date><subject>Art History and Communications Studies</subject><title>The history and politics of touchscreens for Music Production</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/pr76f5817.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/w66345975</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Art History and Communication Studies</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:8k71nk42m</identifier><datestamp>2020-03-21T05:02:11Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Schizophrenia (SCZ) and autism spectrum disorder (ASD) are psychiatric diseases with complex inheritance. Genetic studies have not identified susceptibility genes to adequately explain the heritability and the etiology of these diseases is largely unknown.We identified susceptibility genes enriched for de novo mutations (DNMs) in at least two independent whole exome sequencing (WES) publications. Genes associated with hypertrophic cardiomyopathy (HC) were used as control genes. We selected for rare inherited and DNMs in the ASD network using a WES dataset (2392 ASD families) and in the SCZ network using three independent WES datasets (35 trios; 598 trios; 5090 case controls). We compared the mutation load in the 'disease network' between affected and unaffected individuals for each dataset. The analyses were repeated using the 'HC network'. 14 SCZ genes and 143 ASD genes were identified. When using the 598 SCZ trios, probands were enriched in functional variants relative to the average mutation load of parents in the SCZ network (p = 0.04) but not in the HC genes (p = 0.23). All functional variants identified in the SCZ network were inherited. Similar results were obtained using the case control dataset (SCZ network: p = 0.02; HC network: p = 0.09). When analyzing ASD sibpairs, unaffected siblings were significantly enriched in functional variants in the ASD network (p = 0.02) but also throughout the exome based on a permutation analysis using all genes with functional variants. When controlling for sequencing depth through a conditional logistic regression and applying stricter filtering criteria, the difference was not statistically significant (p = 0.1358).We provide preliminary evidence that the accumulation of rare variants (mainly inherited) in the identified SCZ susceptibility genes is associated with SCZ. However, this was not the case for the ASD dataset that we had access to.</description><description>La schizophrénie (SCZ) et le trouble du spectre autistique (ASD) sont des maladies psychiatriques avec des héritages complexes. Les études génétiques n'ont pas identifié des gènes de susceptibilité pour expliquer l'héritabilité et l'étiologie de ces maladies est inconnue. Nous avons identifié les gènes de susceptibilité de maladies enrichies pour les mutations de novo (DNM) signalés par au moins deux publications de séquençage complet (WES). Les gènes témoins sont associés à la cardiomyopathie hypertrophique (HC). Nous avons sélectionnées des variantes rares (héréditaires et de novo) des gènes ASD en utilisant 2392 familles atteints du ASD et des gènes SCZ en utilisant 35 trios, 598 trios et 5090 individus affectés/non affectés. Nous avons comparé le nombre des mutations dans le 'réseau de maladie' entre les individus affectés et non affectés. L'analyse a été répétée en utilisant les gènes de HC. 14 gènes de SCZ et 143 gènes de ASD ont été identifié. Les proposants de les 598 trios ont été enrichis en variantes fonctionnelles du réseau de SCZ par rapport à la moyenne nombre de mutations de leurs parents (p = 0,04) mais pas dans les gènes de HC (p = 0,23). Les variantes dans les gènes de SCZ ont été héritées. Résultats similaires one été observé pour les 5090 individus affectés et non affectés (SCZ: p = 0,02; HC: p = 0,09). L'ordre de l'analyse de ASD, les frères et sœurs (FES) non affectés ont été enrichis en variantes fonctionnelles par rapport aux proposants dans les gènes de ASD (p = 0.02) et aussi tout au long de l'exome basé sur des permutations en utilisant tout les gènes avec les variantes fonctionnelles. Ce résultat n'est pas significative (p = 0.1358) lors de la comptabilisation de l'effet de séquençage par une régression logistique conditionnelle et en utilisant les critères de filtrage plus stricts. On observe que l'accumulation de variantes rares (principalement héréditaires) dans le réseau de 14 gènes est associée à SCZ. Cependant, ce n'était pas le cas pour l'ensemble de données ASD auquel nous avons eu accès.</description><creator>Fulginiti, Vanessa</creator><contributor>Ioannis Trakadis (Internal/Supervisor)</contributor><date>2018</date><subject>Human Genetics</subject><title>Testing the network hypothesis for schizophrenia and autism spectrum disorder using whole exome sequencing data</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/7h149r87w.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/8k71nk42m</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Human Genetics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:5712m9107</identifier><datestamp>2020-03-21T05:02:12Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La luminosité du Grand Collisionneur de Hadrons (LHC) situé au laboratoire CERN atteindra jusqu'à 7 fois la valeur nominale à la suite d'une série de mises à niveau techniques planifiées au cours de la prochaine décennie. Ce haut niveau de luminosité est un défi de taille pour les systèmes d'acquisition de données des expériences associées au LHC. Afin de bénéficier de l'augmentation de la luminosité du LHC, le détecteur ATLAS, l'une des expériences de physique des particles du LHC, sera amélioré pendant le « Long Shutdown 2 » du LHC qui débutera en 2019. Une partie du système de détection de muons d'ATLAS sera remplacé dans le but de réduire le taux de déclenchement du système d'acquisition de données pour les événements à un muon sans pour autant augmenter les seuils de quantité de mouvement transverse. La moitié des nouveaux détecteurs seront de type « small-strip Thin Gap Chamber » (sTGC), une variante des détecteurs TGC actuels d'ATLAS, qui se distinguent par une meilleure aptitude pour la localisation de particles. Une simulation d'un ensemble de modules sTGC dans ATLAS a été réalisée afin de confirmer que les méthodes de fabrication des nouveaux modules de détection et que la technologie sTGC permettra d'atteindre les critères de performance demandés pour la mise à niveau d'ATLAS. Des mesures de la résolution spatiale, obtenue en utilisant des rayons cosmiques et un faisceau de pions, sont aussi présentées. La résolution spatiale avec rayons cosmiques est obtenue in-situ en utilisant une technique d'analyse innovatrice qui corrige pour les désalignements entre les plans de détection ainsi que pour d'autres effets intrinsèques. Finalement, une procédure de certification a été développée pour le contrôle qualité des nouveaux détecteurs sTGC. Les résultats de la procédure, obtenus avec un petit détecteur prototype, sont présentés à titre de démonstration de faisabilité.</description><description>The luminosity of the Large Hadron Collider (LHC) at the CERN laboratory will reach up to 7 times the design value following a series of upgrades planned over the next decade. The increased luminosity puts a high pressure on the acquisition systems of the LHC particle physics experiments. In order to fully benefit from the increased LHC luminosity, the ATLAS detector, one of the LHC particle physics experiments, will be upgraded during the LHC Long Shutdown 2 beginning in 2019. Part of the ATLAS muon detector system will be replaced to reduce the single muon trigger rate without raising the transverse momentum thresholds. Half of the newly installed detectors are small-strip Thin Gap Chambers (sTGC), a variant of the current ATLAS TGC technology with improved tracking capabilities. A simulation of a set of sTGC detector modules in ATLAS is performed to certify that the manufacturing process and the detector technology are adequate to deliver the performance requirements for the ATLAS upgrade. Measurements of sTGC spatial resolution using cosmic rays and in a test-beam setup are presented. The cosmic-ray measurements are performed in-situ using novel techniques to correct for detector planes misalignments and detector effects. A certification procedure for the quality control of sTGC modules was developed. Results of the procedure with a sTGC prototype are shown as a proof of concept.</description><creator>Lefebvre, Benoit</creator><contributor>Brigitte Vachon (Supervisor)</contributor><date>2019</date><subject>Physics</subject><title>Characterization studies of small-strip thin gap chambers for the ATLAS upgrade</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/b2773x97c.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/5712m9107</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Physics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:bg257h16d</identifier><datestamp>2020-03-21T05:02:13Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Under what conditions does international economic interdependence between liberal states and mercantilist rising powers likely to produce peaceful and cooperative foreign relations? International Relations scholars have been debating whether interdependence leads to peace or conflict between states. It appears that non-liberal rising powers such as China can strengthen their coercive power through interdependent relationships without liberalizing their domestic and foreign policies. The 2018 trade war between China and the U.S. highlights the risks associated with economic interdependence in the contemporary world. This thesis contributes to the understanding of interdependence in international relations by focusing on the intermediate effects of domestic state decentralization. It suggests that under a decentralized state system, subnational governments are more likely to develop self-interested foreign policy preferences and to actively participate in international affairs. In China, some of these local foreign policies have successfully restrained the zero-sum competitive interests of the central state. Chinese coastal provinces—which are more integrated into the world market—are less interested in state-led economic strategies, such as the Belt and Road Initiative.  Seeking foreign capital and technologies, some local governments in China have also established cooperation in carbon emission control with foreign states and pushed the central state for stronger commitment to climate change issues. This dissertation's findings suggest that, if liberal states utilize the opportunities associated with state decentralization in mercantilist rising powers, economic interdependence can possibly lead to cooperative foreign relations in the contemporary world.</description><description>Dans quelles conditions l'interdépendance économique internationale entre les États libéraux et les puissances mercantilistes montantes est-elle plus susceptible de produire des relations étrangères pacifiques et coopératives ? Les spécialistes des relations internationales sont divisés sur les effets de l'interdépendance et si elle entraîne la paix ou des conflits entre États. Il semble que les puissances montantes non libérales telles que la Chine peuvent renforcer leur pouvoir coercitif grâce à des relations interdépendantes sans libéraliser leur politique nationale et étrangère. La guerre commerciale de 2018 entre la Chine et les États-Unis met en lumière les risques associés à l'interdépendance économique dans le monde contemporain. Cette thèse contribue à la compréhension de l'interdépendance dans les relations internationales en mettant l'accent sur les effets intermédiaires de la décentralisation étatique. Elle suggère que dans un système d'État décentralisé, les gouvernements infranationaux sont plus susceptibles de développer des préférences en matière de politique étrangère et de participer activement aux affaires internationales. En Chine, ces politiques étrangères locales limitent avec succès les intérêts concurrentiels à somme nulle de l'État central. Les provinces côtières de la Chine, qui sont plus intégrées au marché mondial, sont moins intéressées par les stratégies économiques dirigées par l'État, telles que l'initiative Belt et Road. À la recherche de capitaux étrangers et de technologies, certains gouvernements locaux en Chine ont également établi une coopération en matière de contrôle des émissions de carbone avec des États étrangers et poussé l'État central à prendre des engagements plus fermes en matière de changement climatique. Les conclusions de cette thèse suggèrent que, si les États libéraux utilisent les opportunités associées à la décentralisation de l'État dans les puissances mercantiles, l'interdépendance économique peut conduire à des relations de coopération dans le monde contemporain.</description><creator>Han, Zhen</creator><contributor>T V Paul (Supervisor)</contributor><date>2019</date><subject>Political Science</subject><title>Interdependence, state decentralization, and international relations: The China case</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/fx719p570.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/bg257h16d</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Political Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:c534fr10m</identifier><datestamp>2020-03-21T05:02:13Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Ireland officially won independence from British colonial rule in 1922, which instigated a series of constitutional debates. The 1922 Free State Constitution was at the heart of the Irish Civil War and gave way in 1937 to the Irish Constitution. Since 1937, there have been thirty-six proposed amendments to the constitution; these amendments touch on social issues, state policies, and the evolving relationship between Ireland and the European Union. As the constitution defines citizenship, each new popular referendum and amendment brings about shifts in the parameters stipulating the reciprocal rights, duties, and obligations between individual citizens and the state. Since the 1970s, Irish citizens have frequently sought constitutional change as a means of negotiating the gulf between the ideals of the state and human experiences that fall outside these ideals. Since the Irish Constitution goes into great detail about areas of the law such as the family, the workplace, and religion, citizenship negotiates a hypothetical social milieu meant to represent the moral fabric of the nation. Irish writers have been integral to imagining these negotiations in various ways since independence. The social milieu outlined by the Irish state in the constitution provides writers with a groundwork on which to contest, and explore alternative versions of, ideal citizenship. Novels and short stories focus on characters who occupy, to varying degrees, the place of the permitted citizen operating within definitions of the ideal citizen. Narrative fiction also offers forms through which to imagine constitutional amendments. Open to interpretation and legal amendment, the constitution lends itself to a variety of narrative techniques. Examining a wide range of novels and two short stories, I argue that narrative fiction since independence has been integral to the social impetus for amendments to the Irish Constitution as they affect definitions of citizenship. Chapter One illustrates how Seán O'Faoláin in "Midsummer Night Madness," Frank O'Connor in "Guests of the Nation," and Elizabeth Bowen in The Last September contest state definitions of belonging at the beginning of Eamon De Valera's program of constitutional reform in the late 1920s and early 1930s. Through readings of Flann O'Brien's At Swim-Two-Birds, Colm Tóibín's The Heather Blazing, and Edna O'Brien's Down by the River, Chapter Two establishes the need for narrative fiction to negotiate the equivalent values of citizens in the face of the limitations of the Supreme Court, despite the interpretive powers exercised by the judiciary after the 1960s. The final two chapters of the dissertation turn to intangible qualities of citizenship. Chapter Three examines Edna O'Brien's The Country Girls, Roddy Doyle's The Woman Who Walked into Doors, and Anne Enright's The Gathering as interrogations of reliable citizenship for Irish women; through acts of unreliability, the women who narrate each novel overcome a status quo of silence in Ireland when it comes to victims of abuse. Chapter Four re-examines the long tradition of emigration narratives through the reorganization of ideals in Kate O'Brien's Mary Lavelle, John McGahern's The Leavetaking, and Colm Tóibín's The Blackwater Lightship. While citizenship creates the category of the noncitizen, in Ireland a further distinction can be made between ideal citizenship and permitted citizenship. Constitutional amendments reflect an ongoing negotiation of equivalent values amongst Irish citizens as they reframe the ideals of belonging in the nation—a negotiation in which narrative fiction plays an imaginative role.</description><description>L'Irlande obtint officiellement son indépendance de la domination coloniale britannique en 1922, évènement qui provoqua une série de débats constitutionnels. La Constitution de l'État libre de 1922 fut au cœur de la guerre civile irlandaise et céda la place en 1937 à la Constitution irlandaise. Depuis 1937, il y a eu trente-six amendements proposés à la Constitution; ces amendements touchent aux questions sociales, aux politiques d'État et à l'évolution des relations entre l'Irlande et l'Union européenne. Comme la Constitution définit la citoyenneté, chaque nouveau référendum populaire et chaque amendement apporte des changements dans les paramètres stipulant les droits, les devoirs et les obligations réciproques entre les citoyens et l'État. Depuis les années 1970, les citoyens irlandais se sont fréquemment tournés vers le changement constitutionnel pour négocier le fossé entre les idéaux de l'État et leurs propres expériences qui échappent à ces idéaux. Puisque la Constitution irlandaise aborde en détail les domaines du droit tels que la famille, le lieu de travail et la religion, la citoyenneté négocie un milieu social hypothétique qui est destiné à représenter le tissu moral de la nation. Les écrivains irlandais ont promulgué une imagination diversifiée de ces négociations depuis l'indépendance. Le milieu social décrit par l'État irlandais dans la Constitution fournit aux écrivains une base sur laquelle se fonder afin de contester et d'explorer des versions alternatives de la citoyenneté idéale. Les romans et les nouvelles se concentrent sur des personnages qui occupent, à divers degrés, la place du citoyen autorisé selon les définitions du citoyen idéal. La fiction narrative offre également une structure permettant d'imaginer des amendements constitutionnels. Ouvert à l'interprétation et à la modification légale, la Constitution se prête à une variété de techniques narratives. En examinant une large gamme de romans ainsi que deux nouvelles, je propose que la fiction narrative depuis l'indépendance a participé de façon importante à l'élan social quant aux amendements à la Constitution irlandaise qui affectent les définitions de la citoyenneté. Le premier chapitre illustre comment Seán O'Faoláin dans «Midsummer Night Madness», Frank O'Connor dans «Guests of the Nation» et Elizabeth Bowen dans The Last September contestent les définitions d'appartenance de l'État tels que spécifiées au début du programme de réforme constitutionnelle d'Eamon De Valera à la fin des années 1920 et au début des années 1930. En lisant At Swim-Two-Birds de Flann O'Brien, The Heather Blazing de Colm Tóibín et Down by the River d'Edna O'Brien, le chapitre deux établit le rôle de la fiction narrative face aux limites de la Cour suprême, malgré les pouvoirs d'interprétation exercés par le pouvoir judiciaire après les années 1960. Les deux derniers chapitres de la dissertation se tournent vers les qualités intangibles de la citoyenneté. Le chapitre trois examine The Country Girls d'Edna O'Brien, The Woman Who Walked into Doors de Roddy Doyle et The Gathering d'Anne Enright en tant qu'interrogations de citoyenneté fiable pour les femmes irlandaises; par des actes de non-fiabilité, les femmes qui racontent chaque roman surmontent un statu quo de silence en Irlande dans le cadre de victimes d'abus. Le chapitre quatre réexamine la longue tradition des récits d'émigration à travers la réorganisation des idéaux dans Mary Lavelle de Kate O'Brien, The Leavetaking de John McGahern et The Blackwater Lightship de Colm Tóibín. Alors que la citoyenneté crée naturellement la catégorie des non-citoyens, en Irlande, une distinction additionnelle peut être faite entre la citoyenneté idéale et la citoyenneté permise. Les amendements constitutionnels reflètent une négociation continue de valeurs équivalentes entre les citoyens irlandais qui recadrent les idéaux d'appartenance à la nation—une négociation dans laquelle la fiction narrative joue un rôle imaginatif.</description><creator>Harkin, Keelan</creator><contributor>William Allan Hepburn (Supervisor)</contributor><date>2019</date><subject>English</subject><title>Imagining constitutions: Citizenship and narrative form in Irish literature since independence</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/fj236438z.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/c534fr10m</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of English</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:fx719p588</identifier><datestamp>2020-03-21T05:02:14Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>In recent decades, there has been immense progress in DNA sequencing technologies. One domain where these techniques are undoubtedly transformative is medicine. Understanding the underlying genomic and genetic factors in diseases is important in diagnosis, treatment, and identification of at-risk family members. In this regard, cancer genome analysis provides a better understanding of the underlying tumorigenic mechanisms and gives hope of finding genetic events that contribute to metastasis, recurrence, and therapeutic resistance, which are the most common causes of cancer fatality. In the first part of this thesis, we focus on uncovering the genetic predisposition factors in familial pancreatic cancer. By applying whole exome sequencing (WES) to 109 familial pancreatic cases and performing a filter-based candidate gene approach focused on DNA repair genes, we propose FAN1, NEK1 and RHNO1 as the strongest candidates.  In the second part, we investigate the mechanisms underlying resistance to chemotherapy in Triple-negative breast cancer (TNBC). WES- and RNA-seq analysis on serial tumor biopsies during chemotherapy suggests that there are two major factors associated with chemotherapy: RAD21 gene amplification and presence of immune response. The results of this study suggest that RAD21 may be both a marker and a target to overcome drug resistance in TNBCs, and combination of chemotherapy and immunotherapy (anti-PD-1/PD-L1 monoclonal antibody therapies) would improve outcomes of TNBC patients, especially PD-L1-positive patients with low tumor-infiltrating lymphocytes (TILs) in tumors.Furthermore, motivated by accurately identifying pathogenic variants from WES data, I developed an improved ensemble machine learning method, ClinPred, to predict in silico and select pathogenic variants in large-scale sequencing studies.  Through rigorous testing, while avoiding problems common in machine learning, such as overfitting and circularity, I showed that ClinPred outperforms all currently available prediction methods, achieving the highest Area Under the Curve (AUC) score and increasing both the specificity and sensitivity in different test datasets. It also obtained the best performance according to various other metrics. Together, our work demonstrates the value of next generation sequencing techniques as powerful tools for understanding the mechanisms of various diseases and their subsequent implications for the clinical arena.</description><description>Au cours des dernières décennies, d'immenses progrès ont été réalisés dans les technologies de séquençage de l'ADN. Un domaine où ces techniques sont sans aucun doute transformatrices est la médecine. Comprendre les facteurs génomiques et génétiques sous-jacents des maladies est important dans le diagnostic, le traitement et l'identification des membres de la famille du patient à risque. À cet égard, l'analyse de la génomique du cancer permet une meilleure compréhension des mécanismes tumorigéniques sous-jacents et nous donne espoir de trouver les événements génétiques qui mènent aux métastases, à la réapparition du cancer et à la résistance aux traitements thérapeutiques, qui sont les causes les plus fréquentes de décès par le cancer. Dans la première partie de cette thèse, nous nous concentrons sur la découverte des facteurs de prédisposition génétique au niveau du cancer du pancréas familial. En appliquant le séquençage de l'exome entier (WES) à 109 cas pancréatiques familiaux et en utilisant une approche, qui filtre les résultats du séquençage, basée sur des gènes candidats de la réparation de l'ADN, nous proposons FAN1, NEK1 et RHNO1 comme étant les candidats les plus forts. Dans la deuxième partie, nous étudions les mécanismes sous-jacents à la résistance à la chimiothérapie du cancer du sein triple négatif. L'analyse du séquençage de l'exome entier et séquençage haut débit d'ARN des biopsies sur la tumeur lors de plusieurs étapes de la chimiothérapie, suggère qu'il y a deux facteurs majeurs associés à la chimiothérapie : l'amplification du gène RAD21 et la présence d'une réponse immunitaire. Les résultats de cette étude suggèrent que RAD21 pourrait être à la fois un indicateur et une cible pour vaincre la pharmacorésistance du cancer du sein triple négatif, et qu'une combinaison de chimiothérapie et d'immunothérapie (anti-PD-1 / PD-L1) améliorerait les résultats des patients atteints du cancer du sein triple négatif, en particulier les patients atteints de tumeurs PD-L1-positifs / faibles enTILs.De plus, motivée par l'identification précise des variantes pathogènes obtenus à partir des données du séquençage de l'exome entier, j'ai développé une méthode d'apprentissage automatique d'ensemble améliorée, ClinPred, pour prédire in silico et sélectionner des variantes pathogènes dans des études de séquençage à grande échelle. Grâce à des tests rigoureux dans lesquels sont évités les problèmes communs en apprentissage automatique, comme le surapprentissage ou la circularité, j'ai démontré que ClinPred surpasse toutes les méthodes de prédiction actuellement disponibles, en obtenant le score le plus élevé pour la superficie sous la courbe et en ayant plus de spécificité et  sensibilité lors de différentes analyses. ClinPred a obtenu les meilleures performances en fonction de divers autres indicateurs.Ensemble, nos travaux démontrent la valeur des techniques de séquençage de nouvelle génération en tant qu'outils puissants pour comprendre les mécanismes de diverses maladies et leurs implications subséquentes pour l'arène clinique.</description><creator>Alirezaie, Najmeh</creator><contributor>Jacek Majewski (Supervisor)</contributor><date>2019</date><subject>Human Genetics</subject><title>Next generation sequencing in medicine</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/z316q376p.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/fx719p588</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Human Genetics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:rx913s15k</identifier><datestamp>2020-03-21T05:02:15Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Ice is known to form on numerous structures and surfaces. Whether it is on an airplane wing or the blades of a wind turbine, icing is an issue that needs to be dealt with as it interferes with airfoil performance and is costly to remove. One approach to overcome icing is to coat the surfaces with an icephobic layer. Intuitively, one would be inclined to think that any hydrophobic material will suffice. However, E. Ling showed that hydrophobic surfaces are not necessarily icephobic [1]. This conclusion was used as the foundation of this research. Using diblock copolymers, a specific class of polymers composed of two segments of different polymers covalently joined together, the aim was to synthesize an amphiphilic material that would serve as the coating. The blocks chosen were 2,2,2-trifluoroethyl methacrylate (TFEMA) and oligo(ethylene glycol) methyl ether methacrylate (OEGMA) and were synthesized by nitroxide-mediated radical polymerization (NMP). Gel permeation chromatography (GPC) and 1H nuclear magnetic resonance (NMR) were used to monitor chain growth, dispersity, and conversion. The copolymer was successfully synthesized and spincoated on a 1" x 1.45" stainless steel 304 (SS304) substrate at different concentrations in toluene. Nanoindentation was then used to measure layer thickness and study the moduli of elasticity of the different samples. Ice adhesion testing was done on samples coated with TFEMA, and on samples coated with the copolymer. In addition, uncoated samples were tested for reference. TFEMA samples showed little change in adhesion force with increasing concentration, whereas samples coated with the diblock were able to decrease the average adhesion force with increasing concentration. Overall, TFEMA samples showed a 42% adhesion force decrease relative to SS304, whereas the copolymer showed a 57% decrease. This makes the final product a good starting point for future research on icephobic coatings.</description><description>La glace est connue pour sa formation sur divers surfaces et structures. Que ce soit sur une aile d'avion ou sur les pales d'une éolienne, le givrage est un problème qui doit être traité car il gêne les performances de la surface portante et est coûteux à enlever. Une approche pour surmonter le givrage consiste à recouvrir les surfaces d'une couche glacephobique. Intuitivement, on serait enclin à penser que n'importe quel matériau hydrophobe suffira. Cependant, E. Ling a montré que les surfaces hydrophobes ne sont pas nécessairement glacephobique [1]. Cette conclusion a été utilisée comme fondement de cette recherche. En utilisant des copolymères diblocs, une classe spécifique de polymères composés de deux segments de polymères différents liés par covalence, l'objectif était de synthétiser un matériau amphiphile qui servirait de revêtement. Les blocs choisis étaient le méthacrylate de 2,2,2-trifluoroéthyle (TFEMA) et le méthacrylate d'éther méthylique d'oligo (éthylène glycol) (OEGMA) et ont été synthétisés par polymérisation radicalaire à médiation par un nitroxyde (NMP). La chromatographie par perméation de gel (CPG) et la résonance magnétique nucléaire (RMN) 1H ont été utilisées pour surveiller la croissance, la dispersité et la conversion de la chaîne. Le copolymère a été synthétisé et spincé avec succès sur un substrat en acier inoxydable 304 (SS304) de 1" x 1,45" à différentes concentrations en toluène. La nanoindentation a ensuite été utilisée pour mesurer l'épaisseur de la couche et étudier les modules d'élasticité des différents échantillons. Des tests d'adhérence sur glace ont été effectués sur des échantillons revêtus de TFEMA et sur des échantillons revêtus du copolymère. De plus, les échantillons non revêtus ont été testés pour référence. Les échantillons de TFEMA ont montré peu de modification de la force d'adhérence avec une concentration croissante, alors que les échantillons revêtus du dibloc étaient capables de diminuer la force d'adhésion moyenne avec une concentration croissante. Dans l'ensemble, les échantillons de TFEMA ont présenté une diminution de la force d'adhérence de 42% par rapport au SS304, tandis que le copolymère présentait une diminution de 57%. Cela fait du produit final un bon point de départ pour des recherches futures sur les revêtements glace phobiques.</description><creator>Zalouk, Marwan</creator><contributor>Milan Maric (Internal/Cosupervisor2)</contributor><contributor>Phillip Servio (Internal/Supervisor)</contributor><date>2019</date><subject>Chemical Engineering</subject><title>Ice adhesion on amphiphilic methacrylate copolymer surfaces</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/qj72p945g.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/rx913s15k</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Chemical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:0z709011q</identifier><datestamp>2020-03-21T05:02:16Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>In the pursuit of increasingly intelligent learning systems, abstraction plays a vital role in enabling sophisticated decisions to be made in complex environments. The options framework provides formalism for such abstraction over sequences of decisions in the context of reinforcement learning. Most prior work on abstraction in reinforcement learning requires that options be given a priori, presumably specified by hand, which is neither efficient, nor scalable, and can lead to suboptimal behaviour. Indeed, it is preferable to learn options directly from interaction with the environment. Despite several efforts, this remains a difficult problem.In this thesis, we tackle this problem by developing a novel policy gradient method for the automatic learning of policies with options. While employing behaviours that follow a hierarchical policy, during learning this algorithm employs inference, rather than explicit memory in order to represent its own behaviour. This allows for simultaneous improvement of all options available to an agent. We develop both online and trajectory-based versions of the algorithm. Furthermore, the algorithm can be employed in an off-policy manner, without observing option labels. The differentiable inference procedure employed yields options that can be easily interpreted. Empirical results confirm these attributes, and indicate that our algorithm has an improved sample efficiency relative to state-of-the-art in learning options end-to-end.</description><description>Dans le cadre de systèmes d'apprentissage de plus en plus intelligents, l'abstraction fait un rôle essentiel dans la prise de décisions complexes dans des environnements complexes. Le cadre des options fournit un formalisme pour abstraction sur séquences de décisions dans le contexte de l'apprentissage par renforcement. La plupart des travaux antérieurs sur l'abstraction dans l'apprentissage par renforcement exigent que les options soient données a priori, probablement spécifiées à la main, ce qui n'est ni efficace ni évolutif et peut conduire à un comportement sous-optimal. En effet, il est préférable d'apprendre des options directement à partir de l'interaction avec l'environnement. Malgré plusieurs efforts, cela reste un problème difficile.Dans cette thèse, nous nous attaquons à ce problème en développant une nouvelle méthode de gradient de politique pour l'apprentissage automatique de politiques avec des options. Tout en employant des comportements qui suivent une politique hiérarchique, cet algorithme utilise, lors de l'apprentissage, l'inférence plutôt que la mémoire explicite pour représenter son propre comportement. Cela permet d'améliorer simultanément toutes les options disponibles pour un agent. Nous développons des versions en ligne et basées sur la trajectoire de l'algorithme. De plus, l'algorithme peut être utilisé de manière non réglementaire, sans observer les étiquettes d'option. La procédure d'inférence différenciable employée donne des options faciles à interpréter. Les résultats empiriques confirment ces attributs et indiquent que notre algorithme a une efficacité d'échantillon améliorée par rapport aux options d'apprentissage de pointe de bout en bout.</description><creator>Smith, Matthew</creator><contributor>Joelle Pineau (Internal/Supervisor)</contributor><date>2019</date><subject>Computer Science</subject><title>Learning options through inference-based policy gradients</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/nz806220b.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/0z709011q</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><resumptionToken completeListSize="47894">oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):3500</resumptionToken></ListRecords></OAI-PMH>