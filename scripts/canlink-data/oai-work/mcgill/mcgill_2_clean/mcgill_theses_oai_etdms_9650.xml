<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/assets/blacklight_oai_provider/oai2-b0e501cadd287c203b27cfd4f4e2d266048ec6ca2151d595f4c1495108e36b88.xsl"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd"><responseDate>2020-07-24T23:27:19Z</responseDate><request resumptionToken="oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):9650" verb="ListRecords">https://escholarship.mcgill.ca/catalog/oai</request><ListRecords><record><header><identifier>oai:escholarship.mcgill.ca:5t34sn36z</identifier><datestamp>2020-03-21T17:17:44Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Cette étude examine la relation entre les stratégies d'adaptation, l'identité culturelle et la consommation de drogues et d'alcool chez les jeunes des Premières Nations. Quatre-vingt sept étudiants provenant de deux écoles dans deux communautés distinctes des Premières Nations au Québec, Canada ont participé à cette étude. Les résultats démontrent que l'adoption de comportements ethniques, une composante de l'identité culturelle, peut protéger contre la consommation de drogues et d'alcool. D'autre part, les participants qui s' identifient à la culture blanche et qui utilisent le désengagement comportemental comme stratégie d'adaptation sont les plus susceptibles à consommer ces stupéfiants. Les résultats de cette étude soutiennent la notion que l'identité culturelle joue un rôle important dans la protection des jeunes des Premières Nations contre la consommation de drogues et d'alcool. Les interventions qui mettent en valeur les moyens de développer l'identité culturelle chez les jeunes des Premières Nations seront peut être plus efficaces à prévenir la consommation de drogues et d'alcool comparé à celles qui promeuvent la transmission de stratégies d'adaptation positives.</description><description>The following research will examine the relationship between coping strategies, cultural identity and substance use in First Nations youth.  The participants include 87 students from two schools in two separate First Nations communities in Quebec, Canada. Self-report ratings of cultural identity, coping strategies and substance use were obtained. Engaging in ethnic behaviors, a component of cultural identity, was found to protect against substance use. On the other hand, participants who identified with mainstream culture and who used behavioral disengagement as a coping strategy were most likely to engage in substance use.  The results from this study support the notion of cultural identity as a protective factor by suggesting that cultural identity plays an important part in protecting First Nations youth against substance use.  Interventions aiming to reduce or eliminate substance use may be more effective when focusing on ways of developing cultural identity in First Nations youth as opposed to focusing on the transmission of positive coping strategies.</description><creator>Blacklock, Adrienne</creator><contributor>Jacob A Burack (Internal/Supervisor)</contributor><date>2015</date><subject>Education - Psychology</subject><title>The role of coping and cultural identity in protecting First Nations youth against substance use</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/2n49t515t.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/5t34sn36z</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of Educational and Counselling Psychology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:v692t938d</identifier><datestamp>2020-03-21T17:17:45Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>This dissertation takes as its subject the complete corpus of Venetian-language polyphony printed in Italy during the 1560s and ‘70s, investigating issues of language and genre, ethnic and transnational identity, musical and literary parody, and the relationship of written music to extemporaneous performance.Chapter 1 examines a number of issues relating to dialect music in Renaissance Italy, and through Charles Ferguson's concept of linguistic triglossia and Benedetto Croce's concept of letteratura dialettale riflessa, which provide an overarching theoretical framework. Questions posed and addressed in this chapter include: what is the Venetian language, and how does it relate structurally and sociologically to contemporary linguistic systems? What is the relationship between language, dialect, and musical genre in Italian music prints?Chapter 2 seeks to individuate the key elements that set Venetian-language works apart from those in other dialects. Compositions for four or more voices are shown to occupy a cultural and musical space more closely approximating that of the madrigal than do other dialect works, as befitting the special status of the language in Venice. Questions posed and addressed in this chapter include: How are the giustiniane of the 1570s related to the late fifteenth-century genre of the same name? What are the musically defined subgenres of Venetian-language polyphony, and how do they reflect upon corresponding subgenres of the madrigal? How are Venetian works registrally and technically distinct from other dialect works by the same composers? How is compositional craft used as a signifier of the collocation of Venetian in an intermediate cultural space?Chapter 3 examines the musical legacy of the Venetian poet Andrea Calmo, whose stage performances and verse publications inspired two anthologies of three-voice giustiniane and the first collection of four-voice works published by Lodovico Agostini. Questions posed and addressed in this chapter include: How did poets and composers negotiate the conversion of text and music in the high style into dialect genres? How were such dialect parodies situated within the broader tradition of improvised recitation and performance in both theatrical and informal contexts?Chapter 4 examines the musical legacy of Calmo's frequent associate Antonio Molino, whose stage performances and verse publications inspired the so-called greghesche: polyphonic songs that employed the Venetian language as spoken by ethnic Greeks. Multiple lines of evidence tie the composition and performance of these works to the salon of the patrician Domenico Venier. Questions posed and addressed in this chapter include: why are two of the five surviving polyphonic laments for Adrian Willaert included in a collection of dialect music? Who are the two female singers frequently referenced in the 1564 primo libro? How does Molino's own first book of madrigals, published four years later, serve to situate the earlier anthology within the tradition of informal improvisation?Finally, the conclusion of this dissertation reflects on the many recurring threads that have a resonance beyond the particular corpus on which it is focused. These are connected to recent developments in the critical framework of multimodality, and may help to provide a way forward in the analysis of other repertoires that present similar questions to the scholarly investigator.</description><description>Cette dissertation a pour sujet le corpus complet d'oeuvres polyphoniques en langue vénitienne imprimées en Italie durant les années 1560 et 1570, s'intéressant à des questions de langue et de genre, d'identités ethniques et transnationales, de parodie musicale et littéraire, ainsi qu'aux liens existant entre la musique écrite et la performance improvisée.Le chapitre 1 examine un certain nombre d'enjeux en lien avec la musique en dialecte de la Renaissance italienne, et par le biais du concept linguistique triglossia énoncé par Charles Ferguson et du concept de letteratura dialettale riflessa de Benedetto Croce, qui fournissent les fondements théoriques généraux. Les questions posées et abordées dans ce chapitre incluent : quelle est la langue vénitienne, et comment est-elle liée structurellement et sociologiquement aux systèmes linguistiques contemporains? Quelle est la relation entre langage, dialecte, et genre musical dans les éditions musicales italiennes?Le chapitre 2 cherche à différencier les éléments-clés distinguant les oeuvres en langue vénitienne de celles écrites en d'autres dialectes. Il a été établi que les compositions pour quatre voix ou plus occupent un espace culturel et musical plus proche de celui du madrigal que celles écrites en d'autres dialectes, conformément au statut spécial de cette langue à Venise. Les questions posées et abordées dans ce chapitre incluent: en quoi les giustiniane des années 1570 sont-elles reliées au genre du même nom datant de la fin du 15e siècle? Quels sont les sous-genres musicalement définis de la polyphonie en langue vénitienne, et comment reflètent-ils les sous-genres correspondants pour le madrigal? Comment les oeuvres vénitiennes sont-elles, au plan technique et du registre, distinctes des autres oeuvres en dialecte par les même compositeurs? Comment les habiletés compositionnelles sont-elles employées en tant que signe de la collocation du vénitien dans un espace culturel intermédiaire?Le chapitre 3 examine l'héritage musical du poète vénitien Andrea Calmo, dont les performances scéniques et les publications en vers ont inspirées deux anthologies de giustiniane à trois voix, et le premier recueil d'oeuvres à quatre voix publié par Lodovico Agostini. Les questions posées et abordées dans ce chapitre incluent : comment les poètes et compositeurs ont-ils négocié la conversion du texte et la musique de style élevé vers un genre en dialecte? Comment ces parodies avec dialectes se situent-elles à l'intérieur d'une tradition plus large de récitations improvisées et de performances dans des contextes théatral et informel?Le chapitre 4 examine l'héritage musical de l'associé habituel de Calmo, Antonio Molino, dont les performances scéniques et les publications en vers ont inspirées les soi-disant greghesche : des chansons polyphoniques employant la langue vénitienne telle que parlée par les grecs. De multiples sources mettent en lien la composition et la performance de ces oeuvres avec le salon du patricien Domenico Venier. Les questions posées et abordées dans ce chapitre incluent : pourquoi deux des cinq lamentations polyphoniques pour Adrian Willaert figurant-elles dans une collection de musique en dialecte? Qui sont ces deux chanteuses dont le primo libro fait mention? En quoi le propre premier livre de madrigaux de Molino, publié quatre ans plus tard, sert-il à situer cette anthologie précédente au sein de cette tradition d'improvisations informelles?Finalement, la conclusion de cette dissertation rassemble plusieurs des fils conducteurs récurrents ayant eu une résonnance au-delà du corpus particulier sur laquelle elle se concentre. Ceux-ci sont en lien avec les développements récents dans le cadre critique de la multi-modalité, et pourraient aider à faire progresser l'analyse de d'autres répertoires présentant au chercheur érudit des questions similaires.</description><creator>Donnelly, Daniel</creator><contributor>Schubert, Peter N. (Supervisor2)</contributor><contributor>Cumming, Julie E. (Supervisor1)</contributor><date>2015</date><subject>Communications And The Arts - Music</subject><title>Cantar à la Venessiana: Venetian-language polyphony in the secondo cinquecento</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/m039k822s.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/v692t938d</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Schulich School of Music</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:ng451m74d</identifier><datestamp>2020-03-21T17:17:46Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Recherche sur le savoir et la production numérique dans les communautés de l'innovation en est encore à ses premiers stades. La recherche la plus soutenue a mis l'accent sur le développement de logiciels libres et open-source qui devinent un concurrent sérieux pour les logiciels propriétaires. Le système d'exploitation Linux, le serveur Web Apache et le navigateur Firefox sont tous des produits open-source qui ont obtenu un grand succès commercial contre leurs concurrents propriétaires. Il a été avancé que le logiciel open-source combine des aspects de l'investissement privé et des modèles de production d'action commune. Cette nouvelle combinaison nécessite des révisions fondamentales aux théories de l'innovation. Avec l'objectif d'obtenir une meilleure compréhension de l'innovation ouverte dans la domaine de soins de santé informatique, cette recherche se concentre sur la façon dont les communautés d'innovation en ligne créent, partagent et évoluent des artefacts de connaissance.Plus précisément, j'explore le développement, l'évolution et la création de connaissances dans une communauté de l'innovation centrée sur un dossier médical informatisé open-source nommé OSCAR. Cette communauté est canadienne, a été en existence depuis une décennie, et a développé un dossier médical informatisé qui a diffusé rapidement (actuellement utilisé par plus de 1500 médecins canadiens suivant plus d'un million de patients). OSCAR est disponible gratuitement comme un logiciel open-source et a gagné des parts de marché contre des produits commerciaux coûte généralement $25000 par an. Ce succès est inhabituel et significatif. Contrairement à d'autres projets open-source, ce logiciel est intégré dans une communauté de médecins plutôt que d'une communauté de programmeurs. La communauté est active à la fois face à face par des réunions d'utilisateurs et en ligne par l'intermédiaire de forums de discussion.En se concentrant sur la création du logiciel et  l'évolution de connaissance, je prends sur trois études connexes de cette communauté d'innovation pour répondre aux questions de recherche suivantes: (1) Qu'est ce qui détermine les contributions des membres de la communauté? (2) Comment peut la communauté intégrer les contributions individuelles dans l'artefact numérique? (3) Comment peut la communauté se grandir, s'évoluer et maintenir sa structure de collaboration? Ces études contribuent théoriquement en explorant les échanges de connaissances et de la dynamique de l'innovation dans une communauté d'innovation qui implique divers groupes de participants (par exemple, des médecins, des programmeurs, des infirmières, des administrateurs). Ils aideront aussi à faire la lumière sur une classe importante de communautés de l'innovation, celle où le Canada est un leader et où les résultats de l'innovation aident informatiser les soins de santé au Canada.</description><description>Research on knowledge and digital production in Communities of Innovation is still in its early stages. The most sustained research has focused on open-source software development as it has emerged as a serious competitor to the traditional proprietary software. The Linux operating system, the Apache web server, and the Firefox browser are all successful open-source products that achieved wide commercial success over their proprietary competitors. It has been argued that open-source software combines aspects of private investment and common action production models. This new combination requires fundamental revisions to theories of innovation. With the objective of gaining a deeper understanding of open innovation in healthcare, this research focuses on how online communities focused on innovation create, share, and evolve knowledge artifacts.Specifically, I explore the development, evolution, and knowledge creation in a community of innovation centered on an open-source Electronic Medical Record (EMR) named OSCAR. This community is primarily Canadian, has been in existence for a decade, and has developed an EMR that is rapidly diffusing (currently used by over 1,500 Canadian doctors to follow over a million patients). The OSCAR EMR is freely available open-source software and is gaining market share against commercial products typically costing $25,000 per year. Given the complexity of such software, the mission-critical nature of patient records for solving Canadian and world health issues, and the fact that the vast majority of users (family doctors) are not computer savvy, this success is unusual and significant. Contrary to other open-source projects, this software is embedded in a community of doctors rather than a community of programmers. The community is active both face to face via user meetings and online via discussion forums.Focusing on knowledge creation and software evolution, I take on three interrelated studies of this healthcare community of innovation to answer the following research questions: (1) What determines individual members' contributions in the community? (2) How does the community integrate individual contributions into the digital artifact? (3) How does the community grow and evolve overtime creating and sustaining its collaborative structure? Taken together, the studies contribute theoretically by exploring the knowledge exchanges and innovation dynamics in a community of innovation that involves diverse groups of participants (e.g., doctors, programmers, nurses, administrators). They will also help shed light on an important class of innovation communities, one where Canada is a leader and where the innovation outcomes are helping computerize healthcare in Canada.</description><creator>Safadi, Hani</creator><contributor>Samer Faraj (Supervisor)</contributor><date>2015</date><subject>Business Administration - General</subject><title>Knowledge creation in health IT online communities</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/pv63g3128.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/ng451m74d</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Desautels Faculty of Management</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:hh63sz990</identifier><datestamp>2020-03-21T17:17:47Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Over the past decade, genomic technologies have promised to revolutionize breast cancer research with better predictions of disease progression and patient prognosis through the identification of novel molecular targets. These technologies have led to the discovery of numerous different genomic subtyping schemes, each purported to offer relevant information beyond traditional clinical features. Yet it remains unclear what these schemes have contributed to our understanding of breast cancer biology and the reasons for disease recurrence. To address this issue, we have built a novel framework termed Breast Signature Analysis Tool (BreSAT), along with a companion collection of breast cancer datasets, highly annotated signatures, statistics, and visualizations, designed for accurate and ease-of-use application in breast cancer. This framework represents a new way of cataloguing tumors according to their biological properties, as opposed to broad gene expression profiles. We have applied BreSAT and its associated catalogue of signatures to thousands of breast tumor samples, and identify that tumor properties associated with recurrence are confounded by association with other clinicopathological variables such as estrogen receptor status and the genomic subtype. In addition to identifying properties associated with recurrence in breast cancer, we have sought to discover the molecular markers that drive different tumor phenotypes. We identified that expression of the oncogene MET in mouse mammary glands leads to the generation of tumors with characteristics of human triple-negative breast cancer. Additionally, synergy between MET and loss of p53 in similar mouse model leads the development of tumors a claudin-low phenotype, that arise with a higher penetrance and lower latency. Moreover, MET activity is required for maintenance of the claudin-low morphological phenotype and metastatic capacity of cell lines, suggesting that MET may represent an avenue for targeted therapeutics in human patients with claudin-low breast tumors.  Finally, we have discovered that molecular features of breast cancer progression from a non-invasive to an invasive state are confounded by tumor subtype. To find more accurate markers of disease progression, we identified tumor properties that differentiate non-invasive tumors from invasive ones within each subtype. We observed that there is little overlap, suggesting that distinct properties drive tumor progression in different subtypes. Furthermore, we were able to identify a small number of non-invasive breast tumors with molecular features that make them more likely to progress. Together, these discoveries are leading to a more comprehensive understanding of the molecular features that drive breast cancer biology, disease progression, and patient outcome.</description><description>Au cours de la dernière décennie, les technologies génomiques ont promis de révolutionner la recherche sur le cancer du sein, avec de meilleures prévisions de progression de la maladie et le pronostic du patient, grâce à l'identification de nouvelles cibles moléculaires. Ces technologies ont conduit à la découverte de nombreux différents systèmes de sous-typage génomique, chaque censé fournir les informations pertinentes au-delà des caractéristiques cliniques traditionnels. Pourtant, on ne sait pas ce que ces programmes ont contribué à notre compréhension de la biologie du cancer du sein et les raisons de récidive de la maladie.Pour résoudre ce problème, nous avons construit un cadre nouveau appelé Breast Signature Analysis Tool (BreSAT), avec une collection d'ensemble de données sur le cancer du sein, des signatures annotés, des statistiques et des visualisations, conçu pour l'application et d'utilisation dans le cancer du sein. Ce cadre représente un nouveau mode de catalogage des tumeurs en fonction de leurs propriétés biologiques, par opposition à des profils d'expression génique larges. Nous avons appliqué BreSAT et notre catalogue de signatures à des milliers d'échantillons de tumeurs du sein, et d'identifier que les propriétés tumorales associés à la récidive sont confondus par l'association avec d'autres variables clinico-pathologiques tels que le statut de récepteur d'oestrogène et le sous-type génomique.En plus d'identifier les propriétés associées à une récidive du cancer du sein, nous avons cherché à découvrir les marqueurs moléculaires qui conduisent phénotypes tumoraux différents. Nous avons déterminé que l'expression de l'oncogène MET dans les glandes mammaires de souris conduit à la génération de tumeurs avec des caractéristiques du cancer du sein humaine triple négatif. De plus, la synergie entre MET et la perte de p53 dans un modèle de souris similaire conduit le développement de tumeurs avec un phénotype de claudine-bas, qui se posent avec une pénétrance élevée et une latence plus faible. En outre, l'activité MET est nécessaire pour le maintien du phénotype morphologique claudine-bas et la capacité métastatique de lignées cellulaires, suggérant que ce statut peut représenter une avenue pour les thérapies ciblées chez des patients humains atteints de tumeurs mammaires claudine-bas.Enfin, nous avons découvert que les caractéristiques moléculaires de la progression du cancer du sein à partir d'un non-invasive d'un état invasive sont brouillées par le sous-type de tumeur. Pour trouver des marqueurs plus précis de la progression de la maladie, nous avons identifié des propriétés tumorales qui différencient des tumeurs non invasives de ceux envahissantes au sein de chaque sous-type. Nous avons observé qu'il ya peu de chevauchement, ce qui suggère que des propriétés distinctes voiture progression tumorale chez les différents sous-types. En outre, nous avons pu identifier un petit nombre de tumeurs du sein non invasif avec des caractéristiques moléculaires qui les rendent plus susceptibles d'évoluer. Ensemble, ces découvertes mènent à une compréhension plus complète des caractéristiques moléculaires qui conduisent la biologie du cancer du sein, la progression de la maladie, et les résultats des patients.</description><creator>Lesurf, Robert</creator><contributor>Michael Trevor Hallett (Supervisor)</contributor><date>2015</date><subject>Health Sciences - General</subject><title>Stratified informatics analysis for breast cancer: types, subtypes, and models of the disease</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/6395wb53m.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/hh63sz990</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Biochemistry</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:9880vt91d</identifier><datestamp>2020-03-21T17:17:48Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>This thesis focuses on the design of a low power ultra wideband (UWB) transceiver and a low power sensor interface architecture, both for use in wireless sensor networks.Pulse-based UWB radios communicate using short broadband pulses, which allow the transceiver to be duty cycled such that power is only consumed when a pulse is being transmitted or received.  This enables increased power savings when compared to traditional narrowband transceivers.  The receiver designed here is based on peak detection, and it is shown that this type of non-coherent receiver can perform better than a more complex energy detection receiver in interference dominated environments (such as urban areas) in both an additive white Gaussian noise channel, and a multipath environment.The fabricated UWB receiver uses a clock and data recovery system to synchronize the local receiver clock to the transmitted data to reduce synchronization time and enable more efficient communications for sensor networks, which typically have a small data payload.  By moving the synchronization to the analog domain, the size and power consumption of the digital backend is reduced significantly when compared to other receiver architectures.  The clock and data recovery synchronization scheme also provides real time tracking of any variations in the transmitted data rate and the receiver clock, which minimizes the need for a high precision crystal reference in either system.  The fabricated UWB transmitter is implemented by exciting a pulse shaping filter with a broadband pulse, and the resulting signal conforms to the FCC spectral mask including the GPS stopband.  The demonstrated transceiver system achieves a sensitivity of -66.5 dBm with a power consumption of ~400 μW at a 1 Mbps data rate, making it suitable for wireless sensor networks and other low power, low data rate systems.An architecture for an energy efficient sensor interface for frequency domain sensors is also presented.  The proposed system produces a digital output with inherent temperature compensation without the need for a high accuracy temperature sensor, a heater, or a temperature insensitive clock.  This architecture is targeted towards systems where the emphasis is placed on battery longevity as opposed to high resolution sensing, such as in wireless sensor nodes.</description><description>Cette thèse porte sur la conception d'un émetteur-récepteur faible puissance à bande ultra large (UWB) et d'une architecture d'interface de capteur faible puissance, pour une utilisation dans les réseaux de capteurs sans fil.Les émetteurs-récepteurs UWB à impulsion communiquent à l'aide de courtes impulsions à large bande, qui permettent à l'émetteur-récepteur d'être activé et désactivé de façon à ce que l'énergie soit consommée seulement lorsqu'une impulsion est transmise ou reçue. Cela permet une augmentation des économies d'énergie par rapport aux émetteurs-récepteurs classiques à bande étroite, qui comportent une porteuse. Le récepteur conçu ici est basé sur la détection de crêtes et il est démontré que ce type de récepteur non-cohérent peut faire mieux qu'un récepteur de détection d'énergie plus complexe dans des environnements dominés par les interférences (comme dans les zones urbaines) à la fois au niveau d'un canal à bruit blanc gaussien additif et d'un environnement de propagation par trajets multiples.Le récepteur UWB fabriqué utilise un système de récupération d'horloge et de données pour synchroniser l'horloge locale du récepteur avec les données transmises pour réduire le temps de synchronisation et permettre des communications plus efficaces pour les réseaux de capteurs, qui ont généralement une faible charge utile de données. En déplaçant la synchronisation dans le domaine analogique, la taille et la consommation d'énergie des circuits numériques sont considérablement réduites par rapport à d'autres architectures de récepteur. Le régime de récupération d'horloge et de données fournit également un suivi en temps réel de toutes les variations dans le débit des données transmises par l'émetteur et dans la fréquence d'horloge du récepteur, ce qui réduit la nécessité d'une référence fréquentielle de haute précision dans les deux systèmes. L'émetteur UWB fabriqué est mis en œuvre en excitant un filtre de mise en forme d'impulsions avec une impulsion à large bande et le signal résultant est conforme au masque spectral de la FCC, incluant la bande GPS à éviter. Le système d'émetteur-récepteur réalise une sensibilité de  66.5 dBm avec une consommation d'énergie d'environ 400 W à un débit de données de 1 Mbps, ce qui convient aux réseaux de capteurs sans fil et à d'autres systèmes à faible puissance et à faible débit de données.Une architecture d'interface pour capteurs énergiquement efficace pour les capteurs dans le domaine fréquentiel est également présentée. Le système proposé produit une sortie numérique avec compensation de température inhérente sans l'usage d'un capteur de température à haute précision, d'un dispositif de chauffage, ou d'une horloge insensible à la température. Cette architecture est orientée vers les systèmes où l'accent est mis sur la longévité de la batterie plutôt que de la détection à haute résolution, comme dans les nœuds de capteurs sans fil.</description><creator>Allidina, Karim</creator><contributor>Mourad N El-Gamal (Supervisor)</contributor><date>2015</date><subject>Engineering - Electronics and Electrical</subject><title>A low power ultra wideband transceiver and sensor interface architecture for wireless sensor networks</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/41687m25q.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9880vt91d</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:44558h267</identifier><datestamp>2020-03-21T17:17:49Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Le Télescope du pôle Sud (SPT) est un télescope de 10 mètres de diamètre situé au pôle Sud géographique. De février 2007 à novembre 2011, nous avons utilisé le SPT a fin de mener une enquête de cinq ans sur les quelque 2500 degrés carré carrés du ciel austral en ondes millimétriques. Dans cette thèse nous décrivons le travail accompli dans ce projet du SPT tel que les techniques de rétroaction numérique pour la lecture de bolomètres; ces techniques nous ayant permis de mettre à niveau des instrumentations comme celles déployées et présentement utilisées sur le SPT. Nous examinons l'ensemble des données obtenues, leur filtration, la production des cartes, puis l'extraction d'un catalogue d'amas de galaxies. En utilisant cette liste comprenant des centaines de galaxies sélectionnées par le SPT, nous contraignons les paramètres cosmologiques, ce qui nous amène à noter que l'échelle de masse d'amas de galaxies sous-jacente est l'erreur systématique dominante. Nous présentons une nouvelle méthode bayésienne pour contraindre les paramètres cosmologiques conjoin-tement avec un nombre arbitraire de relations entre les observables et la masse, d'une manière efficace. En utilisant cette méthode, nous calculons les contraintes sur les modèles cosmologiques.</description><description>The South Pole Telescope (SPT) is a 10 m telescope located at the geographic south pole. From February of 2007 to November of 2011, we used the SPT to perform a a five year survey of 2500 square degrees of the southern sky in millimeter waves. In this thesis, we describe work on the SPT project, such as digital feedback techniques for bolometer readout that are enabling next-generation instruments, including an implementation that is currently in use on the SPT. We discuss the 2500 square degree dataset, how to filter the data, generate maps, and extract a catalog of galaxy clusters. Using this list of hundreds of SPT-selected galaxy clusters we constrain cosmological parameters, noting that the scale of underlying cluster masses is the dominant systematic error. We present a novel Bayesian method for jointly fitting cosmological parameters as well as an arbitrary number of observable-mass scaling relations, in a computationally efficient way. Using this method, we compute constraints on cosmological models.</description><creator>de Haan, Tijmen</creator><contributor>Matthew Adam Dobbs (Supervisor)</contributor><date>2015</date><subject>Physics - Astronomy and Astrophysics</subject><title>Cosmological constraints from the South Pole telescope galaxy cluster survey</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/zk51vk955.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/44558h267</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Physics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:8c97kt391</identifier><datestamp>2020-03-21T17:17:50Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Tightropes is a work for sextet (fl., cl., vl., vc., pno. and perc.) that explores the conceptsof trope and tropism as extended metaphors for music composition through the exploitation and manipulation of commonplace musical idioms. The thesis is in two parts: the musical work in full score followed by an analytic text. The analysis first defines these extramusical concepts and correspondingly explores techniques for their application as musical metaphors. Following this, it discusses my intention to create a piece of music that is precarious in nature, manipulating a listener's sense of expectation as a musical metaphor for the suspenseful nature of tightrope as a subject. The consolidation of these musical metaphors necessitated a novel approach to buildingmusical character and musical form. The different characters utilize in various ways a system of weighted pitches drawing other pitches toward them with decreasing rhythmic values (creating a "magnetic" attraction). The form is constructed as an extended string of distinct and contracting musical moments. This approach is explored in detail in the analysis along with its effects on a listener's temporal perception. The conclusion opens the door to further compositional exploration by observing how the flexibility of these techniques facilitates integration across multiple musical idioms and their unification into an idiosyncratic musical language.</description><description>Tightropes est une oeuvre pour sextuor (fl., clar., vl., vc., piano et perc.) qui explore les concepts de trope et de tropisme comme métaphores pour la composition musicale et leur potentiel de manipulation d'idiomes familiers. La thèse est en deux parties : la partition del'oeuvre suivie d'un texte analytique. L'analyse s'emploie en un premier temps à définir cesconcepts extramusicaux puis procède à une exploration des méthodes d'application de cesconcepts comme métaphores musicales. Suivra une présentation du projet visant à créer une piècede musique de nature précaire, en se jouant des attentes des auditeurs de la même manière qu'unfunambule crée le suspense en tenant ses spectateurs en haleine. L'intégration de ces métaphoresmusicales a conduit au développement d'une nouvelle façon de définir les caractères musicaux etd'envisager la forme. Les différents caractères utilisent un système de notes polarisées autourdesquelles gravitent d'autres notes dont la durée se raccourcit plus elles s'en approchent (créantune sorte d'attraction "magnétique"). La forme quant à elle sera articulée comme un écheveau de"moments musicaux" distincts qui se contractent de plus en plus. Cette approche est présentée endétails de même que ses implications au niveau de la perception temporelle. La conclusion ouvre la voie à de futures démarches compositionnelles en soulignant que la flexibilité de ces techniques permet une intégration plusieurs idiomes musicaux et leur fusion en un langage syncrétique autonome.</description><creator>Russo, Darren</creator><contributor>Denys Bouliane (Internal/Supervisor)</contributor><date>2015</date><subject>Communications And The Arts - Music</subject><title>Tightropes</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/w37639949.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/8c97kt391</identifier><degree><name>Master of Music</name><grantor>McGill University</grantor><discipline>Schulich School of Music</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:4j03d2977</identifier><datestamp>2020-03-21T17:17:50Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Le dosage d'immunoadsorption par enzyme liée (en anglais, ELISA) est le standard de la mesure de la concentration de protéines, mais il ne peut que détecter une seule protéine à la fois. Les micro-puces à anticorps ont été développées afin d'accommoder des milliers de micro-points sur une seule lamelle, permettant ainsi de faire plusieurs immunoessais en parallèle. Jusqu'à maintenant, les micro-puces à anticorps ont été utilisées pour diverses applications incluant la découverte de biomarqueurs pour un certain nombres de cancers et autres maladies. Cependant, le temps requis pour l'essai qui varie entre plusieurs heures jusqu'à une journée, et la basse capacité de multiplexer avec un maximum de ~50 protéines pour les immunoessais sandwich, sont encore les difficultés qui limitent l'adoption des micro-puces à anticorps pour faire des immunoessais.Dans cette thèse, nous avons développé de nouveaux formats de micro-puces à anticorps qui surmontent les limites de transport de masses et du multiplexage, et avons démontré leur utilisation dans la mesure de plusieurs protéines dans le sang. Spécifiquement, (i) nous avons développé un format de micro-puces de billes-en-gel (en anglais, BiGDM) qui encapsule des micro-billes enrobées d'anticorps dans des gouttes d'hydrogel 3D qui sont ensuite imprimées sur une lamelle de verre. L'architecture 3D et l'hydrogel poreux aident à améliorer le transport de masses des protéines pendant les essais; (ii) nous avons établi une nouvelle technologie apellée "snap chip" pour co-localiser les anticorps de capture et de détection correspondants dans un format de micro-puce à anticorps co-localisé (en anglais, ACM) en transférant les anticorps d'une micro-puce à l'autre grâce à un mécanisme à pression, améliorant ainsi la capacité de multiplexage et simplifiant la procédure de l'ACM; (iii) nous avons encore amélioré la capacité de multiplexage du "snap chip" par un nouveau procédé de double transfert qui possède une précision améliorée, et développé une deuxième version du mécanisme à pression qui est portable et facile d'utilisation; (iv) nous avons finalement utilisé le "snap chip" pour la mesure de plusieurs protéines dans des séries de plusieurs échantillons de sérum pendant la progression de tumeurs du sein humain dans un modèle de souris.Les nouveaux formats de micro-puces à anticorps décrits dans cette thèse ont ouverts de nouvelles avenues pour surmonter les difficultés de multiplexage et transport de masses des formats de micro-puces conventionnels, et leur utilisation pour la détection de plusieurs protéines dans le sang indique que ces technologies prometteuses pourront servir à la découverte et à la validation de protéines biomarqueurs pour diverses maladies incluant le cancer.</description><description>The enzyme-linked immunosorbent assay (ELISA) is the golden standard for the measurement of proteins, but can only detect one protein at each time in the conventional format. Antibody microarrays have been developed to accommodate thousands of micro-spots on a single slide, thus allowing multiple immunoassays to be conducted in parallel. To date antibody microarrays have been used for various applications including the discovery of protein biomarkers for a variety of cancers and other diseases. However, the relatively long assay time from hours to overnight and low multiplexing capability with a maximum of ~50 proteins for sandwich assays are still the main challenges limiting the wide use of antibody microarrays to perform immunoassays. In this dissertation, we have developed novel formats of antibody microarrays to overcome the mass transport and multiplexing limitations, and have demonstrated their use for multiple protein analysis in blood. Specifically, (i) we have developed a beads-in-gel droplet microarray (BiGDM) that encapsulates antibody coated microbeads in 3D hydrogel droplets spotted onto a glass slide. The 3D architecture and the highly porous gels help enhance mass transport of proteins during the assays; (ii) we have established a novel technology named "snap chip" to colocalize cognate capture and detection antibodies in an antibody colocalization microarray (ACM) format by transferring antibodies from microarray-to-microarray in a snap apparatus, thus improving multiplexing capability and simplifying ACM procedure; (iii) we have further improved the multiplexing capability of the snap chip by a double transfer process with improved alignment accuracy, and designed a second version of the portable and convenient-to-use snap apparatus; (iv) we have finally used the snap chip for a serial analysis of multiple proteins in sera during the progression of human breast tumor in a mouse model.         The novel antibody microarrays reported in this dissertation have introduced new avenues to overcome mass transport and multiplexing challenges in conventional microarrays, and their use in the detection of multiple proteins in blood indicates that they are promising technologies for the discovery and validation of protein biomarkers for a variety of diseases including notably cancer.  </description><creator>Li, Huiyan</creator><contributor>David Juncker (Supervisor)</contributor><date>2015</date><subject>Biology - Molecular</subject><title>Novel antibody microarray technologies for multiplex protein analysis in complex samples</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/8w32r849j.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/4j03d2977</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Biomedical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:z890rx69r</identifier><datestamp>2020-03-21T17:17:51Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>What influence does affectivity have on the memorial text? Do memorialists consistently relate certain passions, while others are very rarely, if ever, brought to mind? Could this preference also influence the subjects recalled by the memorialists or influence the rhythm of the text itself? In this thesis, each of the former questions are answered in the affirmative. Within the memorial text, there is a visible link between passion and memory (what memorialists choose to include or exclude from their works). By dividing passions into the following categories: agreeable, disagreeable, mixed, and ambivalent (a division supported by treatises of the era and by the Encyclopédie), we will see that agreeable and ambivalent passions (passions such as joy, hope, wonder, and astonishment), are much more likely to be remembered than disagreeable or mixed passions (sadness, fear, anger, and pity, for example). This preference, interesting in and of itself, is not without consequence; it influences the subjects memorialists choose to relate. Passions, however, do not simply influence what the memorialists remember. They influence how memorialists remember, subtly influencing the rhythm of the text.  </description><description>Quelle influence l'affectivité a-t-elle sur le texte mémorial ? Certaines passions y reviennent-elles de manière continuelle, tandis que d'autres en sont notablement absentes ? Cette préférence pourrait-elle influencer les sujets narrés par les mémorialistes, voire le rythme du texte ? Il nous semble qu'il convient d'apporter une réponse positive à ces questions. Dans le texte mémorial, le lien entre les passions et la mémoire (ce que les mémorialistes incluent et excluent de leurs œuvres) est manifeste. En divisant les passions dans les catégories suivantes : agréable, désagréable, mixte et ambivalente (une division appuyée par les traités de l'époque et par l'Encyclopédie), nous verrons que les mémorialistes relatent souvent les passions agréables et ambivalentes (telles que la joie, l'espérance, l'admiration et l'étonnement); ce n'est pas le cas des passions désagréables et mixtes (la tristesse, la crainte, la colère et la pitié, par exemple) qui sont souvent absentes du texte. Cette préférence intéressante n'est pas anodine. Elle influence les sujets que les mémorialistes relatent. Nous verrons cependant que les passions n'influencent pas seulement ce dont les mémorialistes se souviennent, mais comment ils s'en souviennent, déteignant ainsi subtilement sur le rythme du texte.</description><creator>Corbett, Nicole</creator><contributor>Frederic Charbonneau (Supervisor)</contributor><date>2015</date><subject>Literature - General</subject><title>Souvenirs et affectivité: «Les passions dans les mémoires particuliers du XVIIIe siècle»</title><language>fre</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/1r66j4092.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/z890rx69r</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of French Language and Literature</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:j6731696b</identifier><datestamp>2020-03-21T17:17:52Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Background: In Canada, the United States of America (U.S.A), and many other regions world-wide, more and more people are dying of prescription opioid analgesic (POA) overdose death. The death rate from POA overdose has quadrupled in the U.S.A. since 1999 and tripled in Ontario. These pharmaceuticals remain useful and important tools in the practice of medicine, although many have suggested changes to prescribing behavior should be among the intervention strategies to curb this epidemic. Canadian physicians wish to minimize overdose and other opioid related-harms while using these medications to optimal clinical effectiveness. To assist physicians in achieving this balance, a national collaboration examined evidence and published the Canadian Guideline for Safe and Effective use of Opioids in Non-Cancer Pain (CGCNCP) in 2010. We retrospectively assessed if non-concordance with prescription characteristic recommendations given in this guideline was predictive of overdose death. Methods: Using a nested-case control design within the public health insurance cohort of Quebec from 2001-2010, we examined the relationship between death from opioid overdose and dispensed opioid prescriptions non-concordant with recommendations in the CGCNCP. Cases meeting criteria for prescription opioid overdose death were identified through provincial coroner and death certificate data and were restricted to individuals with pharmaceutical insurance from the Régie d'Assurance Maladie du Québec (RAMQ) in the 210 days prior to overdose death. Individuals with an active cancer diagnosis were excluded because of substantial differences in prescribing recommendations in cancer-related pain management. Controls were sampled randomly from time, age, and sex matched individuals in the same cohort and subject to the same inclusion criteria. Non-concordance was assessed through longitudinal analysis of data on prescriptions dispensed in the 180 days prior to case death. We used conditional logistic regression to estimate the magnitude of the relationship between number of non-concordance events and overdose death. Results: Five hundred people who died of POA overdose while covered by RAMQ pharmaceutical insurance were dispensed at least one POA in the 180 days prior to death, of which 73 had an age, sex, and time-matched control who had also been dispensed at least one POA in the same period. There were 1,326 dispensed opioid prescriptions among cases, with a total of 375 non-concordant events, and 469 dispensed opioid prescriptions among controls, with a total of 111 non-concordant events. In multivariate analysis, POA overdose death was associated with the number of dispensed benzodiazepine prescriptions (aOR 2.91; 95% CI 1.21-7.00), and opioid prescriptions (aOR 1.20; 95% CI 1.02-1.40), as well as initiating opioid therapy with an extended release formulation (aOR 6.38; 95% CI 1.07-37.94). Total number of non-concordance events was not significantly associated with POA overdose death (aOR 1.03; 95% CI 0.88-1.21).  Interpretation: Increased numbers of dispensed opioid and benzodiazepine prescriptions are important risk factors for POA overdose death in Quebec. Prescription of extended release opioids to opioid naïve patients is significantly associated with increased odds of POA overdose death; prescribers should initiate therapy using immediate release formulations and transition patients to extended release when stable dosing is established. Further study with a larger number of cases is needed to determine whether non-concordance with additional CGCNCP recommendations is associated with POA overdose death.</description><description>Contexte: Au Canada, aux États-Unis, ainsi que dans plusieurs autres régions à travers le monde, la mortalité liée aux surdoses d'opioïdes d'ordonnance a augmenté rapidement.  Le taux de mortalité dû à surdose d'opioïdes d'ordonnance a quadruplé en Amérique depuis 1999 et a triplé en Ontario durant la même période. Les médecins canadiens souhaitent minimiser les surdoses et d'autres méfaits associés avec ces médicaments, tout en utilisant ces médicaments à leur potentiel thérapeutique maximal. Afin d'aider les médecins à atteindre cet équilibre, une collaboration nationale a examiné l'évidence et a publié le Canadian Guideline for Safe and Effective Use of Opioids in Chronic Non-Cancer Pain (CGCNCP) en 2010. Nous avons évalué de manière rétrospective si la non-concordance des prescriptions avec les recommandations émises par le CGCNCP prédisait le décès par surdose. Méthodologie: Nous avons utilisé une modèle d'étude cas-témoins; les cas viennent de la cohorte des bénéficiaires de le Régie d'assurance de maladies du Québec (RAMQ) entre 2001 et 2010. Les cas qui remplissaient les critères pour une surdose d'opioïdes d'ordonnance ont été identifiés par le bureau du coroner du Québec et par les certificats de décès et ont été restreint aux individus participants au régime d'assurance médicaments de la RAMQ pendant les 210 jours précèdent le date de décès. Les individus avec un diagnostic de cancer ont été exclus au cause des différences considérables entres les recommandations pour les ordonnances pour la gestion de la douleur lié au cancer. Les témoins ont été sélectionnés au hasard des individus de la même cohorte qui étaient apparié selon le sexe, l'âge et qui étaient vivant le jour de décès du cas apparié. Les témoins ont été soumis aux mêmes critères d'inclusion que les cas. Nous avons mesuré non-concordance en effectuant une analyse longitudinale des donnes d'ordonnances émises pendant les 180 jours avant le décès. Nous avons utilisé une régression logistique conditionnelle pour mesurer l'association entre non-concordance et mortalité. Résultats: Cinq cent victimes de surdose qui étaient bénéficiaires d'assurance médicaments de la RAMQ avaient été distribué au moins une ordonnance d'opioïdes dans les 180 jours précèdent leurs décès. De celles-ci, 73 avait un témoin apparié qui avait aussi été distribué au moins un ordonnance d'opioïdes dans la même période. Il y avait 1,326 prescriptions distribué pour des opioïdes chez les cas, comprenant une totale de 375 instances de non-concordance, et 469 prescriptions distribué pour des opioïdes parmi les témoins, comprenant une totale de 111 instances de non-concordance.  Dans l'analyse multivariée, le décès suite à la surdose a été associée avec le nombre d'ordonnance de benzodiazépines distribués (aOR 2.91; 95% CI 1.21-7.00),  et le nombre d'ordonnance d'opioïdes (aOR 1.20; 95% CI 1.02-1.40), ainsi que l'initiation de thérapie en utilisant d'opioïdes à action prolongée (aOR 6.38; 95% CI 1.07-37.94). Le nombre total d'instances de non-concordance n'était pas associé de manière significative avec les décès lié à la surdose d'opioïdes d'ordonnance (aOR 1.03; 95% CI 0.88-1.21).Interprétation: L'augmentation de nombre d'ordonnances d'opioïdes et de benzodiazépines constituent des facteurs de risques importants pour le décès suite à une surdose au Québec. L'initiation de la thérapie avec les opioïdes à action prolongée augmente de manière significative les chances de décès suite à une surdose.  Les prescripteurs devraient initier la thérapie en utilisant des opioïdes à action immédiate et passer aux opioïdes à action prolongé quand le dosage c'est stabilisé.  Des futures études comprenant un nombre plus grand de cas sont nécessaire pour déterminer si la non-concordance avec les autres recommandations de CGCNCP sont associé aux surdoses d'opioïdes d'ordonnance.</description><creator>Fuller, Colleen</creator><contributor>David Buckeridge (Internal/Supervisor)</contributor><date>2015</date><subject>Health Sciences - Medicine and Surgery </subject><title>The association between non-concordance with the Canadian guideline for safe and effective use of opioids in chronic non-cancer pain and opioid overdose death in Quebec</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/8w32r8509.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/j6731696b</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Epidemiology and Biostatistics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:hq37vr623</identifier><datestamp>2020-03-21T17:17:53Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>De nombreuses études, tant aux États-Unis qu'en Europe, ont étudié le carrefour giratoire en tant que moyen d'améliorer la sécurité des intersections. L'objectif principal de ces études a été l'enquête de l'efficacité des carrefours giratoires, ainsi que les facteurs contributifs associés au risque de collision en regardant à la fois le nombre et la gravité des accidents. Malgré le nombre d'études dans ce domaine, très peu de recherches existent dans le contexte Canadien ou provinciale Québécois où les facteurs locaux pourraient jouer en faveur ou contre les carrefours giratoires. Plus important encore, la popularité des carrefours giratoires dans la Province de Québec a considérablement augmenté dans les dernières années. Les préoccupations liées aux problèmes de sécurité dans les carrefours giratoires restent, sans réponse claire. Cela étant dit, une quantité importante de données d'accident ne sont pas géocodées, ce qui est essentiel pour les études d'occurrence d'accidents et les analyses de la gravité des blessures. Cette thèse tente d'enquêter la sécurité des carrefours giratoires dans la province de Québec, Canada, en combinant différentes sources de données et en utilisant diverses approches statistiques. Pour atteindre cet objectif, la thèse est divisée en trois objectifs principaux; 1) développer une méthode gratuite et accessible de géocodage des données d'accident, 2) étudier l'impact que les carrefours giratoires ont sur la sécurité des usagers de la route à l'aide de données historiques d'accident, et 3) identifier les facteurs associée à la fréquence des accidents dans les carrefours giratoires et la gravité des blessures. Parmi d'autres résultats, une méthodologie pour cartographier les données d'accident est proposé en utilisant un algorithme personnalisé qui fait appel à un service internet tel que l'interface de programmation d'application de Google Maps (API). On constate qu'un taux de correspondance de 78% peut être atteint, ce qui est comparable à des options commerciales. Avec la révision appropriée de l'utilisateur, les résultats sont suffisants pour des applications pratiques telles que l'analyse de la sécurité aux intersections. Grâce à l'application d'un modèle logit ordonné afin d'identifier les facteurs qui contribuent à la gravité des blessures aux carrefours giratoires, la recherche dans le troisième chapitre a identifié que des facteurs comme un plus grand nombre de véhicules impliqués, les accidents survenus dans l'intersection, les renversements de véhicules, la participation des bus, les accidents survenus dans le noir sur les routes non éclairées et les conditions de neige ont mené à une augmentation de la gravité des blessures dans les carrefours giratoires. De même, les facteurs associés à des accidents impliquant uniquement les voitures, les accidents avec des animaux et des routes enneigées ont été trouvés être associés à des blessures moins graves.Enfin, à partir des résultats du chapitre 4, qui traite de l'efficacité de la sécurité aux carrefours giratoires, un nombre d'observations ont été faites. Bien que jugée statistiquement non significatif, les observations suggèrent que les petits carrefours giratoires, les carrefours giratoires dans lesquels un seul type d'usagé est présent (c'est-à-dire le comportement local ou autoroutier; mais pas les deux en même temps), et les carrefours giratoires avec une vitesse uniforme sur l'ensemble de ses approches tendent ont démontré une fréquence de collision réduite, telle qu'estimée par la méthodologie avant-après avec groupe de comparaison. L'une des principales faiblesses de cette méthode est qu'il ne prend pas en compte les effets de régression vers la moyenne; une idée qui sera discutée au long de ces travaux.  </description><description>Numerous studies both in the United States and Europe have investigated the roundabout as a means to improve the safety of intersections. The focus of these studies has been the investigation of the effectiveness of roundabouts as well as the contributing factors associated to crash risk looking at both the number and the severity of crashes. Despite the number of studies in this area, very little research exists in the Canadian or Quebec provincial context in which local factors could play in favour or against roundabouts. More importantly, the popularity of roundabouts in the Province of Quebec has increased significantly in the last years. Safety concerns associated with this type of intersection remain, with no clear answer.That being said, an important amount of crash record data is not geocoded, which is essential for crash occurrence and severity analysis studies. This thesis attempts to investigate roundabout safety in the Province of Quebec, Canada by combining different sources of data and using various statistical approaches. In order to accomplish this goal, the thesis is divided into three main objectives; 1) to develop a free and accessible method of geocoding crash record data, 2) to investigate the impact that roundabouts have on the safety of road users using historical crash record data and 3) to identify contributing factors associated to roundabout crash frequency and injury severity. Among other results, a methodology for mapping crash data is proposed using a custom algorithm that calls on an online service such as the Google Maps application programming interface (API). It is found that a match rate of 78% can be achieved, which is comparable to commercially available geocoding options. With proper user revision, the results are sufficient for practical applications such as intersection safety analysis. Through the application of an ordered logit model in order to identify factors that contribute to injury severity at roundabouts the research in the third chapter identified that factors such as a larger number of involved vehicles, accidents occurring within the intersection, vehicle rollovers, the involvement of buses, accidents occurring in the dark on unlit roads and snow conditions led to increased injury severity within roundabouts. Similarly, factors associated to accidents involving only cars, animal strikes and snow-covered roadways were found to be associated with less severe injuries. Finally, from the results of Chapter 4, which deals with the safety effectiveness of roundabout, a number of observations were made. While found to be statistically insignificant, the observations suggest that smaller roundabouts, roundabouts in which only one type of user is present (i.e. local or highway driver behavior, not both) and roundabouts with a consistent speed on all of their approaches are observed to demonstrate a reduced crash frequency, as estimated through the before-after method with comparison group. One of the main weaknesses of this method is its inability to account for regression-to-the-mean effects; an idea that will be discussed throughout the work.</description><creator>Burns, Shaun</creator><contributor>Karim Ismail (Internal/Cosupervisor2)</contributor><contributor>Luis Miranda-Moreno (Internal/Supervisor)</contributor><date>2015</date><subject>Engineering - Civil</subject><title>Safety at Quebec's roundabouts: Investigating injuries and accident occurrence</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/xs55mf84j.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/hq37vr623</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Civil Engineering and Applied Mechanics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:02871005g</identifier><datestamp>2020-03-21T17:17:54Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Dans les pays développés, la co-infection avec le virus de l'hépatite C  (HCV) se produit dans ≥ 30% des patients infectés par le virus d'immunodéficience humain type-1 (VIH-1). Comparé au VIH-1 seul, la co-infection avec HCV est associée avec une augmentation des problèmes rénaux, une plus grande prévalence des maladies cardiovasculaires et une augmentation des problèmes moteur-cognitifs. Par contre, la complication la plus importante reste les maladies du foie dans les cas de co-infection au VIH-1/HCV. Les problèmes du foie reliés au HCV (incluant la fibrose, la cirrhose et maladies du foie en phase terminal) sont plus répandus et accélérés chez les individus infectés par le VIH-1. Même si la biopsie du foie reste le test standard pour déterminer le niveau de fibrose du foie associé avec le HCV, ce test peut causer des complications et être assujetti à des erreurs d'échantillonnage. De ce fait, la recherche pour des méthodes non-invasives pour évaluer le niveau de fibroses du foie demeure nécessaire. À cette fin, nous avons comparé le profile protéomique du plasma à diffèrent niveau de fibrose chez des patients HCV mono et VIH-1/VHC co-infectés en utilisant le ‘surface-enhanced laser desorption ionization-time-of-flight mass spectrometry' (SELDI-TOF MS) : la Spectrométrie de masse utilisant le laser. Cette technologie nous permet une grande capacité de profilage des protéines d'un spécimen biologique natif. En utilisant SELDI-TOF MS pour développer des algorithmes pour évaluer le niveau de fibrose du foie chez les individus co-infectés par le VIH-1/HCV, nous avons identifié les protéines du sérum apolipoprotéine A1, haptoglobine et  plasminogène comme des biomarqueurs potentiels. Au cours de cette étude, nous avons observé une importante hétérogénéité dans le protéome plasmatique des patients co-infectés. En particulier, nous nous sommes intéressés au taux de progression de fibrose du foie chez les patientes co-infectés par le VIH-1/HCV, en mesurant l'index aspartate aminotransférase (AST) sur plaquette (APRI), en relation avec la séquence d'infection avec les deux virus. Nous avons montré que la séquence d'infection n'a pas d'effet sur le pourcentage de patients qui développeront une fibrose du foie mais par contre les patients qui ont été infectés par le VIH-1 en premier auront une progression plus rapide.</description><description>Hepatitis C virus (HCV) co-infection occurs in ≥ 30% of Human immunodeficiency virus type-1 (HIV-1)-infected patients in developed countries. Compared to HIV-1 alone, co-infection with HCV is associated with: increased HIV-1-related kidney problems, higher prevalence of cardiovascular disease, and increased cognitive-motor impairment. However, liver disease is by far the most serious complication of HIV-1/HCV co-infection. HCV–associated liver damage (including fibrosis, cirrhosis and end of stage liver disease (ESLD)) are all more prevalent and accelerated in HIV-1-infected individuals. Although, liver biopsy remains the gold standard for staging HCV-associated liver disease, this test can result in serious complications and is subject to sampling error. These problems have prompted a search for non-invasive methods for liver fibrosis staging.To this end, we compared plasma proteome profiles at different stages of fibrosis in HCV mono and HIV-1/HCV co-infected patients using surface-enhanced laser desorption ionization-time-of-flight mass spectrometry (SELDI-TOF MS). This technology offers high-throughput protein profiling of native biological specimens. Using SELDI-TOF MS to develop algorithms for the staging of liver fibrosis in HIV-1/HCV co-infected individuals, we were able to identify serum apolipoprotein A1, haptoglobin and plasminogen as candidate biomarkers for liver fibrosis. In the course of this work, we observed an important heterogeneity in the plasma proteome of co-infected patients. In particular, we were interested in fibrosis progression rates in HIV-1/HCV co-infected patients as assessed by the aspartate aminotransferase (AST)-to-platelet-ratio index (APRI) according to the sequence of infection with both viruses. We have shown that the sequence of infection has no effect on the percentage of patients who will eventually develop liver fibrosis but that those who are infected with HIV-1 first will progress to liver fibrosis at an accelerated rate.</description><creator>Melendez-Peña, Carlos</creator><contributor>Momar Ndao (Supervisor2)</contributor><contributor>Brian Ward (Supervisor1)</contributor><date>2015</date><subject>Health Sciences - Medicine and Surgery </subject><title>HIV-1/HCV co-infection; proteomics and liver fibrosis</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/ht24wn35f.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/02871005g</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Medicine</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:2227ms937</identifier><datestamp>2020-03-21T17:17:55Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La lecture, à l'instar d'autres compétences acquises, se développe suite à un enseignement formel et se perfectionne grâce à une pratique rigoureuse.  Cependant, les personnes bilingues (qui maîtrisent et utilisent deux, voire plusieurs, langues) ont nécessairement moins d'expérience de lecture en langue maternelle (L1) et en langue seconde (L2) que les locuteurs monolingues, car ces derniers lisent exclusivement dans leur L1.  Ainsi, dans le cadre de la recherche sur le bilinguisme et le traitement du langage en général, une question fondamentale demeure : de quelle manière l'accumulation d'expérience avec L2 pourrait-elle affecter la lecture, tant en L2 qu'en L1?  Bien qu'il semble logique que l'accumulation d'expérience avec L2 favorise de meilleures performances de lecture en L2, le lien entre l'expérience en L2 et la lecture en L1 semble moins évident.  En fait, en linguistique, il est communément accepté que, une fois acquises, les compétences générales associées à L1 sont à l'abri de toute interférence pouvant être causée par la L2, particulièrement à l'âge adulte.  Toutefois, nous nous attendons à ce que les compétences en L1 et L2 puissent s'influencer l'une l'autre dans la mesure où l'expérience de toute une vie permet d'actualiser de façon adaptative la représentation et l'accès aux connaissances linguistiques complexes.  Afin de déterminer si l'accumulation d'expérience en L2 influence non seulement la lecture en L2, mais aussi la lecture en L1, nous avons ici eu recours à des enregistrements oculométriques recueillis auprès de jeunes adultes bilingues français-anglais de même qu'auprès d'adultes plus âgés dont l'expérience linguistique en L2 varie.        Les études présentées dans cette thèse suggèrent que le fait d'avoir plus d'expérience récente en L2 parmi les jeunes adultes bilingues améliore la lecture en L2, mais nuit, étonnamment, la lecture en L1, contredisant du fait même la croyance répandue sur l'invulnérabilité de L1 face aux changements d'expérience à l'âge adulte. Fait à noter, ces changements dans la fonction de lecture sont atténués parmi les adultes plus âgés, ce qui porte à croire que l'expérience accumulée en L1 et en L2 au cours de la vie pourrait contrer l'influence de l'expérience linguistique courante, en particulier lors du traitement de la langue maternelle plus fréquemment utilisée.  Par conséquent, l'impact de l'expérience courante en L2 sur la lecture en L1 et en L2 varie selon l'emplacement du locuteur bilingue le long du spectre de l'âge adulte.  Les recherches futures devraient davantage examiner si les résultats observés peuvent se généraliser à d'autres populations bilingues (par exemple, les enfants) et d'autres domaines linguistiques (par exemple, la production).</description><description>Reading, like many other acquired skills, is developed and refined through extensive formal instruction and practice.  However, bilinguals, by virtue of knowing and using two or more languages, necessarily have less first- (L1) and second-language (L2) reading experience than monolinguals who, by definition, read in one language exclusively.  Thus, an important question for the study of bilingualism and language generally is how changes in L2 experience affect reading in both the L1 and the L2.  While it stands to reason that increased L2 experience should relate to enhanced reading fluency in the L2, it is less clear whether L1 reading fluency should also be affected.  Indeed, a commonly held belief within linguistics is that L1 skills of any kind, once acquired, are immune to the impact of L2 experience, particularly in adulthood.  However, to the extent that life-long experience can adaptively update the representation and access of complex linguistic knowledge, we would expect L1 and L2 skills to trade-off to some degree as a function of increasing L2 experience.  To this end, the present thesis uses eye movement recordings to investigate whether such a trade-off in L1/L2 reading occurs for French-English bilingual younger and older adults, who vary continuously in current L2 experience.          The studies presented in this thesis suggest that greater current L2 experience among bilingual younger adults strengthens L2 reading, and more interestingly, weakens L1 reading—contradicting the commonly held belief that L1 skills are immune to experience-dependent change in adulthood.  Of note, experience-dependent changes in reading are attenuated for bilingual older adults—suggesting that accumulated life-long L1/L2 experience might counter the influence of current language experience, particularly when processing the more frequently used L1.  Accordingly, the impact of current L2 experience on L1/L2 reading varies according to which end of the adult life-span bilinguals are situated.  Future research should more closely examine whether the findings observed here occur for other bilingual populations (e.g., children) and other language domains (e.g., production).</description><creator>Whitford, Veronica</creator><contributor>Debra Ann Titone (Supervisor)</contributor><date>2015</date><subject>Psychology - Cognitive</subject><title>The impact of second-language experience on bilingual reading across the adult life-span</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/00000312d.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/2227ms937</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Psychology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:cc08hj535</identifier><datestamp>2020-03-21T17:17:56Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>L'enseignement de l'anglais langue seconde (ALS) au Québec est particulier suite aux nombreuses lois sur la langue, ainsi que l'emplacement géographique de la province qui côtoie d'autres provinces anglophones, dans un pays bilingue.  La présente étude explore les raisons pour lesquelles les enseignant(e)s d'ALS continuent d'utiliser le Français (qui est une langue commune des enseignant(e)s) dans les cours d'ALS, même si le Ministère de l'Éducation prescrit le contraire. L'étude explore ce sujet selon deux perspectives: une perspective linguistique et une perspective socioculturelle et politique.  Pour cette étude, neuf élèves du secondaire et deux enseignants du secondaire en ALS ont été interviewés, ensuite observés dans leurs cours d'ALS et ensuite interviewés pour une deuxième fois. Les observations ont été enregistrées sous format audio, transcrits et compilés avec les grilles d'observation, pour ensuite analyser le tout pour trouver les thèmes émergents. Après l'analyse des thèmes, les résultats correspondaient avec les résultats de recherches antérieurs. Les enseignant(e)s utilisaient le français pour expliquer des notions de grammaire ou des concepts linguistiques complexes, ainsi que faire de la discipline, la gestion de classe et clarifier des notions.  Le côté politique et socioculturel a révélé que les jeunes Québécois du secondaire désiraient parler plus d'anglais et avoir plus d'initiative à parler anglais dans le cours d'ALS, mais ils n'étaient pas par contre prêts à renoncer à leurs accents Québécois et adopter une manière de parler plus anglophone. Ils avaient aussi une tendance à retomber dans les habitudes de parler français quand ils travaillaient en groupe ou avaient des discussions hors sujet. Dans d'autres cas, certains élèves n'avaient pas assez de confiance quand venait le temps d'utiliser l'anglais, car ils avaient tendance à se comparer à leurs pairs bilingues dans la classe.</description><description>Teaching English as a Second Language (ESL) in Quebec has its own particularities due to language laws and its geographical position, i.e. that it is a French province surrounded by English-speaking provinces within a federally bilingual country.  This study investigates the reasons why ESL teachers use the French (L1) language (which is shared by all the students and teachers in this study) in ESL classrooms in Quebec, although it is prescribed to use English (L2) as the language of instruction.  This study investigates the matter from two different standpoints: the linguistic perspective as well as the socio-cultural and political perspectives.  For this study, nine secondary school students and two ESL teachers were initially interviewed, then observed in the classroom, and interviewed after observation to get a more in-depth perception of why and when they use French (L1) and English (L2) in the classroom. The interviews and observations were audio-recorded, transcribed and thematically analyzed to identify emerging themes amongst teachers and students.  After the themes were analyzed, the results were found to be consistent with previous research, in which teachers used the L1 to explain grammar and complicated concepts, to discipline, for classroom management, and to clarify tasks. The political and socio-cultural perspectives revealed that although Quebecois students said they wanted to speak more English and have stricter rules about speaking French in class, they are still not ready to take on native-like English speech.  They also can't help but fall back on French when working in groups, negotiating meaning or during off-task behavior.  Some students also have confidence issues when it comes to expressing themselves, especially if they feel less proficient than their bilingual peers.</description><creator>Moiseeva, Sophia</creator><contributor>Lise Winer (Internal/Supervisor)</contributor><date>2015</date><subject>Education - Language and Literature</subject><title>The use of French L1 in English L2 secondary school classrooms in Quebec</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/z603r164b.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/cc08hj535</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of Integrated Studies in Education</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:kw52jb92q</identifier><datestamp>2020-03-21T17:17:56Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The rapid development and dissemination of the local DJ performance along with web hosted music production and remix competitions, facilitated by social media- fueled contest platforms, has led to immediate shifts in the creative practices of those involved in fields related to these sites and their offerings. These developments have reoriented certain labour practices into networks of competition, where DJs, producers, and their audiences are asked to engage with these crowdsourced competition platforms and their partners for a chance to sign away their work or play at a club or festival for the promise of exposure if they happen to be ‘lucky' or ‘talented' enough to win a contest. Often ‘winning' these contests is only part of a process of further enmeshing creative workers and their networks in the social media- fueled ecosystems that these websites have set up. In order to begin to analyze these competitive practices I intend to draw a line of recent history and debate to reveal the web of connections that links local Electronic Dance Music (EDM) networks and their engagement with social media- fueled contest websites as well as local promoters of DJ contests and theirs backers. I will reveal the ideologies and discourses that bubble beneath the surface of EDM related networks and practices and how they allow for and rationalize these competitive practices, while at the same time permitting DJs to argue against the selling of their related creative works to the very media companies that own the websites they compete to labour on. In doing so I will study an array of people, practices, and discourses to reveal the rationalization of exploitative competitive labour practices, and call for the development of policies and protections by governments for creative workers who have little to gain and so much to lose by continuing to be involved in these competitions.</description><description>Le développement rapide et la diffusion des compétitions de DJ locaux et les plates-formes de concours  associées aux médias sociaux ont conduit à des changements immédiats dans les pratiques créatives de ceux associés à ces sites ainsi que dans leurs offres. Ces développements ont réorienté certaines pratiques de travail dans des réseaux de concurrence, où les DJ et leurs publics sont invités à participer à ces concours ‘crowdsourced' ainsi qu'avec leurs partenaires afin d'avoir une chance de renoncer à leur travail ou de jouer dans un club ou un festival pour la promesse d'exposition s'il sont assez «chanceux» ou «talentueux» pour gagner un concours. Bien souvent,  «gagner» ces concours n'est qu'une partie d'un processus d'enferrement des travailleurs créatifs et de leurs réseaux dans les ecosystemes alimentés par les réseaux sociaux  mis en place par ces sites internet. Pour commencer à analyser ces pratiques concurrentielles, j'ai l'intention de mettre en relations  l'histoire contemporaine et des débats récents pour révéler le réseau de connexions qui relient les réseaux d'Electronic Dance Music (EDM) locaux aux sites web de concours alimentés  par les médias sociaux ainsi qu'aux promoteurs locaux de concours DJ et leurs bailleurs. Afin de trouver ces liens, j'ai l'intention de «jouer à chat» avec les DJ et leurs réseaux. Je mettrai en lumières les idéologies et discours qui sous-tendent les réseaux et les pratiques liées à l'EDM et comment ils permettent de rationaliser et ces pratiques concurrentielles, tout en permettant en même temps aux DJs de s'opposer à la vente de leurs œuvres créatrices connexes aux médias propriétaires des sites sur lesquels les DJs luttent pour participer. Ce faisant, je vais étudier une série de personnes, d pratiques et de discours, afin de révéler la rationalisation des pratiques de travail concurrentielles d'exploitation, tout en lançant un appel au développement de politiques et de mesures de protection gouvernement pour les créateurs qui ont peu à gagner et beaucoup à perdre par continuer à participer à ces compétitions.</description><creator>Karpetz, Jonathan</creator><contributor>Straw, William O  (Internal/Supervisor)</contributor><date>2015</date><subject>Communications And The Arts - Music</subject><title>Competitive labour practice in creative economies. Contemporary contests in electronic dance music networks</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/b5644v762.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/kw52jb92q</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of Art History and Communication Studies</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:fx719q25x</identifier><datestamp>2020-03-21T17:17:57Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La thromboembolie veineuse, comprenant la thrombose veineuse profonde et l'embolie pulmonaire,  est une cause majeure de morbidité et de mortalité liée au cancer et ses traitements. Il est bien connu que l'apparition d'une tumeur maligne prédispose les patients à des troubles de l'hémostase. Les patients atteints de cancer ont un risque 6-7 fois plus élevé de thromboembolie veineuse par rapport aux individus sains. Cependant, les mécanismes régulant les interactions entre le cancer et la thrombose veineuse ne sont pas entièrement compris, principalement parce que les modèles animaux sont rares et nécessitent le sacrifice des animaux. Le développement de modèles animaux utilisant des techniques non invasives permettrait de suivre plus précisément la formation et la résolution du thrombus chez la souris. Nous avons développé un modèle in vivo et non-invasif pour visualiser et mesurer la formation, la progression et la régression du thrombus dans le système veineux murin. Ce modèle en combinaison avec des mesures traditionnelles (mesure du poids et analyse histologique du thrombus) a ensuite été utilisé pour étudier la thrombose veineuse induite par le cancer chez la souris. Il est bien connu que les tumeurs malignes favorisent le développement d'un milieu pro-coagulant. Gas6 est une protéine aux propriétés pro-coagulantes. Les souris déficientes pour Gas6 sont protégées contre la thromboembolie veineuse et développent de plus petit thrombus par rapport aux souris de type sauvage. Notre laboratoire a récemment démontré que Gas6 produit par l'endothélium induit l'expression du facteur tissulaire qui conduit à la thrombose veineuse. La déficience en Gas6 est également associée à la progression plus lente des tumeurs. Toutefois, le rôle de Gas6 dans la thrombose veineuse liée au cancer n'a jamais été étudié. Nous avons démontré que Gas6 favorise la thrombose veineuse induite par le cancer en augmentant l'expression de la prostaglandine E synthase dans l'endothélium, qui à son tour augmente les taux de la prostaglandine E2 et facilite l'activation plaquettaire. En conclusion, le travail présenté dans cette thèse a permis d'établir un nouveau modèle in vivo pour la visualisation et la mesure précise de la thrombose veineuse chez la souris. Ces travaux ont également  permis de mieux comprendre le rôle de Gas6 dans la thrombose veineuse induite par le cancer.</description><description>Venous thromboembolism (VTE), which comprises deep vein thrombosis and pulmonary embolism, is a major cause of morbidity and mortality related to cancer and its treatments. It is well recognized that the onset of malignancy predisposes patients to haemostatic disorders. Cancer patients have a 6-7 fold higher risk of VTE compared to healthy individuals. However, mechanisms underlying the interactions between cancer and VTE are not entirely understood, mainly because animal models studying this disease are scarce and in most cases very crude. Characterizing animal models using non-invasive techniques may be a powerful tool to study thrombus formation and resolution more precisely in mice. We first established a non-invasive, in vivo method for monitoring thrombus formation, progression and regression in the murine venous system. This method in combination with traditional measurements (thrombus weight and histological analysis) was then used to study cancer-induced venous thrombosis in mice. It is well known that malignancies thrive in pro-coagulant milieu. Growth arrest specific 6 (Gas6) is a protein with pro-coagulant properties. Gas6 deficient mice are protected against lethal thrombosis, and develop smaller thrombi compared to wild type (WT) littermates. Our laboratory recently demonstrated that endothelial derived Gas6 induces the expression of tissue factor in the endothelium leading to venous thrombosis. Gas6 deficiency is also associated with slower progressing tumors. However, role of Gas6 in cancer-induced thrombosis has never been studied. We show that Gas6 enhances cancer-induced venous thrombosis by upregulating prostaglandin E synthase in the endothelium, which in turn increases prostaglandin E2 (PGE2) levels and facilitates platelet activation. In conclusion, the work from this thesis provides a novel in vivo model for monitoring venous thrombosis and elucidates the role of Gas6 in cancer-induced venous thrombosis.</description><creator>Aghourian Namagerdy, Meghedi</creator><contributor>Mark D Blostein (Supervisor)</contributor><date>2015</date><subject>Biology - Physiology</subject><title>Role of Gas6 in cancer-induced venous thrombosis</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/1j92gb28h.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/fx719q25x</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Physiology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:fx719q266</identifier><datestamp>2020-03-21T17:17:58Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La technique de métallurgie des poudres (PM) s'est avéré être l'une des voies les plus prometteuses pour la production des mousses métalliques. Dans le cas des mousses d'aluminium, cette technique requiert le mélange d'Al ou de poudres d'alliages à base d'Al avec un agent moussant (le TiH2 est le plus souvent utilisé) ; un précurseur est ensuite formé par la compaction du mélange à haute densité. Le traitement thermique du dit précurseur permet la formation de mousse par fusion simultanée des poudres métalliques et la libération de gaz provenant de la décomposition de l'agent moussant. Néanmoins, la disparité entre la température de décomposition de TiH2 (généralement entre 450-650 °C) et le point de fusion d'Al ou d'alliage d'Al (environ 660 °C) sont les principaux inconvénients de cette technique, car ils conduisent au craquement de pores et à la perte d'hydrogène avant le moussage. De plus, si la formation de mousse se produit à une température élevée (~800 °C), d'autres problèmes tels que la coalescence des pores, le drainage du métal et l'écroulement de la mousse peuvent se produire. L'objectif de cette étude est  de développer des nouveaux alliages moussants à  base d'aluminium susceptibles de doter la mousse d'une plus grande stabilité et expansion ainsi que des propriétés mécaniques supérieures.Afin de pallier les différences entre la température de décomposition et celle de fusion, la chimie des mousses d'Al a été modifiée dans la présente recherche, en introduisant de petites quantités de Sn (≤ 5% en poids). Les rôles de Sn dans le processus de moussage d'Al sont (i) l'amélioration de l'intégrité du mélange de poudre pendant la compaction à chaud de Sn, compte tenue de sa faible température de fusion, (ii) le contrôle de la décomposition progressive du TiH2 et (iii) l'amélioration de la tension superficielle d'Al liquide, ayant pour conséquence un plus haut niveau de contrôle de  l'expansion, ainsi qu'une meilleure stabilité de la mousse, même sous une basse température de moussage (725 ° C).L'expansion et la stabilité de la mousse sont plus contrôlées par la formation in-situ de phases intermétalliques. Les calculs thermodynamiques utilisant le logiciel thermodynamique FactSage ont été largement utilisés pour la conception d'alliages, et des analyses thermiques d'alliages ont été réalisées afin de comprendre l'évolution des alliages sélectionnés pendant le processus de moussage. Cinq éléments d'alliage (Co, Mg, Mn, Ni et Ti) ont été sélectionnés dans le but de changer le comportement de moussage d'Al-3% poids Sn. Ces alliages ont été conçus (i) pour améliorer l'expansion de la mousse (en atteignant une expansion maximale plus élevée) et/ou (ii) pour stabiliser la mousse (uniformisation de la taille et de la distribution des pores) par la formation des phases intermétalliques durant le processus de moussage. Les propriétés mécaniques des nouveaux alliages à base d'Al-Sn sont supérieures à celles des mousses classiques d'alliage d'Al. L'amélioration de l'efficacité et de la capacité d'absorption d'énergie a été observée suite à une augmentation de quantité d'élément d'alliage (en particulier à de plus grandes quantités de Ti, Mn ou Ni). Ceci en résulte des composés intermétalliques formés par les éléments d'alliage dans les parois cellulaires. Un modèle corrélant les courbes contrainte-déformation avec le mode de fracture de la paroi cellulaire au cours du test de compression a été proposé.</description><description>The powder metallurgy (PM) technique is one of the most promising means of producing metallic foams. In the case of Al foams, this technique requires the mixing of Al or Al-based alloy powders with a blowing agent (most commonly TiH2) after which the mixture must be compacted to a high density to form a precursor. Heat treating the precursor allows foam formation by simultaneously melting metal powders and releasing gas from blowing agent decomposition. Nevertheless, the mismatch between TiH2's decomposition temperature (typically between 450–650 oC) and the melting point of Al or Al alloy (about 660 oC) the main drawback of this technique as it leads to the formation of crack-like pores and to hydrogen loss prior to foaming. In addition, if foaming occurs at an elevated temperature (~800 oC), it leads to problems such as pore coalescence, metal drainage and foam collapse.The purpose of this study is to develop new Al alloys that when foamed will produce stable and highly expanding foams with superior mechanical properties. In order to overcome the temperature mismatch between TiH2's decomposition and Al's melting point, Al foam's chemistry was modified in this work by alloying it with small amounts of Sn (≤ 5 wt.%).  The roles of Sn in the foaming process of Al are found to be  (i) improving integrity of the powder mixture during hot compaction due to Sn's low melting temperature, (ii) controlling of gradual decomposition of the TiH2 and (iii) decreasing surface tension of liquid Al, resulting in higher foam expansion even at lower foaming temperature (725 oC), and higher foam stability. Foam expansion and stability were further controlled by in-situ formation of intermetallic phases. Thermodynamic calculations made using FactSage thermodynamic software were used extensively to design foam alloys, and the foam alloys were thermally analyzed to build an understanding of the selected alloys' evolution during the foaming process. Five alloying elements (Co, Mg, Mn, Ni and Ti) were selected to change the foaming behavior of Al-3wt.% Sn alloy. Alloys based on these were designed (i) to enhance foam expansion (reaching higher maximum expansion) and/or (ii) to stabilize the foam (regularizing pore size and distribution) by forming an intermetallic phase during the foaming process. The mechanical properties of new Al-Sn based alloys are superior to conventional Al alloy foams. An improvement of energy absorption efficiency and capacity was observed with increasing amounts of alloying element (particularly at higher amounts of Ti, Mn or Ni). This is the result of the intermetallics formed by alloying elements in the cell walls. A model correlating stress-strain curves with the cell wall's fracture mode during compression testing was proposed.</description><creator>Aguirre Perales, Lydia</creator><contributor>Robin Drew (Supervisor2)</contributor><contributor>In-Ho Jung (Supervisor1)</contributor><date>2015</date><subject>Engineering - Materials Science</subject><title>On the stabilization of aluminum foams by tin additions and in situ intermetallic formation</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/g158bm335.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/fx719q266</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Mining and Materials</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:12579w29j</identifier><datestamp>2020-03-21T17:17:59Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Quantification of inhibitory appositions on pain-processing lamina I parabrachial projection neurons in a rat model of neuropathic painIntroduction: Pain information transmitted by primary afferent fibres from the periphery to the dorsal horn of the spinal cord is modulated by input from local inhibitory and excitatory interneurons and relayed to the brain. A state of reduced inhibition in the spinal cord has been implicated in the pain hypersensitivities associated with neuropathic pain (NP). A recent study from our lab showed a loss of GAD65 (glutamic acid decarboxylase) immunoreactive inhibitory boutons, in the superficial dorsal horn in a rat model of NP. The purpose of this study was to determine if there is a loss of GAD65+ terminals apposing on neurons expressing the substance P receptor (NK1) in lamina I of the dorsal horn which project to the lateral parabrachial nucleus (LPb).  Methods: The retrograde tracer choleratoxin B (CTB) was injected into the LPb of male Sprague-Dawley rats that received a unilateral chronic constriction (CCI) or sham injury of the sciatic nerve. Animals were tested weekly for nociceptive hypersensitivities.  Horizontal sections of lumbar spinal cord were stained for NK1, CTB and GAD65.  Neurons were imaged using a confocal microscope and density of GAD65 appositions was quantified. Results: CCI-operated animals developed mechanical and cold allodynia whereas sham operated controls did not. There was no significant difference between apposition density on NK1r+ lamina I parabrachial projection neurons in neuropathic compared to control animals. Neurons were re-analyzed after being classified into three morphological subclasses: fusiform, multipolar and pyramidal. Pyramidal projection neurons in lamina I had a significantly lower density of inhibitory appositions in cuff- as compared to sham-operated controls. There was no significant difference detected in fusiform or multipolar neurons.</description><description>Quantification des appositions inhibitrices sur les neurones nociceptifs de projection de la lamina I, dans un modèle de douleur neuropathique chez le ratIntroduction : L'information nociceptive transmise par les fibres afférentes primaires depuis la périphérie vers la corne dorsale de la moelle épinière où elle est modulée localement par des interneurones excitateurs et inhibiteurs  puis transmise au cerveau. Un état d'inhibition réduite dans la moelle épinière a été associé aux hypersensibilités nociceptives associées à la douleur neuropathique (NP). Une étude récente de notre laboratoire a montré une perte des boutons inhibiteurs immunoréactifs pour GAD65 (de l'acide glutamique décarboxylase), dans la corne dorsale superficielle dans un modèle de NP chez le rat. Le but de cette étude était de déterminer si une perte de boutons GAD65 positifs en apposition sur les neurones exprimant le récepteur de la substance P (NK1) de la lamina I de la corne dorsale qui se projettent vers le noyau parabrachial lateral (LPb). Méthodes : Le traceur rétrograde CTB (sous-unité B de la toxine cholérique) a été injecté dans le LPb de rats mâles Sprague-Dawley ayant subit une constriction chronique unilatérale (CCI) du nerf sciatique ou une chirurgie contrôle. Les animaux ont été testés chaque semaine pour les sensibilités nociceptives. Les sections horizontales de la moelle épinière lombaire ont été marquées pour NK1, CTB et GAD65. Les neurones ont été pris en photographie à l'aide d'un microscope confocal et la densité des appositions GAD65 a été quantifiée. Résultats : Les animaux CCI ont développé une allodynie mécanique et une allodynie au froid, alors que les animaux ayant subit une opération fictive contrôle ne l'ont pas. Aucune différence significative n'a pu être mise en évidence entre les animaux neuropathiques et contrôle concernant la densité des appositions sur les neurones NK1R + de lamina I projetant vers le LPb. Les données ont été analysées après avoir pris en compte les trois sous-types morphologiques de ces neurones, a savoir: fusiforme, multipolaire et pyramidale. Seuls les neurones pyramidaux de projection de la lamina I présentaient une densité d'appositions significativement plus faible chez les animaux cuff par rapport aux animaux contrôle. Aucune différence significative n'a pu être été décelée pour les neurones multipolaires et fusiformes.</description><creator>Nahas, Robert</creator><contributor>Alfredo Ribeiro Da Silva (Internal/Supervisor)</contributor><date>2015</date><subject>Biology - Neuroscience </subject><title>Quantification of inhibitory terminals apposing on lamina I spino-parabrachial projection neurons in a rat model of neurpathic pain</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/8w32r851k.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/12579w29j</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Integrated Program in Neuroscience</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:5q47rr89r</identifier><datestamp>2020-03-21T17:18:00Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>In this PhD thesis, stable carbon nanotube (CNT) colloidal suspensions, known as CNT nanofluids, were synthesized and studied for use in solar thermal energy harvesting applications. The production of a CNT nanofluid that is capable of remaining stable over long periods of time and at the high solar heating temperatures involves a multi-step process, which was developed, characterized and optimized in this thesis.  An inexpensive and scalable thermal chemical vapour deposition (t-CVD) process was used to produce CNTs directly from stainless steel mesh. It was found that the acetylene concentration within the t-CVD reactor during growth could be used as a way of controlling the average CNT diameter, with smaller diameter nanotubes being easier to break and remove from the substrate for nanofluid production. In addition this growth method generates an open porous network of CNTs that can then be easily surface-treated using a glow discharge plasma. Functionalization using an argon/oxygen/ethane gas mixture was found to graft oxygen-containing moieties (primarily carboxylic groups) to the surface of the CNTs, mostly likely through a sidewall defect-bonding process.Nanofluids produced with the functionalized-CNTs were quantitatively shown to remain stable in a number of polar base fluids, including water, alcohols and glycols. In particular, the CNT nanofluids using denatured alcohol and glycols as base fluids are stable over extended periods of time (currently tested up to 10 months at 20 °C), at high temperatures (up to 170 °C in glycols for 1 hour), and after repeated evaporation/condensation cycling (using denatured alcohol as base fluid). Optical absorbance measurements of the CNT nanofluids showed that for short collection depths (cm) only small amounts of CNTs (on the order of mg L-1) are required to obtain close to 100 % absorption of solar radiation (assuming no scattering). The unmatched stability of the CNT nanofluids, coupled with their strong broadband electromagnetic absorption properties make them ideal candidates for volumetric solar energy harvesting, and open the door to other interesting potential applications.</description><description>Cette thèse de doctorat porte sur la synthèse et la caractérisation approfondie de suspensions colloïdales stables contenant des nanotubes de carbone (NTC) – des nanofluides de NTC – et de leur usage potentiel comme fluides absorbeurs et caloporteurs de l'énergie solaire. La synthèse d'un nanofluide de NTC qui reste stable sous les conditions opératoires typiques des panneaux solaires thermiques, c.-à.-d. sur de longues périodes et à hautes températures, nécessitait le développement d'un nouveau procédé. Ce procédé intégré est décrit, caractérisé et optimizé dans cette thèse.  Un procédé de dépôt chimique en phase vapeur a été développé pour la synthèse directe de NTC sur des grillages fins d'acier inoxydable. Ce procédé s'avère économique et peut être mis à l'échelle. Il a été observé que la concentration du gaz d'acétylène présent dans le réacteur lors de la croissance des NTC peut être utilisée comme levier pour contrôler leur diamètre moyen; les plus petits NTC étant plus facilement cassés de la surface de croissance, ceux-ci sont donc préférés pour la synthèse de nanofluides. Cette technique de synthèse donne également lieu à des réseaux ouverts et poreux de NTC sur la surface du grillage et ainsi, à une fonctionnalisation chimique de surface aisée avec l'aide d'un plasma produit par une décharge électroluminescente. Des traitements par plasma soutenus dans des mélanges argon/oxygène/éthane donnent lieu à l'ajout sur la surface de NTC de fractions chimiques contenant de l'oxygène - des groupes fonctionnels carboxyles en majorité – fort probablement par l'intermédiaire de liaisons latérales sur les défauts des NTCs.Il a été démontré que les nanofluides de NTCs produits avec le nouveau procédé demeurent stables dans plusieurs liquides polaires (eau, glycols, alcools). En particulier, les nanofluides utilisant l'alcohol dénaturé et les glycols comme liquide de base demeurent stables sur de longues périodes (plus de 10 mois à 20 oC, jusqu'à présent), à haute température (jusqu'à 170 °C avec le glycol comme liquide de base et pour une heure), et même à la suite de nombreux cycles d'évaporation/condensation du fluide de base (alcool dénaturé). Les mesures d'absorbance optique des nanofluides de NTC ont montré qu'une absorption presque complète du spectre solaire (i.e. 100 %, en négligeant la diffusion de la lumière) peut être obtenue sur une courte distance (1 cm) avec une faible quantité de NTC (environ 1 mg L-1). La grande stabilité ainsi que la capacité à absorber les ondes électromagnétiques sur une plage large du spectre font des nanofluides de NTC des candidats idéaux à titre de fluides absorbeurs et caloporteurs pour les capteurs solaires thermiques, et pour bien d'autres applications potentielles.</description><creator>Hordy, Nathan</creator><contributor>Jean-Luc Meunier (Supervisor2)</contributor><contributor>Sylvain Coulombe (Supervisor1)</contributor><date>2015</date><subject>Engineering - Chemical</subject><title>Plasma functionalized carbon nanotubes suspensions for high temperature direct absorption thermal energy harvesting</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/76537401w.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/5q47rr89r</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Chemical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:4x51hn32f</identifier><datestamp>2020-03-21T17:18:01Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Software debugging is now widely reported to constitute the majority of software development time and cost, largely due to the effects of continuously rising software complexity. In a trend which is expected to continue, complex software faults that can require weeks to resolve are becoming increasingly commonplace. Since traditional debugging methods are considered unsuitable for resolving such faults, trace generation is being recognized as a solution to future debugging needs. This thesis presents trace generation infrastructure that includes advanced on-chip supporting hardware, complementary software tools, and interfaces to bridge the gap between them. The contributions enable or enhance the use of trace generation across a variety of software development platforms.Even though embedded software development is increasingly performed on software emulators, many existing emulators lack trace generation capabilities. This thesis provides the ubiquitous QEMU emulator with the ability to perform trace experiments. The described extensions enable continuous instruction-level trace generation to be controlled using a standard software debugger client, which is given the ability to create tracepoints to dynamically log registers and memory addresses. The infrastructure is made aware of operating system context-switching in a unique way, which allows traces to be collected in five different modes: from all executed code, down to a single Linux process.For hardware-based development platforms, the volume of on-chip trace data generated in real-time can exceed the ability to practically transfer or store it. This thesis presents two different schemes for the compression of execution traces, which are vital in establishing the flow of software execution post-hoc. The Architecture-Aware Trace Compression (AATC) scheme eliminates previously unidentified redundancies within typical execution traces using a combination of on-chip predictors, transforms, and encoders. The scheme achieves the highest-performance compression of any similar method, most notably by exploiting the widespread use of linked branches, as well as the compiler-driven movement of return addresses between link-register, stack, and program counter. The Multi-Architectural Trace Compression (MATC) scheme is also introduced to compress the execution traces of any fixed instruction-width soft-core processor deployed on Field-Programmable GateArray (FPGA) platforms. A novel architecture is presented in which five parameterizable variants of a pipelined scheme allow different combinations of unused logic and memory resources to be repurposed for trace compression purposes.</description><description>Le déboguage est désormais largement reconnu comme la tâche coûtant le plus cher et prenant le plus de temps de développement dans le contexte de projets logiciels. Cela est fortement lié à l'augmentation de la complexité de ce type de projet. Il arrive de plus en plus souvent que la correction de défauts logiciels complexes prenne plusieurs semaines, et cette tendance s'accentue avec le temps. Puisque les méthodes de déboguage traditionnelles ne permettent plus de résoudre ces défauts, de nouvelles méthodes comme la génération de traces sont proposées pour la résolution des bogues modernes. Cette thèse propose une infrastructure de génération de traces incluant une portion matérielle avancée, des outils logiciels complémentaires, ainsi que des interfaces servant à lier ces deux éléments. Ces contributions permettent ou améliorent l'utilisation de la génération de traces à travers diverses plates-formes de développement logiciel.Malgré que le développement de logiciels embarqués soit de plus en plus effectué à l'aide de logiciels d'émulation, ces logiciels sont souvent incapables d'effectuer la génération de traces. Cette thèse présente un ajout à l'émulateur QEMU permettant la génération de traces. Les extensions proposées permettent de générer des traces d'instructions en continu, et ce à l'aide d'un débogueur logiciel standard. Ce débogueur est doté de la capacité de créer des points de traçage pour enregistrer les registres et les adresses mémoire de façon dynamique. Cette infrastructure est de plus prévenue des changements de contexte effectués par le système d'exploitation grâce à une approche unique qui permet de récolter les traces selon cinq modes différents (soit pour tout le code exécuté, soit de façon graduellement plus précise jusqu'à ne retenir qu'un seul processus Linux).Pour les plates-formes de développement matériel, le volume de données associé aux traces générées sur la puce en temps réel peut dépasser la capacité de transfert ou d'enregistrement disponible. Il est donc essentiel de compresser ces données pour permettre de reconstituer le fil de l'exécution du logiciel après coup. Deux approches sont présentées pour la compression des traces d'exécution. L'approche de Compression de Traces Basée sur l'Architecture (AATC) élimine certaines redondances qui étaient auparavant ignorées au sein de traces d'exécution typiques grâce à une combinaison de prédicteurs matériels, de transformées et d'encodeurs. Cette méthode permet d'obtenir une compression supérieure à toutes les méthodes comparables, notamment en tirant profit de l'ubiquité des points de branchage liés ainsi que du déplacement des adresses-retour entre le registre-retour, la pile, et le compteur d'instructions. La seconde approche appelée Compression de Traces Multi-Architecture (MATC) permet quant à elle de compresser les traces d'exécution de tout processeur soft-core utilisant des instructions à taille fixe et déployé sur un circuit logique programmable (FPGA). L'architecture proposée comporte cinq variantes qui permettent divers niveaux de réappropriation des circuits logiques et des ressources mémoire inutilisés pour la compression de traces.</description><creator>Mihajlovic, Bojan</creator><contributor>Warren Gross (Supervisor2)</contributor><contributor>Zeljko Zilic (Supervisor1)</contributor><date>2015</date><subject>Engineering - Electronics and Electrical</subject><title>Enhancing trace generation-based software debugging infrastructure for physical and emulated development platforms</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/np193c889.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/4x51hn32f</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:8623j200g</identifier><datestamp>2020-03-21T17:18:01Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>CONTEXTE  L'Organisation mondiale de la santé (OMS) recommande le déparasitage de masse à partir de l'âge de 12 mois dans les zones où l'infestation par les helminthes transmis par le sol (HTS) est endémique. Par contre, les données sur les avantages pour les enfants âgés de moins de deux ans sont limitées et la couverture n'est pas optimale. Cet âge correspond à une période critique pour l'intervention afin de promouvoir la santé et prévenir la malnutrition à court terme ainsi qu'à long terme. Par conséquent, l'objectif de cette étude était de démontrer l'effet d'une intervention de déparasitage, y compris la fréquence et les moments optimaux, et sur la croissance et le développement des enfants âgés entre 12 et 24 mois. MÉTHODES  Un essai contrôlé randomisé à double insu a été mené à Iquitos, au Pérou, sur le déparasitage. Des enfants de 12 mois ont été inscrits aux centres de santé pendant leurs visites de routine et des suivis ont eu lieu lors de leurs visites à 18 mois et à 24 mois. L'assignation aléatoire était faite à l'un des quatre groupes d'interventions : 1) déparasitage à 12 mois et placébo à 18 mois ; 2) placébo à 12 mois, déparasitage à 18 mois ; 3) déparasitage à 12 mois et à 18 mois ; ou 4) placébo à 12 mois et à 18 mois. À chaque visite, le poids, la longueur, la présence d'infection HTS, et l'information sociodémographique et épidémiologique ont été notés. Le développement a été évalué à l'inclusion et à la visite à 24 mois. Des analyses de variance ANOVA ont été utilisées avec une approche intention de traiter, et l'imputation multiple pour les valeurs manquantes. Des analyses ajustées, ‘complete case', ‘per protocol' et de sous-groupes ont également été menées.  RÉSULTATS  Entre septembre 2011 et juin 2012, 1760 enfants ont été inclus. À l'inclusion, la prévalence de HTS était de 14,5%, le retard de croissance était de 24,2%, et l'insuffisance pondérale était de 8,6%. Un total de 1563 enfants (88,8%) ont assisté à la visite de 24 mois. Entre 12 et 24 mois, la prévalence d'infection HTS a augmenté jusqu'à 42,6%, le retard de croissance a augmenté à 46,8%, et l'insuffisance pondérale a augmenté à 10,2%. Le groupe de déparasitage à 12 mois seulement a démontré les plus grands gains de poids et de longueur. Aucun groupe n'avait de gains en croissance ou en développement plus élevés de manière significative que le groupe placébo à 12 mois et à 18 mois. Par contre, pour les enfants qui ont été déparasités à 12 mois, comparé aux enfants déparasités à 18 mois, il y avait un effet statistiquement significatif sur le gain de poids (différence non-ajustée en kg (IC95) : 0,12 (0,01, 0,23)) et de longueur (différence non-ajustée en cm (IC95) : 0,31 (0,04, 0,58)). CONCLUSION  En conclusion, il n'y avait aucun avantage statistiquement significatif de déparasitage sur la croissance de cette population d'enfants d'âge préscolaire. Cependant, les résultats indiquent que, pour les enfants âgés entre 12 et 24 mois, un déparasitage unique à 12 mois offre les plus grands bénéfices de la croissance par rapport à plus tard ou de déparasitage plus fréquente. Une amélioration des effets peut être apparente dans les zones de prévalence ou l'intensité de l'infection plus élevé. Ces résultats contribuent aux données probantes à l'appui des politiques et recommandations de l'OMS sur le déparasitage d'enfants d'âge préscolaire dans les zones endémiques. Ils contribuent aussi des renseignements pratiques pour guider les gouvernements qui se chargent d'intégrer le déparasitage dans leurs programmes de santé de l'enfant.</description><description>BACKGROUND   The World Health Organization recommends mass deworming in soil-transmitted helminth (STH)-endemic areas as of 12 months of age; however, evidence of benefits in children under two years of age is limited and coverage remains suboptimal. This age corresponds to a critical window to intervene and prevent poor health and malnutrition in the short- and long-term. Therefore, the objective of this study was to determine the effect of a deworming intervention, including optimal timing and frequency, on growth and development in children from 12 to 24 months of age. METHODS   A double-blind randomized controlled trial of deworming was conducted in Iquitos, Peru. Children were enrolled during their routine 12-month clinic visits in study health centres and followed-up at their 18- and 24-month visits. Random assignment was to one of four groups: 1) deworming at the 12-month visit, placebo at the 18-month visit; 2) placebo at the 12-month visit, deworming at the 18-month visit; 3) deworming at both the 12- and 18-month visits; or 4) placebo at both the 12- and 18-month visits. Weight, length, STH infection, and socio-demo-epi information were ascertained at all visits. Development was assessed at baseline and the 24-month visit. One-way ANOVA analyses used an intention-to-treat approach with multiple imputation for missing values. Adjusted, per-protocol, complete case and subgroup analyses were also conducted. RESULTS   A total of 1760 children were enrolled between September 2011 and June 2012. At baseline, the prevalence of any STH was 14.5%, stunting was 24.2% and underweight was 8.6%. A total of 1563 (88.8%) children attended the 24-month visit. Between 12 and 24 months, STH infection prevalence rose to 42.6%, stunting increased to 46.8% and underweight increased to 10.2%. The greatest gains in weight and length were observed in the deworming-at-12-months-only group. No group had gains in growth or development statistically significantly higher than the placebo group; however, there was a statistically significantly greater improvement in weight gain (unadjusted difference in kg (95% CI): 0.12 (0.01, 0.23)) and length gain (unadjusted difference in cm (95% CI): 0.31 (0.04, 0.58)) in children receiving deworming at the 12-month visit compared to the 18-month visit.CONCLUSION   Overall, there was no statistically significant benefit of deworming on growth in this population of preschool-age children. However, the results do indicate that, for children between 12 and 24 months of age, once-yearly deworming at 12 months of age provides the greatest growth benefits compared to later or more frequent deworming. A greater benefit may be apparent in areas of higher prevalence or intensity of infection. These results contribute to WHO policy and recommendations on deworming targeting preschool-age children in the over 100 STH-endemic areas of the world. They also contribute to providing practical guidance to governments in integrating deworming into early childhood health care.</description><creator>Joseph, Serene</creator><contributor>Theresia Gyorkos (Supervisor)</contributor><date>2015</date><subject>Health Sciences - Epidemiology</subject><title>Improving early childhood growth and development in low- and middle-income countries: a randomized controlled trial of deworming incorporated into routine child health care in Peru</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/tx31qm87b.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/8623j200g</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Epidemiology and Biostatistics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:br86b6463</identifier><datestamp>2020-03-21T17:18:02Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>This thesis focuses on classifying faces, specifically facial traits (attributes) and head pose, in fully unconstrained real-world videos. Recent literature shows that these facial classes can be beneficial for improving the performance of real-world applications, such as face recognition and verification. How to robustly obtain these facial classes is still an open problem, especially in the presence of the challenges of real-world environments: non-uniform illumination conditions, arbitrary occlusions, face scales, motion blur and background clutter. Thus, we propose a hierarchical temporal probabilistic graphical model which resolves the class ambiguity by enforcing consistency in feature and class level beliefs over a video sequence. This model is a general formulation, so that it can use different types of features and can be adapted to different face related inference tasks. It does feature and classifier level fusion as well as spatial and temporal modeling of the facial class. As output, the model provides a probability distribution function (PDF) over the possible values of the facial class of interest for each video frame. Further contributions of this thesis are: (i) collecting unconstrained challenging McGillFaces [1] database, which is now publicly available, (ii) proposing a fully automatic face tracking/localization framework, and (iii) introducing a semi-automatic framework which reduces the time of manual head pose labeling. In this thesis, a comprehensive set of experimental results are provided. The experiments performed on the McGillFaces database show that the proposed face tracking framework leads to an increase of 36% in the face localization performance compared to solely employing a well-known real-world face detector over each video frame. The proposed semi-automatic pose labeling framework achieves a labeling accuracy of 96.98% when only 30% of video frames are manually labeled. The proposed facial trait classifier is shown to outperform the current state-of-the-art approaches by 9.44% for gender classification, and by 10.13% for facial hair classification tasks. Furthermore, the proposed head pose estimation model outperforms the next closest competitor by 13.87% and 19.89% when McGillFaces and Multi-PIE [2] databases are used, respectively. Lastly, it is shown that incorporating the head pose information into the proposed trait classification model leads to superior results on challenging McGillFaces database compared to alternative approaches: 100% and 98.33% for gender and facial hair classification tasks, respectively.</description><description>Cette thèse porte sur la classification de visages, en termes de leurs traits (attributes) et de leur pose, à partir de vidéos réelles acquises en environnement non-contraint. La littérature démontre qu'une telle classification des visages peut améliorer la performance pour certaines applications, comme la reconnaissance de visages et la vérification d'identité. La méthode permettant de départager ces classes avec robustesse demeure inconnue, en particulier lorsque l'image est tirée d'un environnement réel, en présence de conditions d'éclairage non-uniformes, d'occlusions arbitraires, de multiples échelles de visage, d'un flou de mouvement ou d'un arrière-plan complexe. Par conséquent, nous proposons un modèle statistique graphique, hiérarchique et temporel qui tente de résoudre l'ambiguïté inter-classe en imposant une cohérence dans la classification (degrés d'appartenance), tout au long d'une séquence vidéo. Ce modèle est une formulation générale, de sorte qu'il peut utiliser différents types de caractéristiques et peut être adapté à différentes tâches liées à l'inférence de visages. Il permet la fusion, tant au niveau des caractéristiques que du classificateur, ainsi qu'une modélisation spatiale et temporelle des classes de visages. En guise de sortie, le modèle fournit la densité de probabilité (PDF) pour toutes les valeurs de classes considérées, et ce, pour chaque image de la séquence vidéo. Cette thèse a notamment contribué par (i) l'élaboration et le partage d'une base de données d'images non-contraintes de visages (McGillFaces [1]), (ii) le développement d'un environnement complètement automatisé pour le suivi et la localisation de visages et finalement par (iii) l'introduction d'un environnement semi-automatique qui réduit le temps de classification manuelle de la pose du visage. Un ensemble complet de résultats expérimentaux qualitatifs et quantitatifs est fourni. Les expériences réalisées sur la base de données McGillFaces démontrent que la méthode proposée pour le suivi du visage conduit à une augmentation de 36% de la performance de localisation par rapport à l'utilisation d'un algorithme de détection du visage bien connu sur chaque image de la vidéo. L'outil semi-automatique pour la classification de la pose du visage proposé admet une précision de 96,98% alors que seulement 30% des trames vidéo sont étiquetés manuellement. Les performances du classificateur proposé pour les traits du visage surpasse l'état de l'art de 9,44% pour la classification du genre, et de 10,13% pour la classification de la pilosité faciale. De plus, le modèle d'estimation de la pose surpasse le plus proche concurrent de 13,87% et 19,89% respectivement, lorsque les banques d'images McGillFaces et Multi-PIE [2] sont utilisés. Enfin, il a été démontré que l'ajout de l'information de pose dans le modèle de classification de trait du visage proposé conduit à de meilleurs résultats sur la base de données McGillFaces par rapport à d'autres approches, soit 100% pour le genre et 98,33% pour la présence de pilosité faciale.</description><creator>Demirkus Brandlmaier, Meltem</creator><contributor>Tal Arbel (Supervisor1)</contributor><contributor>James J Clark (Supervisor2)</contributor><date>2015</date><subject>Engineering - Electronics and Electrical</subject><title>A hierarchical temporal probabilistic graphical model for labeling and classifying faces in real-world videos</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/d791sk305.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/br86b6463</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:qr46r411m</identifier><datestamp>2020-03-21T17:18:03Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Agility - the capability of organizations to sense and respond to market opportunities and threats with speed and surprise - is quickly becoming an essential element for companies to effectively compete in hypercompetitive environments. At the same time, firms are using applications that enable close integration among organizational units. Current environment necessitates that firms pursue agility as well as tight integration. However, we still do not understand how integration affects agility. Although the literature suggests that integration enables digital options that facilitate agility, it is not clear what specifically those digital options are and how do they inform the integration-agility relation. Using coordination theory, this thesis argues that integration enables coordination among internal functions of a business unit and with external partners which facilitates business unit agility. Specifically, we argue that integration allows advanced structuring through process coupling and dynamic adjustment through knowledge flow which, in turn, enable the two agility capabilities of sensing and responding. This thesis contributes by opening up the black-box of the mediating variables that inform the integration-agility relation. We argue that the mediating variables of knowledge exploitation, knowledge exploration, and internal and external process coupling play a crucial role in this relation. Overall, this thesis contributes to the integration-agility relation by answering the following questions: (1) what is the effect of internal and external electronic integration on the sensing and responding capabilities of business units? (2) what is the role of knowledge leveraging and process coupling constructs in the relation between electronic integration and sensing and responding capabilities of business units? The model is tested with 303 business managers responsible for handling business unit operations of manufacturing organizations. Support was found for nine out of ten hypotheses which primarily argue that integration within business units and with outside partners leads to business units' increased capability to have advanced structuring internally and externally of the value chain. Moreover, they lead to increased capability to have dynamic adjustment within and outside the value chain. Both, advanced structuring and dynamic adjustment, lead to higher capability to sense change in the business environment and respond to it with agility.</description><description>Agilité - la capacité des organisations à déceler et à répondre aux opportunités commerciales et aux menaces du marché avec rapidité et surprise – est devenue rapidement un élément essentiel pour les entreprises qui évoluent dans des environnements hyper compétitifs. En même temps, les entreprises utilisent des technologies de l'information qui permettent une intégration étroite des unités et des processus de l'organisation. Cependant, nous ne comprenons toujours pas comment l'intégration influe sur l'agilité. Bien que la littérature suggère que l'intégration permette des options numériques qui facilitent l'agilité, il n'est pas clair à savoir quelles sont précisément ces options numériques et comment elles orientent la relation entre l'intégration et l'agilité. En utilisant la théorie de la coordination, cette thèse soutient que l'intégration permet la coordination entre les fonctions internes d'une unité d'affaires et avec des partenaires externes, ce qui facilite l'agilité de l'unité d'affaires. Plus précisément, nous soutenons que l'intégration permet de coupler les processus et favorise l'ajustement dynamique via la gestion des connaissances qui, à leur tour, facilitent les deux fonctionnalités de l'agilité : la détection et la capacité de réponse. Cette thèse contribue à ouvrir «la boîte noire» des variables médiatrices qui influencent la relation entre l'intégration et l'agilité. Nous soutenons que les variables médiatrices de l'exploitation et de l'exploitation des connaissances et du couplage des processus internes et externes jouent un rôle crucial dans cette relation. Cette thèse répond aux questions suivantes : (1) quel est l'effet de l'intégration électronique interne et externe sur les capacités de détection et de réponse des unités commerciales? (2) quel est le rôle que la gestions des connaissances et le couplage des processus d'affaires jouent dans la relation entre l'intégration électronique et les capacités de détection et de réponse des unités commerciales? Le modèle a été testé auprès de 303 gestionnaires d'entreprises manufacturières. Les résultats supportent neuf des dix hypothèses qui soutenaient essentiellement que l'intégration au sein des unités opérationnelles et avec des partenaires externes augmentent l'agilité organisationnelle.</description><creator>Nazir, Salman</creator><contributor>Alain Pinsonneault (Supervisor)</contributor><date>2015</date><subject>Business Administration - Management</subject><title>The effect of internal and external electronic integration on business unit agility</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/8w32r852v.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/qr46r411m</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Desautels Faculty of Management</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:mk61rm34w</identifier><datestamp>2020-03-21T17:18:04Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The aim of this thesis is to analyse the understanding of revolutionary violence as depicted in two canonical dramas of the German revolutionary theater: Georg Büchner's Dantons Tod and Ernst Toller's Masse Mensch. I argue that both Büchner and Toller approach the question of revolutionary violence symmetrically but from opposite angles: Büchner by questioning violence and Toller by questioning non-violence. In the first chapter, I outline Walter Benjamin's theory of the ‘real state of exception' in the context of his engagement with Carl Schmitt, as well as the relevant aspects of three canonic theories of revolutionary violence (Sorel, Merleau-Ponty, and Fanon), which I then apply to the representation of violence in Dantons Tod and Masse Mensch. In the second chapter I try to reconstruct the political views and the revolutionary background of the two authors. In the first part of the third chapter, I then interpret both Dantons Tod and Masse Mensch as a ‘real state of exception' according to Benjamin. In the second part, I then analyse the representation of revolutionary violence in both dramas with the help of the three theories of violence outlined. Among the different forms of revolutionary violence I examine are: the juxtaposition of force and power (Sorel), and progressive, regressive, internal and therapeutic violence (Merleau-Ponty, Fanon). The thesis concludes with a discussion of the utopia of non-violence as it is also depicted in both dramas.</description><description>L'objet du présent mémoire est l'analyse de la violence révolutionnaire dans les drames Dantons Tod de Georg Büchner et Masse Mensch d'Ernst Toller. Nous soutenons que Büchner et Toller abordent la question de la violence révolutionnaire de façon symétrique mais de deux angles opposés dans la mesure où Büchner remet en question la violence et Toller la non-violence. Dans le premier chapitre, nous reconstruisons le développement quasi-dialogique des théories de l'état d'exception de Carl Schmitt et de Walter Benjamin ainsi que du «vrai état d'exception» de Benjamin. De plus, nous exposons les aspects pertinents de trois théories de la violence (Sorel, Merleau-Ponty, Fanon) à l'aide desquels nous analysons la violence révolutionnaire dans les deux drames. Le deuxième chapitre porte sur les convictions politiques ainsi que sur l'expérience révolutionnaire de Büchner et de Toller. Dans la première partie du troisième chapitre, nous interprétons Dantons Tod et Masse Mensch comme de «vrais états d'exception». Dans la seconde partie, nous faisons l'étude comparée de la violence révolutionnaire dans les deux drames. Parmi les formes de violences auxquelles nous nous attardons se trouvent l'opposition entre la force et la violence (Sorel) ainsi que les catégories de la violence progressive, régressive, intestine et thérapeutique (Merleau-Ponty, Fanon).  Finalement, nous abordons l'utopie de la non-violence dans les deux œuvres.</description><creator>Gosselin, David</creator><contributor>Paul Peters (Internal/Supervisor)</contributor><date>2015</date><subject>Literature - Germanic</subject><title>Georg Büchner und Ernst Toller die revolutionäre gewalt in den «Dramen dantons tod und masse mensch»</title><language>ger</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/j6731697m.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/mk61rm34w</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of Languages, Literatures, and Cultures</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:70795b81b</identifier><datestamp>2020-03-21T17:18:05Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>This dissertation establishes a new chronology for the development of the detective figure in English literature. In opposition to the traditional view of detective literature as a nineteenth-century innovation, this study argues that the roots of the literary detective figure can instead be found considerably earlier, during the long eighteenth century (1688-1832). As rationalist scientific knowledge increased during the Enlightenment, people no longer believed that an omniscient providence directly intervened in human affairs to detect criminal activity. During this period, providentially motivated criminal texts of the early modern period were gradually replaced by human-driven detective narratives.The first chapter examines how popular works about two real-life criminals contributed to the growth of detective fiction. The thief-taker Jonathan Wild (1683-1725) was depicted as both a criminal and a successful investigator who maintained methodical records and managed a network of deputies. The dual nature of Wild as a criminal and a detective would influence the portrayal of the detective as a potentially untrustworthy figure throughout the century. The prolific body of texts on the trial of Elizabeth Canning (1734-1773) highlighted the problem of evidence in criminal trials: through their consumption of these chapbooks and pamphlets, readers trained themselves to analyze texts critically and to perform detailed literary investigations.The second chapter analyzes the activities of two early fictional investigative figures: Emily St. Aubert of Ann Radcliffe's The Mysteries of Udolpho (1794) and Caleb Williams of William Godwin's Things as They Are; or, The Adventures of Caleb Williams (1794). Both of these novels feature proto-detective figures who actively investigate by collecting evidence, piecing together clues, and drawing conclusions based on the facts they have gleaned through these detective activities.The third chapter details the emergence of two literary detectives who appeared in novels near the end of the long eighteenth century. The anonymously published Richmond; or, Scenes in the Life of a Bow Street Officer, Drawn Up from his Private Memoranda (1827) was the first English novel to feature a professional detective as the main character. Edward Bulwer-Lytton's Pelham; or, The Adventures of a Gentleman (1828) introduced the first aristocratic detective in English literature, thus adding respectability to counteract the roguish origins and criminal connections of the detective figure.The conclusion details how this collection of foundational eighteenth-century narratives influenced the development of the mystery novel genre in the nineteenth and twentieth centuries. It considers how these early texts affected the depiction of a variety of later prominent detective characters, including Raymond Chandler's Philip Marlowe, Arthur Conan Doyle's Sherlock Holmes, Dashiell Hammett's Sam Spade, Carolyn Keene's Nancy Drew, and Dorothy L. Sayers's Lord Peter Wimsey.</description><description>Cette dissertation établit une nouvelle chronologie du développement des personnages ayant le rôle de détective dans la littérature anglaise. Contrairement à l'idée traditionnelle que le roman policier est une innovation du XIXe siècle, cette étude affirme que les fondements de la littérature policière apparaissent  beaucoup plus tôt, c'est-à-dire durant le XVIIIe siècle prolongé (1688-1832). Lors du développement des connaissances scientifiques rationnelles au cours du siècle des Lumières, les gens ne croyaient plus qu'une force omnisciente,  voire un dieu, intervenait dans les affaires humaines pour élucider l'activité criminelle. Les textes criminels du début de la période moderne, dans lesquels la Providence jouait un rôle, ont graduellement été remplacés par des narrations centrées sur l'humain.Le premier chapitre démontre la façon dont les oeuvres populaires au sujet de deux vrais criminels ont contribué au développement de ce genre de fiction en littérature. Le chasseur de primes Jonathan Wild (1683-1725), qui amenait les criminels devant la justice, est dépeint comme étant lui-même un criminel, mais il est également présenté comme un enquêteur renommé, qui conservait méthodiquement les archives et gérait tout un réseau d'adjoints. Les deux facettes contradictoires de Wild, lui-même criminel et détective, ont influencé la représentation du détective à travers le siècle. Il fut considéré comme une personne sur qui on ne devrait peut-être pas se fier. L'abondante collection de textes sur le procès d'Elizabeth Canning (1734-1773) souligne le problème des preuves dans les procès criminels: par la lecture de chapbook et de pamphlets, les lecteurs se sont entraînés à analyser les textes de façon critique et à mener une enquête littéraire détaillée.Le deuxième chapitre analyse les activités de deux personnages fictifs d'enquêteurs : Emily St. Aubert, dans The Mysteries of Udolpho (1794) par Ann Radcliffe, et Caleb Williams, dans Things As They Are; or, The Adventures of Caleb Williams (1794) par William Godwin. Ces deux romans présentent des prototypes de détectives qui enquêtent activement en recueillant des preuves, en rassemblant des indices et en tirant des conclusions basées sur les faits recueillis.Le troisième chapitre décrit l'émergence de deux personnages précoces de détectives fictifs qui sont apparus dans des romans de la fin du XVIIIe siècle prolongé. L'oeuvre anonyme Richmond; or, Scenes in the Life of a Bow Street Officer, Drawn Up from his Private Memoranda (1827) a été le premier roman anglais à présenter un détective professionnel comme personnage principal. Le roman Pelham; or, The Adventures of a Gentleman par Edward Bulwer-Lytton (1828) a créé le premier détective aristocrate de la littérature anglaise, faisant une césure avec les détectives du passé, à la morale douteuse et associés à la criminalité, rendant ainsi l'image du détective plus honorable.La conclusion explique comment cette collection de récits fondateurs du XVIIIe siècle ont influencé le développement du roman-mystère durant le XIXe et le XXe siècle. Elle détermine quels effets ces premiers textes ont eu sur la représentation d'une variété de personnages de détectives célèbres qui sont venus subséquemment, dont Philip Marlowe dans les romans de Raymond Chandler, Sherlock Holmes, décrit par Arthur Conan Doyle, Sam Spade de Dashiell Hammett, Nancy Drew par l'auteure Carolyn Keene, et Lord Peter Wimsey de Dorothy L. Sayers.</description><creator>Holland-Barnes, Joanne</creator><contributor>Peter Sabor (Supervisor)</contributor><date>2014</date><subject>Literature - English</subject><title>From providence to police: the development of the literary detective figure in the long eighteenth century</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/1c18dj656.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/70795b81b</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of English</discipline></degree></thesis></metadata></record><resumptionToken completeListSize="47894">oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):9675</resumptionToken></ListRecords></OAI-PMH>