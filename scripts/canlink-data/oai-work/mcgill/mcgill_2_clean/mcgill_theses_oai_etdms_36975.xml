<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/assets/blacklight_oai_provider/oai2-b0e501cadd287c203b27cfd4f4e2d266048ec6ca2151d595f4c1495108e36b88.xsl"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd"><responseDate>2020-07-25T03:29:29Z</responseDate><request resumptionToken="oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):36975" verb="ListRecords">https://escholarship.mcgill.ca/catalog/oai</request><ListRecords><record><header><identifier>oai:escholarship.mcgill.ca:5d86p453z</identifier><datestamp>2020-03-23T05:03:23Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Plusieurs modèles de récupération en mémoire proposent que le contexte d'une séquence est intégré aux représentations planifiées lors de la production de cette séquence.  Les erreurs d'ordre sériel, où des évènements corrects sont produits aux mauvais endroits dans la séquence, démontrent que l'accès à de multiples éléments dans une séquence se fait simultanément.  La production de séquences musicales remet en question les modèles de planification qui se basent sur le contexte.  Les relations contextuelles entre les évènements d'une séquence musicale pourraient améliorer la planification et la récupération des séquences, ce qui contredit l'idée que de longues séquences nuisent à la mémoire.  Nous avons testé les prédictions du Range Model (Palmer &amp; Pfordresher, 2003; Pfordresher et al., 2007), un modèle formel de récupération contextuelle, concernant les effets du contexte sur la planification de séquences musicales.  Vingt-six pianistes expérimentés ont pratiqué de nouveaux extraits musicaux qui étaient placés dans des contextes longs et courts, jusqu'à ce qu'ils atteignent une performance sans erreurs.  Ensuite, ils ont joué les séquences à des tempos rapides et modérés, qui ont été choisis pour induire des erreurs.  Pour les contextes longs, les erreurs dans l'ordre sériel des notes étaient associées à de plus grandes distances entre les évènements en question dans la séquence, ainsi qu'à des évènements similaires au niveau métrique.  Ces résultats confirment les prédictions du Range Model.  Les contextes longs, comparés aux contextes courts, augmentaient également l'effet du tempo sur le taux d'erreur.  Ces résultats suggèrent que les contextes longs facilitent la planification de séquences en augmentant la saillance des relations hiérarchiques entre les évènements, ce qui permet aux pianistes de planifier de plus longues étendues d'évènements dans la séquence.  L'avantage que ces contextes longs apportent à la planification d'évènements appuie les modèles incrémentiels, et nuance les théories qui considèrent l'information contextuelle comme étant nuisible à la récupération.  Dans le domaine de la performance musicale, les contextes longs peuvent faciliter la planification de séquences en renforçant les associations entre les évènements proches et similaires.  Ceci est conforme aux théories contextuelles de mémoire pour les hauteurs musicales. </description><description>Many models of memory retrieval assume that events in a sequential context are incorporated in planned representations during sequence production.  Serial ordering errors, in which correct events are produced in incorrect sequence positions, offer evidence for the simultaneous accessibility of sequential elements.  Musical sequences pose a challenge to contextual models of planning; contextual relationships among events in music may enhance sequence planning and retrieval, contrary to traditional effects of list length on forgetting.  We tested predictions of the range model (Palmer &amp; Pfordresher, 2003; Pfordresher et al., 2007), a formal contextual model of retrieval, regarding the effects of sequential context on event planning in music performance.  Twenty-six skilled pianists practiced novel musical excerpts that were embedded in large and small musical contexts until they achieved an error-free performance, and subsequently performed the sequences at fast and moderate tempi, chosen to elicit errors.  Serial ordering pitch errors tended to arise from greater sequential distances and from more metrically similar events when excerpts were placed in larger contexts, as predicted by the range model.  Large contexts also enhanced the effect of tempo on error rates in the excerpt, relative to small contexts.  These findings suggest that larger contexts facilitate sequence planning by increasing the salience of hierarchical event relationships, making it possible for performers to prepare larger ranges of contextual events.  Advantages conferred on sequence planning by larger contexts support incrementality models and qualify theories in which contextual information is viewed as always detrimental to remembering.  In music performance, larger contexts may facilitate planning by strengthening associations among proximal and similar sequence elements, consistent with contextual theories of pitch memory.</description><creator>Mathias, Brian</creator><contributor>Caroline Palmer (Internal/Supervisor)</contributor><date>2011</date><subject>Psychology - Cognitive</subject><title>Effects of context on memory retrieval in music performance</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/6m311t532.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/5d86p453z</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Psychology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:f7623h71d</identifier><datestamp>2020-03-23T05:03:23Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Cette thèse se fonde sur la littérature existante de la représentation de circonscription électorale (ou la représentation dyadic) qui évalue comment étroitement les élus représentent les avis de leurs constituants dans leurs rôles officiels. Tandis que beaucoup de recherche a été complétée sur ce type de représentation dans des systèmes présidentiels, beaucoup a moins été complétée dans des systèmes parlementaires. Il y a les typiquement hauts niveaux de représentation de circonscription électorale dans des systèmes présidentiels, mais cela ne signifie pas qu'il n'y a aucune présence de cela dans des systèmes parlementaires. Après le design de recherche d'une étude de représentation de circonscription électorale complétée au niveau national au Canada qui a trouvé un peu d'évidence de ce type de représentation, cette étude cherche à reproduire cette étude au niveau provincial en Alberta pour voir si l'évidence peut être trouvée à ce niveau aussi, ajoutant ainsi à la littérature comparative plus large sur la représentation de circonscription électorale.</description><description>This thesis builds on the existing constituency representation (or dyadic representation) literature that assesses how closely elected officials represent their constituents' views in their official roles. While much research has been completed on this type of representation in presidential systems, much less has been completed in parliamentary systems. There are typically high levels of constituency representation in presidential systems, but that does not mean that there is no presence of it in parliamentary systems. Following the research design of a study of constituency representation completed at the national level in Canada that found some evidence of this type of representation, this study seeks to replicate that study at the provincial level in Alberta to see if evidence can be found at that level also, thus adding to the broader comparative literature on constituency representation.</description><creator>Volker, Derek</creator><contributor>Dietlind Stolle (Internal/Supervisor)</contributor><date>2011</date><subject>Political Science - General</subject><title>Constituency representation in parliamentary systems: an examination of evidence in the Legislative assembly of Alberta</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/bn999b84g.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/f7623h71d</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of Political Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:dn39x534s</identifier><datestamp>2020-03-23T05:03:23Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Principalement fondée par le travail de George Gerber, mais aussi présente dans celui de d'autres théoriciens médiatiques incluant John Berger, Roland Barthes et Michael Hoechsmann, cette thèse a pour but d'explorer le concept des médias comme pédagogie publique. Fondé sur ces théories, une analyse approfondie des publicités produites par les fournisseurs de produits en téléphonie mobiles et leurs effets sur la jeune génération dans le cadre du nouveau phénomène de cyber intimidation sera examinée.Ensuite, par l'entremise de travaux et d'écrits de pédagogues critiques tels que Paulo Freire, Henry Giroux, Shirley Steinberg, Joe Kincheloe et Donaldo Macedo, une approche d'éducation médiatique sera présentée, ce qui a pour but de donner plus de pouvoir aux jeunes en leur permettant d'examiner d'une façon critique les médias conçus de leur consommation.</description><description>Partially grounded in the work of George Gerbner, and also in other media theorists including John Berger, Roland Barthes and Michael Hoechsmann, this thesis aims to explore the concept of media as public pedagogy.  Based on these theories, an in-depth analysis of the advertisements produced by cellular goods and service providers and their effect on the youth generation with respect to the relatively new phenomenon of cyber-bullying will be examined.  Then, through the works and writings of critical pedagogues including Paulo Freire, Henry Giroux, Shirley Steinberg, Joe Kincheloe and Donaldo Macedo, a media literacy approach to education will be introduced which aims to empower youth by enabling them to critically examine the media designed for their consumption.</description><creator>Sportun, Jaime</creator><contributor>Michael Hoechsmann (Internal/Cosupervisor2)</contributor><contributor>Shirley Steinberg (Internal/Supervisor)</contributor><date>2011</date><subject>Education - Curriculum and Instruction</subject><title>Advertising as a pedagogy? using literacy and critical pedagogy to empower youth</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/c821gq06p.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/dn39x534s</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of Integrated Studies in Education</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:6395wc65m</identifier><datestamp>2020-03-23T05:03:24Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Most of the current optimization techniques for the design of light-weight structures are unable to generate structural alternatives at the concept stage of design. This research tackles the challenge of developing methods for the early stage of design involving structures made up of conventional materials and composite laminates. For conventional materials, the recently introduced shape transformer approach is used. This work extends the method to deal with the case of torsional stiffness design, and generalizes it to single and multi-criteria selection of lightweight shafts subjected to a combination of bending, shear, and torsional load. The prominent feature of the work is the useful integration of shape and material to model and visualize multi-objective selection problems. The scheme is centered on concept selection in structural design, and hinges on measures that govern the shape properties of a cross-section regardless of its size. These measures, referred to as shape transformers, can classify shapes in a way similar to material classification. The procedure is demonstrated by considering torsional stiffness as a constraint. Performance charts are developed for both single and multi-criteria cases to let the reader visualize in a glance the whole range of cross-sectional shapes for each material. Each design chart is explained with a brief example. The above mentioned approach is also extended to incorporate orthotropic composite laminates. Design charts are obtained for the selection of five generic design variables: shape, size, material, layup, and number of plies. These charts also aid in comparing the performances of two commonly used laminates in bending and torsion - angle plies and cross plies. For a generic composite laminate, due to the number of variables involved, these kinds of design charts are very difficult. However, other tactics like using an analytical model for function evaluation can be used at conceptual stage of design. This is demonstrated with the example of a helicopter wing spar made up of composite laminates. The objective is to select the optimum shape and layup which perform best with respect to three conflicting criteria: mass, torsional-bending coupling, and location of mass center and aerodynamic center. The formulation is based on Kollar's methodology. The three-dimensional Pareto front obtained is mapped on to two dimensions for better visualization using contour representation.</description><description>La plupart des méthodes d'optimisation qui existe actuellement pour la fabrication des structures légères sont incapables de générer des structures alternatives au début de la conception. Cette étude cherche à démontrer les difficultés qui existent au début de la conception et propose des solutions en se servant des matériaux conventionnels et des composites laminés.Pour des matériaux conventionnels, la nouvelle méthode de « shape transformers » a été utilisée. Dans cette étude, la méthode traditionnelle a été modifiée et inclus un modèle de rigidité pour la torsion et ainsi généralise cette méthode afin qu'on puisse l'utiliser pour la sélection (simple ou multiples) des arbres légères soumis a une combinaison des forces de flexion, de cisaillement et de torsion. L'aspect important de ce projet démontre l'intégration de la forme ainsi que le matériel sur le modèle afin qu'on puisse visualiser la sélection des problèmes a objectif multiples. Le projet se centralise sur un concept qui facilite la sélection des structures de fabrication, et dépend sur des mesures  qui contrôlent les propriétés de la forme de la section quelle que soit la dimension. Cette mesure plus connu comme la méthode de « shape transformers » peut servir a classer la forme comparable au classement des matériaux. Cette méthode est démontrée en incluant la rigidité pour la torsion comme une restriction. Des tableaux qui comprennent la performance pour le cas simple ou multiples sont présentés afin qu'on puisse visualiser un rayon de section pour chaque matériel. Chaque tableau est expliqué par un bref exemple.La méthode susmentionnée à aussi été prolongé pour inclure des composites laminés orthotropes. Des tableaux de conception  à été conçu afin de pouvoir sélectionner parmi les cinq paramètres : la forme, la dimension, le matériel, le « layup » et le nombre de nappes. Ces tableaux peut aussi servir à comparer la performance de deux laminés commun en flexion ou en torsion notamment le « angle-plies » et le « cross-plies ». Pour des composites laminés génériques, il est difficile de concevoir ce genre de tableau à cause des nombres de paramètres qui existent. Mais il existe d'autres méthodes analytiques qu'on peut utiliser au début de la conception. Ceci est démontré par l'exemple d'un longeron d'aile pour un hélicoptère fait avec des composites laminés. Le but est de pouvoir sélectionner la forme et le « layup » optimale avec la performance maximale à l'égard de trois critères contradictoires notamment : la masse, l'accouplement des forces de flexion et de torsion, l'emplacement de la masse et l'emplacement du centre aérodynamique. La formulation est basée sur la méthode de  Kollar. Le front Pareto en trois dimensions est ainsi projeté sur deux dimensions pour une visualisation plus facile en se servant d'une représentation contour.</description><creator>Singh, Jasveer</creator><contributor>Damiano Pasini (Internal/Supervisor)</contributor><date>2011</date><subject>Engineering - Mechanical </subject><title>Multi-objective selection and optimization of shaped materials and laminated composites</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/rb68xh173.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/6395wc65m</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Mechanical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:p26770734</identifier><datestamp>2020-03-23T05:03:24Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The objective of the present thesis was to determine whether an oral nutrition support regimen based on pressurized whey protein isolate and glucose improves the postoperative utilization of amino acids compared to glucose alone. Patients undergoing colorectal surgery were randomly assigned to receive an oral nutrition support regimen based on pressurized whey protein isolate and glucose or glucose alone. Leucine kinetics, serum hormone and substrate concentrations, resting energy expenditure and substrate utilization were measured before surgery and two days after surgery. The baseline characteristics of the two groups were similar before surgery. Postoperative leucine balance increased in the fed state in both groups but the change in leucine balance was significantly greater in the whey protein-based group. Only the whey protein-based group achieved positive leucine (protein) balance, which was attributed to greater suppression of protein breakdown. Protein synthesis was not affected by feeding or by nutrition regimen. Serum glucose and insulin increased in the fed state but patients in both groups remained normoglycemic. Fasting cortisol, total protein and albumin decreased after surgery in both groups. Postoperative oxygen consumption, carbon dioxide production and respiratory quotient increased in both groups in the fed state; diet group did not affect the calorimetry parameters.  Oral nutrition support based on pressurized whey protein isolate may help to avoid complications associated with postoperative body protein losses and hyperglycemia. Future research should focus on a direct comparison between oral and parenteral nutrition support and the functional clinical impact of minimizing perioperative fasting by implementing this oral nutrition regimen in the immediate perioperative period.</description><description>L'objectif de la présente étude était à déterminer si un régime nutritif oral à base de protéines lactosérum traitée sous pression  et glucose améliore l'utilisation post-opératif des acides aminées a comparé au glucose seul. Des patients subissant une intervention chirurgicale colorectale étaient assignés de façon aléatoire à recevoir un régime orale nutritif à base du glucose seul ou à base de protéines lactosérum traitées sous pression et glucose. Les paramètres suivants étaient quantifiées avant l'intervention et deux jours après l'intervention : cinétiques de leucine, la concentration des hormones et soustrait dans le sérum, la dépense d'énergie à la détente, et l'utilisation de la soustrait. Les deux groupes étaient homogènes avant l'intervention chirurgicale. La balance de leucine post-opérative a augmenté dans l'état nourrie pour les deux groupes, mais l'augmentation était plus grande dans le groupe nourri des protéines lactosérum. Seul le groupe nourri des protéines lactosérum a réussi une balance positive de leucine (des protéines), ce qui est attribuable à l'augmentation de la suppression de la destruction des protéines. La synthèse des protéines n'a pas été affectée par l'alimentation ou par le régime nutritif. Les niveaux de glucose et d'insuline dans le sérum ont augmente dans les deux groupes même si les deux groupes se trouvaient normoglycémiques. Les niveaux à jeun de cortisol, de protéines totales, et de l'albumen ont descendu après l'intervention chirurgicale dans les deux groupes. Les paramètres VO2, VCO2 et QR post-opératives ont augmenté dans les deux groupes à l'état nourri; le régime nutritif n'a pas affecté les paramètres calorimétriques. Un régime nutritif oral à base de protéines lactosérum traitées sous pression peut aider à éviter les complications associées à la perte des protéines corporelles ainsi que l'hyperglycémie suivant une intervention chirurgicale. Les recherches futures devraient cibler une comparaison directe entre la nutrition orale et parentérale, afin de minimiser la période de jeun en implémentant ce régime nutritif oral dans la période périopératoire.</description><creator>Ball, Jennifer</creator><contributor>Stan Kubow (Supervisor2)</contributor><contributor>Linda J Wykes (Supervisor1)</contributor><date>2011</date><subject>Health Sciences - Nutrition</subject><title>Pressurized whey protein-based oral nutrition support promotes anabolism in surgical patients</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/c534fs776.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/p26770734</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Dietetics and Human Nutrition</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:vd66w394h</identifier><datestamp>2020-03-23T05:03:25Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Diéthylstilbestrol (DES), un perturbateur endocrinien, perturbe le fonctionnement physiologique des hormones stéroïdes endogène. L'ADN génomique est considérablement susceptible à la reprogrammation épigénétique durant le développement du fétus et donc l'exposition du fétus au DES in utero peut causer des changements épigénétiques en modifiant la methylation de l'ADN dans les régions promoteur des gènes. Le DES fut prescrit aux femmes enceintes exposant leur foetus et était utilisée en agriculture exposant le public général. Les cardiomyocytes des fétus, des nouveaux nés et des adultes expriment des récepteurs oestrogéniques suggérant que le DES peut influencer le cœur. De plus, les gènes qui contrôlent l'homéostasie du calcium dans les cardiomyocytes sont régulés par les récepteurs oestrogéniques et donc l'exposition au DES in utero pourrait causer des changements épigénétique  dans ces gènes.  Pour utiliser l'exposition environnementale des perturbateurs endocriniens come modèle, nous avons exposé des souris C57bl/6n enceinte au DES pendant les jours 11-14 de leur grossesse. Nous avons par la suite examiné la structure et le fonctionnement cardiaque, ainsi que l'expression des gènes qui contrôlent l'homéostasie du calcium dans le cœur. Notre hypothèse suggère que le DES modifie la structure et le fonctionnement cardiaque ainsi que l'expression des gènes qui contrôle l'homéostasie du calcium dans le cœur chez les souris adultes. L'exposition au DES pendant la grossesse a modifié le rapport de ratio de sexe et a induit des différences dans l'anatomie (poids et distance anogenital) entre les deux sexes. De plus, la structure et le fonctionnement du cœur ainsi que l'expression des gènes qui contrôlent l'homéostasie du calcium dans les souris sédentaires on été influencés par l'exposition au DES in utero. Les modifications des paramètres écho-cardiographiques et du profil d'expression des gènes qui contrôlent l'homéostasie du calcium dans les souris males exposées au DES qui ont nagé suggèrent que leur cœur n'a pas remodelé normalement et que les souris males ne pouvaient pas coopérer avec le stress physiologique de la natation autant que les souris femelles exposées au DES.</description><description>Diethylstilbestrol (DES), a potent endocrine disruptor, alters the physiologic function of endogenous steroid hormones. Moreover, the fetus is highly susceptible to epigenetic reprogramming and thus DES exposure in utero is thought to cause epigenetic changes by altering the methylation status of CpG islands in the promoter region of genes. DES was prescribed to pregnant women exposing the fetus and was used in agriculture exposing the general public. Fetal, neonatal and adult cardiomyocytes express estrogen receptors suggesting that DES might impact the heart. Furthermore, calcium-handling genes in cardiomyocytes are regulated by estrogen receptors and thus are subject to epigenetic changes following DES exposure in utero. As a prelude to exposure to environmental endocrine disruptors, we treated pregnant C57bl/6n mice with DES at gestational days 11-14 and examined cardiac structure/function and calcium handling gene expression in adult progeny. We hypothesized that gestational DES alters cardiac structure/function and expression of calcium handling proteins in cardiomyocytes. It was found that gestational DES exposure had an impact on sex ratio and exhibited sex specific differences on gross anatomy (body weight and anogenital distance) of male and female pups at weaning and at adulthood. Furthermore, in utero exposure to DES impacted cardiac structure/function and gene expression of sedentary C57Bl/6n mice in a sex dependent manner. The altered echocardiographic parameters and expression profile of calcium handling proteins of swim exercised DES treated males suggest that they did not remodel normally and could not cope with the physiological stress of swim exercise as well as DES treated females. </description><creator>Haddad, Rami</creator><contributor>Lorraine E Chalifour (Supervisor)</contributor><date>2011</date><subject>Biology - Physiology</subject><title>Gestational diethylstilbestrol impacts adult progeny heart structure, function and gene expression in mice</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/jd473140f.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/vd66w394h</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Medicine</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:wd3761830</identifier><datestamp>2020-03-23T05:03:25Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The objective of this study was to further characterize the inhibitory serum protein crisis form factor, or CFF, and identify candidate proteins responsible for CFF activity.  Four models for serum CFF induction were tested: C57BL/6 mice infected with P. chabaudi adami AS, C57BL/6 mice inoculated with BCG + LPS, and BALB/c mice infected with P. chabaudi adami DS or DK.  C57BL/6 mice infected with P. chabaudi adami AS produced sera with the most pronounced level of inhibitory activity and were used for CFF analysis.  Heat inactivation did not affect CFF activity, indicating the observed effect was not due to complement proteins, function was lost after heating serum to 100°C.  Gel filtration determined that CFF may be in the range of 20 kDa – 80 kDa.  Serum depletion by IgY retained CFF activity in the low abundance protein fraction (LAP), which was analyzed by MALDI and LC-QToF mass spectrometry and compared to the LAP from naïve mice.  A total of 68 proteins were identified as either up-regulated or unique to the CFF serum, and qualitative analysis revealed one potential CFF candidate: neutrophil gelatinase-associated lipocalin.  In conclusion, we have established a model for inducing serum CFF, characterized some of its physical properties, and through proteomic analysis identified a potential CFF candidate.</description><description>L'objectif de cette étude visait d'une part à approfondir la caractérisation du facteur de la forme de crise (CFF; « crisis form factor »), un facteur protéique inhibiteur présent dans le sérum, et d'autre part à identifier des protéines candidates responsable de l'activité de CFF.  Quatre modèles murins d'induction sérique du CFF ont été testés: des souris C57BL/6 infectées par la souche de P. chabaudi adami AS, des souris C57BL/6 inoculées avec BCG + LPS, et des souris BALB/c infectées respectivement avec les souches de P. chabaudi adami DS ou DK.  L'activité inhibitrice la plus prononcée a été observé à partir du sérum prélevé chez les souris C57BL/6 infectées par la souche de P. chabaudi adami AS. Le sérum issu de ce modèle a donc été utilisé pour la suite des analyses de CFF.  Nous avons déterminé que l'activité de CFF ne provient pas des protéines du complément et que CFF est inactivé lorsque le sérum est bouilli à 100oC.  Le fractionnement du sérum par chromatographie d'exclusion nous a permis de déterminer que CFF est éluée dans les fractions protéiques allant de 20 kDa  à  80 kDa.  Le sérum a ensuite été soumis à une colonne d'affinité IgY afin d'y dépléter les protéines majoritaires.  Suite à cette déplétion, nous avons déterminé que l'activité de CFF est préservée uniquement dans la fraction contenant les protéines sériques de faible abondance (LAP; « low abundance protein »).  Nous avons donc analysé la fraction LAP du sérum induit pour CFF par spectrométrie de masse de type MALDI et LC-QToF, puis comparé son profil protéique à celui de la fraction LAP de sérum issu de souris naïves.  Ces profils protéiques révèlent qu'un total de 68 protéines sont soit surexprimées, soit exclusives au sérum démontrant une activité CFF.  De plus, l'analyse qualitative nous a permis d'identifier une protéine candidate potentiel pour CFF : la gélatinase de neutrophile associée à la lipocaline (NGLA; « neutrophil gelatinase-associated lipocalin »).  En concluant, nous avons établi un modèle d'induction sérique de CFF, avons caractérisé certaines de ses propriétés physiques et avons identifié, par l'entremise de la protéomique, NGLA en tant que candidate potentielle de CFF.</description><creator>Geukers, Karen</creator><contributor>Timothy Geary (Supervisor)</contributor><date>2011</date><subject>Biology - Parasitology</subject><title>Characterization of CFF in the sera of plasmodium-infected mice</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/4q77fw73d.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/wd3761830</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Institute of Parasitology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:9306t332c</identifier><datestamp>2020-03-23T05:03:25Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>1-4% of pulse fractions including pea protein and fiber, chickpea and lentil flour as well as soy flour and protein concentrate were selected and characterized. As preliminary results the functional properties of pulse ingredients are varied upon their protein content and pH of the food carrier. Orange juice, apple juice, yogurt and two probiotic fermented milk were selected for supplementation. 1% and 2% pulse fractions gave comparable results in terms of turbidity, cloud and visual stability, color and sensory attributes for both orange and apple juices beverages. All supplements improved the acidification rate of yogurt and probiotic cultures, but the highest effects were obtained with probiotic supplementation with lentil and soy flour. As for the main study, skim milk (9.5 % w/v solid content) was supplemented with 1-3% (w/v) lentil flour, pea flour or skim milk powder and they were inoculated with yogurt starter cultures or probiotic (L. rhamnosus). Acid production during the fermentation, the pH, syneresis, color, rheological properties (dynamic oscillation temperature sweep test at 4-50 ˚C), and sensory properties (only for yogurt) were studied after production and 28 days of refrigerated storage.1-3% lentil and pea flour enhanced acid production during yogurt fermentation, but the microbial population (CFU) of both S. thermophilus and L. bulgaricus were in the same range in all lentil and pea flour and skim milk supplemented yogurts, after production. Pea flour supplementation enhanced survival of L. bulgaricus after storage. The pH decreased from 4.5 to 4.1 in lentil flour and from 4.5 to 3.75 in pea flour supplemented yogurts, after 28 days. Syneresis in 1-2% lentil and pea flour supplemented yogurts was higher than other samples. In lentil supplemented yogurts, "a" and "L" values did not significantly differ in all samples and remained constant after 28 days whereas, "b" value increased as a result of supplementation. Pea flour supplementation did not alter redness or greenness of yogurts, but the yellowness was significantly higher than other yogurts. Yogurt with 3% lentil and pea flour had higher storage (G΄) and loss (G˝) moduli in comparison with samples supplemented with 1-3% skim milk and the control yogurt. 1-2% lentil and pea flour supplemented yogurt showed comparable sensory properties in comparison with 1-2% skim milk supplemented and control samples.1-3% lentil and pea flour enhanced acid production during probiotic fermentation, and the CFU's of L. rhamnosus were comparable with non-supplemented control sample after production. After 28 days, the CFU`s of 2% and 3% lentil supplemented probiotic were as high as 1% skim milk supplemented sample and the CFU`s of 3% pea flour supplemented probiotic was the highest followed by 3-2% skim milk and 1-2% pea flour supplemented samples. The pH decreased from 4.50 to 3.90 for lentil flour supplemented probiotics and from 4.50 to 4.04 for pea flour supplemented probiotics, over 28 days. Syneresis in 1-3% lentil and pea flour supplemented probiotic was significantly lower than other samples. All lentil flour supplemented samples had significantly lower "L" values and higher "b" and "a" values in comparison with skim milk supplemented samples. Pea flour supplementation slightly changed the color which was not as light as skim milk supplemented samples and they showed more yellowness in final product after production and storage. Probiotic fermented milk with 1-3% lentil and pea flour showed higher G΄ and G˝ in comparison with other samples. </description><description>Des légumineuses  tels que des protéines et fibres de pois, farine de pois chiche, de lentille et de soja ont été sélectionnées et caractérisés. Des résultats préliminaires ont montré que des propriétés fonctionnelles ont variés  en fonction de la teneur en protéines et du pH des légumineuses employées. Du jus d'orange et de pomme, du yogourt et deux laits fermentés à l'aide de probiotiques ont été supplémentés avec les différentes légumineuses à des taux de 1 à 4%. Les supplémentations à 1 et 2% ont donné des résultats comparables en termes de turbidité, de stabilité, de couleur et d'attributs sensoriels pour les jus d'orange et de pomme. L'addition  de légumineuse a permis d'avoir une acidification plus rapide dans les yaourts et les cultures probiotiques, mais le effet le plus important a été obtenu avec farine de lentilles et le soja dans les cultures probiotiques. Comme précédemment, des laits écrémés (9,5% p/v) ont été supplémentés avec 1-3% (p/v) de farine de lentilles, de pois ou de poudre de lait écrémé. Ils ont été inoculés avec des cultures de yogourt, des probiotiques (L.rhamnosus). La production d'acide lors de la fermentation, le pH, la synérèse, la couleur, les propriétés rhéologiques (essai dynamique balayer oscillation de température à 40-50˚C), et les propriétés sensorielles (uniquement pour les yogourts) ont été étudiés après la production et  durant 28 jours d'entreposage frigorifique. 1-3% de farine de lentilles ou de pois  ont amélioré la  production d'acide pendant la fermentation du yogourt, mais les UFC  ont les même compte pour les laits suppléments que pour les témoins (lait écrémé). Il est a noter que L. bulgaricus  avaient un meilleur taux de survie au jour 28 avec une supplémentation en farine de pois. La diminution du pH dans les yogourts est de 4,5 à 4,1 avec la farine de lentille et de 4,5 à 3,75 avec farine de pois, après 28 jours. La synérèse pour les yogourts supplémentés à 1 et 2% avec de la farine de lentille ou de pois était supérieure d'autres échantillons. Lorsque le taux de supplémentation augmente en farine de lentille ou de pois, il n'y a pas de différence significative pour les valeurs de a alors que la valeur b a augmenté en fonction de la supplémentation.Les yogourts faits  de 1 a 3 % farine de lentilles et de pois 1 3% avaient un module élastique (G') et un module visqueux (G˝) plus élevés que les échantillons supplémentés en lait écrémé et que les témoins.  Les Yogourts avec 1 à 2% de farine de lentilles et de pois possèdent des  propriétés sensorielles comparable a celles des yogourts faits avec 1 a 2% de lait écrémé et celles des témoins. 1-3%  de  farine de lentilles ou de pois dans des laits avec probiotiques ont amélioré la  production d'acide pendant la fermentation, et les UFC de L rhamnosus  étaient comparable  a ceux des témoins (lait écrémé) après production. Après 28 jours, les UFC pour les échantillons supplémentés avec 2 et 3% de farine de lentille étaient aussi élevées que ceux supplémentés avec 1% de lait écrème et les UFC  pour les échantillons supplémentés avec 3% de farine de pois étaient plus élevées que ceux de tous les autres échantillons. Durant les 28 jours de production le pH diminue dans les laits probiotiques contenant de la farine de lentille de 4,50 à 3,90 et pour ceux contenant de la farine de pois de  4,50 à 4,04. La synérèse dans laits probiotiques avec 1 à 3% de farine de lentilles ou de pois a été significativement plus faible que les autres échantillons. Tous les échantillons contenant de farine de lentilles avaient significativement  une valeur de L plus bas  et des valeurs de b et a  plus élevés  en comparaison aux échantillons supplémentés en lait écrémé. L'addition de farine de pois a entraîné une modification de couleur b.Les laits probiotiques supplémentés avec 1 a 3 % de farine de lentilles et de pois ont des valeurs de G' et G˝ supérieures aux autres échantillons. </description><creator>Zare, Fatemeh</creator><contributor>Valerie Orsat (Supervisor)</contributor><date>2011</date><subject>Agriculture - Food Science and Technology</subject><title>Supplementation of beverage, yogurt and probiotic fermented milk with lentil flour and pea flour and study of the microbial, physical and sensory properties of supplemented products after production during storage</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/0c483p28m.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9306t332c</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Bioresource Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:8910jz57p</identifier><datestamp>2020-03-23T05:03:26Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Le graphène, une seule feuille de graphite, a de nombreuse propriétés électroniques et mécaniques intéressantes, et ce qui en fait une solution viable pour l'électronique de demain. Il reste le matériau le plus largement étudié en physique de la matière condensée en 2011. En raison des effets du désordre, de nombreux propriétés utiles du graphène prédite par la théorie n'apparaissent pas dans les systèmes du monde réel, et les effets exacts du désordre dans le graphène n'ont pas été étudiées à toute satisfaction. L'objectif de cette thèse est de fournir une étude premiers principes de l'effet du désordre introduit dans des nanostructures de graphène. Nous allons passer brièvement en revue les concepts de base de la théorie électronique de la matière condensée, suivie par une discussion plus détaillée sur la théorie de la fonctionnelle de la densité (DFT) qui est la théorie atomique la plus couramment appliquée pour la physique matériaux. Nous allons ensuite présenter la méthode LMTO, des de la DFT, qui est spécialisée dans le calcul des cristaux solides. LMTO est mathématiquement très efficace et est en mesure de traiter plus de quelques milliers d'atomes, tout en restant raisonnablement précise. Ces qualités font que la méthode LMTO est très utile pour l'analyse du transport quantique. Nous discuterons ensuite l'application du DFT est dans le formalisme de la fonction non-équilibre de Green de Keldysh (NEGF) pour traiter les systèmes non-équilibre, tels que le courant de charge. Enfin, dans NEGF-DFT, nous allons utiliser l'approximation du potentiel cohérent (CPA) et la correction non-équilibre de vertex (NVC) afin d'appliquer la théorie de la moyenne du désordre de configuration. Ce cadre théorique est ensuite appliquée à l'étude du transport quantique dans le graphène avec du désordre atomique. Nous allons étudier les effets de la substitution du bore (B) et de l'azote (N) dans le graphène connecté aux électrodes de graphène pure. Nous avons calculé le transport quantique des dispositifs de graphène en fonction de la concentration du désordre x, longueur du dispositif L, l'énergie E, et nos résultats suggèrent que le dopage affecte grandement les propriétés de transport quantique en induisant diffusion de maniere significante. En particulier, ceci est la première fois que la conductance en fonction de la concentration du dopage x est obtenue à partir de théorie premiers principes atomiques. Il est important de noter que la théorie de la NVC nous permet de déterminer directement la contribution de la diffusion à la conductance totale. étant donné que les atomes B et N les atomes sont situés de chaque côté du carbone dans le tableau périodique, il est intéressant de constater que la diffusion du désordre due à ces impuretés apparait presque parfaitement de chaque côté du niveau de Fermi dans le graphène. Un tel comportement peut être compris du point de vue de la charge des dopants.</description><description>Graphene, a single sheet of graphite, has many interestingelectronic and mechanical properties, making it a viable candidate fortomorrow's electronics. It remains the most widely studied material in condensed matter physics as of2011. Due to various disorder effects, manyuseful properties of pristine graphene predicted by theory may notshow up in real world systems, and the exact effects of disorder on graphenenanoelectronics have not been investigated to any satisfaction.The research goal of this thesis is to provide first principles calculations to study disorder scattering in graphene nanostructures.We shall briefly review the basic concepts of electronicstructure theory of condensed matter physics, followed by a moredetailed discussion on density functional theory (DFT) which is themost widely applied atomistic theory of materials physics. We thenpresent the LMTO implementation of DFT specialized in calculatingsolid crystals. LMTO is computationally very efficient and isable to handle more than a few thousand atoms, while remaining reasonablyaccurate. These qualities make LMTO very useful for analysingquantum transport. We shall then discuss applying DFT within the Keldysh non-equilibrium Green's function formalism(NEGF) to handle non-equilibrium situations such as current flow. Finally, within NEGF-DFT, we shall use the coherentpotential approximation (CPA) and the non-equilibriumvertex correction (NVC) theory to carry out configurational disorder averaging. This theoretical framework is thenapplied to study quantum transport in graphene with atomisticdisorder. We shall investigate effects of substitutional boron (B)and nitrogen (N) doping in a graphene device connected to intrinsicgraphene electrodes. We have calculated quantum transport oftwo-probe graphene devices versus disorder concentration x, device length L, electron electron energy E, and our results suggest that doping greatlyaffects quantum transport properties by inducing significantdiffusive scattering.In particular, it is the first time inliterature that conductance versus doping concentration x isobtained from atomic first principles. Importantly, the NVC theoryallows us to directly determine the diffusive scatteringcontribution to the total conductance. Since B and Natoms are located on either side of carbon in the periodic table, avery interesting finding is that disorder scattering due to theseimpurities are mirrored almost perfectly on either side of the graphene Fermilevel. Such a behavior can be understood from the point of view ofcharge doping.</description><creator>Wang, Zi</creator><contributor>Hong Guo (Internal/Supervisor)</contributor><date>2011</date><subject>Physics - Theory</subject><title>Electronic structure and quantum transport in disordered graphene</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/9593v0476.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/8910jz57p</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Physics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:nv9357133</identifier><datestamp>2020-03-23T05:03:26Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>This doctoral thesis comprises three parts. The first two parts (Chapter 2 and 3) define the role of the host cell restriction factor tetherin in restriction of HIV-1 cell-to-cell spread. These chapters also characterize the tetherin-inducible cell line Sup-T1 that was used in Chapter 4 to investigate whether the antiviral activity of protease inhibitors might partially be attributed to tetherin modulation.  Tetherin is an intrinsic host cell restriction factor that inhibits virus release by linking the viral membrane of the budding virus to the cellular membrane. The antiviral activity of tetherin has been commonly attributed to its cell surface expression. In HIV-1 infections, the viral protein Vpu antagonizes the tetherin-mediated restriction of virus release and downmodulates tetherin from the cell surface. In Chapter 2, we show that tetherin, besides restricting virus release, also restricts direct viral cell-to-cell spread. We also provide evidence that Vpu poses a fitness cost to HIV-1 in regard to cell-to-cell spread in the absence of tetherin, but is necessary for efficient cell-to-cell spread in the presence of tetherin. Tetherin appears also to play a role in synapse formation. In Chapter 3, we characterized cell line specific differences of the tetherin-Vpu interrelation in regard to cell surface expression of tetherin and virus release. However, Vpu-mediated tetherin antagonism in regard to cell-to-cell spread was similar in all cell lines and seemed to be independent of the level of tetherin cell surface downmodulation. In Chapter 4 we assessed whether protease inhibitors, whose antiviral activity partially depends on modulation of transmembrane proteins, may also modulate tetherin cell surface expression and/or the Vpu-mediated downmodulation of cell surface tetherin. As such, modulation was not apparent; thus, the antiviral activity of PIs is unlikely to be influenced by tetherin modulation activity. </description><description>Cette thèse de doctorat se compose de trois parties. Les deux premières parties (Chapitres 2 et 3) s'intéressent au rôle du facteur de restriction cellulaire tetherin dans l'inhibition de la propagation du VIH-1 de cellule à cellule. Ces Chapitres décrivent également la caractérisation de la lignée cellulaire Sup-T1 qui exprime la tetherin de manière inductible. Cette lignée cellulaire est utilisée dans le Chapitre 4 pour étudier si l'activité antivirale des inhibiteurs de protéases peut, en partie, être due à la régulation de la tetherin.  La tetherin est un facteur de restriction intrinsèque de l'hôte qui inhibe le relargage du virus en liant la membrane virale du virion bourgeonnant à la membrane cellulaire. L'activité antivirale de la tetherin est généralement attribuée à son expression à la surface cellulaire. Dans l'infection par le VIH-1, la protéine virale Vpu empêche l'action de la tetherin et limite son expression à la surface de la cellule hôte.  Dans le Chapitre 2, nous montrons qu'en plus d'inhiber le relargage des virions, la tetherin inhibe également la propagation de cellule à cellule. Nos résultats suggèrent que Vpu réduit la capacité infectieuse du virus en l'absence de la tetherin mais est absolument nécessaire à la propagation de cellule à cellule en présence de tetherin. La tetherin semble jouer un rôle dans la formation de synapse intercellulaire. Dans le Chapitre 3, nous analysons des différences entre des lignées cellulaires dans l'interaction fonctionnelle entre Vpu et la tetherin. Ces différences contribuent à la régulation de l'expression de la tetherin à la surface cellulaire et au relargage des virions dans ces différentes lignées cellulaires. Néanmoins, aucune différence dans la régulation de la propagation de cellule à cellule n'a pu être observée. À ce titre, l'inhibition de la propagation de cellule à cellule semble indépendante du niveau d'expression de la tetherin à la surface cellulaire. Dans le Chapitre 4, nous étudions si les inhibiteurs de protéase, dont l'activité antivirale dépend en partie de la régulation de protéines transmembranaires, peuvent également moduler l'expression de la tetherin à la surface cellulaire et/ou l'inhibition de la tetherin par Vpu. Cette étude suggère que l'activité antivirale des inhibiteurs de protéases ne dépend pas d'un effet sur la tetherin. </description><creator>Kuhl, Björn</creator><contributor>Mark Wainberg (Supervisor)</contributor><date>2011</date><subject>Biology - Microbiology</subject><title>Interrelationship between tetherin-mediated restriction and its Vpu-mediated antagonism in HIV-1 cell-to-cell spread and the potential to develop Vpu as an antiviral target</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/x059cc52m.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/nv9357133</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Medicine</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:2227mv094</identifier><datestamp>2020-03-23T05:03:26Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>L'ajustement du facteur de confusion est la clé dans l'estimation de l'effet de traitement dans les études observationelles. Deux techniques bien connus d'ajustement causal sont le score de propension et la probabilité de traitement inverse pondéré. Nous avons comparé les propriétés asymptotiques de ces deux estimateurs et avons démontré que la première méthode est un estimateur plus efficace. Étant donné que d'ignorer des facteurs de confusion importants ne fait que biaiser l'estimateur, il semble bénéfique de tenir compte de tous les co-variables. Cependant, ceci peut entrainer une inflation de la variance des paramètres estimés et provoquer des biais également. Par conséquent, nous présentons une pénalisation technique basée conjointement sur la probabilité du traitement et sur les variables de la réponse pour sélectionner la clé co-variables qui doit être inclus dans le modèle du traitement attribué. Outre le biais introduit par la non-randomisation, nous discutons d'une autre source de biais introduit par un échantillon non représentatif de la population cible. Plus précisément, nous étudions l'effet de la longueur du biais de l'échantillon dans l'estimation de la résultante du traitement. Nous avons introduit une pondération et une solide équation d'estimation double pour ajuster l'échantillonnage biaisé et la non-randomisation dans la généralisation du modèle à temps accéléré échec réglage. Puis, les propriétés des estimateurs du vaste échantillon sont établies. Nous menons une étude étendue pour examiner la simulation des propriétés des estimateurs du petit échantillon. Dans chaque chapitre, nous appliquons notre propre technique sur de véritables ensembles de données et comparons les résultats avec ceux obtenus par d'autres méthodes.</description><description>Confounder adjustment is the key in the estimation of exposure effect in observational studies. Two well known causal adjustment techniques are the propensity score and the inverse probability of treatment weighting. We have compared the asymptotic properties of these two estimators and showed that the former method results in a more efficient estimator. Since ignoring important confounders result in a biased estimator,  it seems beneficial to adjust for all the covariates.  This, however, may result in an inflation of the variance of the estimated parameters and induce bias as well. We present a penalization technique based on the joint likelihood of the treatment and response variables to select the key covariates that need to be included in the treatment assignment model. Besides the bias induced by the non-randomization, we discuss another source of bias induced by having a non-representative sample of the target population. In particular, we study the effect of length-biased sampling in the estimation of the treatment effect. We introduced a weighted and a double robust estimating equations to adjust for the biased sampling and the non-randomization in the generalized accelerated failure time model setting. Large sample properties of the estimators are established.We conduct an extensive simulation studies to study the small sample properties of the estimators. In each Chapter, we apply our proposed technique on real data sets and compare the result with those obtained by other methods.</description><creator>Ertefaie, Ashkan</creator><contributor>Masoud Asgharian-Dastenaei (Internal/Supervisor)</contributor><contributor>David Stephens (Internal/Cosupervisor2)</contributor><date>2011</date><subject>Pure Sciences - Statistics </subject><title>Casual inference via propensity score regression and length-biased sampling</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/6682x792j.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/2227mv094</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Mathematics and Statistics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:9p290f68g</identifier><datestamp>2020-03-23T05:03:27Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Recent studies suggest an increased prevalence of food-induced allergy; peanut, tree nut, seafood and sesame cause most of the severe clinical manifestations of food allergy, i.e. anaphylaxis and death. However, estimates of severe food allergies vary considerably between studies and no population-based studies assessing the prevalence and potential demographic predictors of these allergies had been conducted in Canada. We aimed to determine the prevalence of peanut, tree nut, fish, shellfish, and sesame allergy in Canada and identify potential demographic predictors of these allergies. Using comparable methodology to Sicherer et al in the US (JACI 2003;112:1203 &amp; JACI 2004;114:159), we performed a cross-Canada, random telephone survey. Food allergy was defined as either perceived (based on self-report), probable (based on convincing history or self-report of physician diagnosis), or confirmed (based on history and evidence of confirmatory tests). Data on demographic characteristics of participating households were collected and multivariate logistic regressions were used to assess potential determinants of probable allergies.  Of 10,596 households surveyed in 2008 –2009, 3666 responded (34.6% participation rate), of which 3613 completed the entire interview, representing 9667 individuals. The prevalence of perceived peanut allergy was 1.00% (95% CI, 0.81%, 1.22%); tree nut, 1.22% (95% CI, 1.01%, 1.46%); fish, 0.51% (95% CI, 0.38%, 0.67%); shellfish, 1.60% (95% CI, 1.36%, 1.87%); and sesame, 0.10% (95% CI, 0.05%, 0.19%). The prevalence of probable allergy was 0.93% (95% CI, 0.75%, 1.14%); 1.14% (95% CI, 0.94%, 1.37%); 0.48% (95% CI, 0.35%, 0.63%); 1.42% (95% CI, 1.19%, 1.67%); and 0.09% (95% CI, 0.04%, 0.18%), respectively. Peanut, tree nut and sesame allergy were more common in children [odds ratio (OR) 2.24 (95% CI, 1.40, 3.59), 1.73 (95% CI, 1.11, 2.68) and 5.63 (95% CI, 1.39, 22.87), respectively] while fish and shellfish allergy were less common in children [OR 0.17 (95% CI, 0.04, 0.72) and 0.29 (95% CI, 0.14, 0.61)]. Tree nut and shellfish allergy were less common in males [OR 0.55 (95% CI, 0.36, 0.83) and 0.63 (95% CI, 0.43, 0.91)]. Shellfish allergy was more common in urban settings [OR 1.55 (95% CI, 1.04, 2.31)]. There was a trend for most food allergies to be more prevalent in the more educated [tree nut OR 1.90 (95% CI, 1.18, 3.04)] and less prevalent in immigrants [shellfish OR 0.49 (95% CI, 0.26, 0.95)], but wide CIs preclude definitive conclusions for most foods.  Our results indicate disparities between perceived and confirmed food allergy and that age and sex, place of residence, socioeconomic status and birth-place may influence the development of food allergy.  </description><description>Les résultats d'études récentes suggèrent une prévalence accrue d'allergies d'origine alimentaire notamment aux arachides, aux noix provenant d'arbres, aux fruits de mer et au sésame, ces dernières causant les manifestations cliniques les plus graves, c.-à-d. l'anaphylaxie et la mort. Cependant, les estimations d'allergies alimentaires graves varient énormément d'une étude à l'autre. Par ailleurs, aucune étude de cohorte visant à évaluer la prévalence des facteurs prédictifs démographiques en cause dans ces allergies n'a été menée au Canada. Notre objectif est d'établir la prévalence des allergies aux arachides, aux noix provenant d'arbres, au poisson, aux mollusques et crustacés et au sésame au Canada et d'identifier les facteurs prédictifs démographiques qui y sont associés. À l'aide d'une méthodologie similaire à celle de Sicherer et coll. aux É.-U. (JACI 2003;112:1203 et JACI 2004;114:159), nous avons mené une enquête téléphonique aléatoire à travers le Canada. L'allergie alimentaire a été définie comme étant perçue (basée sur l'auto déclaration), possible (basée sur des antécédents convaincants ou l'auto déclaration du diagnostic du médecin) ou confirmée (basée sur les antécédents et sur la présence de tests de confirmation). Nous avons collecté auprès des ménages participants, des données sur les caractéristiques démographiques et des modèles de régression logistique multiple ont été utilisés pour évaluer les facteurs de risque potentiels associés aux allergies. Des 10 596 ménages sollicités en 2008 et 2009, 3666 ont répondu (taux de participation de 34,6 %). De ce nombre, 3613 ont complété l'entrevue, ce qui représente 9667 personnes. La prévalence de l'allergie aux arachides perçue était de 1,00 % (IC 95 %, 0,81 %, 1,22 %); celle de l'allergie aux noix provenant d'arbres de 1,22 % (IC 95 %, 1,01 %, 1,46 %); celle de l'allergie au poisson 0,51 % (IC 95 %, 0,38 %, 0,67 %); celle de l'allergie aux mollusques et crustacés de 1,60 % (IC 95 %, 1,36 %, 1,87 %); et celle de l'allergie au sésame de 0,10 % (IC 95 %, 0,05 %, 0,19 %). La prévalence d'une allergie possible était de 0,93 % (IC 95 %, 0,75 %, 1,14 %); 1,14 % (IC 95 %, 0,94 %, 1,37 %); 0,48 % (IC 95 %, 0,35 %, 0,63 %); 1,42 % (IC 95 %, 1,19 %, 1,67 %); et 0,09 % (IC 95 %, 0,04 %, 0,18 %) respectivement. Les allergies aux arachides, aux noix provenant d'arbres et au sésame étaient plus répandues chez les enfants [rapports de cote (RC) 2,24 (IC 95 %, 1,40, 3,59), 1,73 (IC 95 %, 1,11, 2,68) et 5,63 (IC 95 %, 1,39, 22,87) respectivement] alors que les allergies au poisson et aux mollusques et crustacés étaient moins courantes chez les enfants [RC 0,17 (IC 95 %, 0,04, 0,72) et 0,29 (IC 95 %, 0,14, 0,61)]. Les allergies aux noix provenant d'arbres et aux mollusques et crustacés étaient moins répandues chez les hommes [RC 0,55 (IC 95 %, 0,36, 0,83) et 0,63 (IC 95 %, 0,43, 0,91)]. L'allergie aux mollusques et crustacés était plus courante en milieu urbain [RC 1,55 (IC 95 %, 1,04, 2,31)]. On a observé une tendance voulant que pour la plupart des allergies alimentaires, la prévalence soit plus importante auprès des populations bénéficiant d'un niveau de scolarité plus élevé [noix provenant d'arbres RC 1,90 (IC 95 %, 1,18, 3,04)] et moins importante chez les immigrants [mollusques et crustacés RC 0,49 (IC 95 %, 0,26, 0,95)]. Par contre, pour la plupart des aliments, la présence de larges IC ne permet pas de tirer des conclusions définitives. Nos résultats indiquent une disparité entre l'allergie alimentaire perçue et confirmée ainsi que le fait que l'âge et le sexe, le lieu de résidence, le statut socioéconomique et le lieu de naissance pourraient être en cause dans le développement d'une allergie alimentaire.</description><creator>Ben-Shoshan, Moshe</creator><contributor>Ann Clarke (Supervisor1)</contributor><contributor>Lawrence Joseph (Supervisor2)</contributor><date>2011</date><subject>Health Sciences - Epidemiology</subject><title>Severe food allergies in Canada and potential demographic predictors</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/70795c89r.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9p290f68g</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Epidemiology and Biostatistics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:kh04dt52z</identifier><datestamp>2020-03-23T05:03:27Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Human pancreatic islet transplantation presents an attractive method for type I diabetes cellular therapy. However, there remain several limitations that should be addressed in order to increase the efficacy of the transplantation procedure; the most important of which are addressing the shortage of available pancreatic tissue and the viability of post-isolation islets. These obstacles are overcome through methods directed at long-term in vitro preservation, culture, and expansion of post-isolation islets in order to arrive at functionally viable islet populations for transplantation purposes. This thesis presents a novel system that promotes in vitro human pancreatic islet preservation and culture in a controlled microenvironment that is monitored noninvasively. The development of this system is accomplished in four consecutive stages: i) optimization of a two-dimensional surface-modified extracellular matrix (ECM) substrate, ii) fabrication of a geometrically controlled and interconnected scaffold suitable for islet culture, iii) three-dimensional in vitro culture incorporating the optimized ECM components and fabricated scaffold, and iv) incorporating the three-dimensional microenvironments within a multi-welled perfusion bioreactor, coupled with dielectric measurement electrodes, for the long-term in vitro culture of human  pancreatic islets. Several novelties attributed to the developed system are also presented. The two-dimensional studies revealed fibronectin to enhance glucose-dependent insulin functionality and morphology, while collagen I/IV contribute to adhesion. The microfabricated Poly(lactic-co-glycolic acid) (PLGA) scaffolds were constructed to give suitable pore structures and full interconnectivity, in a reproducible geometrically controlled manner. Furthermore, the incorporation of the optimized ECM components into the scaffolds was accomplished through islet embedding in an ECM laden gel that is seeded within the microfabricated scaffold pore structures. The three-dimensional microenvironment encouraged long-term human islet culture, giving high insulin release indices of ~1.8, while increasing islet gene expression. Finally, a fabricated multi-well perfusion bioreactor, equipped with an electrical impedance dielectric spectroscopy monitoring system, was employed in the controlled three-dimensional culture of the isolated islets. This system was successful in the long-term monitoring of human pancreatic islet differentiation and redifferentiation in a controlled three-dimensional microenvironment, yielding a population that is characteristically, morphologically, and functionally analogous to freshly isolated islets.</description><description>La transplantation humaine d'îlots pancréatiques se présente comme une méthode intéressante pour le traitement du diabète de type I au niveau cellulaire. Cependant, plusieurs problèmes persistants limitent l'efficacité de la procédure de transplantation; les principaux sont le manque de tissu pancréatique disponible et la viabilité des îlots après leur isolement. Ces obstacles sont surmontés par des méthodes de préservation, de culture, et d'expansion in vitro à long terme d'îlots isolés afin de parvenir à des populations d'îlots fonctionnellement viables pour des fins de transplantation. Cette thèse présente un nouveau système qui favorise la préservation et la culture in vitro d'îlots pancréatiques humains dans un microenvironnement contrôlé et surveillé de manière non invasive. Le développement de ce système est réalisé en quatre étapes successives : i) l'optimisation d'un substrat 2D de matrice extracellulaire modifié en surface, ii) la fabrication d'un échafaudage interconnecté à géométrie contrôlée, élément approprié à la culture des îlots, iii) la culture in vitro 3D intégrant le substrat de la matrice optimisé et l'échafaudage fabriqué, et iv) l'intégration des microenvironnements en trois dimensions au sein d'un bioréacteur à perfusion multi-sources, couplé avec des électrodes de mesure diélectrique pour la culture in vitro à long terme des îlots pancréatiques humains. Plusieurs nouveautés attribuées au système développé sont également présentées. Les études 2D révèlent que la fibronectine améliore la fonctionnalité et la morphologie de l'insuline dépendant du glucose, tandis que les collagènes I/IV contribuent à l'adhésion. Les échafaudages en PLGA (acide poly-lactique-co-glycolique) micro-fabriqués ont été élaborés de façon à fournir des structures poreuses et une inter-connectivité complète de manière reproductible et géométriquement contrôlée. De plus, l'incorporation de composants optimisés de matrices extracellulaires dans les échafaudages a été accomplie grâce à un enrobage des îlots dans un gel de matrices extracellulaires semé dans les structures poreuses d'échafaudages micro-fabriqués. Le microenvironnement 3D a favorisé la culture à long terme d'îlots humains, donnant des indices élevés de libération d'insuline d'approximativement 1.8, tout en augmentant l'expression des gènes des îlots. Enfin, un bioréacteur à perfusion multi-sources, équipé d'un système de surveillance d'impédance électrique par spectroscopie diélectrique, est utilisé pour la culture 3D contrôlée  des îlots isolés. Ce système  permet de surveiller à long terme la différenciation et la re-différenciation des îlots pancréatiques humains dans un microenvironnement 3D contrôlé, donnant une population dont les caractéristiques morphologiques et fonctionnelles en particulier équivalent à celles d'îlots fraîchement isolés.</description><creator>Daoud, Jamal</creator><contributor>Maryam Tabrizian (Internal/Supervisor)</contributor><contributor>Lawrence Rosenberg (Internal/Cosupervisor2)</contributor><date>2011</date><subject>Engineering - Biomedical</subject><title>Development of a three-dimensional microenvironment and dielectric monitoring system for long-term «in vitro» culture and differentiation of human pancreatic islets</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/3x816r706.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/kh04dt52z</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Biomedical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:x346d8224</identifier><datestamp>2020-03-23T05:03:27Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Nous dépendons hautement de nos yeux pour presque toutes nos activités quotidiennes. Le système oculomoteur est responsable de déplacer les yeux en réponse aux stimuli différents comme les perturbations de tête ou les mouvements des cibles visuelles. Il nous permet de rester concentré aux cibles visuelles, changer l'attention visuelle et compenser pour les perturbations du monde extérieur. Les chercheurs ont étudié ce système pendant des décades pour comprendre ses mécanismes en utilisant des techniques de modélisation et d'identification. Aujourd'hui, les protocoles cliniques incorporent des techniques mathématiques pour évaluer la fonctionnalité de modalités oculomotrices de patients par l'analyse des réponses de patients aux stimuli isolés différents.  Les réponses du système oculomoteur (les mouvements des yeux) se relaient entre les phases rapides et lentes. Cela rend le système oculomoteur un système hybride ou échangeant. Pourtant, en raison de la difficulté d'analyser une réponse hybride, cet échange est le plus souvent ignoré. Aucune méthode d'analyse n'existe encore qui peut étudier la réponse du système oculomoteur objectivement dans sa totalité.  Ici nous proposons, pour la première fois, les instruments automatisés pour analyser des réponses oculomotrices (les phases lentes et rapides) obtenues par une modalité oculomotrice dans l'isolement ou les sous-systèmes oculomoteurs multiples dans la coordination. Nous pouvons maintenant simultanément classifier et identifier les réponses d'un biosystème multi-entrée et multi-mode comme le système oculomoteur.Nous avons validé nos méthodes sur les simulations sans bruit et bruyantes et les avons ensuite appliquées aux dossiers de données expérimentales. Les retards visuels et vestibulaires, la constante de temps des canals demi-circulaires, et la dynamique centrale ont été découverts pour les phases rapides et lentes de réponses oculomotrices dans tous les cas.  En utilisant nos instruments, nous montrons que la dynamique de sous-systèmes oculomoteurs, plutôt que juste leurs augmentations, diffère par l'isolement comparé à leur coordination combinée. Cela a des implications cliniques très importantes; par exemple, cela signifierait que l'on ne peut pas évaluer les réflexes d'une personne dans l'obscurité et tirer des conclusions sur comment ils se comporteraient en présence de la lumière. Avec le pouvoir d'analyse de nos nouvelles méthodes, les protocoles cliniques d'essai peuvent maintenant être améliorés pour évaluer ces sous-systèmes dans l'isolement et dans la coordination, efficacement et objectivement.</description><description>We are highly dependent on our eyes for almost all our daily activities. The oculomotor system is responsible for moving the eyes in response to various stimuli such as head perturbations or visual target movements. It enables us to stay focused on visual targets, switch visual attention, and compensate for external world perturbations. Researchers have been studying this system for decades, to understand its mechanisms using modeling and identification techniques. Today, clinical protocols incorporate mathematical techniques to test the functionality of patients' oculomotor modalities through the analysis of patients' responses to various isolated stimuli. Oculomotor responses (eye movements) alternate between fast and slow phases. This makes the oculomotor system a hybrid or switching system. However, due to the difficulty of analyzing a hybrid response, this switching is most often disregarded. No analysis method exists yet which can study the whole nystagmus response in oculomotor systems objectively.Here we propose, for the first time, automated tools to analyze oculomotor responses (slow and fast phases) elicited by one oculomotor subsystem in isolation or multiple oculomotor subsystems in coordination. We can now simultaneously classify and identify the responses of a multi-input multi-mode biosystem such as the oculomotor system. We validated our methods on noise-free and noisy simulations and then applied them to experimental data records. Visual and vestibular delays, semicircular canal time constant, and central dynamics were detected in both fast and slow phases of oculomotor responses in all cases. Using our tools, we show that the dynamics of oculomotor subsystems, rather than just their gain, differ in isolation compared to their combined coordination. This has very important clinical implications; for example, this would mean that one cannot test a person's reflexes in the dark, and draw conclusions on how they would behave in the presence of light. With the analysis power of our new methods, clinical test protocols can now be improved to test these subsystems in isolation and in coordination efficiently and objectively.</description><creator>Ghoreyshi Langroudi, Atiyeh</creator><contributor>Henrietta L Galiana (Internal/Supervisor)</contributor><date>2011</date><subject>Engineering - Biomedical</subject><title>Simultaneous identification and classification of oculomotor subsystems in isolation and in coordination</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/k0698c83v.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/x346d8224</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Biomedical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:cn69m817g</identifier><datestamp>2020-03-23T05:03:28Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>In humans, there are 18 known histone deacetylases (HDACs) that can be divided into four classes, with HDAC4, 5, 7 and 9 forming the class IIa subgroup.  These four deacetylases are signal-responsive transcriptional co-repressors involved in a wide variety of physiological and pathological processes.  In response to a spectrum of extracellular signals, class IIa HDACs become phosphorylated on three or four conserved serine residues, creating specific binding sites for 14-3-3 chaperone proteins and inducing deacetylase nuclear export and derepression of target genes.  The goal of my thesis project was to identify regulatory mechanisms underlying class IIa HDAC nucleocytoplasmic trafficking.  Following a literature review in Chapter I are two sets of novel findings from my thesis project.  In Chapter II, I identify the salt-inducible kinases, SIK2 and SIK3 as novel class IIa HDAC kinases that induce the nuclear export of these deacetylases.  I also demonstrate that SIK2/3-mediated HDAC export is stimulated by liver kinase B1 (LKB1, a major tumour suppressor for lung and other cancers) and inhibited by protein kinase A (PKA).  In Chapter III, I demonstrate that PKA can also prevent nuclear export of HDAC4, 5, and 9 independent of SIK2/3 inhibition.  PKA achieves this by controlling a novel phosphorylation event that is unique to these three deacetylases but absent from HDAC7.  Due to the pervasive roles of LKB1, PKA, and class IIa HDACs in health and disease, these findings may lead to a better understanding of the etiology of various maladies and point to novel targets for therapeutic intervention in the future.</description><description>Chez l'homme, la famille d'enzymes histone déacétylase (HDAC) compte 18 membres.  Ces protéines peuvent être répartis en quatre classes; dont la classe IIa est composée d'HDAC4, 5, 7 et 9.  Les membres de cette classe agissent comme corépresseur de la transcription et interviennent dans une grande variété de processus physiologiques et pathologiques.  En réponse à une gamme copieuse de signaux extracellulaire, les HDAC de la classe IIa sont phosphorylées sur trois ou quatre résidus sérine conservés.  Cet événement crée des sites de liaison spécifiques pour les protéines 14-3-3, qui agissent comme chaperon et induisent l'exportation nucléaire des HDAC.  De ce fait, la relocalisation des HDAC, anéantit la répression d'expression de gènes cibles.  Le but de mon projet de thèse était d'identifier les mécanismes sous-jacents qui règlent la localisation nucléocytoplasmique de la classe IIa d'HDAC.  Suite à une revue de la littérature scientifique au chapitre I, deux séries de résultats parvenant de mon projet de recherche sont présentées.  Dans le chapitre II, j'identifie les protéines salt-inductible kinase, SIK2 et SIK3, comme étant kinases d'HDAC de la classe IIa qui induisent l'exportation nucléaire de ceux-ci.  Je démontre ainsi que cette exportation est stimulée par liver kinase B1 (LKB1, un suppresseur de tumeur impliqué dans la pathologie de plusieurs cancers) et inhibée par la protéine kinase A (PKA).  Dans le chapitre III, je démontre que la PKA peut également empêcher l'exportation nucléaire de HDAC4, 5 et 9 indépendamment de SIK2/3.  PKA atteint cet objectif en dirigeant un événement de phosphorylation unique au déacétylases de la classe IIa, autres que HDAC7.  En effet, puisque LKB1, PKA, et les HDAC de la classe IIa jouent un rôle omniprésent en matière de santé, ces résultats pourraient conduire à une meilleure compréhension de l'étiologie de diverses maladies et engendrer des nouvelles cibles thérapeutiques.</description><creator>Walkinshaw, Donald</creator><contributor>Xiang-Jiao Yang (Supervisor)</contributor><date>2011</date><subject>Biology - Molecular</subject><title>Histone deacetylase regulation by LKB1 and PKA signaling pathways</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/pg15bk07m.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/cn69m817g</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Medicine</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:9593v049r</identifier><datestamp>2020-03-23T05:03:28Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>While there may be a consensus regarding the provision of medical and genetic information to the offspring of gametes donation, the disclosure of nominative information continues to be a source of controversy—as much for a child who is looking to find out his origins, the donor who wants to maintain his anonymity and privacy, or for parents seeking information about how their child was conceived. This issue has been making the news lately as an increasing number of countries have, over the past 20 years, decided to end donor anonymity. The laws of Quebec and Canada continue to maintain the principle of donor anonymity.The choice of whether to favour donor anonymity or the child's attempts to learn about his origins and has significant consequences for everyone involved in gametes and embryos donation. The clash of values and debates that have led to uncertainty about making the "right legislative choice" and our ability to consider any of these positions to be the best requires thinking about the basis of the decision-making process. This means looking beyond legislation and taking ethics into consideration. In a context of normative pluralism, how does one strike a balance between the rights and interests of the offspring of assisted reproduction, the gamete donors and the couple that made use of assisted reproduction to conceive a child, while maximizing the benefits of assisted reproduction and minimizing negative consequences?Based on the analysis made by the Royal Commission on New Reproductive Technologies (Canada, 1993), we are proposing a study on internormative phenomena between the substantive rule that must be adopted by the state (whose regulatory legitimacy is affirmed) and the ethics of solicitude. This internormativity is the theoretical instrument that allows exchanges and inter influence among various types of norms.Based on empathy and responsibility, the ethics of care is of interest as it defines the person not only in terms of rights, but in terms of his relationships with others. This is a key element of the issues being examined where stakeholders maintain interrelations in a variety of areas—legal, affective, sociological or biological. Apart from the moral considerations, this leads us to consider each party's responsibility from a different angle while seeking to demonstrate the latter's impact on substantive rule. The ethics of care being based on the interdependancy of relationships between individuals, with the child at the centre, we notice it comes up at two levels: first in the parent–child relationship regarding secrecy of the method of conception then, in a donor–child relationship with respect to obtaining personal information.Lastly, based on the assumption that the ethics of care can be a relevant instrument for guiding lawmakers, we will compare Canadian and Quebec legislation with that of France and the United Kingdom. Investigating potential changes to the law requires an examination of legislation that has already done away with anonymity or contemplates doing so. France and the United Kingdom have long led the way in providing a legal framework for assisted reproduction. One of the objectives of the comparative law study is to analyze how ethics and law interact in the conflict and manifest themselves in various legislative approaches. This will ultimately enable us to better understand, comment and critique the positions adopted by Canada and Quebec.</description><description>S'il existe un consensus sur la transmission de renseignements médicaux et génétiques aux enfants issus d'un don d'engendrement, la divulgation d'informations nominatives continue de semer la controverse. Tant à l'égard de l'enfant en quête d'un droit aux origines, du donneur désirant le respect de son anonymat et de sa vie privée ou des parents qui aspirent au secret entourant le mode de conception de leur enfant. La problématique devient d'actualité en raison, notamment, du fait que depuis près de vingt ans de plus en plus de pays décident de mettre fin à l'exigence de non divulgation de l'identité du géniteur. Les cadres législatifs canadien et québécois persistent quant à eux à maintenir la philosophie de l'anonymat du tiers donneur. Le choix de favoriser soit l'anonymat des donneurs, soit la quête de l'enfant quant à ses origines a des conséquences importantes pour tous les acteurs du don de gamètes ou d'embryons. En découle des affrontements de valeurs et des débats où l'incertitude liée au "bon choix législatif", dans l'optique où nous pouvions considérer l'une ou l'autre des positions comme étant la meilleure, requiert de s'attarder aux fondements du processus décisionnel. Cela implique nécessairement une réflexion allant au-delà du seul législateur et engageant cette normativité qu'est l'éthique. Ainsi, en contexte de pluralisme normatif, comment trouver un juste équilibre entre les droits et intérêts des enfants issus de la procréation assistée, ceux des donneurs de matériel reproductif ainsi que ceux du couple y ayant recours, et maximiser les avantages de la procréation assistée tout en réduisant au minimum ses conséquences négatives? Dans la lignée du cadre d'analyse retenu par la Commission royale sur les nouvelles technologies de la reproduction (Canada, 1993), nous proposons une étude des phénomènes d'internormativité entre la règle de droit positif que doit adopter l'État (dont la légitimité régulatrice est affirmée) et l'éthique de la sollicitude. Cette internormativité est l'instrument théorique permettant des échanges et une inter influence entre les différents types de norme. Se basant sur l'empathie et la responsabilité, l'éthique de la sollicitude a d'intéressant qu'elle définit la personne non pas uniquement en rapport à ses droits, mais dans sa relation avec autrui. C'est un élément vital de la problématique sous étude où les acteurs demeurent inter reliés sous différents angles, que celui-ci soit juridique, affectif, sociologique ou biologique. Au-delà des considérations morales, cela nous amène à considérer la responsabilité de chacun selon un nouvel angle de réflexion tout en cherchant à démontrer l'impact de ce dernier sur la règle de droit positif. L'éthique de la sollicitude reposant sur l'interdépendance des rapports entre individus, l'enfant en étant ici le point de mire, nous en remarquons l'apparition à deux niveaux dans la problématique : en premier lieu dans le rapport parents – enfant quant au secret sur le mode de conception puis, dans le lien donneur – enfant relativement à l'obtention d'informations nominatives. Enfin, partant de l'hypothèse que l'éthique de la sollicitude peut être un instrument pertinent pour guider le législateur, nous effectuons une étude comparatiste des lois canadienne et québécoise avec celles de la France et du Royaume-Uni. S'interroger sur une modification potentielle de la loi implique de regarder des législations qui l'ont fait en abolissant l'anonymat ou qui y songent. De longue date, la France et le Royaume-Uni furent des précurseurs dans l'encadrement juridique de la procréation assistée. L'un des objectifs du recours au droit comparé est donc d'analyser comment éthique et droit interagissent dans le cadre du conflit, se manifestant dans diverses approches législatives. Cela nous permet ultimement de mieux comprendre, commenter et critiquer les positions adoptées par le Canada et le Québec.</description><creator>Cousineau, Julie</creator><contributor>Angela Campbell (Internal/Supervisor)</contributor><date>2011</date><subject>Social Sciences - Law</subject><title>L'anonymat des dons de gamètes et d'embryons au Québec et au Canada: Essai théorique sur l'internormativité entre le droit positif et l'éthique de la sollicitude dans la résolution du conflit</title><language>fre</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/x920g186z.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9593v049r</identifier><degree><name>Doctor of Civil Law</name><grantor>McGill University</grantor><discipline>Faculty of Law</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:w3763b97b</identifier><datestamp>2020-03-23T05:03:29Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Une plate–forme flottante à câbles multiples peut être décrite comme un système flottant attaché au fond de la mer par une série de câbles. Les câbles fournissent la rigidité horizontale et verticale au bâtiment en surface, garantissant sa stabilité dans une vaste gamme de conditions océaniques. Le système étudié dans cet ouvrage est un "Tension Leg Platform", ou TLP. Historiquement, les TLPs ont été utilisées pour l'extraction d'hydrocarbure en mer, mais elles pourraient être envisa ées pour des applications tel que les iles flottantes ou les éoliennes de haute mer. Cet ouvrage met l'accent sur la dynamique des câbles et sur les différences que cette dynamique peut créer entre les modèles couplés et découplés. Nous commençons par une étude préliminaire qui analyse le niveau d'erreur entre un modèle TLP couplé et découplé. Un modèle découplé ignore la dynamique intrinséque et les charges environnementales sur les câbles en traitant chacun de ceux–ci comme un ressort sans masse. Un système couplé, par contre, prend en compte les effets de la masse distribuée tout au long du câble. Les premières investigations de cet ouvrage ont permis de déterminer des indicateurs de performance qui peuvent être utilisés pour prévoir les divergences entre ces deux types de modèle. Les résultats démontrent qu'un ensemble de conditions complexes doit être en place pour obtenir des résultats similaires avec les deux modèles. Pour justifier ces affirmations, un modèle dynamique couplé et un modèle dynamique découplé à 6 degrés de liberté sont développés. Les forces générées par les tendons sont déterminées en analysant les mouvements de la plate–forme dans le modèle découplée. Dans le modèle couplé, la dynamique des câbles est simulée en utilisant un système de masses localisées. Les forces et couples environnementales sont ceux dues aux vagues, à l'attraction gravitationnelle et à la flottance. Ces modèles sont utilisés pour faire des études de cas, menant à des recommandations pour améliorer la precision du modèle découplé. Une méthodologie pour obtenir le profil d'équilibre pour un système de câbles à masses localisées est aussi présentée. Il est parfois plus complexe de résoudre un problème statique qu'un problème dynamique. Dans cet ouvrage, le profile d'équilibre des câbles est obtenu par une méthode balistique, ce qui est plus efficace que les méthodes traditionnelles. Pour le problème en trois dimensions, la solution est obtenue à l'aide d'un ensemble de trois équations, peu importe la résolution de discrétisation des câbles. Finalement, une application pratique pour les modèles TLPs couplés et découplés est présentée. Cette analyse vise à déterminer une configuration optimale des tendons en minimisant l'accélération de la plate–forme. La fonction à minimiser représente le pourcentage de la population susceptible de ressentir la cinétose (mal de mer). En modifiant les points d'attache des tendons, il est possible de réduire ce pourcentage. Cette procédure d'optimisation réduit de manière significative les variations dans la tension des câbles.</description><description>A Tension Leg Platform (TLP) is a floating system connected to the sea floor by a series of pretensioned cables. The cables provide horizontal and vertical stiffness to the surface vessel, ensuring stability in a wide range of sea conditions. Historically, TLP's have been used for hydrocarbon extraction below the seabed. Proposed futurefor TLP's include at–sea wind farms and floating islands. In this work, the focus is on the interactions between the surface platform and its tethers, and how cable model assumptions can alter the dynamic response of these systems. A preliminary study is conducted to analyze the degree of discrepancy between an uncoupled TLP dynamics model in comparison to a coupled TLP dynamics model. An uncoupled TLP model ignores the intrinsic dynamics and environmental loads on the cables by treating each tether as an ideal massless spring. A coupled TLP system, in contrast, considers the effects of distributed mass along the tether. The initial investigation in this work results in metrics that can be used to forecast the discrepancy between these two systems. In general, the most noticeable differences occur in the heave and roll/pitch degrees–of–freedom, due to low tether damping. The results show that a more elaborate set of conditions, other than the platform-to-cable mass ratio, must be satisfied in order for the two models to provide similar results. To substantiate these claims, two different six degrees–of–freedom deterministic dynamic models are developed. In the uncoupled analysis, the restoring force generated by the tendons is determined by evaluating the generalized platform motion, based on fundamental kinematic principles. In the coupled model, a lumped mass system is included to model the tether dynamics. The environmental forces and moments considered to be acting on the platform are due to waves, buoyancy, and gravity. These models are utilized to conduct case studies, resulting in proposed modifications to the uncoupled tether model. The modifications increase the accuracy of the uncoupled system. A methodology to obtain the equilibrium profile for the lumped mass cable system is also presented. Surprisingly, more effort is often needed to solve the static problem than the dynamics problem. In this work, the equilibrium cable profile is obtained with a shooting algorithm, which is more efficient than conventional methods. For the three–dimensional problem, the solution is obtained from a set of three equations, regardless of the cable discretization resolution. Finally, an application for the coupled and uncoupled TLP models is presented. This analysis seeks an optimal tendon configuration based on minimizing the deck accelerations. The objective function represents the percentage of the population susceptible to kinetosis (motion sickness). By modifying of the tendon/platform attachment points, the population size succumbing to the effects of kinetosis can be reduced. This proposed optimization process is also shown to significantly reduce variations in tether tension.</description><creator>Masciola, Marco</creator><contributor>Frederick Driscoll (Supervisor2)</contributor><contributor>Meyer Nahon (Supervisor1)</contributor><date>2011</date><subject>Engineering - Mechanical </subject><title>Dynamic analysis and design optimization of a multi-tethered buoyant platform</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/gm80j073t.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/w3763b97b</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Mechanical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:70795c90h</identifier><datestamp>2020-03-23T05:03:29Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Le Canada accuse un retard important par rapport à d'autres pays dans le développement de dossiers de santé électroniques. Si le Canada développe un système de dossier de santé électronique pancanadien (DSE), la qualité des soins patients peut s'améliorer. Une revue de la littérature décrit les avantages potentiels des DSEs tels que des améliorations de la recherche médicale, une réduction au niveau des temps d'attente en salle d'urgence et des tests diagnostiques. Un tel système facilitera la disponibilité des dossiers médicaux pour les fournisseurs de soins médicaux et les aideront à prendre des décisions critiques éclairées. Indépendamment des avantages d'un tel système, des implications sur le point de vue légal et éthique empêchent son développement et sa mise en œuvre. Les gouvernements fédéraux et provinciaux sont en désaccord quant à qui la responsabilité des soins médicaux incombe. Les Canadiens doivent être consultés sur la mise en œuvre de ce système et leurs préoccupations quant à la législation sur la vie privée doivent être adressées. Inforoute Santé du Canada a entrepris des démarches afin de créer un système de DSEs interopérable au Canada avec des protocoles d'audit, la technologie de carte à puce, etc. Une analyse de l'Alberta, qui a créé son propre système de DSE provincial, a permis de voir les bénéfices d'un tel système. Les études de cas portant sur les systèmes de DSEs de l'Alberta et du Royaume-Uni devraient être utilisées comme fondement afin de débuter le développement d'un système national au Canada. Les études ont démontré que les Canadiens supporteront l'initiative d'un système de DSE pancanadien si le Canada adresse les préoccupations entourant la mise en œuvre de ce système national par des mesures avec sanction afin de répondre aux implications éthiques que ce dernier pose (le consentement éclairé, l'accès illégal, etc.). Avant d'adresser les dilemmes éthiques que pose ce système, les gouvernements doivent assumer la responsabilité de décider qui développera et maintiendra ce système.</description><description>Canada lags behind other countries in the development of electronic health records. If Canada develops a pan-Canadian electronic health record (EHR) system, the quality of patient care can improve. A review of the literature lists potential benefits of EHRs such as improvements in medical research, a reduction in emergency room and diagnostic test wait times. Such a system will make medical records readily available to health care providers which will help them make informed critical decisions.  Regardless of the benefits of such a system, there are legal and ethical implications hindering its development and implementation. The federal and provincial governments are at odds as to who is in charge of health care. Canadians need to be consulted on its implementation, and their concerns regarding privacy legislation addressed. Canada Health Infoway has undergone initiatives to create an interoperable EHR system in Canada with audit trails, smart card technology, etc. The benefits of such a system are seen in an analysis of Alberta that has created its own provincial EHR system. Case studies of both Alberta and the United Kingdom's EHR systems should be used as a foundation to begin developing Canada's national system. If Canada addresses the concerns surrounding the implementation of a national EHR system through policies with sanctions to deal with the ethical implications of such a system (informed consent, unlawful access, etc), then studies have shown that Canadians will support a pan-Canadian EHR system initiative.  Before addressing ethical dilemmas, the governments must assume responsibility of who will develop and maintain this system. </description><creator>Nanouris, Elizabeth</creator><contributor>Antonia Maioni (Internal/Supervisor)</contributor><date>2011</date><subject>Political Science - Public Administration</subject><title>The ethical and legal complications surrounding the implementation of a pan-Canadian electronic health record (EHR) system</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/kd17cz39c.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/70795c90h</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of Political Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:f4752m94g</identifier><datestamp>2020-03-23T05:03:30Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>In this thesis we expose a p-adic analogue of a classical result of Shimura on the algebraicity of CM values of modular forms and certain of their nonholomorphic derivatives. More specifically, we define an analogue of the Shimura-Maass differential operator for rigid analytic modular forms on the Cerednik-Drinfeld p-adicupper half plane. This definition leads us to define the space of nearly rigid an-alytic modular forms, which is a p-adic analogue of the space of complex valuednearly holomorphic modular forms. Our main theorem is a statement about the algebraicity of values of nearly rigid analytic modular forms at CM points in thep-adic upper half plane.</description><description>Nous démontrons un variante p-adique d'un résultat classique de Shimura sur l'algébricité des valeurs des formes modulaires et de certaines de leurs dérives non-holomorphes aux points CM. Plus précisément, nous définissons un analogue rigide analytique de l'opérateur différentiel de Shimura-Maass pour les formes modulaires rigide analytiques sur le demi-plan p-adique de Cerednik-Drinfeld. Cette définition nous conduit a définir l'espace des formes modulaires presque rigide analytiques, qui correspond dans notre analogie a l'espace des formes modulaires presque holomorphes. Notre résultat principal est un énoncé d'algébricité des valeurs des formes modulaires presque rigide analytiques en des points CM dansle demi-plan p-adique de Cerednik-Drinfeld.</description><creator>Franc, Cameron</creator><contributor>Henri Darmon (Internal/Supervisor)</contributor><date>2011</date><subject>Pure Sciences - Mathematics </subject><title>Nearly rigid analytic modular forms and their values at CM points</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/9880vw08k.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/f4752m94g</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Mathematics and Statistics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:ks65hh39c</identifier><datestamp>2020-03-23T05:03:30Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>ABSTRACTWhat is the nature of legal rules, and how do we discern whether they can be harmonized?  My thesis seeks to answer these questions through a comparative analysis of civil law and common law jurisdiction rules in transnational cases.  I develop a methodology for comparing legal rules that defines rules by their history, epistemology and cultural context.  I seek to discover the legal traditions' essential components linked to their jurisdiction rules.  I hypothesize that rules rooted to incompatible essential components are likely not capable of harmonization.  Legal communities deeply value their tradition's essential components, which arise from unique historical events that shape the tradition.  Further, a tradition's essential components affect allowable legal reasoning structures used by judges, and the structure of legal rules generally. When applying this methodology to personal jurisdiction rules, two essential components emerge.  The first is a differing view regarding flexibility and judicial discretion on the one hand, and formalism and predictability on the other.  Common law jurisdiction rules arose from English equity courts' unfettered freedom to create substantive law and remedies.  They are predominately judge-made multi-factor tests derived from inherent judicial discretion to ensure equitable outcomes.  Examples are forum non conveniens, anti-suit injunctions, and U.S. courts' minimum contacts test.  Conversely, civil law jurisdiction rules are straightforward code provisions, linked to historical limitations on the judiciary predictable rules, which guarantee that litigants' rights are observed.  This essential component is manifested in legal reasoning prohibiting overt judicial discretion.  A second essential component also emerged.  The common law accepts a relatively aggressive judicial power.  This power is tied to the historical link between the Crown and English chancellors, as well as concurrent jurisdiction in English and U.S. domestic courts prior to the merger of equity and common law courts.  This royalty-based judicial power resulted in tag jurisdiction, anti-suit injunctions and conditional forum non conveniens stays, all of which the civil law rejects.  The civil law favors a more passive judicial role, also linked to mistrust of the judiciary.  These implicit assumptions regarding the nature of judges are not overtly apparent, but appear beneath the surface as salient underlying tenets.  Several attempts at harmonizing personal jurisdiction rules have failed in recent years.  The European Court of Justice has prohibited English courts' use of discretionary jurisdiction doctrines, resulting in vocal opposition by the English legal community.  The negotiations leading up to the Choice of Court Convention, which originally envisioned global harmonization of jurisdiction rules, ended in discord between U.S. and EU delegates.  These two essential components contributed to these harmonization failures.  They further explain why harmonization based on Quebec's forum non conveniens statutory provision or the Transnational Principles of Civil Procedure is unlikely.  In the final chapter, this thesis asks the peripheral question of whether harmonization where a forum selection clause exists is occurring, and if so, whether the essential components methodology can explain such harmonization.  Both the civil law and common law presume that such clauses are valid, relying on the principle of party autonomy.  Despite this commonality, judges in the two traditions continue to utilize different legal reasoning when considering a forum selection clause's validity.  Like harmonization of jurisdiction approaches where an arbitration agreement exists, it is likely that harmonization through a common framework, such as the Choice of Court Convention, is possible if a common essential component exists, despite continued divergence in approaches.  </description><description>RÉSUMÉQuelle est la nature des règles de droit et comment savoir si elles doivent être harmonisées? La présente thèse tente de répondre à ces questions en présentant une analyse comparative des règles du droit civil et de la common law dans la jurisprudence internationale. Nous y présentons une méthodologie conçue pour la comparaison des règles de droit selon leur histoire, leur épistémologie et leur contexte culturel. Notre but est de découvrir les éléments constitutifs des traditions juridiques et leur lien avec les règles de compétence.  Nous soulevons l'hypothèse que les règles liées à des éléments constitutifs incompatibles ne peuvent probablement pas être harmonisées. Lorsque cette méthodologie est employée dans le cadre des règles de compétence personnelle, deux éléments émergent. Le premier comprend d'une part, une approche divergente concernant la souplesse et le pouvoir judiciaire discrétionnaire; d'autre part, le formalisme et la prévisibilité. Les règles de compétence en matière de common law ont été créées dans un contexte où les tribunaux d'equity en Angleterre jouissaient d'une grande liberté pour créer des règles et recours substantiels. Il s'agit principalement de critères multifactoriels conçus par des juges, découlant du pouvoir judiciaire discrétionnaire inhérent visant à assurer des résultats équitables. Il pourrait par exemple s'agir de cas de forum non conveniens, anti-suit injunctions, ou du critère de lien minimal des tribunaux américains. À l'inverse, les règles de compétence en matière de droit civil sont clairement établies dans des dispositions du code en raison d'une méfiance historique à l'endroit du système judiciaire et d'une volonté de se fonder sur des règles prévisibles garantissant le respect des droits des parties. Le second élément constitutif repose sur le fait que la common law accepte un pouvoir judiciaire relativement plus agressif. Ce degré de pouvoir découle du lien historique entre la Couronne et les chanceliers anglais, ainsi que des compétences concurrentes dans les tribunaux nationaux anglais et américains avant la fusion des tribunaux d'equity et de common law. Ce pouvoir judiciaire associé à la royauté a permis l'essor de la compétence personnelle, des anti-suit injunctions et des suspensions conditionnelles en cas de forum non conveniens; autant d'éléments que le droit civil rejette explicitement. De fait, le droit civil privilégie une fonction juridictionnelle plus passive, également en raison d'une méfiance à l'endroit du système judiciaire, ce qui est incompatible avec l'approche de la common law. Plusieurs essais d'harmonisation des règles de compétence personnelle se sont soldés par des échecs au cours des dernières années. La décision de la Cour européenne de justice d'interdire aux tribunaux anglais l'emploi des doctrines sur la compétence discrétionnaire s'est soldée par une vive opposition de la communauté juridique anglaise.  Qui plus est, les négociations ayant mené à la création de la Convention sur les accords d'élection de for dont le but original était d'harmoniser les règles en matière de compétence à l'échelle mondiale, se sont soldées par un désaccord entre les délégués des États-Unis et de l'Union européenne. Dans le chapitre final, notre thèse aborde les questions connexes à la possibilité d'harmonisation lorsqu'une clause d'élection de for existe et, le cas échéant, si notre méthodologie fondée sur les éléments constitutifs permet d'expliquer une telle harmonisation. </description><creator>Conley, Anna</creator><contributor>Frederic Bachand (Internal/Supervisor)</contributor><date>2011</date><subject>Social Sciences - Law</subject><title>Harmonizing jurisdiction in transnational cases: a deep comparative inquiry</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/z603r269x.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/ks65hh39c</identifier><degree><name>Doctor of Civil Law</name><grantor>McGill University</grantor><discipline>Faculty of Law</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:m613n2627</identifier><datestamp>2020-03-23T05:03:31Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La production d'hydroelectricite est devenue le sujet d'un debat international ces dernieres annees en raison de l'emission des gaz a effet de serre (GES) qui resulte de l'inondation de la zone en amont d'un barrage hydroelectrique lors de la creation du reservoir. Le debat vise a determiner si les reservoirs des barrages hydroelectriques sont des sources negligeables de GES, plus particulierement en relation avec le dioxyde de carbone (CO₂) et le methane (CH₄). La plupart des etudes sur les echanges carboniques dans les reservoirs hydroelectriques furent basees sur des mesures irregulieres ou sporadiques prises sur terrain, et consequemment elles n'examinent pas en profondeur les tendances transitoires des flux de carbone (C) des reservoirs, ni l'heterogeneite des flux a travers les differents types d'ecosystemes inondes. Ceci etant dit, la modelisation des ecosystemes ainsi que les experimentations de laboratoire pourront ameliorer notre comprehension quant a l'inondation des echanges carboniques des ecosystemes terrestres qui surviennent suite au developpement hydroelectrique. Ma recherche vise a examiner l'alteration des echanges carboniques dans les forets boreales et les tourbieres avant et apres leur inondation, ainsi qu'a prevoir les echanges carboniques des ecosystemes boreals pendant la duree de l'inondation. La region sous etude fut le reservoir Eastmain-1 au nord du Quebec, dont la creation du reservoir fut terminee en 2006. Pour cette recherche, j'ai cree un modele sur le C des reservoirs (FF-DNDC) en modifiant Forest-DNDC, un modele de processus biogeochimique destine aux forets et les milieux humides. FF-DNDC a ete concu pour simuler les processus carboniques dans les sols inondes ainsi que dans la colonne d'eau, et a ete utilise pour predire les flux de CO₂ dans les forets boreales inondees et les tourbieres. Avant la modification du logiciel, j'ai teste la fiabilite avec laquelle Forest-DNDC pourra simuler les flux de CO₂ dans les forets d'epinette noire et les tourbieres. Ce test a demontre que Forest-DNDC peut simuler les flux de CO₂ avec une grande precision, et peut donc etre utilise pour evaluer les dynamiques de C suivant leur inondation. Des experiences d'incubation a court terme utilisant des sols boreals et de la vegetation ont revele que l'inondation diminue les taux de production de CO₂, tout en augmentant les taux de production de C dissous. Les experiences ont quantifie les changements dans les taux de mineralisation du C avant et apres l'inondation, afin de determiner les parametres de decomposition des sols dans les conditions inondees; ces parametres furent ensuite utilises dans FF-DNDC. Les simulations des ecosystemes inondes dans le reservoir Eastmain-1 ont indique qu'il y avait une emission de CO₂ des surfaces d'eau, et donc que la direction des flux de CO₂ a change (allant d'une absorption a une emission par l'ecosysteme) compare aux flux chez les forets et les tourbieres naturelles. Les flux de CO₂ simules dans la foret inondee et la tourbiere diminuaient pendant la duree de l'inondation, et la foret avait des flux de CO₂ superieurs a ceux de la tourbiere pendant la premiere decennie de l'inondation. Par la suite, ce contraste s'est inverse. Les resultats de mes modelisations et experiences mettent en evidence l'importance des variations spatiales et temporelles des echanges carboniques dans les paysages boreals nouvellement inondes.</description><description>Development of hydroelectricity in recent years has stirred an international debate in relation to greenhouse gas (GHG) emissions caused by flooding, which results from the creation of hydroelectric reservoirs. The debate focuses on whether hydroelectric reservoirs are negligible global GHG sources, particularly with regards to carbon dioxide (CO₂) and methane (CH₄). Most carbon (C) exchange studies applied to hydroelectric reservoirs have been based on irregular or sporadic field measurements and, therefore, hardly address the transient nature of reservoir C flux and the heterogeneity in flux that occurs across different types of ecosystems inundated with water. In this context, ecosystem modeling and laboratory experiments can improve our understanding of C exchange that takes place in flooded terrestrial ecosystems as a consequence of hydroelectric development. The aim of this research was to examine C exchange variation in boreal forest and peatland ecosystems prior to and after flooding as well as to project boreal ecosystem C exchange for the duration of the inundation period. The primary study area was the Eastmain-1 reservoir located in northern Quebec where impoundment was completed in 2006. For this research, a reservoir C model (FF-DNDC) was developed by modifying Forest-DNDC, a process-based biogeochemical model utilized for forest and wetland ecosystems. FF-DNDC was designed to replicate C processes that take place in submerged soil and the water column. It is used to simulate CO₂ flux in flooded boreal forest and peatland ecosystems. The reliability of the Forest-DNDC simulation in relation to CO₂ flux in black spruce forest and peatland ecosystems was tested before modifications to the software took place. This test showed that Forest-DNDC reasonably simulated CO₂ flux and, as a result, supported the application of the model to simulate C dynamic changes after flooding occurs. Short-term incubation experiments using boreal soil and vegetation samples revealed that flooding decreased rates of CO₂ production but increased rates of dissolved C production. The experiments quantified changes that occurred in C mineralization rates prior to and after flooding, which determined soil decomposition parameters under flooded conditions that were then applied to FF-DNDC. The Eastmain-1 reservoir flooded ecosystem simulations detected CO2 emissions from the water surface, and, hence, the direction in CO₂ flux changed (from uptake to release) in comparison to flux that occurred in natural forest and peatland ecosystems. Simulated CO₂ flux for both the flooded forest and peatland ecosystems decreased with the duration of inundation, and the forest ecosystem showed larger CO₂ flux than the peatland ecosystem in the first decade after flooding was initiated. The trend of larger flux in the forest ecosystem was reversed after the first decade. Modeling and experimental results from this study emphasize the importance of spatial and temporal variation of C exchange in newly flooded boreal landscapes.</description><creator>Kim, Youngil</creator><contributor>Nigel Thomas Roulet (Supervisor)</contributor><date>2011</date><subject>Earth Sciences - Biogeochemistry</subject><title>Modeling and experimental analysis of carbon exchange from artificially flooded forest and peatland ecosystems</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/wm117s990.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/m613n2627</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Geography</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:k643b525f</identifier><datestamp>2020-03-23T05:03:31Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Neural populations in the basolateral amygdala (BLA) have been shown to be an essential substrate for associative fear memories.  However, it remains unclear whether distinct associative memories are mediated by independent or overlapping populations of BLA neurons.  The focus of this dissertation is to describe efforts undertaken to use reconsolidation to advance this issue.  I used the fact that initiation of reconsolidation is dependant on the reactivation of a particular memory.  Therefore, if two memories are stored by the same overlapping population within the BLA, then interference through blockade of reconsolidation of one should lead to impairments in both.  Conversely, if the two memories are stored independently of each other within the BLA, then blockade of reconsolidation of one memory should leave the second intact.  I have investigated this with two protocols that each result in two distinct fear memories.  Using a single tone-shock, I investigated the relationship of auditory and contextual fear memory.  My findings demonstrate a complex functional interaction between these two memories.  I designed a novel 2-tone protocol with which I attempted to use the selective blockade of reconsolidation to test a model of fear memory acquisition.  This attempt illuminated the need for further knowledge regarding the boundary conditions of reconsolidation.  I also describe an unbiased approach to detect molecular mechanisms unique to either consolidation or reconsolidation.  One candidate from this screen was validated for its role in consolidation in the BLA.  The experiments described in this dissertation provide a unique view of how fear memory representations are organized in the amygdala and how manipulations of reconsolidation can be used to understand the structure of memory. </description><description>Les populations neuronales situées dans l'amygdale basolatérale (BLA) sont reconnues comme étant un substrat essentiel aux mémoires associés à la peur. Il n'est pas encore clairement établi si des souvenirs associatifs distincts sont reliés à des populations de neurones de la BLA indépendantes ou se chevauchant. Cette dissertation décritles efforts entrepris pour faire progresser nos connaissances sur cette dernière interrogation en utilisant la reconsolidation. Pour mon étude, je me suis basé sur le fait que la reconsolidation est dépendante de la réactivation d'un souvenir en particulier. Par conséquent, si deux souvenirs sont emmagasinés par la même population de neurones se chevauchant dans la BLA, alors l'interférence causée par le blocage de la reconsolidation devrait altérer les deux souvenirs. Inversement, si deux souvenirs sont emmagasinés de manière indépendante l'un de l'autre à l'intérieur de la BLA, alors le blocage de la reconsolidation d'un seul souvenir devrait laisser le second intact. J'ai examiné cette hypothèse à l'aide de deux protocoles qui ont chacun produit deux mémoires distinctes associées à la peur. En utilisant une seule association tonalité-décharge électrique, j'ai étudié la relation entre la mémoire auditive et contextuelle associée à la peur. Mes résultats ont démontrés une interaction fonctionnelle complexe entre ces deux types de souvenirs. J'ai conçu un nouveau protocole composé de deux tonalités avec lequel j'ai essayé de bloquer sélectivement la reconsolidation pour tester un modèle d'acquisition de mémoires associées à la peur. Cette expérience démontre le besoin d'en apprendre davantage sur les conditions limitant la reconsolidation. De plus, j'ai décris une approche impartiale pour détecter les mécanismes moléculaires uniques à la consolidation ou à la reconsolidation. Suite au criblage de plusieurs molécules, une molécule candidate a été reconnue pour son rôle dans la consolidation dans la BLA. Les expériences décrites dans cette dissertation amène une perspective nouvelle sur la façon dont les mémoires reliées à la peur sont organisées dans l'amygdale et démontre comment la manipulation de la reconsolidation peut être utilisée pour comprendre la structure de la mémoire.</description><creator>Honsberger, Michael</creator><contributor>Karim Nader (Supervisor)</contributor><date>2011</date><subject>Psychology - Experimental</subject><title>Parsing memory structure with reconsolidation</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/dz010v00n.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/k643b525f</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Psychology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:8p58pj07z</identifier><datestamp>2020-03-23T05:03:32Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Faulty assumptions about the nature of interest group activity have misled scholars' assessments of interest group influence in the European Union (EU). The influence literature portrays interest groups as commonly using undue pressure and purchase tactics in order to change the minds of decision-makers. However, this work on influence has yet to take seriously insights from the rest of the interest group literature, which has long established that interest groups are much more likely to lobby decision-makers who already share their views (friends) rather than to attempt to change the minds of those who do not (foes). Moreover, in lobbying friends, interest groups are best understood as informational service bureaus, providing policy-relevant information to decision-makers in exchange for legitimate access to the policy-making process. This dissertation brings these insights to bear on interest group influence in the EU. I conceive of interest group influence as a function of an interest group's ability to efficiently and reliably provide policy-relevant information to EU decision-makers. To this end, I examine the information processing capacity – how interest groups gather, filter, make sense of, generate and transmit information – of EU interest groups within a comparative framework. I find that, in general, interest group influence in the EU is balanced with no particular set of groups dominating the EU policy-making process at the expense of others.</description><description>Des hypothèses erronées quant à la nature de l'activité des groupes d'intérêt ont induit en erreur plusieurs experts dans leur analyse de l'influence de ces groupes au sein de l'Union européenne (UE). Leur travaux sur l'influence des groupes de pression affirment que les groupes d'intérêt recourent couramment à une pression inutile et à des techniques de vente dans le but de faire changer d'avis les décideurs politiques. Toutefois, cette lecture de l'influence de ces groupes n'a pas su intégrer les conclusions du reste des travaux scientifiques sur les groupes d'intérêt qui affirment depuis longtemps que ces groupes d'intérêt sont bien davantage susceptibles de faire pression sur des décideurs qui partagent déjà leur point de vue (alliés) que d'essayer de faire changer d'avis ceux qui ne le partagent pas (adversaires). De plus, dans le cercle des lobbyistes, les groupes d'intérêt sont davantage perçus comme des bureaux de renseignements, qui fournissent des informations pertinentes d'un point de vue politique aux décideurs en échange d'un accès légitime au processus décisionnel. Ce projet de recherche s'attarde à illustrer les principes qui sous-tendent l'influence des groupes d'intérêt dans l'Union européenne. Je considère l'influence des groupes d'intérêt comme fonction de leur capacité à fournir de manière efficace et fiable des informations pertinentes d'un point de vue politique aux décideurs de l'UE. À cet effet, j'examine la capacité des groupes d'intérêt au sein de l'UE à traiter l'information, à savoir comment ces groupes rassemblent, sélectionnent, analysent, génèrent et transmettent l'information, dans une analyse comparative. J'estime qu'en général, l'influence des groupes d'intérêt de l'UE n'est pas caractérisée par la présence de certains groupes en particulier qui domineraient le processus décisionnel européen au détriment d'autres groupes.</description><creator>Chalmers, Adam</creator><contributor>Juliet Johnson (Internal/Supervisor)</contributor><date>2011</date><subject>Political Science - General</subject><title>Interests, information and influence: a comparative analysis of interest group influence in the European Union</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/q811kp79r.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/8p58pj07z</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Political Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:41687n34w</identifier><datestamp>2020-03-23T05:03:33Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Au cours des vingt dernières années, les nanotubes de carbone (NTCs) ont reçu énormément d'attention au sein de la communauté scientifique en raison de leurs propriétés extraordinaires. Bien que beaucoup de travaux ont été réalisés afin d'améliorer la qualité des NTCs tout en essayant de diminuer leur coût de production, ce coût demeure un obstacle majeur quant à leur utilisation dans la vie quotidienne. Ce problème est particulièrement important dans le contexte des matériaux nanocomposites à base de polymère où des volumes importants de NTCs sont nécessaires. Ce projet de maîtrise avait pour objectif le développement d'une méthode de synthèse simple, peu coûteuse et pouvant facilement être mise à l'échelle. Dans ce contexte, nous avons eu recours à la croissance directe de NTCs sur de l'acier inoxydable, sans utiliser de prétraitement ou catalyseur externe. Nous avons démontré que le substrat de croissance est recyclable pour des usages multiples. Nous avons étudiés l'effet de l'apport de carbone lors de la croissance sur la densité et la morphologie des NTCs, ainsi que sur l'adhésion des tubes à l'acier inoxydable. Nous avons constaté que l'augmentation de l'apport en carbone mène à l'augmentation de nombre de parois de NTCs et à une plus forte adhésion à la surface. L'étude portant sur la croissance des nanotubes de carbone a été effectuée en parallèle avec une étude sur l'utilisation des NTCs comme matériau de remplissage dans les composites à base de polyalcool vinylique (PVA). Il est bien connu qu'en raison de leur énergie de surface élevée, les NTCs ont tendance à s'agglomérer lorsqu'ils sont introduits dans les polymères et les solvants. La fonctionnalisation de surface des NTCs dans une décharge électroluminescente entretenue par couplage capacitif radio fréquentiel (RF) dans un mélange de gaz Ar/C2H6/O2 a été utilisée pour surmonter les problèmes d'agglomération. Cette fonctionnalisation introduit des liens covalents à la surface des NTCs avec des groupes polaires. Des nanofluides NTC/eau distillé créés à partir des NTC fonctionnalisés demeurent stables sur de longues périodes de temps (&gt; 6 mois) et ce, même après chauffage jusqu'au point d'ébullition. Les composites PVA/NTC produits sont homogènes et montrent une bonne dispersion des NTCs. Du point de vue thermique, les composites montrent une légère augmentation de la température de transition vitreuse ainsi que du point de fusion, ainsi qu'un retard dans la dégradation du polymère. Du point de vue mécanique, les composites formés avec une très faible charge massique (0,3 % en masse) montrent des hausses de 28% et 41% dans leur résistance à la traction et module de Young par rapport au polymère pur. </description><description>Over the past 20 years carbon nanotubes (CNTs) have received a great deal of attention in the scientific community due to their extraordinary properties. Although much work has been done to increase the quality of CNT while lowing the cost of production, their high cost is still a major obstacle in preventing their use in everyday life. This issue is especially significant in composite research where a high volume of CNTs is needed. This work presents a simple, inexpensive and scalable method to grow CNTs directly from stainless steel (SS) mesh, without any pretreatment or the use of external catalyst. In addition, the growth substrate is shown to be recyclable for multiple uses. The effect of carbon input on the density, morphology and removal of CNTs was examined. It was found that increased carbon input leads to the growth of larger diameter multi-walled CNTs with stronger adhesion to the surface. The study on the growth of CNTs was done in parallel with a study on the use of CNTs as filler material in poly vinyl alcohol (PVA) composites. However, due to their high surface energies, CNTs often agglomerate together when introduced into polymers and solvents. Surface functionalization of the CNTs via a C2H6/O2 capacitively-coupled RF plasma discharge was used to overcome the issue of agglomeration. The aqueous nanofluids that were created by removal of the CNTs from the substrate through ultrasonication were found to remain stable after boiling and after extended periods of time (&gt; 6 months). The PVA/CNT composites produced were homogenous with good dispersion of the CNTs. Thermally, the composites exhibited a small increase in glass transition and melting point temperatures, as well as a retardation in the degradation of the polymer. Mechanically, the 0.3 wt.% Functionalized-CNT composite showed 28% and 41% increases in tensile strength and modulus, respectively, over the neat polymer. </description><creator>Hordy, Nathan</creator><contributor>Sylvain Coulombe (Internal/Cosupervisor2)</contributor><contributor>Jean-Luc Meunier (Internal/Supervisor)</contributor><date>2011</date><subject>Engineering - Chemical</subject><title>Direct growth of carbon nanotubes from stainless steel grids and plasma functionalization for poly(vinyl alcohol) composite production</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/xd07gx79w.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/41687n34w</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Chemical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:9880vw11w</identifier><datestamp>2020-03-23T05:03:35Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1.0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Le fruit de la canneberge est depuis longtemps utilisé par la médecine traditionnelle  dans le cadre d'infection urinaire, mais son mécanisme d'action reste mal connu. Récemment plusieurs études ont montré l'implication d'un composé majeur du fruit, le proanthocyanidine (CPAC), dans les propriétés antibactériennes et anti-infectieuses de la canneberge. Le travail présenté ici vise à évaluer l'effet du PAC sur les cellules épithéliales au cours de l'infection par deux bactéries intestinales : Salmonella Typhimurium et la souche d'Escherichia coli entéropathogène (ECEP). Nous avons montré par des techniques d'imagerie que le remodelage du cytosquelette d'actine des cellules hôtes, étape nécessaire à l'infection par les ECEP, était abolit en présence de CPAC, de même, une inhibition significative de l'infection de cellules HeLa par Salmonella Typhimurium est observée en présence du composé. L'absence d'effet du CPAC sur la prolifération bactérienne et sur la sécrétion de facteurs de virulence dans les deux systèmes expérimentaux suggère un impact du composé sur la permissivité des cellules hôtes. De façon concordante, nous avons montré un rôle critique du CPAC dans la polymérisation des filaments d'actine des cellules non-infectées. La phagocytose de particules inertes par une lignée macrophagique qui dépend d'un remodelage actif du cytosquelette est également inhibée par le CPAC, confirmant l'impact majeur du composé sur le fonctionnement cellulaire. Des expériences in vivo d'infection par Citrobater Rodentium (un modèle murin d'ECEP) n'ont pas permis de mettre en évidence d'effet significatif du CPAC sur l'incidence et la sévérité de la maladie malgré l'effet majeur observé in vitro sur les cellules épithéliales. L'ensemble de ces travaux apporte un nouvel éclairage sur l'effet du CPAC dans les interactions entre les pathogènes et les cellules hôtes, il souligne également les différences entre des systèmes expérimentaux in vitro et les mécanismes prenant place dans des organismes complexes in vivo. Des expériences supplémentaires prenant en compte différents paramètres comme le PH intestinal semblent nécessaires pour évaluer définitivement l'impact du CPAC sur les infections entériques.</description><description>Cranberry-derived compounds, including a fraction known as proanthocyanidins (PACs) exhibit anti-microbial, anti-infective, and anti-adhesive properties against a number of disease-causing organisms.  This thesis illustrates the effect of cranberry proanthocyanidins (CPACs) on the infection of epithelial cells by two enteric bacterial pathogens, enteropathogenic Escherichia coli (EPEC) and Salmonella Typhimurium.  Immunofluorescence data showed that actin pedestal formation, required for infection by enteropathogenic Escherichia coli (EPEC), was disrupted in the presence of CPACs.  In addition, invasion of HeLa cells by Salmonella Typhimurium was significantly reduced.  CPACs had no effect on bacterial growth, on the production of bacterial virulence proteins or the viability of host cells.  Interestingly, we found that CPACs had a potent and dose-dependent effect on the host cell cytoskeleton that was evident even in uninfected cells.  CPACs inhibited the phagocytosis of inert particles by a macrophage cell line, providing further evidence that actin-mediated host cell functions are disrupted in the presence of cranberry CPACs.  Thus, although CPAC treatment inhibited Salmonella invasion and EPEC pedestal formation, our results suggest that this is likely primarily because of the perturbation of the host cell cytoskeleton by CPACs rather than an effect on bacterial virulence itself.  Additional work suggests that while CPACs disrupt epithelial tight junctions in vitro, they are well tolerated in vivo.  The use of CPACs for the treatment or prevention of enteric infection in vivo by Citrobacter rodentium was also evaluated, though no conclusions, positive or negative can be drawn thus far.  These findings underline the difficulties of translating experimental results to living systems but have significant implications for the interpretation of experiments on the effects of CPACs on bacteria-host cell interactions.</description><creator>Harmidy, Kevin</creator><contributor>Nathalie Tufenkji (Internal/Supervisor)</contributor><contributor>Samantha Gruenheid (Internal/Cosupervisor2)</contributor><date>2011</date><subject>Biology - Microbiology</subject><title>Perturbation of host cell cytoskeleton by cranberry proanthocyanidin and its effect on enteric infections</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/kp78gm58b.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9880vw11w</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Chemical Engineering</discipline></degree></thesis></metadata></record><resumptionToken completeListSize="47894">oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):37000</resumptionToken></ListRecords></OAI-PMH>