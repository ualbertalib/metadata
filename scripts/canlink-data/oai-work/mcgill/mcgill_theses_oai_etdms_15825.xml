<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/assets/blacklight_oai_provider/oai2-b0e501cadd287c203b27cfd4f4e2d266048ec6ca2151d595f4c1495108e36b88.xsl"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd"><responseDate>2020-07-25T01:03:02Z</responseDate><request resumptionToken="oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):15825" verb="ListRecords">https://escholarship.mcgill.ca/catalog/oai</request><ListRecords><record><header><identifier>oai:escholarship.mcgill.ca:qf85nf691</identifier><datestamp>2020-03-21T19:53:56Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The stringent response (SR) is a conserved bacterial stress response mechanism that allows bacteria to survive during stress and starvation. This response is mediated by (p)ppGpp, a hyperphosphorylated guanosine signal that regulates expression of genes to inhibit cellular proliferation and induce genes important for survival and adaptation. This study investigates the role of the SR in regulating oxidative stress pathways in Pseudomonas aeruginosa (PA), a human opportunistic pathogen that can cause infections in immunocompromised patients, and patients suffering from cystic fibrosis. Our results demonstrate that inactivation of the SR significantly increased susceptibility to killing by multiple oxidants, impaired anti-oxidant defenses, and increased the levels of endogenous reactive oxygen species (ROS). In addition, we demonstrated that overexpressing KatA, the primary catalase in PA, protected the ΔSR mutant from hydrogen peroxide killing as well as several antibiotics. Our results also suggested that hydroxyalkyl quinolone molecules were responsible for increased intracellular levels of ROS but did not impair catalase activity. In summary, we found that the SR was required for tolerance against oxidative stress, and regulated expression of both catalases katA and katB. Finally, overexpression of the KatA catalase was sufficient to protect against hydrogen peroxide killing, and partially protected against antimicrobial killing.</description><description>La réponse stringente (RS) est un mécanisme commun aux bactéries qui leur permet de répondre et survivre aux stress nutritionels et environmentaux. Cette réponse est médiée par le signal (p)ppGpp, une petite molécule de guanosine hyperphosphorylée. Celle-ci régule l'expression des gènes afin d'inhiber la prolifération cellulaire et d'induire des gènes importants pour la survie et d'adaptation au stress. Cette étude porte sur le rôle de la RS dans la régulation des voies de stress oxydatif chez Pseudomonas aeruginosa (PA), un pathogène humain opportuniste qui peut causer des infections chez les patients immunosupprimés et les patients souffrant de fibrose kystique. Nos résultats démontrent que l'inactivation de la RS augmente grandement la susceptibilité aux oxidants, diminue les défenses anti-oxidantes, et induisent une production endogènes dérivés réactifs de l'oxygène (DRO) plus élevée. Nous avons également démontré que la sur-expression de KatA, l'enzyme catalase principale chez PA, protège le mutant ΔRS contre le peroxyde d'hydrogène ainsi que plusieurs antibiotiques bactériocides. Finalement, nos résultats suggèrent aussi que les molécules hydroxyalkyl quinolones sont responsables de l'augmentation des niveaux intracellulaires de DRO, mais n'altèrent pas l'activité des superoxide dismutases ou catalases. En résumé, la RS est nécessaire à la tolérance contre le stress oxidatif, et régule l'expression des deux catalases katA et katB. De plus, l'activité de la catalase KatA est suffisante pour protéger le mutant RS contre le peroxide d'hydrogène, et partiellement protéger contre l'effect bactericide des antibiotiques.</description><creator>Khakimova, Malika</creator><contributor>Dao Nguyen (Internal/Supervisor)</contributor><date>2013</date><subject>Biology - Microbiology</subject><title>The role of the stringent response in the regulation of anti-oxidant defenses in «Pseudomonas aeruginosa»</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/05741w23g.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/qf85nf691</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Microbiology and Immunology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:w6634714t</identifier><datestamp>2020-03-21T19:53:57Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The interaction between coastal aquifers and estuaries governs many important ecological and water quality processes. The purpose of this research is to use distributed temperature sensing (DTS) in the Indian River Bay estuary, Delaware, to detect differences in variance and mean of temperature at the sediment-water interface.  DTS uses the scatter of laser light in a fibre optic cable as a means to repeatedly measure temperature to 0.1˚C at 1m intervals along the length of the cable. Low variances in temperature are interpreted as being the result of the moderating thermal influence of groundwater discharge. From September 16 to 19 2011, two kilometres of DTS cable were deployed in the near shore environment of Holts Landing State Park. Variance increases with distance from shore as the power function s2=-33.63(d ( 1.012)) + 2.685 (r2=0.78). Narrow zones with significantly lower temperature variances (Kruskal-Wallis with Tukey's HSD, p&lt;0.05) and means (Friedman with Tukey's HSD, p&lt;0.05) than adjoining zones exist within the near shore area. Zones of high variance at the western and eastern edges of the study site are associated with ancient shallow peat-filled valleys capped with fine sediments. A broad zone of low variance next to the western valley is interpreted to imply that over-pressured fresh groundwater is discharging at the paleo-valley margins, creating a pattern of submarine groundwater discharge which differs from existing models. An attempt to use diurnal temperature signal amplitudes at various sediment depths to calculate vertical porewater flux were unsuccessful, likely due to rapidly-rising temperatures, interference between tidal and diurnal signals, and a short measurement period. DTS appears to hold promise in detecting temperature patterns simultaneously across different scales, and can be used to rapidly fill in gaps of knowledge in hydrogeologic systems.</description><description>Les interactions entre les aquifères côtiers et les estuaires régissent beaucoup de processus écologiques importants qui ont des implications sur la qualité de l'eau souterraine et marine. La compréhension de la nature et de l'ampleur de ces interactions est devenu un foyer de recherches, facilité par des avances récentes dans notre capacité de détecter la décharge submersible d'eaux souterraines. Cette étude emploie la détection distribuée de température (DDT) dans l'estuaire de la baie Indian River, sur la côte du Delaware, afin de détecter des différences dans la variance et la moyenne de la température des eaux à l'interface entre la baie et le sédiment dans la zone près du rivage du parc Holts Landing. Des variances basses sont interprétées comme étant le résultat de l'influence de modération des eaux souterraines, compatible avec les autres études, et le fait que les zones peu profondes près du rivage, qui devraient éprouver plus de variation de la température que des zones plus profondes, sont au contraire plus stables. La variance augmente avec la distance du rivage à mesure que la fonction s2=-33.63 (d(- 1.012)) +2.685 (r2=0.78). Près du rivage, il y a des endroits étroits avec des variances (Kruskal-Wallis avec Tukey's HSD, p&lt;0.05) et moyens (Friedman avec Tukey's HSD, p&lt;0.05) sensiblement plus basse que leurs zones proximales. Des zones de la variance élevée aux bords a l'ouest et l'est de l'emplacement d'étude sont associées aux anciennes vallées peu profondes remplies de la tourbe et maintenant couvertes avec les sédiments fins. Une large bande de bas désaccord à côté de la vallée occidentale implique que les eaux souterraines fraîches sosu pression élevée coulent aux marges de la vallée, créant un modèle du SGD qui n'équipe pas des modèles précédents. Une tentative d'employer des amplitudes de signal de la température à de diverses profondeurs de sédiment pour calculer le flux vertical d'eau interstitielle a échoué, probablement en raison des temperatures croissantes, interférence entre les signaux de la marée et diurne, et une période d'échantillon courte. DDT semble tenir la promesse en détectant des tendences de la température à travers différentes gammes simultanément, et peut être employé pour trouver les pieces manquantes de la connaissance des systèmes hydrogéologiques.</description><creator>Carver, Robert</creator><contributor>Jeffrey McKenzie (Internal/Supervisor)</contributor><date>2013</date><subject>Health And Environmental Sciences - Environmental Sciences</subject><title>Inferring hydrogeologic processes with distributed temperature sensing in Indian River Bay, Delaware</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/wp988p519.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/w6634714t</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Earth and Planetary Sciences</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:n583xz63z</identifier><datestamp>2020-03-21T19:53:57Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>This thesis will involve an examination of Enlightenment notions of humans and nature, and how these have been embedded in modern human activities. The thesis will focus on the key theories arising from: Hobbes and the materialists; Descartes and the dualists; and Newton and the classical economists. Particular ideas, concerning the natural philosophy of Descartes and Hobbes, and the physics of Newton and its impact on classical and neoclassical economists, will be examined. A broad historical trajectory of their ideas, and their influence, will be traced through time to today. The example of livestock agriculture, focussing on the practice of factory farming, will be used as a tangible example of the ways in which certain conceptions of humans, nature, and human-nature relations are now manifest in our modern society.  Factory farming will be used as a centre piece to illuminate the ethical and animal welfare implications manifest in Enlightenment narratives. Data on global livestock agriculture drawn from the UNFAO Livestock's Long Shadow report 2006 will be used to reveal the myriad negative repercussions that livestock agriculture has had, and continues to have, on animals and the natural environment. The concluding chapter will weave together the ideas of the thesis, and offer a brief glimpse of alternative human-nature narratives which may be more conducive to the flourishing of intergenerational and interspecies life.</description><description>Cette thèse examine des concepts philosophiques sur la nature humaine et de l'environnement provenant des philosophes des Années Lumières. La thèse se concentre sur les théories de: Hobbes et les matérialistes; Descartes et les dualistes; puis Newton et les économistes classiques. Une trajectoire historique de ces idées et de leur influence sera donnée. L'agriculture moderne, en particulier l'élevage industriel, sera utilisé pour donner un exemple tangible de la façon dont certaines conceptions philosophiques de l'être humain, de l'environnement, et de l'interaction entre l'humanité et la nature se manifestent aujourd'hui dans notre société moderne.  Selon notre thèse, l'élevage industriel moderne reflète ou révèle malheureusement bien des implications éthiques et des protections des animaux des philosophes des Années Lumières. Des données sur l'élevage industriel  provenant de l'Organisation des Nations Unies pour l'Alimentation  et l'Agriculture seront utilisées pour démontrer les multitudes répercussions négatives que l'agriculture moderne a eu, et continue d'avoir, sur les animaux et l'environnement. Le dernier chapitre comprend une synthèse des idées principales de cette thèse, et offre brièvement quelques narratifs ou discours alternatifs sur l'être humain et l'environnement qui pourraient conduire à un plus grand épanouissement intergénérationnel et interspécifique de la vie sur Terre.</description><creator>Ames, Julie Anne</creator><contributor>Peter Gilbert Brown (Internal/Supervisor)</contributor><date>2013</date><subject>Social Sciences - Geography </subject><title>Enlightenment philosophies of humans and nature: implications for animal agriculture</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/z029p836w.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/n583xz63z</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of Geography</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:9p290f13w</identifier><datestamp>2020-03-21T19:53:58Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Both tectonics and climate profoundly influence orogenisis, but specifics regarding the forcings, interactions and feedbacks are still largely unclear.  This study addresses the evolution of the Cordillera Blanca Mountain Range of northern Peru: an elevated, high-relief, 200 km long string of glaciated peaks comprising the spine of the Andes.  Extension along the Cordillera Blanca Detachment Fault (CBDF) actively produces relief along the western flank of the range, exceeding several kilometers in many areas. Abundant records of past glaciations span from &gt;440 ka to the present in the form of moraine and bog deposits.  Thus, tectonics (active faulting) and climate (glacial erosion) are operating in tandem to produce some of the highest topography in the western hemisphere.  Understanding these processes in the Cordillera Blanca will provide an invaluable perspective into tectonic and climatic effects on orogenisis.Through the combined use of cosmogenic 10Be, low temperature thermochronology and digital terrain analysis, I explore the erosional and morphologic history of the range over a variety of spatial and temporal scales.  Significant variations in modern range elevation (maximum, mean, modal and minimum), relief (local and within basins) and slope (maximum, mean and minimum) exist along the strike of the range, potentially reflecting the combined effects of variable displacement along the CBDF and varying degrees of glacial erosion.  The morphology of the adjacent supradetachment basin varies as well, containing zones with distinct styles of faulting and basin growth, likely defined in part by the segmentation history of the CBDF.  By combining Holocene-scale 10Be basin-averaged erosion rates with new thermochronologic data, I expand the known denudation history of the range.  These two datasets constrain the exhumation and erosional history of the range-forming Cordillera Blanca Batholith from the late Miocene to Holocene, and expand the thermal history of the range southwards to include the older Carhuish Stock.  Two new vertical 10Be exposure age transects allow comparison of fluvial incision rates within the Cordillera Blanca Batholith and the older Coastal Batholith.  Incision rates from the site in the Cordillera Blanca record uplift on the order of ~1 mm yr-1, and potentially place a minimum constraint on CBDF slip rates at this location. Incision rates from the Coastal Batholith are twice as fast (~2 mm yr-1) possibly representing large-scale regional uplift.  Exhumation rates and erosion rates generally fall between 0.01 and 0.5 mm/yr, suggesting a fairly continuous state of erosion over long-term (10^6 yrs) to recent (&lt;10^3 yrs) time scales.  Aside from a seemingly isolated zone of elevated erosion rates, no trends are observed along the strike of the mountain range.  As the CBDF is believed to display variable slip-rates along strike, it seems that associated base level lowering is not a first order control on basin-averaged erosion rate.</description><description>Bien qu'il soit établi que la tectonique et le climat influencent profondément l'orogénèse, plusieurs questions demeurent en ce qui a trait aux forçages, interactions et rétroactions. Cette étude se penche sur l'évolution de la cordillère Blanche, dans le nord du Pérou : une chaîne de sommets glacés à haut relief de 200 km de longueur, épine dorsale des Andes. L'extension le long de la faille de détachement de la cordillère Blanche (FDCB) cause la formation de relief sur le flanc ouest de la chaîne sur plusieurs kilomètres dans certaines zones. D'abondantes traces de glaciations passées, datant de plus de 440 ka jusqu'à la période actuelle, sont présentes sous forme de dépôts de moraines et de tourbières. Donc, la tectonique (mouvements de failles actives) et le climat (érosion glaciaire) opèrent en tandem pour produire l'une des topographies les plus accidentées de l'hémisphère ouest. Une évaluation pointue des procédés en cause dans la cordillère Blanche permettra une meilleure compréhension des effets de la tectonique et du climat sur l'orogénèse. En utilisant une combinaison de datation par l'isotope cosmogénique 10Be,  de thermo-chronologie de basse température et d'analyse de modèles numériques de terrain, cette étude explore l'historique d'érosion et morphologique de la chaîne sur plusieurs échelles spatiales et temporelles. De variations significatives d'altitude moderne de la chaîne (maximale, moyenne, modale et minimale), de relief (local et en bassin) et de pente (maximale, moyenne et minimale) existent le long de la chaîne et sont potentiellement dues aux effets combinés de mouvements variables le long de la FDCB et de différents degrés d'érosion glaciaire. La morphologie du bassin de supra-détachement adjacent varie également et contient des zones dotées de styles distincts de faille et de développement de bassin, probablement définis en partie par l'historique de segmentation de la FDCB. En combinant les rythmes d'érosion (âges 10Be, moyennes de bassin à l'échelle holocène) avec de nouvelles données thermo-chronologiques, ces travaux augmentent l'étendue connue de l'historique de dénudation de la chaîne. Ces deux bases de données documentent l'historique d'exhumation et d'érosion du batholithe de la cordillère Blanche depuis la fin du Miocène jusqu'à l'Holocène et étendent l'historique thermal de la chaîne vers le sud pour inclure le plus ancien Carhuish Stock. Deux coupes d'âges d'exposition verticale par 10Be permettent une comparaison des rythmes d'incision fluviale au sein du batholithe de la cordillère Blanche et du plus ancien batholithe côtier. Les rythmes d'incision au site de la cordillère Blanche indiquent un soulèvement d'environ 1 mm par an et suggèrent un glissement minimal de la FDCB de cet ordre à cet endroit. Les rythmes d'incision au batholithe côtier sont deux fois plus rapides (~2 mm par an), possiblement dû à un soulèvement d'échelle régionale. Les rythmes d'exhumation et d'érosion sont généralement de 0.01 à 0.5 mm par an, indiquant une érosion continue sur le long (10^6 années)  et court terme (&lt;10^3 années). Outre une zone isolée de rythmes d'érosion apparemment élevés, aucune tendance n'est observée le long de la chaîne de montagnes. Comme la FDCB est connue pour ses rythmes de glissement variables le long de la chaîne, il semble que l'abaissement du niveau de base associé ne soit pas un contrôle de premier ordre sur les rythmes d'érosion moyens à l'échelle du bassin.</description><creator>Hodson, Keith</creator><contributor>Sarah Hall (Internal/Supervisor)</contributor><date>2013</date><subject>Earth Sciences - Geology</subject><title>Morphology, exhumation, and Holocene erosion rates from a tropical glaciated mountain range: the Cordillera Blanca Peru</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/z603r2132.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9p290f13w</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Earth and Planetary Sciences</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:8336h519z</identifier><datestamp>2020-03-21T19:53:59Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Analysis on hydroclimatic variables can provide information on how the climate has evolved over time. This can be accomplished through time series analysis. Trend analysis in hydroclimatic variables is challenging due to their non-stationary nature and the presence of noise and stochastic components in them. The principal objective of this study is to detect and analyze trends in mean surface air temperature, total precipitation and mean streamflow obtained from several stations in Ontario and Quebec, Canada. To accomplish this, we co-utilized the wavelet transform (WT) technique (more specifically, the discrete wavelet transform (DWT)) and the Mann-Kendall (MK) trend test. The time series used were decomposed via the DWT in order to separate their high-frequency and low-frequency components, prior to testing their statistical significance with the MK trend test. The trend (i.e. slowly changing processes) is assumed to be contained in the low-frequency component of the data. The trends in temperature, precipitation and flow are assessed on different bases: monthly, seasonal, and annual. Temperature trends for the different seasons (i.e. winter, spring, summer, and autumn) were also assessed. In this study, we demonstrated the use of WT in extracting information contained in the time series that is not obvious in the raw data. The advantages of the WT technique are highlighted by its ability to extract time-frequency information contained in the analyzed time series  manifested in the form of periodicities ranging from intra-annual to decadal events. A new criterion is also proposed in this study where the relative error of the MK Z-values between the approximation component of the last decomposition level and the original data was used to determine the number of decomposition levels of the analyzed time series, the type of Daubechies (db) mother wavelet, and the border condition to be used in the DWT procedure.The procedures contained in the methodology for trend analysis outlined in this study have not been explored in the existing literature. First of all, we tested for the presence of a significant autocorrelation in a time series prior to applying the MK test, which is often ignored in many trend detection studies. The time series were then decomposed via the DWT; the MK trend test and sequential MK test were then applied in order to determine the most significant periodic mode affecting the observed trends. In this study, three versions of MK test were used, depending on the characteristics of the analyzed data. The original MK test was used on data that exhibit neither seasonality patterns nor significant autocorrelations. Seasonal MK test by Hirsch and Slack (1984) was used on the time series exhibiting seasonality cycles (with or without significant autocorrelations). Modified MK test by Hamed and Rao (1998) was used on data with significant autocorrelations. Finally, combining the application of the DWT and MK test in trend assessment in hydroclimatic time series (especially in the context of Canadian studies) has not been explored. Therefore, the results obtained in this study contribute to furthering the overall understanding of climatic change in Southern Ontario and Quebec. Although the trends in the different variables studied are affected by different time periodicities, the study found that generally positive trends are more dominant. Among the most important findings of this study are: (i) all temperature data show positive values, which implies warming trends (ii) precipitation and flow trends are affected by fluctuations of up to four years, and (iii) annual positive trends in temperature may be attributed mostly by winter and summer warming. This suggests that if the temperature trends remain in the positive direction, other hydroclimatic indices may also experience significant changes in the future.</description><description>Quoique le système climatique soit très complexe, une analyse des variables hydroclimatiques peut indiquer l'évolution du climat avec le temps. Une analyse de séries temporelles peut servir à ces fins; plus spécifiquement, l'analyse des tendances des variables hydroclimatiques peut approfondir l'étude des retombées des changements climatiques. L'analyse des tendances des variables hydroclimatiques est un défi en raison de leur caractère non stationnaire et la présence de bruit et d'autres éléments stochastiques. L'objectif principal de cette étude fut de détecter et d'analyser les tendances de différent types de données (débit, pluviométrie, température moyenne de l'air en surface), provenant de plusieurs stations en Ontario et au Québec (Canada). Ces stations sont concentrées dans le sud de ces provinces. Pour accomplir cette tâche, nous avons utilisé à la fois une technique de transformée par ondelettes (TO) [spécifiquement une transformée d'ondelette discrète (TOD)] et le test standard d'analyse des tendances Mann-Kendall (MK). Les séries temporelles furent décomposées par TOD afin de séparer à même les données les éléments à haute et basse fréquence, avant d'évaluer leur signification statistique avec le test MK. La tendance (i.e., le procédé à changement lent) est censé appartenir à l'élément à basse fréquence de la série temporelle. Les tendances du débit, de la pluie et de la température furent évaluées sur différentes échelles temporelles : mensuelle, saisonnière et annuelle. Les tendances temporelles de température pour les différentes saisons (hiver, printemps, été, automne) furent également évaluées.Cette étude montra comment l'utilisation du TO permet d'identifier et extraire des informations présentes dans une série temporelle qui ne sont pas évidentes à première vue dans les données brutes, ou suivant qu'on applique seulement le test des tendances MK. Les avantages de la méthode TO sont manifestes dans son habilité à extraire des informations temps-fréquence (i.e., périodicité intra-annuelle à décennale selon le genre de données utilisées) de la série temporelle analysée. Nous proposons un nouveau critère, où l'erreur relative entre les valeurs-Z du test MK pour l'élément d'approximation du dernier niveau de décomposition et celui des données d'origine sert à déterminer le nombre de niveaux de décomposition de la série temporelle analysée, le type d'ondelette mère de Daubechies (db), et les conditions de bordure devant servir à la TOD.Particulièrement dans le contexte canadien, l'utilisation d'une combinaison de TOD et du test MK dans l'évaluation de tendances dans les séries temporelles de données hydoclimatques demeure rare. Les résultats de cette étude contribueront donc à une compréhension globale grandissante des changements climatiques du sud de l'Ontario et du Québec. Quoique les tendances des différentes variables étudiées suivent différentes périodicités temporelles, l'étude montre que les tendances à la hausse dominent. Parmi les plus importantes conclusions de cette étude sont: (i) les tendances de débit et de précipitation suivent des fluctuations de jusqu'à quatre ans, (ii) toutes les catégories de données de température montrent des tendances à la hausse, laissant entendre une tendance au réchauffement, et (iii) les tendances annuelles à la hausse de la température peuvent être attribuées à un réchauffement des hivers et étés. Cela implique que si les tendances de température demeurent à la hausse, d'autres indices hydroclimatiques montreront des changements dans l'avenir.</description><creator>Nalley, Deasy</creator><contributor>Jan Adamowski (Internal/Supervisor)</contributor><date>2013</date><subject>Earth Sciences - Hydrology</subject><title>Analyzing trends in temperature, streamflow and precipitation over Southern Ontario and Québec using the discreet wavelet transform</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/c247dw93b.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/8336h519z</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Bioresource Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:v118rh96v</identifier><datestamp>2020-03-21T19:54:00Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>En s'appuyant sur des mesures de transport effectuées sur deux dispositifs qui incluent des boîtes quantiques doubles verticales, nous modélisons et analysons les données pour étudier le mélange des niveaux d'énergie intra-boîte et les oscillations du courant de longue période. Bien que les spectres expérimentaux à une particule soient en général bien décrits par les spectres des potentiels de confinement harmoniques elliptiques, l'observation d'anticroisements des niveaux dans les spectres à une particule indique que les potentiels réels des boîtes ne sont pas parfaitement harmoniques elliptiques. Nous avons réussi à modéliser avec succès le phénomène de croisement des niveaux, ainsi que le spectre dans son ensemble, en ajoutant de petits défauts au potentiel de confinement harmonique elliptique idéal. En comparant les spectres résultant aux données expérimentales et en ne retenant que les défauts qui améliorent la concordance avec ces données, nous avons developpé itérativement un potentiel qui donne lieu à un spectre s'accordant très bien avec l'expérience. Nous étudions une caractéristique du courant tunnel qui est hystérétique lors d'un balayage du champ magnétique et qui montre des oscillations temporelles du courant quasi-périodiques et de longue durée de vie. Les précédentes observations de semblables oscillations du courant ont été limitées au régime de blocage de spin à basse tension, tandis que celles-ci sont observées à tension élevée (-12 mV) et à large champ magnétique (~ 4 T). Nous appliquons des techniques de traitement de signal telles que l'autocorrélation et l'analyse du spectre de puissance pour quantifier le comportement oscillatoire des mesures de courant, révélant une forte  périodicité centrale de ~ 100-150 s des oscillations et un maximum de la densité spectrale de puissance qui est près de quatre ordres de grandeur supérieur au bruit de fond intrinsèque. En outre, nous quantifions un certain nombre d'autres aspects de cette fonction oscillante, y compris la transition des observations du courant de l'etat `haut' vers l'état `bas' lorsqu'un champ magnétique est balayé à travers la caractéristique. Bien qu'un modèle expliquant l'origine de ces phénomènes ne soit pas encore disponible, ils sont postulés être le résultat d'interactions hyperfine.</description><description>Building upon transport measurements conducted on two vertical double quantum dot devices, we model and analyze data to investigate intra-dot energy level mixing and long-period oscillations of current. While experimental single-particle spectra are well-described overall by the spectra of elliptical harmonic confinement potentials, the observation of level anticrossings in the single-particle spectra indicates that the real dot potentials are not perfectly elliptical harmonic. We successfully model the level crossing phenomenon, and the spectrum as a whole, by adding small defects to the ideal elliptical harmonic confinement potential. By checking the resulting spectra against the experimental data and only keeping the defects which improve the match, we iteratively develop a potential that gives rise to a spectrum that agrees very well with experiment.We investigate a tunneling current feature that is hysteretic under B-field sweeps and exhibits long-lived quasi-periodic temporal oscillations of current. Previous observations of similar current oscillations have been limited to the low-bias spin blockade regime, while these are observed at high bias (-12 mV) and high magnetic field (~4 T). We apply signal processing techniques such as autocorrelation and power spectrum analysis to quantify the oscillatory behaviour of the current measurements, revealing a strong central periodicity of ~100-150 s for the oscillations and a peak in power spectral density that is almost four orders of magnitude higher than background noise. In addition, we quantify a number of other aspects of this oscillating feature, including the transition of current observations from the `high' state to the `low' state as magnetic field is swept through the feature. Though a model explaining the origin of these phenomena is still lacking, they are postulated to be the result of hyperfine interactions.</description><creator>Harack, Benjamin</creator><contributor>David Austing (Internal/Supervisor)</contributor><contributor>Michael Hilke (Internal/Cosupervisor2)</contributor><date>2013</date><subject>Physics - Solid State</subject><title>Energy level mixing and hyperfine effects in double vertical quantum dots</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/fq977z55c.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/v118rh96v</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Physics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:mp48sh17r</identifier><datestamp>2020-03-21T19:54:01Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Le repère de guidage, la nétrine-1 et ses récepteurs, supprimé dans le cancer colorectal (DCC) et les homologues UNC-5, sont impliqués dans le développement et l'organisation des circuits mésocorticolimbique de la dopamine (DA). Nous avons précédemment démontré que les souris hétérozygotes pour le gène dcc ont altérations phénotypiques spécifiques du cortex préfrontal médiale (CPFm) circuits, ce qui n'apparaissent qu'après l'adolescence. Actuellement, le rôle de UNC5C dans le développement et la fonction des projections DA de l'aire tegmentale ventrale (ATV) reste mal comprise. Le but de cette étude était de déterminer si l'expression UNC5H est sélectivement exprimée par les neurones dopaminergiques qui se projettent à l'CPFm ou noyau accumbens (NAcc). À cette fin, j'ai utilisé un traceur des voies rétrograde du CPFm, et le centre et l'enveloppe du NAcc. J'ai combiné cela avec immunomarquage de la tyrosine hydroxylase (TH) et UNC5H dans l'ATV de souris adultes de type sauvage. Neurones avec n'importe quelle combinaison d'étiquettes ont été visualisées sous un microscope optique et comptées à l'aide d'une optique de conception de fractionnement stéréologique. Mon analyse a révélé que l'expression UNC5H par neurones DA de l'ATV n'est pas spécifique à la cible, tandis que l'expression UNC5H par l'ATV non-DA neurones est sélective pour les neurones se projetant vers le CPFm. Ces résultats jeté les bases de futures études visant à évaluer le rôle de UNC5H dans l'organisation de DA et non DA-circuits de l'ATV.</description><description>The guidance cue, netrin-1, and its receptors, deleted in colorectal cancer (DCC) and the UNC-5 homologues, are involved in the development and organization of mesocorticolimbic dopamine (DA) circuitry. We have previously demonstrated that mice heterozygous for the dcc gene have phenotypic alterations specific to medial prefrontal cortex (mPFC) circuitry, which only appear after adolescence. Currently, the role of UNC5C in the development and function of VTA DA projections remains poorly understood. The goal of this study was to determine whether UNC5H expression is selectively expressed by DA neurons which project to the mPFC or nucleus accumbens (NAcc). To this end, I used retrograde tract-tracing from the mPFC, and the core and shell of the NAcc. I combined this with immunolabeling of tyrosine hydroxylase (TH) and UNC5H in the ventral tegmental area (VTA) of adult wild type mice. Neurons with any combination of labels were visualized under a light microscope and counted using an optical fractionator stereological design. My analysis revealed that UNC5H expression by VTA DA neurons is not target-specific, whereas UNC5H expression by VTA non-DA neurons is selective for neurons projecting to the mPFC. These findings set the basis for future studies aimed at assessing the role of UNC5H in the organization of DA and non-DA VTA circuitry.</description><creator>Daubaras, Mark</creator><contributor>Ana Cecilia Flores Parkman (Internal/Supervisor)</contributor><date>2013</date><subject>Psychology - Psychobiology </subject><title>Is there differential expression of the netrin-1 receptor, UNC-5, between neurons of the mesocortical and mesolimbic pathways?</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/mp48sh181.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/mp48sh17r</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Integrated Program in Neuroscience</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:db78tg58c</identifier><datestamp>2020-03-21T19:54:02Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Surface plasmon resonance (SPR) sensing is seen as a viable option for developing biological sensors that provide portable, real-time, integrated detection systems. Certain implementations of this sensing technique have already been commercialized, but there is a continued trend to provide systems that are ever-more compact and integrated. In accordance with this trend, previous work has designed a multi-channel SPR device which relies on diffractive lenses to couple light to and from its sensing spots. This thesis presents the development of a fabrication process for these lenses using electron beam lithography, and presents optical results from a prototype device. The fabrication process is demonstrated to provide a high degree of control for pattern alignment and for the size of fabricated features. The developed method is then used to create a reflective diffractive lens on a silicon substrate. The diffraction efficiency of the lens is measured to be approximately 18%, and the focal spot size of the lens is in accordance with predictions based upon the fabricated profile.</description><description>La résonance plasmonique de surface (SPR) est considérée comme une option convenable pour le développement de capteurs biologiques offrant un système de détection portatif, en temps réel et intégré. Certains instruments utilisant cette technique de détection ont déjà été commercialisés; cependant, la tendance se maintient pour le développement de systèmes qui sont encore plus compacts et intégrés. Dans cette même direction, un dispositif SPR à multiples canaux basé sur des lentilles diffractives pour focaliser la lumière vers et depuis les régions de détection a été conçu précédemment. Cette thèse présente la conception d'un procédé de fabrication pour ces lentilles utilisant la lithographie par faisceau d'électrons ainsi que les résultats optiques obtenus avec un prototype. Il est démontré que le procédé de fabrication permet un grand contrôle de l'alignement du motif et de la taille des détails. La méthode conçue est ensuite utilisée pour créer une lentille diffractive et réflective sur un substrat de silicium. L'efficacité de diffraction de la lentille est de 18% environ et la taille du faisceau au foyer est en accord avec les prédictions basées sur le profile de fabrication.</description><creator>St Quintin, Andra</creator><contributor>Andrew G Kirk (Internal/Supervisor)</contributor><date>2013</date><subject>Engineering - Electronics and Electrical</subject><title>Electron beam lithography of a diffractive element for surface plasmon resonance sensing</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/c247dw94m.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/db78tg58c</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:jw827g287</identifier><datestamp>2020-03-21T19:54:03Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Élever un enfant ayant un trouble du développement comprend des défis supplémentaires par rapport aux faiblesses uniques de l'enfant.  Ceux-ci peuvent profondément affecter le bien-être du parent. Cette étude chercha à évaluer une gamme de domaines du fonctionnement de l'enfant, ainsi que les stratégies d'adaptation des parents, pour déterminer quelles caractéristiques influent le plus sur la santé mentale du parent. L'hypothèse émise avança que les parents ayant un enfant avec des troubles de comportement, des faiblesses sociales, et un fonctionnement adaptatif inférieur démontreront plus de dépression, d'anxiété, et d'hostilité (une mesure de la colère et de l'agressivité).  De même, il a été prévu que les parents ayant des stratégies mal adaptées par rapport à l'élevage des enfants éprouveront ces mêmes symptômes. En utilisant les donnés du National Early Intervention Research Initiative (NEIRI), la présente étude visa 124 parents d'enfants ayant un trouble du développement. Une analyse de régression multiple révéla que l'indice prédisant le mieux la dépression, l'anxiété, et l'hostilité chez les parents fut la présence de troubles de comportement chez l'enfant. Les compétences sociales des enfants prédirent de façon significative les indices de l'anxiété et l'hostilité chez les parents, mais pas la dépression. Le soutien social prédit la dépression, l'anxiété, et l'hostilité parentale. Cependant, les autres stratégies d'adaptation n'eurent pas d'effets significatifs sur la santé mentale des parents dans cet échantillon. Cette étude a de nombreuses implications pour les interventions axées sur des familles comprenant des enfants avec des troubles du développement.</description><description>Parenting a child with a developmental disability has its own set of additional challenges or difficulties associated with the child's impairments, which can have a great impact on parents' well-being. The present study sought to assess a range of child functioning domains and parent coping skills in order to understand which child characteristics and parent coping strategies are the most predictive of parent mental health. It was hypothesized that parents of children with more behaviour problems, fewer social skills, and lower adaptive functioning would exhibit more symptoms of depression, anxiety, and hostility (a measure of anger and aggression). Similarly, parents who used more maladaptive coping strategies and fewer adaptive coping strategies were also expected to experience more symptoms of depression, anxiety, and hostility. Using data from the National Early Intervention Research Initiative (NEIRI), this study included 124 parents of children with DD. Multiple regression analyses indicated that child behaviour problems were the strongest child functioning predictor of parent depression, anxiety, and hostility. Children's social skills were a significant predictor of parent anxiety and hostility, but did not significantly predict depression in parents. Social support was a significant predictor of depression, anxiety, and hostility in parents. However, other coping strategies did not significantly predict variance in parent mental health. This study has implications for family-centered intervention services for children with DD and their families. </description><creator>Manay Quian, Natalia</creator><contributor>Ingrid Sladeczek (Internal/Supervisor)</contributor><date>2013</date><subject>Education - Psychology </subject><title>Child functioning, parent coping strategies and parent mental health outcomes in families with children with developmental disabilities</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/qn59q7812.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/jw827g287</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of Educational and Counselling Psychology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:1c18dk17r</identifier><datestamp>2020-03-21T19:54:03Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les recherches précédentes on montrés que des mécanismes hyper-redondants (MHR)sont fortement adaptables en bougeant sur la terre. Cependant, leurs capacités pourraient aussi être étendues aux environnements aquatiques par la propulsion semblable à celle de l'anguille. Les nageurs anguilliforme naturels sont autant manuvrables qu'extrêmement efficaces. Cependant, ces propriétés dépendent de déformations très spécifiques du corps. La compréhension actuelle de la nage ondulatoire ne fournit pas de méthode claire ou de façon optimale afin de définir ces déformations pour un système fortement articulé. L'étude présentée ici résout cette question en développant un processus informatique capable de produire des démarches optimales pour un robot hyper-redondant nageant. Le processus est composé d'un modèle nageant et d'un algorithme d'essaim de particules faits sur mesure. Cette solution d'optimisation est utilisée pour produire des démarches efficaces pour la natation sur une gamme de vitesses différentes et pour la haute accélération. Bien que le développement du processus d'optimisation soit une fin en soi, les propriétés de la cinématique de la nage optimale fournis aussi un aperu sur les MHRs et sur la natation ondulatoire dans un sens plus général. Des stratégies de contrôle simples, des problèmes-clés pour le design, et des sujets potentiels pour le travail à venir sont extraits des résultats.</description><description>Hyper-redundant mechanisms (HRMs), also known as snake-like robots, have been the target of a small but focused research push over the past four decades. Consisting of a simple kinematic chain with a large number of redundant degrees of freedom (DoF), they can act manipulators approximating the form and function of an elephant's trunk, or undulatory locomotors mimicking the motions of snakes, worms, and other creatures. Although past research on locomotion has largely restricted itself to land-based studies, hyper-redundant mechanisms are inherently well suited to aquatic propulsion. Their structural form allows them to directly mimic the swimming motions of anguilliform fish. Biological anguilliform swimmers are both maneuverable and extremely efficient, however, these properties hinge upon finely tuned body deformations. The current understanding of undulatory swimming does not provide a clear method to optimally define these deformations for a highly articulated system. The present study solves this issue by developing a scheme capable of producing optimal gaits for a hyper-redundant swimmer. The optimization process consists ofa self-propelled swimming model and a custom particle swarm algorithm. The proposed scheme is used to produce optimal gaits for efficient swimming over a range of different velocities and for high acceleration. Although the development of the gait generation process is an end in itself, the properties of the optimal swimming kinematics also provide insight on HRMs and undulatory swimming in a more general sense. Simple control strategies, key issues for design, and potential topics for future work are extracted from the results.</description><creator>Wiens, Alexander</creator><contributor>Meyer Nahon (Internal/Supervisor)</contributor><date>2013</date><subject>Engineering - Mechanical </subject><title>Gait optimization for a multilink anguilliform swimmer</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/k930c180j.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/1c18dk17r</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Mechanical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:sn00b224t</identifier><datestamp>2020-03-21T19:54:04Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La rareté de la dolomite récente contraste avec son abondance dans des roches sédimentaires anciennes, conduisant au paradoxe communément appelé "le problème de la dolomite". Malgré de nombreuses tentatives, en l'absence de médiation bactérienne, la dolomie n'a jamais été précipitée à la température ambiante à partir de l'eau de mer naturelle. Il a été proposé que les environnements naturels propices à la formation de dolomite peuvent être des systèmes dynamiques, pour lesquels la chimie de l'eau (pH, alcalinité, l'état de saturation à l'égard de minéraux spécifiques) fluctue en réponse aux variations des conditions environnementales (par ex.: l'activité biologique, la température, la salinité). Cependant, il y a très peu de la littérature consacrée à la simulation de ces changements environnementaux. Dans cette étude, nous avons simulé, en alternant entre des intervalles de dissolution et de précipitation dans l'eau de mer naturelle par une purge de gaz de différentes pressions partielles en CO2 (pCO2), la nature dynamique des milieux naturels. En alternant entre des périodes de sur-saturation et sous-saturation par rapport à l'aragonite, seule de la calcite a été détectée après le 18ième cycle à 25 °C. En revanche, nous n'avons observé ni calcite et ni dolomite dans les précipités aragonitiques après 20 et 25 cycles à 40 °C. Une partie des objectifs de cette étude - contrer règle d'Ostwald sur les transformations successives (états intermédaires) et la synthèse de calcite dans l'eau de mer naturelle à 25 °C - ont été atteints, mais l'expérience à 40oC n'a pas donné le résultat espéré. Une explication possible est que des noyaux stables de calcite ne se sont pas accumulés à une concentration assez élevée après 25 cycles à 40 °C, que suffisamment de surface calcitique était disponible pour contrer la nucléation de l'aragonite. Une autre explication est que la stabilité des grappes de pré-nucléation, dont la conformation dépend possiblement de la chimie de la solution et de la température, se forment et contrôlent la cristallisation d'un polymorphe spécifique de carbonate de calcium.</description><description>The scarcity of recent dolomite contrasts strongly with its common abundance in ancient sedimentary rocks, leading to the paradox commonly referred to as the "dolomite problem". Despite many attempts, dolomite has never been precipitated at room temperature from natural seawater in the absence of bacterial mediation. It has been proposed that natural environments conducive to dolomite formation may be dynamic systems, in which the water chemistry (pH, alkalinity, saturation state with respect to specific minerals) fluctuates in response to variations in environmental conditions such as biological activity, temperature, salinity. Nevertheless, there is little literature dedicated to simulating such environmental changes. In this study, we simulated the dynamic nature of natural environments by alternating between intervals of dissolution and precipitation in natural seawater through purging gases of different CO2 partial pressures (pCO2). By alternating between periods of aragonite supersaturation and undersaturation, aragonite was obtained during the first few cycles at 25 and 40oC, but only calcite was detected in the 18th cycle of the experiments at 25oC. In contrast, neither calcite nor dolomite were detected in the precipitates after 20 and 25 cycles at 40oC. Parts of the objectives in this study—breaking the Ostwald Step Rule and synthesizing calcite from natural seawater at 25oC—were achieved, but the 40oC experiment did not yield the result we hoped for. One possible explanation is that stable calcite nuclei may not have accumulated to a high enough concentration after 25 cycles at 40oC that sufficient calcite surfaces were available to offset the nucleation of aragonite. Another explanation is that stable pre-nucleation clusters, whose conformation may also be dependent on solution composition and temperature, control the crystallization of a set calcium carbonate polymorph. </description><creator>Wang, Tingting</creator><contributor>Alfonso Mucci (Internal/Supervisor)</contributor><date>2013</date><subject>Earth Sciences - Geochemistry</subject><title>Breakdown of the Ostwald step rule - The precipitation of calcite and dolomite from seawater at 25 and 40 °C</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/41687m75x.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/sn00b224t</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Earth and Planetary Sciences</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:7h149t16b</identifier><datestamp>2020-03-21T19:54:05Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>This thesis provides a comprehensive criticism of the current models of understanding and caring for the mentally ill in a western context. I will outline the debates surrounding the conceptualization, diagnosis and treatment of mental illness. The western, psychiatric, biologically based understanding of mental illness is the dominant model of understanding and treating mental illness, despite the evidence that it encompasses an incomplete understanding of the causation and nature of mental illness. I will outline the difficulties in the creation of a cohesive definition of mental illness, including philosophical and cultural perspectives. I will examine the impact of historical, societal and capital pressures on the creation of these definitions. I will describe the practical issues and ethical tensions inherent when a definition or diagnosis of mental illness is created and taken up by mental health practitioners, who use this definition to develop treatment plans for the mentally ill. I will conclude that these issues result in a system of conflicting values which leads to less than ideal care for a uniquely vulnerable population. In this light, I conclude that the exclusive use of the DSM diagnoses as an objective basis for the creation of treatment plans is ethically questionable. I call for a new model of professional practice based on individualized treatment and primarily I call for a reduced focus on diagnosis in the care of the mentally ill.</description><description>Cette thèse propose une critique complet des modèles actuels de compréhension et d'empathie pour les malades mentaux dans un contexte occidental. Je vais chercher à décrire la compréhension actuelle de l'Ouest et débats entourant le diagnostic et le traitement de la maladie mentale. Le western, psychiatrique, la compréhension fondée sur la biologie de la maladie mentale est augmentation de la prévalence et de l'influence dans le monde. Cependant, je vais montrer que d'autres modèles et de leurs les traitements associés ont le potentiel, et le font souvent, générer améliorée résultats. Je crois que ce que j'appelle le modèle occidental medical de la maladie mentale englobe une compréhension incomplète de la causalité et le traitement de la maladie mentale. Je vais mettre en lumière les problèmes pratiques et des tensions éthiques inhérentes quand une définition ou le diagnostic de la maladie mentale est créé  et utilise par les praticiens de santé mentale , qui utilisent cette définition à élaborer des plans de traitement pour les malades mentaux. Je exposer les difficultés dans la création d'une définition cohérente de la maladie mentale, y compris les perspectives philosophiques et culturels. Je vais examiner l'impact des pressions sociétales sur la création de ces définitions. Je vais conclure que le modèle occidental répandue médical, tout en étant utile en tant qu'outil, est imparfait comme une approche exclusive de soins de santé mentale. Cette faiblesse est observé lorsque l'on prend note de la variation incroyable dans le diagnostic et l'expérience de la maladie mentale chez les individus. Dans cette optique, je conclus que l'exclusivité, l'utilisation aveugle des diagnostics comme une base objective pour la création de plans de traitement est éthiquement discutable. Je suggeste à un nouveau modèle de pratique professionnelle basée sur le traitement individualisé et je demande une moindre accent sur le diagnostic dans la prise en charge des malades mentaux.</description><creator>Pachkowski, Katherine</creator><contributor>Jennifer Fishman (Internal/Supervisor)</contributor><date>2013</date><subject>Health Sciences - Mental Health</subject><title>The diagnosis of madness: examining conflicting concepts of mental illness and the ethics of care in psychiatry</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/f4752m448.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/7h149t16b</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Medicine</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:8049g8485</identifier><datestamp>2020-03-21T19:54:06Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les structures de télécommunication sont des éléments essentiels des réseaux de télécommunication d'urgence qui doivent rester fonctionnels en cas de séismes. Bien que l'étude du comportement de ces structures sous l'effet du vent ou des séismes ait fait l'objet de plusieurs études numériques utilisant la méthode des éléments finis, très peu de ces études ont été validées à l'échelle réelle par des mesures expérimentales dans la littérature scientifique. Cette recherche présente une étude expérimentale détaillée des caractéristiques dynamiques d'une tour de télécommunication haubanée de 111.2 m de hauteur, propriété d'Hydro Québec et située à Saint-Hyacinthe, Québec. Cette étude procède par mesures de vibrations ambiantes (ou bruit ambiant) le long du mât et des câbles de haubans. Ces enregistrements ont ensuite été analysés pour en extraire les caractéristiques dynamiques telles les fréquences naturelles dominantes et les modes de vibration associés ainsi que leur taux d'amortissement. Ces résultats expérimentaux ont ensuite été comparés aux prédictions numériques par éléments finis afin de déterminer la précision des modèles. Les mesures d'accélération prises sur les câbles de haubans ont été utilisées pour calculer les tensions mécaniques dans les différents groupes de haubans. L'importance d'utiliser des valeurs précises des tensions dans les haubans pour obtenir des prédictions numériques réalistes est démontrée dans les analyses aux valeurs propres (fréquences et modes naturels dominants) et confirmée par une série d'analyses sismiques non linéaires utilisant trois exemples classiques de tremblements de terre. Une dernière série d'analyses sismiques a considéré deux conditions de charges de gravité, soit le pylône sans masses additionnelles et le pylône chargé de tous ses composants fonctionnels - antennes, lignes de communication et accessoires tels les échelles, plates-formes de repos, etc., lesquels contribuent poids et inertie. Ces simulations numériques ont également considéré une variation des tractions initiales d'installation des câbles de haubans entre 8% et 15% de leur capacité ultime, et quatre cas de séismes, ajoutant un séisme artificiel pour Montréal aux trois cas classiques utilisés précédemment. En conclusion, les caractéristiques dynamiques du pylône obtenues par simulation se sont avérées en accord avec les mesures pour cet intervalle de tractions des haubans, ce qui laisse présager une précision réaliste des simulations sismiques quand la variabilité des tractions des haubans est prise en compte.</description><description>Telecommunication structures are essential components of communication and post-disaster networks that must remain operational after a design-level of earthquake. Although many studies have been done to evaluate the response of these structures when subjected to wind and earthquakes, almost all of them are numerical simulations using finite element analysis models. In fact the most common way for predicting the dynamic characteristics of these towers is using nonlinear dynamic analysis models, and there is a lack of experiments in this field. In other words, despite of all the numerical studies which have been done with care and expert knowledge, little validation with physical tests or measurements has been reported to evaluate the level of accuracy of these computational studies. Hence the degree of uncertainty of these modeling predictions has not been determined up to now even in controlled laboratory conditions. The research presents full-scale investigations of the dynamic characteristics of a real 111.2 m tall guyed telecommunication tower owned by Hydro Québec and located in St. Hyacinthe, Québec. Ambient Vibration Measurements (AVM) were carried out on the tower mast and supporting guy cables to determine dominant natural frequencies, mode shapes and damping properties. A comparison of the results extracted from the AVM records and those predicted by detailed finite element models indicates the level of accuracy of the models and future dynamic analysis. Acceleration measurements on the guy wires provide the database for calculating the cable tensions. The importance of considering accurate cable tensions for the study of the dynamic characteristics of the tower was demonstrated by the comparison between the numerical eigenvalue analyses of detailed finite element tower models with various adjustments in cable tensions. This was further emphasized in a series of earthquake simulations under three classical earthquakes records. A final series of numerical simulations were done under two different gravity loading cases, namely with and without consideration of tower attachments such as antennas, transmission lines, and other appurtenances such as ladder, resting platforms, etc., which contribute additional weight and inertia. These simulations were done using a range of guy wire tensions varying between 8% and 15% of the cables rated breaking strength and under four earthquake records, adding an artificial Montreal record to the three previous classical ones. In conclusion, considering that the actual cable tension may vary in the studied range of values has provided a good agreement between the experimental dynamic characteristics of the tower and non-linear finite element models results. On that basis, the accuracy of the seismic analysis results is validated.</description><creator>Ghafari Osgoie, Mahtab</creator><contributor>Ghyslaine McClure (Internal/Supervisor)</contributor><date>2013</date><subject>Engineering - Civil</subject><title>Validation of seismic response prediction of a guyed telecommunication mast with ambient vibration measurements</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/n296x275p.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/8049g8485</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Civil Engineering and Applied Mechanics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:76537448s</identifier><datestamp>2020-03-21T19:54:07Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La superhydrophobicité d'une surface se mesure en termes de sa mouillabilité. Une surface robuste manifeste une superhydrophobicité quand une gouttelette d'eau est doucement déposée sur la surface ou introduite de force sur elle. Régie par la chimie de surface et la topologie de surface, la mouillabilité de surface correspond à des états d'équilibre d'énergie minimisée, également appelés des états de mouillage. Les états mouillants sont caractérisés par des configurations géométriques uniques assumées par chacune des interfaces lorsqu'un système de goutte-surface-air se forme. Les circonstances relatives à la formation d'un système de goutte-surface-air est un facteur important dans la conception des critères de robustesse. Suivant une approche computationnelle en deux étapes, cette thèse analyse les états de mouillage possibles pour une surface et, par conséquent, commente sur la faisabilité de ces états dans le contexte de la conception d'une surface robuste et superhydrophobe. Dans la première étape, une topologie de surface de pilier carré est choisie, et les états de mouillage sont exprimés en termes de la profondeur de pénétration de l'eau dans les vallées de rugosité de la surface. La mouillabilité de la surface est determinée pour les cas suivants: sans pénétration (état Cassie), pénétration partielle (état Cassie métastable) et pénétration complète (état Wenzel). L'état Cassie métastable est quantifié en établissant une relation implicite entre la mouillabilité et la profondeur de pénétration. Dans la deuxième étape, la faisabilité thermodynamique de l'état Cassie métastable est entendue de manière à concevoir le critère de robustesse. L'état Cassie métastable constitue un état intermédiaire possible entre les états Cassie et Wenzel, et l'énergie libre du Cassie métastable détermine l'état de robustesse. Trois cas sont isolés pour la robustesse, qui exigent que le Cassie ou Cassie métastable soit l'état le plus favorable en termes thermodynamiques. On peut atteindre la condition thermodynamique par une combinaison appropriée de la hauteur de pilier et de la chimie pilier. On constate les états Cassie métastable lorsqu'une goutte est déposée à des vitesses faibles (2 mms-1), ce qui pourrait se produire par inadvertance lorsqu'on mesure la mouillabilité. Il est constaté qu'en cas d'une collision inélastique entre le bord de l'eau en mouvement et la surface, la probabilité d'une existence d'un état metastable est plus élevée, donc on a plus de chances de produire une surface superhydrophobe. </description><description>Superhydrophobicity of a surface is measured in terms of its wettability. A robust surface exhibits superhydrophobicity when a water droplet is gently deposited or forcibly impinged on it. Governed by the surface chemistry and the surface topology, the surface wettability corresponds to energy minimized equilibrium states, also known as wetting states. The wetting states are characterized by unique geometric configurations assumed by each of the interfaces as a drop-surface-air system is formed. The circumstances governing the formation of a drop-surface-air system hold a key in designing the robustness criteria. Following a two-step computational approach, this thesis analyses the possible wetting states for a surface and consequently comments on the feasibility of these states in context of designing a robust superhydrophobic surface. In the first step, a square pillar surface topology is chosen, and the wetting states are expressed in terms of the penetration depth of water inside the roughness valleys of the surface. Expressions for surface wettability are determined for no penetration (Cassie state), partial penetration (metastable Cassie state) and complete penetration (Wenzel state). The metastable Cassie state is quantified by establishing an implicit relation between the wettability and the penetration depth. In the second step, the thermodynamic feasibility of the metastable Cassie state is understood so as to design the robustness criterion. The metastable Cassie state forms a possible intermediate state between the Cassie and the Wenzel states, and the free energy of the metastable Cassie state determines the robustness condition. Three cases are isolated for the robustness which require either of the Cassie or the metastable Cassie to be the most thermodynamically favorable state. This thermodynamic condition can be attained with an appropriate combination of pillar height and pillar chemistry. It is seen that the metastable Cassie states exists, when a drop is deposited at low velocities (2 mms-1). It is seen that with the choice of an appropriate drop radius and impact velocity, a metastable state can be found. The existence of a metastable state enhances the chances of rendering a surface superhydrophobic.</description><creator>Sarkar, Anjishnu</creator><contributor>Anne-Marie Kietzig (Internal/Supervisor)</contributor><date>2013</date><subject>Engineering - Chemical</subject><title>Wetting robustness on patterned surfaces</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/rn301495x.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/76537448s</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Chemical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:dv13zx800</identifier><datestamp>2020-03-21T19:54:08Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>CCN (Content Centric Networks) est une architecture réseau récemment proposée. Elle peut potentiellement réduire l'utilisation de bande passante et améliorer l'extensibilité et la sécurité du réseau par rapport à l'architecture IP existante. Dans cette thése, nous conduisons une analyse énergétique comparative des CCN et des réseaux IP dans le cas du streaming vidéo. Nous considérons deux types de consommation d'énergie: celle requise pour construire les éléments du réseau et celle requise pour le fonctionnement du réseau. Nous réalisons des simulations de CCN sur trois topologies réseaux différentes (réseau en arbre, réseau de distribution et maillage partiel) afin de vérifier la réduction du traffic obtenue avec l'introduction d'un cache aux niveau des routeurs. Nous générons deux types de demandes de traffic (Zipf et distribution uniforme) pour réaliser cette analyse. Bien que les éléments d'un réseau CCN aient une plus grande consommation d'énergie par rapport à leur équivalent des réseaux IP et qui sont dues à la présence de mémoire supplémentaire, l'exploitation de leur capacité de cache permet de réduire la consommation d'énergie totale du réseau. Contenu de mise en cache au niveau des routeurs présents sur les niveaux inférieurs du réseau (clients prés) se traduit par la réduction du trafic sur les liens qui sont à proximité du serveur (source de contenu). Nous exploitons cette caractéristique du CCN à base de réseau à l'aide d'adaptation de débit pour obtenir des avantages de l'énergie. Nous considérons à la fois l'incorporation d'un mécanisme en ligne taux d'adaptation ainsi que d'un réseau statique approche de provisionnement et d'observer que ces approches peuvent conduire à une réduction substantielle de la consommation d'énergie pour les CCN. D'autre part, un réseau basé sur IP ne peut pas bénéficier de l'adaptation du débit en raison de l'absence des routeurs capables de cache.</description><description>Content-Centric Networking (CCN) is a recently proposed networking architecture that can potentially lead to reduced bandwidth usage and better scalability and security as compared to the current IP-based architecture. In this thesis,we conduct a green analysis of content-centric networking and IP-based networking for a video streaming scenario.We consider two types of energy consumption: the energy required to manufacture the network devices and the energyrequired for operation. We perform simulations of content centric networking over three different network topologies (i.e., general tree, Content Distribution Network (CDN) tree and partial mesh) to assess the traffic rate reductions achieved by CCN's insertion of caches at routers. We generated two different types of traffic demands (Zipf and Uniformly distributed) to perform our analysis. Although CCN network devices have a higher intrinsic energy consumption compared to the IP-based devices because of the presence of additional memory, by exploiting their caching capabilities it is possible to reduce the overall energy consumption of the network. Content caching at the routers present on lower levels of the network (near clients) results in reducing traffic on the links which are close to the server (content source). We exploit this feature of CCN-based network by using rate adaptation to achieve energy benefits. We consider both the incorporation of an on-line rate adaptation mechanism as well as a static network provisioning approach and observe that these approaches can lead to a substantial reduction in energy consumption for CCN. On the other hand, an IP-based network cannot benefit from rate adaptation due to the absence of  the cache capable routers.</description><creator>Butt, Muhammad Rizwan</creator><contributor>Mark Coates (Internal/Supervisor)</contributor><date>2013</date><subject>Engineering - Electronics and Electrical</subject><title>A green analysis of the content centric networking architecture</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/pc289n49p.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/dv13zx800</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:ht24wn922</identifier><datestamp>2020-03-21T19:54:09Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>A reasonable representation of some complex systems such as social and biological systems is a network topology that allows its components and interactions among them to change over time. Understanding the time-dependence of these networks can lead to invaluable insight about characteristics and structure of time-varying networks. In this thesis, several classes of static and dynamic clustering algorithms and ideas are reviewed. A challenge arising in dynamic clustering schemes is that the detected communities  are not independent over time and the identified clusters at one point of time should not dramatically deviate from the results of previous timesteps. It is especially important to reduce large short term variations and ensure that communities smoothly change over time. Here we present a novel method which is built upon a probabilistic generative Bayesian model to address the problem of identifying consistent and stable overlapping communities in dynamic networks. Synthetic and real networks are used to evaluate the performance with respect to different parameter settings, the model order selection, and the run-time of the proposed algorithm. Performance analysis indicates thatthe algorithm proposed in this thesis outperforms several other state-of-the-art algorithms and provides valuable insights into the evolution and underlying structure.</description><description>Une représentation raisonnable de certains systèmes complexes tels que les systèmes sociaux et biologiques est une topologie de réseau qui permet à ses composants et les interactions entre eux de changer au fil du temps. Comprendre la dépendance temporelle de ces réseaux, conduire à de précieux renseignements sur les caractéristiques et la structure de variables dans le temps des réseaux. Dans cette thèse, plusieurs classes d'algorithmes de clustering statiques et dynamiques et des idées sont passées en revue. Un défi se pose dans des plans de regroupement dynamiques est que les communautés détectées ne sont pas indépendants dans le temps et les grappes fondées à un moment donné du temps ne doit pas s'écarter de façon spectaculaire à partir des résultats de pas de temps précédents. Spécialement, il est de l'importance de diminuer de fortes variations à court terme et d'assurer que les communautés progressivement changer au fil du temps. Ici, nous présentons une nouvelle méthode qui repose sur un modèle bayésien génératif probabiliste pour résoudre le problème de l'identification des communautés stables et cohérentes qui se chevauchent dans les réseaux dynamiques. Réseaux synthétiques et réelles sont utilisées pour évaluer la performance par rapport à différents paramètres, la sélection pour modèle, et le moment de l'exécution de l'algorithme proposé. Analyse de la performance indique quel'algorithme proposé dans cette thèse surpasse plusieurs autres algorithmes et révèle l'aperçu inestimable d'un réseau e-mail réelle.</description><creator>Afsariardchi, Niloufar</creator><contributor>Mark Coates (Internal/Supervisor)</contributor><date>2013</date><subject>Engineering - Electronics and Electrical</subject><title>Community detection in dynamic networks</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/ht24wn93b.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/ht24wn922</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:gb19f9599</identifier><datestamp>2020-03-21T19:54:10Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Ce travail propose comme explication à l'asymétrie avant-arrière, anormalement large, observée au Tevatron, le processus de production de quark top par échange de squark bottom qui s'inscrit dans le Modèle Standard Supersymétrique Minimal, avec violation de R-parité. Les resultats démontrent une bonne concordance entre les données d'asymétrie du quark top, tout en restant en accord avec la section efficace totale de production et la section efficace differentielle. Le modèle développé est fortenant contraint par les données de violation de la parité atomique, resultant des contributions au couplage effectif entre le quark down et le boson Z, mais il est possible de limiter cet effet, en prenant en considération le mélange du squark top. Ce modèle est aussi contraint par les contributions importantes aux courants neutres de changement de saveur. Cependant, si les squarks de troisième génération sont légers, ces contributions peuvent être évitées.</description><description>The interaction of bottom squark-mediated top quark pair production, occuring in the R-parity violating minimal supersymmetric standard model (MSSM), is proposed as an explanation of the anomalously large forward-backward asymmetry (FBA) observed at the Tevatron. It is found that this model can give a good fit to top quark data, both the inclusive and invariant mass-dependent asymmetries, while remaining consistent with the total and differential production cross-sections. The model faces very strict constraints from atomic parity violation (APV), resulting from contributions to the effective down quark-Z vertex, but this constraint may be weakened by the additional diagram which is included when top squark mixing is accounted for, and can be satisfied for suitable values of the top squark mass and mixing angle. The model is also challenged by large contributions to flavour-changing neutral currents, however these may be avoided in scenarios admitting heavy first and second generation squarks.</description><creator>Dupuis, Grace</creator><contributor>James M Cline (Internal/Supervisor)</contributor><date>2013</date><subject>Physics - Theory</subject><title>Top quark forward-backward asymmetry in R-parity violating supersymmetry</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/rj430818s.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/gb19f9599</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Physics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:7h149t17m</identifier><datestamp>2020-03-21T19:54:10Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Toile de fond : La Zambie est l'un pays les plus durement touchés par les infections du virus de l'immunodéficience humaine (VIH) et de la tuberculose (TB), et les personnes inscrites en clinique VIH représentent des groupes à haut risque susceptibles de développer la tuberculose active. L'avènement des techniques peu onéreuses d'établissement rapide d'un diagnostic de la TB, tels que le test GeneXpert de la présence des mycobactéries du complexe tuberculosis (MTB)/ résistance à la Rifampicine (RIF) et l'analyse MODS d'une culture sensible aux médicaments observée au microscope, proposent une méthode diagnostique prometteuse et abordable pour identifier et  traiter rapidement les cas d'infection. Cependant, la rentabilité de ces tests n'est pas bien reconnue dans les régions gravement touchées affichant une prévalence élevée d'infections au VIH. Objectif : Évaluer le rapport coût-efficacité de différentes stratégies de diagnostic TB d'une cohorte de patients infectés par le VIH à Lusaka, en Zambie. Méthodes : L'analyse coût-efficacité (ACE) – rapport de rentabilité – fut menée à bien grâce à l'utilisation d'une modélisation de l'analyse décisionnelle. En prenant en compte les cohortes proportionnelles d'inscrits en clinique VIH au Centre de recherche des maladies infectieuses en Zambie (CRMIZ), on a pu réaliser l'analyse comparative des stratégies suivantes : diagnostic TB conforme à la norme clinique de soins (combinaison de plusieurs méthodes : dépistage des symptômes, examen microscopique de frottis d'expectoration, et radiographie thoracique dans un algorithme diagnostique), test de dépistage TB amélioré (examen microscopique de frottis d'expectoration, radiographie thoracique et culture de la tuberculose), test GeneXpert de MTB/RIF, analyse MODS et traitement empirique. Les cas de guérison de la TB, les décès dus à la TB, les cas d'AVAI (années de vie ajustées en fonction de l'incapacité), et les rapports coût-efficacité différentiels (RCED) furent les aboutissements constatés qui firent l'objet d'une analyse. Une analyse de sensibilité à une voie, à l'aide de graphiques en tornade, fut menée sur tous les paramètres dans le but d'évaluer la consistance des conclusions. Résultats : Les résultats provenant de l'analyse du scénario de référence ont démontré qu'en comparaison avec la norme clinique de soins, le test de dépistage TB amélioré coûtait 2 749,00$ par cas d'AVAI évité. Le test GeneXpert, l'analyse MODS et le traitement empirique étaient tous très rentables puisque les coûts estimés étaient respectivement de 85,00$ par cas d'AVAI évité, 141,00$ par cas d'AVAI évité et 926,00$ par cas d'AVAI évité. L'analyse de sensibilité à une voie démontra que les RCED restaient stables quand les paramètres étaient testés sur différentes plages. Conclusions : Les résultats de cette étude donnent à penser qu'il existe plusieurs solutions de rechange très rentables à la stratégie de dépistage conforme à la norme actuelle de soins cliniques à Lusaka, en Zambie, en demeurant dans le cadre du seuil de la volonté de payer (VDP). Les tests GeneXpert et MODS sont tous deux particulièrement rentables pour établir un diagnostic de la TB chez les participants en clinique de traitement du VIH à Lusaka, en Zambie.</description><description>Background: Zambia is a high burden country for both Human Immunodeficiency Virus (HIV) and Tuberculosis (TB) infection and HIV clinic enrollees are a high-risk group for active TB. The advent of low-cost rapid-diagnostic technologies for TB, such as the Gene Xpert MTB/RIF assay and microscopic-observation drug-susceptibility (MODS) culture, suggest an affordable and promising diagnostic method to quickly identify and treat cases. However, the cost-effectiveness of these tests are not well-established in high burden areas with a high prevalence of HIV.     Objective: To determine the cost-effectiveness of different TB diagnostic strategies in a cohort of HIV-infected patients in Lusaka, Zambia.Methods: Cost-effectiveness analysis (CEA) was carried out using decision analysis modeling. Using the cohort proportions of HIV clinic enrollees at the Centre for Infectious Disease Research in Zambia (CIDRZ), the analysis compared the following strategies: standard of care TB diagnosis (a combination of symptom screening, sputum smear microscopy, and chest x-ray in a diagnostic algorithm), enhanced TB screening (sputum smear microscopy, chest x-ray and TB culture), Gene Xpert MTB/RIF Assay, MODS, and empiric treatment. Outcomes analyzed were TB cures, TB deaths, DALYs, and incremental cost-effectiveness ratios (ICERS). A one way sensitivity analysis using tornado diagrams was conducted on all parameters to test the robustness of the findings. Results: Results from the base case analysis found that compared to standard of care, enhanced screening cost $2,749 per DALY averted. Xpert, MODS, and empiric treatment were all highly cost-effective and cost $85 per DALY averted, $141 per DALY averted, and $926 per DALY averted, respectively. One way sensitivity analysis demonstrated that the ICERs were stable when parameters were tested over ranges. Conclusion: The findings of this study suggest that there are a number of highly cost-effective alternatives to the current standard of care screening strategy in Lusaka, Zambia within the willingness to pay threshold (WTP). In particular, Gene Xpert and MODS are both highly cost-effective for diagnosing TB in HIV clinic enrollees in Lusaka, Zambia.</description><creator>Mishra, Lipi</creator><contributor>Timothy Brewer (Internal/Supervisor)</contributor><date>2013</date><subject>Health Sciences - Epidemiology</subject><title>Evaluating the performance of Tuberculosis screening tools in a cohort of HIV infected patients in Lusaka, Zambia: a cost-effectiveness study</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/5138jj08x.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/7h149t17m</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Epidemiology and Biostatistics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:pg15bj463</identifier><datestamp>2020-03-21T19:54:11Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La présente thèse soumet des propositions de transformations structurelles complètes et de réformes idéologiques du processus de reconnaissance du statut de réfugié au Canada. Ces propositions sont conçues pour promouvoir les intérêts des parties prenantes. Un nouveau modèle du processus de reconnaissance du statut de réfugié, de nouvelles approches en matière d'enquête et d'évaluation de la crédibilité dans le contexte de demande d'asile, ainsi qu'un changement des valeurs systémiques sont proposés dans la présente thèse. Pour modifier le processus de reconnaissance du statut de réfugié en vigueur, il est suggéré de mettre sur pied un modèle qui repose sur un organisme entièrement judiciaire, similaire à la Cour canadienne de l'impôt, ou sur un organisme parajudiciaire ou interdisciplinaire, comme le Tribunal administratif du Québec, pour remplacer l'actuel organisme quasi judiciaire chargé d'effectuer la détermination initiale. Les nouvelles approches en matière d'enquête et d'évaluation de la crédibilité sont axées sur la notion que la vérité, dans le contexte de la demande d'asile, est relative et qu'elle n'est pas établie. Dans la mesure du possible, on devrait également privilégier le dialogue et la libre parole des réfugiés dans la salle d'audience. Les nouvelles valeurs systémiques mises de l'avant sont : la précision (apportée par la réception de renseignements non faussés et par la diffusion d'informations contextuelles de haute qualité); l'efficacité (assurée par la simplicité, l'économie et la rapidité mises sur pied dans les structures d'arbitrage); et la sensibilité de l'appareil judiciaire au contexte (exprimée par la sélection de critères appropriés, par une formation interdisciplinaire propre au contexte et par la promotion d'une culture juridique entourant le processus de prise de décision en matière d'asile). Ces propositions puisent leur inspiration dans des données empiriques, des réflexions universitaires interdisciplinaires et des initiatives antérieures de réforme. Elles sont conçues pour s'adapter aux défis inhérents au processus de reconnaissance du statut de réfugié.</description><description>This thesis presents a comprehensive structural and ideological reform proposal for refugee status determination in Canada designed to advance the interests of stakeholders.   We propose an alternative model for refugee determination, new approaches to fact finding and credibility assessment in the asylum context, and a shift in systemic values.  The alternative refugee status determination model proposed envisions moving from a quasi-judicial  initial determination body to either a wholly-judicial one, similar to the Tax Court of Canada or a para-judicial/interdisciplinary one, similar to the Tribunal administratif du Québec. New approaches to fact finding and credibility assessment have centered on the notion that truth in the asylum context is relative, not fixed, and that dialogue and unfettered refugee speech should be privileged as much as possible in the hearing room.  The new systemic values advanced have been accuracy (achieved through undistorted reception of information and dissemination of high quality contextual information), efficiency (achieved through simplicity, economy and timeliness being built into adjudicative structures) and juridical sensitivity to context (achieved through appropriate selection criteria, context-specific interdisciplinary training, and the fostering of a juristic culture around asylum decision making).  The proposals find their inspiration in empirical data, interdisciplinary academic thought and previous reform initiatives, and are designed to conform to the challenges inherent in refugee status determination.</description><creator>Zambelli, Pia</creator><contributor>Evan Fox-Decent (Internal/Supervisor)</contributor><date>2013</date><subject>Social Sciences - Law</subject><title>Refugee status determination in Canada and the path to radical reform</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/pn89db006.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/pg15bj463</identifier><degree><name>Master of Laws</name><grantor>McGill University</grantor><discipline>Faculty of Law</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:nk322j28r</identifier><datestamp>2020-03-21T19:54:12Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Cette thèse êtudie les avantages que peuvent fournir aux intéressées les micro-réseaux, et propose une approche à l'évaluation des couts et bénéfices. Un cadre flexible est proposé pour classer les intéressés, les avantages, et la répartition des avantages. Une méthodologie est présentée pour évaluer quelques avantages clés, incluant: amélioration de fiabilité, fourniture des services auxiliaires, possibilité de différer les investissements requis par l'augmentation de la charge par la réduction de la charge de pointe, et la réduction des émissions perturbatrices. Enfin, quelques études de cas micro-réseaux existants sont présentées, sous la forme de cas d'aaires à l'aide de la méthodologie présentée. Ceci est fait afin d'illustrer l'estimation et l'allocation des avantages, et pour une meilleure compréhension de l'interaction entreles paramètres qui définissent un projet de micro-réseau et les avantages dont bénéficient chacun des intéssés.</description><description>This thesis examines the benefits that Microgrids can provide to a variety of stakeholders and considers their costs. A flexible framework is proposed in which to consider Microgrid stakeholders, benefits, and benefit allocation. A methodology is presented for evaluating several key benefits, namely: reliability improvement, ancillary service provision, investment deferral resulting from both peak load reduction and ancillary service provision, as well as emissions reduction. Finally, several Microgrid case studies are evaluated as business cases using the methodology presented in order to illustrate benefit estimation and allocation, and to better understand the interaction between the parameters that define a Microgrid project and the resultant benefits seen by each stakeholder.</description><creator>Weyrich Morris, Gregory</creator><contributor>Geza Joos (Internal/Supervisor)</contributor><date>2013</date><subject>Engineering - Electronics and Electrical</subject><title>On the benefits and costs of microgrids</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/j098zf666.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/nk322j28r</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:1z40kx38t</identifier><datestamp>2020-03-21T19:54:13Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Using a fracture mechanics framework, we present a finite element method to simulate the break-up of 2D ice accreted on the wings of aircraft and the shedding of 3D ice accreted on blades of helicopter. The fully automated ice break-up module is integrated in FENSAP-ICE [1-2], which is an in-flight ice accretion simulation code that solves flow, droplet impingement and ice accretion, in sequence. The 2D and 3D crack propagation packages are developed and validated by comparing with published results for a single edge cracked plate test case and a single edge-notched specimen with three points bending load, respectively. Numerous complicated ice-shapes are analyzed and comparisons are performed with a contemporary fracture mechanics code. Under typical icing and flow conditions, linear elasticity is found to be adequate for ice break-up analysis. For ice accreted on wings, an important finding of this study is that the breaking of ice has a strong dependence on its shape, i.e. under similar aerodynamic loading, some ice shapes fail while others do not. For ice accreted on helicopters, the finding is that the rotational speed of the blade and interface strength between ice and blade material are the major factors governing the ice break-up. The main objective of this work is to analyze complex multi-physics phenomenon and provide a simplified ice break-up model for the industrial users and aerodynamic designers. The potential use of this tool, however, is not limited to aerodynamics; it can be applied in areas of environmental science, material science, glaciology, earthquake and rupture analysis. </description><description>Dans le cadre de la mécanique des fractures, nous présentons une méthode d'éléments finis qui simule le bris de la glace accumulée sur les ailes d'avions, en deux dimensions, ainsi que le délestage du givre accumulé sur les pales de l'hélicoptère, en trois dimensions. Le module de bris de glace, entièrement automatisé, est intégré en FENSAP-ICE [1-2], un logiciel de simulation qui résout séquenciellement le flux, l'impact des gouttelettes et le cumul de glace. Les modules bidimensionnels et tridimensionnels de propagation de fissures sont développés et validés par comparaison avec des résultats expérimentaux sur une plaque fissurée d'un seul côté, ainsi que pour un spécimen entaillé d'un seul côté avec une charge de flexion en trois points. Plusieurs formes de glace sont analysées et des comparaisons faites avec un autre code traitant la mécanique des fractures. Dans des conditions typiques de givrage et d'écoulement, l'élasticité linéaire s'est avérée adéquate pour une analyse du bris de glace. Pour la glace accumulée sur les ailes, une conclusion importante de cette étude est que le bris de glace dépend fortement de sa forme, c'est-à-dire que pour des charges aérodynamiques similaires, certaines formes de glace briseront, tandis que d'autres ne le feront pas. En ce qui concerne la glace accumulée sur les hélicoptères, il a été conclu que les facteurs les plus importants pour le bris de glace sont la vitesse rotationnelle de la pale et la force d'adhésion entre la glace et la pale. L'objectif principal de cet ouvrage est d'analyser des phénomènes multi-physiques complexes et de fournir un modèle simplifié du bris de la glace pour les utilisateurs industriels et les concepteurs en aéronautique. L'utilisation de cet outil n'est toutefois pas limitée à l'aérodynamique, puisqu'il peut être employé dans des domaines tels que les sciences environnementales, les sciences des matériaux, la glaciologie et l'analyse des tremblements de terre et de rupture. </description><creator>Zhang, Shiping</creator><contributor>Wagdi George Habashi (Internal/Supervisor)</contributor><date>2013</date><subject>Engineering - Mechanical </subject><title>FEM analysis of in-flight ice break-up</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/g158bm97q.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/1z40kx38t</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Mechanical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:x059cb93n</identifier><datestamp>2020-03-21T19:54:14Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>L'amplitude des mouvements de la colonne lombaire (ou ROM, pour range of motion en anglais) est traditionnellement mesurée à l'aide de multiples mouvements individuels exécutés sur les plans anatomiques. La technique utilisée pour obtenir cette mesure complique la recherche clinique, car elle repose sur l'hypothèse qu'une forte proportion de sujets présente la même déficience. L'objectif de cette thèse était donc d'évaluer la fiabilité d'une nouvelle mesure de mouvement global de la colonne lombaire, qui serait utilisée dans des études futures. Notre étude repose sur l'hypothèse que la fiabilité de cette mesure serait ≥ 0,9; de manière à répondre à des critères préalablement proposés pour suivre les progrès d'un patient unique.Vingt sujets souffrant d'une lombalgie chronique (ou LBP, pour low back pain en anglais) ont été recrutés pour deux séances. À chaque séance, les sujets, aidés d'une rétroaction visuelle, ont effectué 3 séries de 8 mouvements de fin d'étendue de colonne lombaire, à 45 degrés d'intervalle autour d'un cercle complet, et ce, dans un ordre aléatoire. Les mouvements de la colonne lombaire ont été obtenus au moyen de deux capteurs électromagnétiques à 6 degrés de liberté, placés sur la peau au-dessus des apophyses épineuses de la douzième vertèbre thoracique (T12) et de la première vertèbre sacrée (S1). La mesure qui nous intéresse a été calculée d'après la position relative de T12 dans le plan transversal de S1. Deux méthodes d'ajustement de courbe ont été utilisées pour lier les 8 points de fin de mouvement dans chaque série : l'ellipse par les moindres carrés et la fonction spline cubique. L'aire de la forme ainsi obtenue a servi à fournir une mesure de la ROM totale; et le point central, une mesure de la distribution et de la symétrie des mouvements. La théorie de la généralisabilité (en anglais Generalizability Theory) a été employée pour évaluer la fiabilité de l'aire de chaque forme et celle de son point central dans les axes antéro-postérieur et médio-latéral du plan transversal de S1. L'indice de fiabilité était excellent (0,94 – 0,95) pour la ROM globale de la colonne lombaire (l'aire) et allait de modéré à excellent (0,59 à 0,91) pour la distribution des mouvements (points centraux), avec des valeurs légèrement plus élevées pour la méthode d'ajustement par spline. L'analyse des données extrapolées a également indiqué que des valeurs similaires seraient obtenues en utilisant 3 répétitions de la tâche dans une séance unique. Ces résultats appuient l'utilisation de cette nouvelle mesure de la ROM de la colonne lombaire dans de futures études cliniques.</description><description>Lumbar spine range of motion (ROM) is conventionally measured using multiple, individual anatomical plane movements.  This is unwieldy for clinical research, because it relies on the assumption that a large proportion of subjects will present with the same impairment. The objective of this thesis work, therefore, was to assess the reliability of a novel measure of total lumbar spine ROM, to be used in future studies.  We hypothesized that the reliability of this measure would be ≥0.9, so as to meet previously suggested criteria for monitoring individual patient progress. Twenty subjects with chronic low back pain (LBP) were recruited for two testing sessions.  At each session, subjects performed 3 series of 8 end-range, randomly ordered lumbar spine movements, at 45 degrees intervals around the full circle, with the help of visual feedback.  Lumbar spine motion was acquired using two, 6-degrees-of-freedom electromagnetic motion capture sensors placed on the skin over the spinous processes of the twelfth thoracic (T12) and first sacral (S1) vertebrae.  The measure of interest was based on the relative position of T12 in the transverse plane of S1.  Two curve fitting approaches - least-squares ellipse and cubic spline - were used to fit a shape to the 8 end-positions of movement in each series.  The area of this shape was used to provide a measure of the total ROM, and the centre point to provide a measure of movement distribution and symmetry.  Generalizability theory was used to assess the reliability of the area of each shape, and of its centre point in the anterior-posterior and medio-lateral axes of the transverse plane of S1.   The index of dependability for the total lumbar spine ROM (area) was excellent (0.94 - 0.95), and moderate-to-excellent (0.59 – 0.91) for its distribution (centre points), with slightly better values achieved with the spline-fitting approach.  Analysis of extrapolated data also indicated that similar values would be achieved using 3 repetitions of the task in a single testing session.   These results support the use of this novel measure of total lumbar spine ROM in future clinical studies.  </description><creator>Al Zoubi, Fadi</creator><contributor>Richard Preuss (Internal/Supervisor)</contributor><date>2013</date><subject>Health Sciences - Physical Therapy</subject><title>Reliability of a measure of total lumbar spine range of motion in individuals with low back pain</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/6h440x37f.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/x059cb93n</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Physical and Occupational Therapy</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:pc289n50f</identifier><datestamp>2020-03-21T19:54:15Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Semiconductor nanowires, known for their high quality, large surface-to-volume ratio and coaxial quantum confinement, are a promising material for the next generation nano-electronics and nano-photonics devices. Intensive research on this material has been done over the past decade. In particular, the single nanowire electrical device, which can be fabricated using cleanroom technology and is compatible with the well-developed integrated-circuit processing technique, has significant practical applications. In this work, the complete process of fabricating a single nanowire device, from mask design to pre-patterned chip making, from nanowire transfer to nanowire device fabrication, from substrate preparation and cleaning to dicing, from spin-coating and exposure to developing, from metal deposition and lift-off to packaging, was carefully investigated. In addition, basic measurements and preliminary results such as resistance - temperature (R-T) behavior, resistance - magnetic field (R-B) behavior and current - voltage (I-V) curve, are shown. This thesis thus provides detailed information about compatibility of single semiconductor nanowires with the standard integrated-circuit technique and can serve as a manual for single nanowire electrical device fabrication.</description><description>Les nanofils semiconducteurs, connus pour leur haute qualité, leur large rapport surface/volume et leur confinement quantique coaxial, sont des matériaux prometteurs pour la prochaine génération de technologies nanoéléctroniqueset nanophotoniques. Une recherche intensive sur ces matériaux a été effectuée au cours de la dernière décennie. En particulier, les nanofils, qui peuvent être fabriqués en salle blanche, sont compatibles avec la technique maîtrisée du traitement en circuit intégré et ils ont des applications pratiques significatives. Dans ce travail, le processus complet de fabrication d'un dispositif à nanofil simple, de la conception du masque à la fabrication de puces, du transfert du nanofil à la fabrication de dispositifs à nanofil, de la préparation et nettoyage du substrat au découpage en dés, du dépôt par centrifugation et de l'exposition au développement, de la déposition et décollage du métal à l'emballage, a été examiné soigneusement. En outre, des mesures de base et des résultats préliminaires sont également présentés. Cette thèse fournit donc des informations détaillées sur la compatibilité des nanofils semiconducteurs avec la technique standard de circuit intégré et peut servir de manuel pour la fabrication de dispositifs à base de nanofilssimples.</description><creator>Shao, Chenxu</creator><contributor>Zetian Mi (Internal/Cosupervisor2)</contributor><contributor>Guillaume Gervais (Internal/Supervisor)</contributor><date>2013</date><subject>Physics - Solid State</subject><title>Fabrication of indium nitride nanowire hybrid devices</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/pc289n51q.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/pc289n50f</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Physics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:2n49t573q</identifier><datestamp>2020-03-21T19:54:16Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Recent years have seen a huge growth in the demand for online virtual worlds. The type of these online systems can range from virtual meeting setups, to a more video game like competitive environment. An equally large number of virtual worlds have been developed to meet this demand, and the competition between these system is very strong. Developers of such systems can benefit from any edge they can get in terms of technical quality of the system or the enjoy ability of the online experience.We propose that a monitoring system designed especially for virtual worlds will be able to provide that `èdge" to the developers. As such, we present, in this Thesis, a flexible real-time monitoring architecture which caters to the specific challenges and requirements of virtual worlds. Handling huge amount of data present in the worlds is dealt by distributing the data gathering process between multiple node. The proposed system modifies the gathered data, into a form more suitable for users to observe in real-time, by filtering it before displaying the final result. We use Mammoth, a massively multiplayer research framework, as the test-bed for a sample implementation of the proposed architecture. We use the results of experiments conducted on this implementation to validate that the system is indeed suitable for real-time monitoring of virtual worlds.</description><description>De nos jours, la demande des mondes virtuels est en plein essor. Ceux-ci vont des sites de rencontre jusqu'aux environnements compétitifs comme par exemple les jeux vidéo en ligne. Afin de satisfaire la demande de mondes virtuels, de nombreux sites ont été mis en place. Du fait de la très grande concurrence présente, les développeurs des services virtuels essayent de bénéficier de tout avantage possible en termes d'avantages techniques ou de la qualité des expériences vécues en ligne.Nous considérons qu'un système de surveillance des mondes virtuels est en mesure de fournir cet "avantage" aux développeurs. Ainsi, nous présentons dans notre thèse un système de surveillance en temps réel fait sur mesure afin de faire face aux défis et aux besoins particuliers de chaque monde virtuel. Afin de manipuler toute l'information obtenue des mondes virtuels, le processus d'obtention des données est distribué entre plusieurs nœuds. Le système que nous proposons modifie les données obtenues pour les rendre plus faciles à observer en temps réel. Ceci se fait en filtrant les données avant de déployer les résultats. Nous utilisons Mammoth, une infrastructure massif de recherche multi-joueurs comme le banc d'essai pour implémenter un échantillon de l'architecture proposée. Nous utilisons les résultats obtenus des expériences  réalisées dans cette implémentation pour confirmer que le système est approprié pour surveiller les mondes virtuels en temps réel. </description><creator>Khan, Hammad</creator><contributor>Jorg Andreas Kienzle (Internal/Supervisor)</contributor><date>2013</date><subject>Applied Sciences - Computer Science</subject><title>Monitoring distributed virtual worlds</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/p5547w01z.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/2n49t573q</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:t722hd30k</identifier><datestamp>2020-03-21T19:54:16Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Internet applications have recently witnessed tremendous growth in terms of both size and complexity.  Cloud computing is one of the several distributed technologies that have emerged to help meeting the objectives of these applications in terms of achieving high availability, performance and scalability.Platform as a Service (PaaS) is one kind of services provided by cloud solutions. These systems often follow a multi-tier architecture consisting mainly of a presentation tier, an application tier and a database tier. The volumes of data exchanged between the application tier and the database tier become huge, especially for enterprise level applications. As a result, the design of the database tier in cloud systems has to carefully address the scalability challenges rising from the huge data volumes. In this thesis, we propose a data distribution approach to improve the scalability of the database tier. Our approach is applied to a traditional single database server. It works by replacing the traditionally used single machine storage paradigm with a distributed storage paradigm. The suggested approach maintains the features that originally exists in the database system, and additionally provides the features of distribution and replication. Distributing the data storage helps improving the system fault-tolerance as it decreases the possibility of having a failure at the database server. It also helps resolve specific performance issues such as reducing the I/O usage and consecutively decreasing the possibility of an I/O bottleneck. Yet, it produces other performance challenges that need to be addressed.  To prove the feasibility of our proposed approach, we use it to implement two extensions to the storage manager module of the PostgreSQL database system, using the HDFS distributed file system, and the HBase distributed key-value store.</description><description>Les applications Internet ont récemment connu une croissance considérable en termes de taille et de complexité. Afin de satisfaire la forte demande pour les ressources informatiques et les espaces de stockage, les technologies en distribution ont commencé à devenir plus impliquées dans les applications à grande échelle. Le Cloud Computing est l'une de ces nombreuses technologies qui ont émergé pour aider à atteindre les objectifs de ces applications, telles que la haute disponibilité, les performances et l'évolutivité.Platform as a Service (PaaS) est un type de service qui peut être fourni par les solutions de Cloud Computing. Ces systèmes suivent souvent une architecture multi-niveaux qui se compose principalement d'un niveau de présentation, un niveau d'application et d'un niveau de base de données. Les volumes de données échangées entre l'application et la base de données deviennent énormes en particulier pour les applications de niveau entreprise. En conséquence, la conception de la base de données dans les systèmes de Cloud Computing doit prendre en compte le challenge de l'évolution des quantités énormes de données. Dans cette mémoire, nous proposons une approche de distribution des données qui peuvent être utilisées pour améliorer l'évolutivité des bases de données. Nous proposons deux techniques qui peuvent être appliquées à un serveur de base de données unique traditionnelle.Ces techniques fonctionnent en remplaçant le paradigme traditionnel utilisant une seule machine de stockage avec un paradigme de stockage distribué. Les techniques proposées maintiennent les caractéristiques qui existaient à l'origine dans le système de base de données, et en plus fournissent les caractéristiques de la distribution et de la réplication. Ces deux fonctionnalités supplémentaires aident à améliorer le système de tolérance aux pannes, car ils diminuent la possibilité d'avoir une défaillance au niveau du serveur de base de données. La distribution du stockage permet de résoudre les problèmes de performances spécifiques, tels que la réduction de l'utilisation des entrées/sorties et consécutivement de diminuer la possibilité de saturation des entrées/sorties.Par ailleurs, cela produit d'autres défis de performances qui doivent être pris en compte. Pour prouver la faisabilité de nos techniques, nous les avons implémentées comme des extensions du module de gestion de stockage de la base de données PostgreSQL.</description><creator>AlJabban, Tarek</creator><contributor>Bettina Kemme (Internal/Supervisor)</contributor><date>2013</date><subject>Applied Sciences - Computer Science</subject><title>Distributed database storage management for a cloud computing infrastructure</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/hd76s387b.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/t722hd30k</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><resumptionToken completeListSize="47894">oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):15850</resumptionToken></ListRecords></OAI-PMH>