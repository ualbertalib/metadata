<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/assets/blacklight_oai_provider/oai2-b0e501cadd287c203b27cfd4f4e2d266048ec6ca2151d595f4c1495108e36b88.xsl"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd"><responseDate>2020-07-25T03:31:29Z</responseDate><request resumptionToken="oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):37375" verb="ListRecords">https://escholarship.mcgill.ca/catalog/oai</request><ListRecords><record><header><identifier>oai:escholarship.mcgill.ca:9306t3623</identifier><datestamp>2020-03-23T20:10:05Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Ce mémoire comprend trois parties dont la première s’intéresse aux discours posthumes sur l’auteure québécoise Nelly Arcan, morte en 2009. Il s'agit plus précisément de mettre en lumière la mobilisation de la figure de l'écrivaine anglaise Virginia Woolf et d’observer les manières dont l’usage de l’iconographie woolfienne module la figure d’Arcan. Cette analyse concerne trois versions qui en ressortent : l’écrivaine, la suicidée et la féministe. Un texte de création répondant à cette étude initiale tente d'utiliser l’écriture pour contester les divers signes externes, tels le sexe, la langue et les origines, qui servent normalement à circonscrire l’identité individuelle. Un texte intermédiaire qui lie les deux parties du mémoire ainsi présente Quant à je (1996), un agrégat de l’auteure hongroise Katalin Molnár, comme modèle à suivre pour une exploration qui cherche, loin des représentations monolithiques observées dans la première partie, à construire une représentation identitaire hétéroclite</description><description>This thesis is comprised of three parts. The first part examines posthumous discourses on the Quebecoise author Nelly Arcan, who died in 2009. It entails more precisely bringing to light the mobilization of the figure of the English author Virginia Woolf, analyzing the ways in which using Woolfien iconography in discourses modulates the figure of Arcan. This analysis looks at three resulting versions, the writer, the suicide, and the feminist. A creative writing text responds to this initial study by using writing to contest various external signs, such as sex, language and origins, that normally serve to circumscribe individual identity. An intermediary text links the two parts by presenting Quant à je (1996), an aggregate by the Hungarian author Katalin Molnár, as a model to follow in this exploration which seeks, far from the monolithic representations observed in the first part, to construct a heterogenous representation of identity</description><creator>Kogut, Magdalena</creator><contributor>Jane Everett (Supervisor1)</contributor><contributor>Alain Farah (Supervisor2)</contributor><date>2020</date><subject>French Language and Literature</subject><title>L’enterrement de la putain inconvenante ou la canonisation littéraire: Nelly Arcan et Virginia Woolf au Québec suivi du texte de création Agregacja : chercher les divers soi(s)</title><language>fre</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/xd07gz09d.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9306t3623</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of French Language and Literature</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:kk91fr289</identifier><datestamp>2020-03-23T20:10:11Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>L'industrie agricole réclame des tracteurs autonomes pour accélérer le processus des tâches agricoles. Bien que de nombreuses recherches aient été menées sur les véhicules autonomes, ces recherches concernent principalement les véhicules routiers, qui fonctionnent dans un environnement routier contrôlé.Cette thèse fait partie du projet Arion en cours de l'Institut du véhicule innovant (IVI). Le but ultime du projet Arion est de développer un véhicule agricole autonome, capable de fonctionner de manière autonome et en toute sécurité. Cette recherche est dédiée à la conception d'un contrôleur robuste pour maintenir la précision de la trajectoire du véhicule agricole autonome sur différents types de sol.Le véhicule agricole autonome conçu par l'IVI est un véhicule électrique à quatre roues motrices. Dans cette étude, les équations dynamiques du véhicule sont établis. Le modèle dynamique utilisé est le modèle à quatre roues, avec deux roues directrices orientables à l'avant. De plus, les équations de la mécanique des sols, concernant l'interaction entre le sol et les roues, sont développées. Les équations de la mécanique des sols sont alors résolues hors ligne, pour servir de table de recherche en ligne. Cette méthode augmentera l'efficacité, car les équations doivent être résolues numériquement et sont coûteuses en calculs. Les tables de recherche sont créées pour quatre types de sol, l'argile, le terreau, le sable et le terreau sablonneux.L'auteur propose une nouvelle architecture pour le contrôle du véhicule. Le système contient deux contrôleurs: Un PID pour le contrôle de la vitesse longitudinale et un contrôleur à modèle prédictif pour le contrôle de la direction. Dans cette architecture, un réseau de neurones est utilisé pour classifier le type de sol et pour servir de commutateur pour adapter le contrôleur MPC au nouveau type de sol.Le réseau de neurones est entraîne en utilisant des variables physiques, qui peuvent être mesurées avec des capteurs peu coûteux sur le véhicule, tels que la vitesse, l'angle de glissement et le taux de glissement, ainsi que l'enfoncement des roues dans le sol.Par la suite, la performance du contrôleur est évaluée indépendamment pour chaque type de sol, aussi que la performance du véhicule dans une ferme avec un sol mixte. Les résultats montrent une amélioration considérable de la précision lorsque le contrôleur proposé est utilisé</description><description>Agriculture industries call upon autonomous tractors to speed up the process of farming tasks. Although there has been a lot of research on autonomous vehicles, this research mostly concerns road vehicles, which operate in a controlled road environment.This thesis is a part of the ongoing Arion project, from Institut du Véhicule Innovant (IVI). The ultimate goal of the Arion project is to develop an autonomous farming vehicle, which can operate independently and safely. This research is dedicated to designing a robust controller to maintain the accuracy of the autonomous farming vehicle path on different types of soil.The autonomous farming vehicle designed at IVI is an electrical four-wheel-drive vehicle. In this study, the dynamics equations of the vehicle are derived. The model used here is a four-wheel model, with two steerable wheels in the front. Moreover, realistic terramechanics equations, regarding the interaction between the soil and the wheels, are established. The equations of terramechanics are then solved offline, to be used as a lookup table online. This method will increase the efficiency, as the equations need to be solved numerically, and are computationally expensive. The lookup tables are created for four different soil types: Clay, Loam, Sand, and Sandyloam.We introduce a novel scheme for the control of the vehicle. The system contains two controllers: a PID controller for longitudinal speed, and a Model Predictive Controller (MPC) for steering angle. In this scheme, a neural network is used to classify the soil type, and to act as a switch to adapt the MPC controller to the new soil type.The neural network is trained on physical features that can be measured with inexpensive sensors on the vehicle, such as velocity, slip angle, slip ratio, and wheel's sinkage in the soil.The performance of the controller for each soil type is evaluated independently, as well as the performance of the vehicle operating on a field with various soil types. The results show a considerable improvement in accuracy when the proposed controller is used</description><creator>Sobhanigavgani, Zeinab</creator><contributor>Benoit Boulet (Supervisor)</contributor><date>2020</date><subject>Electrical and Computer Engineering</subject><title>Development of a novel neural network-based control scheme for autonomous farming vehicles</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/rj430908r.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/kk91fr289</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:dn39x5573</identifier><datestamp>2020-03-23T20:10:37Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Brain implants have significant implications in treating neurological disorders and diseases and are a key enabler of brain machine interface (BMI) technology. However, brain implants’ widespread adoption in clinical settings is undermined by challenges in obtaining high-quality recordings and issues of long-term reliability caused by the elicited brain foreign body response (FBR). The brain FBR is exacerbated by the substantial mismatch in Young’s modulus (E) between current implants made from materials like silicon (150 - 200 GPa) and brain tissue (0.4 - 15 kPa). Recent research directed towards improving the mechanical compatibility of brain implants has given rise to more compliant implants made from materials like polyimide (4 - 8 GPa) that are flexible but are still orders of magnitude stiffer than the brain. Here, we present novel fabrication and implantation methods for the softest sub-millimetre intracortical implant to date made from Ecoflex, a silicone elastomer with E = 20 kPa. Non-functional Ecoflex implants (300 µm wide x 200 µm thick x 3 mm long) were fabricated using a sacrificial sugar mold replicated via soft lithography that was coupled with vacuum-assisted molding (VAM). To address the challenge of inserting soft implants into the brain, the implants were encased inside micro-molded dissolvable sugar shuttles (700 µm wide x 450 µm thick x 8 mm long) as temporary structural support for the implants to reliably penetrate brain tissue and to be delivered to the target location accurately. The brain FBR of Ecoflex implants was compared to those elicited by PDMS and silicon implants 3-week post implantation in rats. Immunohistochemistry results show lower brain FBR elicited by Ecoflex implants compared to both silicon and PDMS implants suggesting that a functional soft implant made from materials closer to brain stiffness such as Ecoflex could potentially demonstrate superior high-quality recordings and long-term reliability by reducing the brain FBR</description><description>Les implants cérébraux jouent un rôle important dans le traitement des troubles et maladies neurologiques et constituent un élément clé de l’interface cerveau-machine (IMC). Cependant, l’adoption généralisée des implants cérébraux en milieu clinique est limitée par la difficulté à obtenir des enregistrements de haute qualité et les problèmes de fiabilité à long terme causés par la réaction à un corps étranger (RCE) dans le cerveau. Cette RCE est exacerbée par l’importante différence entre le module de Young (E) du cerveau (0,4-15 kPa) et celui des implants cérébraux existants, généralement composés de silicium (100-200 GPa). Des recherches récentes portant sur l’amélioration de la compatibilité mécanique des implants cérébraux ont engendré des implants plus souples, faits par exemple de polyimide (4-8 GPa), qui font preuve d’une plus grande flexibilité mais demeurent plus rigides que le cerveau de plusieurs ordres de magnitude. Nous présentons ici de nouvelles méthodes pour la fabrication et l’implantation de l’implant cérébral le plus souple à ce jour, fait d’Ecoflex, un élastomère de silicone d’une rigidité E=20 kPa. Les implants non fonctionnels en Ecoflex (300 µm de largeur x 200 µm d’épaisseur x 3 mm de longueur) ont été fabriqués à l’aide d’un moule sacrificiel en sucre reproduit par lithographie douce combiné au moulage assisté par le vide (MAV). Pour relever le défi de l’insertion des implants souples dans le cerveau, ces derniers ont été encapsulés dans des navettes de sucre soluble (700 µm de largeur x 450 µm d'épaisseur x 8 mm de longueur) produites par micromoulage. Les navettes agissent à titre de support structural temporaire pour que les implants puissent pénétrer de manière fiable dans le tissu cérébral et être livrés à l’emplacement cible avec précision. La RCE cérébrale des implants en Ecoflex a été comparée à celles générées par des implants faits de PDMS et de silicium trois semaines après leur implantation chez des rats. Les résultats obtenus en immunohistochimie montrent qu’en général, la RCE induite dans le cerveau par les implants en Ecoflex est moindre comparativement à celles induites par les implants de silicium et de PDMS. Cela suggère qu’un implant souple fonctionnel fait de matériaux d’une rigidité plus proche de celle du cerveau, tel qu’Ecoflex, pourrait potentiellement mener à des enregistrements de qualité supérieure et à une meilleure fiabilité à long terme en réduisant la RCE dans le cerveau</description><creator>Zhang, Ningyuan</creator><contributor>Timothy E Kennedy (Supervisor2)</contributor><contributor>David Juncker (Supervisor1)</contributor><date>2020</date><subject>Bioengineering and Biomedical Engineering</subject><title>Silicone-based intracortical implants with brain-like stiffness reduces the brain foreign body response</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/w0892g41f.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/dn39x5573</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Bioengineering and Biomedical Engineering Program</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:d504rq73z</identifier><datestamp>2020-03-23T20:10:50Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>This study focuses on the effect of chevrons located on the tip of a flat plate on the overall aerodynamic performance and the near field structure of the tip vortex. The aerodynamic performance of chevrons with varying depths, cut directly into the tips of a flat plate with a semi aspect ratio of 3 were investigated using a time resolved six axis force/torque sensor at a Reynolds number of 67,000. Results show that that highest lift-to-drag ratio, L/D was obtained for an angle of attack of 5 degrees. For shallower chevrons, this L/D ratio was increased by up to 7.7% compared to a flat plate. It is known that the formation of a tip vortex depends on the geometry of the wing tip (Sarpkaya 1983, Giuni and Green 2013). The tip-vortex was measured using constant temperature anemometry and a four-wire hot-wire probe. The chevron plates formed tip vortices that have lower peak tangential velocities and larger core radii as compared to a flat plate. To ensure that this effect was due to the presence of chevrons and not due to wandering, which is an inherent meandering of the tip vortex, Devenport et. al’s correction was applied to the test plates with a laminar core (Devenport 1996). The tip vortices formed on wing tips with deeper chevrons exhibited a turbulent core, as opposed to those formed on a flat plate. It was also found that deeper chevron plates had an impact on the wandering of the tip vortex- plates with deeper chevrons exhibited a narrow range of frequencies over which the cross power spectral density coefficient showed a spike, as opposed to the flat plate, which showed spikes in the cross power spectral density coefficient at a wide range of frequencies</description><description>Cette étude porte sur l’effet de chevrons situés sur la pointe d’une plaque plate sur les performances aérodynamiques globales et sur la structure en champ proche du tourbillon marginal. Les performances aérodynamiques de chevrons de différentes profondeurs, découpés directement dans les pointes d’une plaque plate avec un demi-allongement d’aile de 3, ont été étudiées à l’aide d’un capteur de force et de moment à six axes à résolution temporelle, à un nombre de Reynolds de 67,000. Les résultats montrent que le rapport de finesse le plus élevé a été obtenu pour un angle d’attaque de 5 degrées. Pour les chevrons moins profonds, ce rapport L/D a été augmenté de 7.7% au maximum par rapport à une plaque plate. Il est démontré que la formation d’un tourbillon marginal dépend de la géométrie de l’extrémité de l’aile (Sarpkaya 1983, Giuni and Green 2013). Le tourbillon marginal a été mesuré par anémométrie à température constante et par une sonde à fil chaud à quatre fils. Les plaques avec chevrons ont formé des tourbillons marginaux ayant des vitesses tangentielles maximales plus basses et des rayons de noyau plus grands par rapport à une plaque plate. Pour s’assurer que cet effet était dû à la présence de chevrons et non à un biais, ce qui est un probléme inhérent au tourbillon marginal, la correction de Devenport et al. (Devenport 1996) a été appliquée aux plaques d’essai avec noyau laminaire. Les tourbillons marginaux formés sur les extrémités des ailes avec des chevrons plus profonds présentaient un noyau turbulent, par opposition à ceux formés sur une plaque plate. Il a également été constaté que les plaques à chevrons plus profonds avaient un impact sur le biais des plaques avec des tourbillons marginaux. Les chevrons plus profonds présentaient une plage de fréquences étroite dans laquelle le coefficient de densité spectrale de puissance croisée mon-trait un pic, par opposition à la plaque plate qui montre des pics du coefficient de densité spectrale de puissance croisée dans une large plage de fréquences</description><creator>Goyal, Anushka</creator><contributor>Jovan Nedic (Supervisor)</contributor><date>2020</date><subject>Mechanical Engineering</subject><title>Modification of tip-vortices using chevron wing tips</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/t722hf34w.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/d504rq73z</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Mechanical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:8g84mr79f</identifier><datestamp>2020-03-23T20:11:00Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>SOMMAIREIntroduction : Le dernier Rapport sur la Malaria dans le Monde, publié en novembre 2017, estimait à 219 millions le nombre de cas de Malaria et à 435 000 le nombre de décès dus à celle-ci pour l'année 2017 (1). L'OMS considère que la microscopie est la référence en matière de diagnostic clinique de la Malaria en raison de sa disponibilité immédiate. Cependant, la microscopie présente de nombreuses lacunes, notamment la variabilité et l'incohérence entre les utilisateurs, dû au fait que de nombreux techniciens en microscopie n'analysent pas le nombre standard de champs à forte puissance (HPF), ne sont pas formés de manière adéquate afin de pouvoir reconnaitre toutes les variétés de Malaria et à la grande disparité associée avec la qualité de la production manuelle de lames Giemsa (4) Afin de remédier à la mauvaise utilisation d'un traitement empirique (guidé par les symptômes), de nombreux organismes de santé gouvernementaux exigent un test de dépistage de la malaria avant de commencer un traitement antipaludique, ce qui a entraîné une demande accrue de 500 millions de tests de dépistage de la malaria en 2012 (10). Comprendre le savoir-faire nécessaire en matière de diagnostic et le représenter au moyen de traitement d'image, d'analyse et de reconnaissance d'algorithmes modèles spécialement adaptés peut aider afin de concevoir un système de diagnostic automatisé. Bien que le sujet de la recherche ne soit pas encore très répandu, le diagnostic automatisé de la malaria traite directement plusieurs lacunes actuelles (11). Ma recherche vise à développer un système d'apprentissage automatique capable d'identifier le stade et le nombre de Plasmodium falciparum dans des érythrocytes en culture, sur la base de leur morphologie en utilisant des lames minces. Le second objectif est de développer un système d'apprentissage automatique permettant d'identifier le nombre de stades anneau parasites dans des érythrocytes en culture dilués avec du sang total frais.Méthode : Des frottis sanguins minces colorés au Giemsa ont été réalisés à partir de cultures synchronisées de la souche 3D7 de plasmodium falciparum conservée dans un incubateur sous agitation à 37 °C, 5% de CO2, 3 % de O2, 92 % de N2. Des frottis sanguins minces ont été observés à l'aide d'un microscope EVOS et des images numériques ont été acquises, enregistrées au format tiff et stockées sur une clé USB. Les images ont été transférées en tant que fichiers sur un ordinateur, prétraitées et segmentées puis les parasites et les diverses étapes du cycle de vie y ont été détectés. L'algorithme formulé à l'aide du programme MATLAB a été formé en utilisant 109 images. 397 images ont été utilisées pour le premier objectif et 163 pour le deuxième objectif. L'algorithme Otsu a été utilisé pour cette étude, les images en niveaux de gris ont été réduites à des images binaires. Résultats : Cette étude a montré une association/corrélation linéaire positive relativement forte entre le comptage automatisé et le comptage manuel. La corrélation entre le nombre manuel et le nombre automatisé était de 0,85. La corrélation de Pearson entre le comptage automatisé et manuel était de 0,7. L'outil de diagnostic a montré une sensibilité de 94,6% pour les anneaux, de 96,5% pour les trophozoïtes et de 98,2% pour les schizontes. De plus, une spécificité de 96,5% pour les anneaux, de 88,9% pour les trophozoïtes et 81,8% pour les schizontes a été démontrée. Les images d'entrée transformées en niveaux de gris ont mis en évidence des parasites contenant de la chromatine.Conclusion : Cette étude a développé un système automatisé pouvant améliorer le diagnostic et donc le traitement de la malaria. La méthode automatisée a détecté plus de trophozoïtes et de schizontes que de stades anneau parasites, avec une valeur de corrélation de 0,83, 0,86 et 0,94 respectivement pour l'anneau, le trophozoïte et les stades anneau</description><description>SUMMARYIntroduction: The latest World Malaria Report released in November 2017 estimated that 219 million cases of malaria occurred and deaths due to malaria reached 435,000 in 2017(1). The WHO considers microscopy to be the gold standard for clinical diagnosis of malaria due to its ready availability. However, microscopy has many shortcomings, including inter-user variability and inconsistency, due to the fact that many microscopy technicians do not assess the standard number of high-power fields, are not adequately trained on recognizing all forms of malaria and the high disparity associated with the quality of manual Giemsa slide production (4) To remedy the mis-use of empiric (symptom-guided) treatment, malaria testing is required by many governmental health organizations before commencing antimalarial drug therapy, thereby resulting in increased demand for up to 500 million malaria tests in 2012 (10). Understanding the diagnostic expertise necessary and representing it by specifically tailored image processing, analysis and pattern recognition algorithms can help in designing an automated diagnosis system. Although it is not yet a widespread research topic, automated diagnosis of malaria directly addresses several current gaps (11). My research aims to develop a machine learning system that can identify the stage and number of Plasmodium falciparum in cultured erythrocytes based on their morphology using thin film slides, the second objective is to develop a machine learning system that can identify the number of ring-stage parasites in samples of cultured erythrocytes diluted with fresh whole blood.Methods: Giemsa stained thin blood smears were made from synchronized cultures of the 3D7 strain of plasmodium falciparum stored in an incubator with shaking at 37oC, 5% CO2, 3 % O2, 92 % N2. Thin blood smears were viewed with an EVOS microscope and digital images were acquired, saved as tiff format and stored in a memory stick. The images were transferred as files to a computer, then the images further pre-processed, segmented, and the parasites and the stages of the life cycle detected. The algorithm formulated with the MATLAB programme was trained using 109 images. For the first objective, 397 images were used and for the second objective 163 images were used.The Otsu algorithm was used for this study, gray level images were reduced to binary images. The algorithm assumes that the images contain foreground and background pixels. Results: This study showed a relatively strong, positive linear association/ correlation between automated count and manual counts. The correlation between the manual count and the automated count was 0.85. The Pearson correlation between the automated and manual count was 0.7. The diagnostic tool showed a sensitivity of 94.6% for rings, 96.5% for trophozoites and 98.2% for schizont. Moreso, it showed a specificity of 96.5% for rings, 88.9% for trophozoites and 81.8% for schizonts. The R and G channels of the RGB color scheme had clear features which were used to identify objects containing chromatin in Giemsa-stained blood films. The input images transformed to grayscale highlighted parasites containing chromatin.Conclusion: This study developed an automated system that could enhance the diagnosis and therefore treatment of malaria. The automated method detected more trophozoites and schizonts than the ring stage parasites as seen with a correlation value of 0.83, 0.86 and 0.94 for the ring, trophozoite and ring stages respectively</description><creator>Maduako, Chidinma</creator><contributor>Timothy Geary (Supervisor1)</contributor><contributor>Petra Rohrbach (Supervisor2)</contributor><date>2020</date><subject>Parasitology</subject><title>Malaria diagnosis based on a machine learning system</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/5138jj93q.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/8g84mr79f</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Institute of Parasitology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:8s45qf13b</identifier><datestamp>2020-03-23T20:11:16Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>RésuméJustification: Il existe des signes de faiblesse au niveau des muscles squelettiques chez les patients atteints de cardiomyopathie hypertrophique (CMH), mais le mécanisme derrière la faiblesse musculaire n'a pas encore été révélé au niveau moléculaire.Objectifs: Pour étudier les mécanismes potentiels qui contribuent à la faiblesse musculaire du diaphragme, du soléus et du psoas dans un modèle de lapin de CHM présentant une mutation faux-sens R403Q dans la chaîne lourde de la β-myosine (β-MyHC) qui a été utilisée.Hypothèse: Les protéines contractiles du diaphragme et du soleus extraites des lapins transgéniques (TG+), porteurs d'une mutation R403Q dans le bêta-MyHC cardiaque, présentaient moins d'activité ATPase et de vitesse d'actine glissant sur les molécules de myosine par rapport aux muscles de type sauvage (WT), suggérant que le β-MyHC cardiaque s'exprime dans les muscles cardiaques et squelettiques lents. Il n’y aura pas de différence dans la vitesse et dans l’activité ATPase du muscle psoas entre les deux groupes.Mèthodes: Deux types d'expériences ont été effectuées sur la myosine purifiée et la méromyosine lourde (HMM) du diaphragme, du soléus et du psoas de WT et TG + chez des lapins afin d'évaluer la vitesse de glissement de l'actine et l'activité de l'ATPase: test de mobilité in vitro (IVMA) et ATPase de myosine activée par l'actine.Rèsultats: Les TG + HMM des muscles du diaphragme et du soléus ont produit des vitesses de glissement de l'actine respectivement 16% et 22% inférieures à celles du WT HMM. L'activité ATPase du diaphragme et du soléus TG + myosine et HMM était également significativement inférieure à celle des échantillons WT. Cependant, il n'y a aucune différence par rapport a la vitesse d'actine et l'activité de l'ATPase pour le psoas musculaire.Conclusion: La CHM modifie les propriétés contractiles des muscles du diaphragme et du soléus au niveau moléculaire, ce qui cause une diminution de la vitesse de la motilité de l'actine induite par la myosine et de l'activité de l'ATPase</description><description>AbstractRationale: There is evidence of skeletal muscles weakness in patients with hypertrophic cardiomyopathy (HCM), but the mechanism behind muscle weakness has yet to be revealed at the molecular level.Objective: To investigate the potential mechanisms which lead to muscle weakness in the diaphragm, soleus and psoas muscles in a rabbit model of HCM that presents a R403Q missense mutation in β-myosin heavy chain (β-MyHC), responsible for familial HCM.Hypothesis: The contractile proteins of diaphragm and soleus muscle taken from transgenic (TG+) rabbit with a R403Q mutation in the cardiac β-MyHC will produce less ATPase activity and velocity of actin sliding over myosin molecules when compared to wild type (WT) muscles, given that cardiac β-MyHC expresses in cardiac and slow skeletal muscles. There will be no differences in the velocity and ATPase activity in the psoas muscle between the two groups.Methods: Two different types of experiments were performed on purified myosin and heavy meromyosin (HMM) of the diaphragm, soleus, and psoas muscles of WT and TG+ rabbits to assess actin sliding velocity and ATPase activity: in-vitro motility assay (IVMA) and actin activated ATPase assay.Results: The TG+ HMM from diaphragm and soleus muscles produced actin sliding velocities that were 16% and 22% lower than WT HMM, respectively. The ATPase activity of diaphragm and soleus TG+ myosin and HMM were also significantly lower than WT samples. However, there was no difference in the actin velocity and ATPase activity for the psoas muscle.Conclusion: HCM changes the contractile properties of the diaphragm and soleus muscles at the molecular level, leading to a lower velocity of myosin-induced actin motility and lower ATPase activity</description><creator>Saikat, Md Rezuanul Haque</creator><contributor>Dilson Rassier (Supervisor)</contributor><date>2020</date><subject>Kinesiology and Physical Education</subject><title>Contractile properties of skeletal muscles in hypertrophic cardiomyopathy</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/bz60d2036.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/8s45qf13b</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Kinesiology and Physical Education</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:bk128g36j</identifier><datestamp>2020-03-23T20:11:31Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The transplantation of encapsulated islets has the potential to provide a long-term treatment for type 1 diabetes while avoiding the need for chronic immunosuppression required for current islet transplants. Conventional encapsulation techniques using nozzles have limited throughput and produce beads that are permeable to immune system components such as antibodies. Islet encapsulation in alginate beads by stirred emulsification and internal gelation can overcome these limitations but generates beads with a broad size distribution. Microchannel emulsification is a versatile approach for the scalable production of oil-in-water (O/W) or water-in-oil (W/O) microdroplets of uniform size. In this study, microchannel emulsification technologies were employed to produce alginate droplets in an oil phase (W/O emulsion). This process was combined with the internal gelation of alginate to introduce a novel microchannel emulsification cell encapsulation bioprocess to the field of cellular therapy. The initial microchannel emulsification prototype was improved by selecting 3M(TM) Novec(TM) 7500 Engineered Fluid as the continuous oil phase and polytetrafluoroethylene as the microchannel plate material to achieve the spontaneous generation of monodisperse alginate microbeads ranging from ~1.5 to 2.5 mm in diameter at production rates exceeding 140 mL/h per microchannel. The beads produced using this device were more uniform in size than beads obtained by stirred emulsification, in addition to demonstrating enhanced compressive burst strength and more uniform pore size distribution based on inverse size exclusion chromatography. Although further process optimization is required to improve encapsulated cell survival, the microchannel emulsification device is a promising alternative technique for the successful immunoisolation of pancreatic islet cells for diabetes cellular therapy. The microchannel emulsification process could also be adapted to other encapsulation applications in the pharmaceutical, food, agriculture and cosmetic industries</description><description>En créant une barrière immunoprotectrice, l’encapsulation d’îlots pourrait mener à un traitement durable au diabète de type 1 tout en évitant le recours aux médicaments immunosuppresseurs présentement requis pour éviter le rejet de greffes d’îlots. Les techniques d'encapsulation par buse conventionnelles ont des taux de production limités et forment des billes qui sont perméables à certaines composantes du système immunitaire comme les anticorps. Une méthode basée sur l’émulsion de l’alginate sous agitation dans une phase organique a été proposée plus récemment afin de surmonter ces limitations, mais ce procédé génère des billes avec une large distribution de taille. L'émulsification par microcanaux est une approche polyvalente pour la production de microgouttelettes uniformes d’huile dans l’eau (H/E) ou d’eau dans l’huile (E/H). Dans cette étude, des technologies d'émulsification par microcanaux ont été utilisées pour produire des gouttelettes d'alginate dans une phase organique (émulsion E/H). Ce procédé a été combiné avec la gélification interne de l'alginate pour introduire un nouveau bioprocédé d'encapsulation cellulaire grâce à l’émulsification par microcanaux dans le domaine de la thérapie cellulaire. Le prototype initial d’émulsification par microcanaux a été amélioré en choisissant le fluide 3M(TM) Novec(TM) 7500 Engineered Fluid comme phase huileuse continue et le polytétrafluoroéthylène comme matériau de fabrication de la plaque à microcanaux pour permettre la génération spontanée de microbilles d'alginate monodispersées allant d'environ 1,5 à 2,5 mm de diamètre à des débits de production supérieurs à 140 ml/h par microcanal. Les billes produites à l'aide de ce dispositif avaient une taille plus uniforme que les billes obtenues par émulsification sous agitation, en plus de démontrer une résistance à l’éclatement sous compression améliorée et une distribution plus uniforme de la taille des pores basée sur la chromatographie d’exclusion de taille en phase inverse. Bien qu’une optimisation supplémentaire du processus soit nécessaire pour améliorer la survie des cellules encapsulées, le dispositif d’émulsification par microcanaux est une technique alternative prometteuse pour l’immunoisolation des cellules d’îlots pancréatiques pour la thérapie cellulaire du diabète. Ce procédé d’émulsification par microcanaux pourrait aussi être adapté à d’autres applications d’encapsulation dans les industries pharmaceutique, alimentaire, agricole et cosmétique</description><creator>Bitar, Christina</creator><contributor>Corinne Hoesli (Internal/Supervisor)</contributor><date>2019</date><subject>Chemical Engineering</subject><title>Optimisation and characterization of a novel microchannel emulsification process for pancreatic beta cell microencapsulation in alginate</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/h989r763q.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/bk128g36j</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Chemical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:6395wc95b</identifier><datestamp>2020-03-23T20:11:50Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La littérature d’enfant peut être vue comme évidence reflétant l’attente culturale liée au genre. Cette étude a commencé par l’investigation du rôle que la littérature d’enfant, Chinoise et Nord-Américaine, joue dans la construction du genre chez les enfants. Le but de cette recherche comparative a été d’identifier la représentation de la femme dans les livres d’enfant en Chine et en Amérique du Nord. Cinquante-quatre livres d’images primés ont été analysés, alors que quatre aspects des caractères féminins ont été examinés : le nombre de fois que les personnages féminins ont été présentés comme personnages principaux et secondaires ; les apparences physiques ; les professions et rôles familiaux ; et les activités et les caractéristiques comportementales. Utilisant l’analyse du contenu, il a été constaté que la caractérisation féminine dans les livres illustrait des attentes de genre différentes dans cultures Chinoise et Nord-Américaine. Cependant, dans l’ensemble, elles ont souvent des similitudes dans la caractérisation des femmes. En particulier, les personnages féminins de ces deux cultures ont été vues se conformant aux stéréotypes de genre traditionnels et défiant les stéréotypes en même temps. Cette coexistence entre les stéréotypes traditionnels et la caractérisation non traditionnelles dans les personnages féminins reflète les attentes complexes liées au genre pour les femmes dans les sociétés Chinoise et Nord-Américaine de nos jours. Les résultats de cette recherche mettent en lumière les implications pouvant encourager les éducateurs et les apprenants à refléter sur comment et pourquoi les élèves considèrent la littérature d’enfant une influence sur le processus de construction du genre. En particulier, alors que les jeunes enfants d’aujourd’hui développent leur identité, de fortes représentations féminines dans la littérature d’enfant peuvent remettre en question leurs stéréotypes de genre et permettre leur responsabilisation</description><description>Children’s literature can be been seen as evidence to reflect cultural gender expectations. This study started with examining gender-based research approaches in children’s literature in North American and Chinese scholarship, demonstrating the need for a cross-cultural comparison in female representation in children’s books. The goal of this comparative research has been to identify and compare female representations in children’s literature using Chinese and North American sources. Fifty four award-winning picture books were analyzed whereby four aspects pertaining to female characters were examined: the amount of times female characters was presented as main characters; their physical appearances; occupations and family roles; and activities and behavioral characteristics. Using content analysis, this study found that the female characterization in the books illustrated some different gender expectations between Chinese and North American cultures. However, overall, Chinese and North American children’s literature often demonstrated similarities when depicting female characters. Particularly, female characters from these two cultures were seen conforming to traditional gender stereotyping and challenging the stereotyping at the same time. This co-existence of traditional gender stereotypes and non-traditional characterizations in female characters reflect the complex gender expectation for women in both Chinese and North American society nowadays. The outcomes of this research into children’s literature illuminates the perception of female gender roles which can further be examined in various societies and cultures. Significantly, the implications from this study might encourage educators and learners to reflect on how and why students consider children’s literature influences their gender construction process. In particular, as today’s young children are developing their identities, strong female representations in children’s literature can challenge their gender stereotypes and allow female empowerment</description><creator>Zhang, Yuwen</creator><contributor>Sheryl Smith-Gilman (Supervisor)</contributor><date>2020</date><subject>Education</subject><title>A comparison of female representations in award- winning children's literature from China and North America, from the 2000s to present</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/12579x77d.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/6395wc95b</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of Integrated Studies in Education</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:9g54xp06s</identifier><datestamp>2020-03-23T20:12:15Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Bicéphale is an original composition for an ensemble of twenty-one instruments. It was composed for my master's degree in composition at McGill University. The analytical paper (volume I) depicts a general overview of the initial inspirations preceding the writing and the different compositional processes used. A more technical approach will detail the structure, the pitch organization and the orchestration. Volume II includes the score of the piece. Bicéphale results from the collaboration with the painter Cléo Garcia whose work and creative process were particularly interesting to transpose into a musical universe. Space, material, textures, colors…. terms relating to both the field of painting and that of music, have guided the creation of the piece</description><description>Bicéphale est une pièce originale pour ensemble de vingt-et-un instruments, composée dans le cadre de mon master de composition à l’université McGill. Le dossier d’analyse de la pièce (volume I) dépeint les inspirations initiales précédant l’écriture ainsi que les différents processus compositionnels utilisés. Une approche plus technique permettra de détailler la structure, l’organisation des hauteurs et l’orchestration. Le volume II contient la partition de la pièce. Bicéphale est le résultat d'une collaboration avec la peintre Cléo Garcia dont le travail et le processus créatif invitent à être transposés dans un univers musical. Espace, matière, textures, couleurs… termes relatifs à la fois au domaine de la peinture et à celui de la musique, furent les fils conducteurs de cette pièce</description><creator>Hejebri, Daphné</creator><contributor>Philippe Leroux (Supervisor)</contributor><date>2020</date><subject>Music</subject><title>Bicéphale</title><language>fre</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/3n2043547.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9g54xp06s</identifier><degree><name>Master of Music</name><grantor>McGill University</grantor><discipline>Schulich School of Music</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:jh343x155</identifier><datestamp>2020-03-23T20:12:18Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Classically cells compartmentalize their constituents into spatial regions boundedby membranes to modulate biochemical reactions. Recently, it has been shown inboth eukaryotic and prokaryotic systems that this compartmentalization can occurin lieu of membranes. The theory of phase transitions, the changing of states in asystem, has been used to explain this process, but the mechanistic details are notwell understood. Namely, the role of certain intrinsically disordered proteins and theproperties which allow them to facilitate these transitions, and the material propertiesthey impart on these structures remains unclear. In this thesis we outline twodistinct methods by which the role of these proteins can be deciphered. Firstly, weintroduce a simple Monte Carlo simulator for a collection of protein systems thatcan vary in charge prole to understand the propensity of dierent charge prolesto phase separate in solution. Secondly, we use single molecule imaging to trackindividual molecules associated with these phase separated states to determine thedierence in kinetics relative to other regions in the cell</description><description>Les cellules classiquement classent leurs constituants dans des regions spatialesdelimitees par des membranes pour moduler les reactions biochimiques. Recemment,il a ete demontre dans les systemes eucaryotes et procaryotes que cette compartimentationpeut se produire a la place des membranes. La theorie des transitionsde phase, le changement d'etats dans un systme, a ete utilisee pour expliquer ceprocessus, mais les details mecanistes ne sont pas bien compris. A savoir le rle decertaines proteines intrinsequement desordonnes et les proprietes qui leur permettentde faciliter ces transitions, ainsi que les proprietes matrielles qu'elles conferentAces structures. Dans ce manuscrit, nous decrivons deux methodes distinctes parlesquelles le r^ole de ces proteines peut tre dechire. Tout d'abord, nous prsentons unsimulateur de Monte Carlo simple pour une collection de systemes proteiques dontle prol de charge peut varier an de comprendre la propension de dierents prolsde charge a se separer en phase dans une solution. Deuxiemement, nous utilisonsl?imagerie de molecule unique pour suivre les molecules individuelles associees a cesetats separes de phase an de determiner la dierence de cinetique par rapport auxautres regions de la cellule</description><creator>Parmar, Baljyot</creator><contributor>Stephanie Weber (Supervisor)</contributor><date>2020</date><subject>Biology</subject><title>Quantifying the kinetics of phase separation «in silico» and «in vivo»</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/rv042z58k.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/jh343x155</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Biology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:x346d856z</identifier><datestamp>2020-03-23T20:12:34Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Many societies around the world are affected by extremist violence. There has been great effort to combat extremism. This study examined women’s roles in preventing extremism in Afghanistan. Using individual interviewing with female educators as the primary research method, the study revealed 7 themes, i.e., Inconsistency in defining extremism, no discussion of extremism in public secondary schools, no criticality in the education system, multidimensionality of extremism, families as a source of extremism, extremism not seen as having religious ideology, extremism is political, a result of the lack of access to quality/critical education and lack of resources. Connecting these themes to the research objectives, I concluded that there is an inconsistent understanding of extremism among female educators which is problematic, and while they are somewhat effective in preventing extremism, some of their male students resist their teachings. Also, lack of resources and quality education was a common concern among female educators and identified as factors that push youth towards extremist violence</description><description>De nombreuses sociétés du monde entier sont touchées par la violence extrémiste et des efforts considérables ont été déployés pour lutter contre l'extrémisme. Cette étude examine le rôle des femmes dans la prévention de l’extrémisme en Afghanistan. En se basant sur des entretiens individuels avec des éducatrices, l’étude a révélé 7 thèmes: incohérence dans la définition de l’extrémisme, absence de discussion sur l’extrémisme dans les écoles secondaires publiques, absence de criticité dans le système éducatif, multidimensionalité de l’extrémisme, l'extrémisme prenant source dans le milieu familial, l'extrémisme n’étant pas considéré comme ayant une idéologie religieuse, l'extrémisme politique, résultat du manque d'accès à une éducation critique et de qualité et du manque de ressources. En reliant ces thèmes aux objectifs de la recherche, j'ai conclu qu'il existe une compréhension incohérente de l'extrémisme parmi les éducatrices et que ceci se relève être problématique. Même si elles sont assez efficaces pour prévenir l'extrémisme, certains de leurs étudiants masculins résistent à leurs enseignements. De plus, le manque de ressources et d’éducation de qualité comme un facteur poussant les jeunes vers la violence extrémiste fut identifié comme étant une préoccupation commune parmi les éducatrices</description><creator>Hashemi, Narjes</creator><contributor>Ratna Ghosh (Supervisor)</contributor><date>2020</date><subject>Education</subject><title>Women’s roles in preventing extremism through education in Afghanistan</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/kh04dt847.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/x346d856z</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of Integrated Studies in Education</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:p5547w850</identifier><datestamp>2020-03-23T20:12:52Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Many musical preferences are strongly based on the visual aesthetics of artists. They are constructed through a combination of a music artist’s geographical location, age, ethnicity, fashion, obscurity, promotional photos, videos, and many other items. We are constantly exposed to both images and music videos of artists through online sources such as music publications, social networks, and media streaming services. As such, images are a large and essential source of consuming visual aesthetics of music artists.A novel study on artist similarity based on visual aesthetics was conducted using images. Specifically, promotional photos of artists were used, as they commonly provide an accurate depiction of the artist’s branding and personality. Using a compiled list of artists taken from current music popularity charts, promotional photos of artists across four genres were retrieved from an online image source. The first stage of image analysis involved using neural networks specifically trained for object detection. The promotional photos were analyzed using two detection models in order to retrieve both the clothing garments portrayed by the artists, as well as the non-fashion objects that appear in the images. A second stage of machine learning was then applied to this new dataset. Common classifiers were trained on the extracted clothing and object text labels, and then used to make genre predictions on the unseen promotional photos.It was found that the fashion items portrayed in the images acted as reasonable features in the genre classification task, predicting the correct genre with an accuracy significantly above chance. The object labels increased the classification precision, suggesting that the inclusion of items beyond clothing aids in this genre classification experiment. By visually clustering the images using a dimension reduction technique, it was possible to observe similar clothing items and objects that defined each genre. This provided insight into the visual stereotypes and fashion trends that are affiliated with each genre</description><description>Plusieurs préférences musicales sont fortement fondées sur l’esthétique visuelle des artistes. Elles sont construites à l’aide d’une combinaison de la localisation géographique de l’artiste musical, ainsi que de son âge, son ethnicité, son style vestimentaire, son exposition média- tique, ses photos promotionnelles, ses vidéos et d’autres éléments. Nous sommes constamment exposés aux images et vidéoclips d’artistes à travers des sources en ligne telles les publica- tions musicales, réseaux sociaux et services de diffusion media. Ainsi, les images sont une grande source essentielle de consommation d’esthétique visuelle liée aux artistes musicaux.Une nouvelle étude traitant de la similarité des artistes selon leur esthétique visuelle été conduite à l’aide d’images. Précisément, les photos promotionnelles d’artistes ont été utilisés, car elles indiquent, la plupart du temps, une représentation précise de l’image de marque et de la personnalité de l’artiste. En utilisant une liste compilée d’artistes à l’aide de classements récents de popularité musicale, les photos promotionnelles de ceux-ci à travers quatre genres ont été obtenus d’une banque de données en ligne. La première étape d’analyse d’image a impliqué l’utilisation de réseaux de neurones spécifiquement entraînés pour la détection d’objets. Les photos promotionnelles ont été analysées à l’aide de deux modèles de détection pour récupérer à la fois les vêtements représentés par les artistes, ainsi que les autres objets non-reliés au style vestimentaire apparaissant dans l’image. Une deuxième étape d’apprentissage machine a ensuite été appliquée sur ce nouvel ensemble de données. Des classificateurs communs ont été entraînés sur les étiquettes des vêtements et les objets. Ils ont été utilisés pour prédire le genre sur les photos promotionnelles non-vues.Il a été découvert que les items reliés au style vestimentaire dépeint dans les images agissent comme une caractéristique raisonnable dans la tâche de classification de genre, réussissant à prédire correctement celui-ci avec une précision significativement plus élevée que le hasard. Les étiquettes des objets ont augmenté la précision de la classification, suggérant que l’inclusion d’items autres que les vêtements bénéficie à cette expérience de classification de genre. En regroupant visuellement les images à l’aide d’une technique de réduction de dimension, il a été possible d’observer des articles vestimentaires et objets similaires qui définissent chaque genre. Cela a permis de mieux comprendre les stéréotypes visuels et les tendances de la mode qui sont affiliées à ces derniers</description><creator>Kam, Andrew</creator><contributor>Ichiro Fujinaga (Supervisor)</contributor><date>2020</date><subject>Music</subject><title>Automatic classification of artist visual aesthetics: linking fashion and genre</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/ht24wp56d.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/p5547w850</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Schulich School of Music</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:ww72bh129</identifier><datestamp>2020-03-23T20:13:08Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The use of room acoustic modeling techniques in real-time interactive applications such as video games and virtual reality has been limited, mainly owing to their high computational costs. Among the various room acoustic modeling techniques, beam tracing is the fastest known deterministic geometrical acoustic technique for modeling specular reflections and has been in common use in various real-time room acoustic auralization engines. Yet, due to its moderately high computational costs, it imposes strict limits on the rate of movement of the sound source and change in the room geometry for seamless auralization of dynamic environments. In this thesis, we propose a physically-informed prioritized beam tracer that focuses on tracing the more relevant beams to reduce the overall computational cost further and hence ease some of these limitations.The proposed algorithm judiciously traces beams by prioritizing them based on estimates of the energy that they carry regardless of the order of reflection. We use three factors to determine the priority of a beam, namely, the width of the beam, attenuation of energy due to transmission in atmosphere and loss of energy at the reflecting surfaces, which together determine the energy of a beam.We present a performance comparison between the proposed beam tracer and some conventional approaches to beam tracing that have been previously published in literature. The beam tracers are evaluated in three different room models of varying levels of complexity and are compared based on two aspects: the number of beams required and the time taken to provide an acceptable level of accuracy of  specular reflection energy. We also explore different conditions for termination of the beam tracing process, evaluating the pros and cons of each approach. Finally, we compare the mentioned priority factors on their influence on the beam tracer's performance.The results show a greater computational gain for more complex rooms compared to simple, convex room models, requiring up to 10 times less beams compared to the conventional breadth-first and the pseudo-breadth-first approach to detect significant specular reflection paths. The beam tracers are also evaluated for use in real-time simulations with iterative refinement of the obtained solution and the timing results show that the prioritized beam tracer performs up to 19 times faster than the pseudo-breadth-first beam tracer</description><description>L'utilisation de techniques de modélisation acoustique des salles dans des applications interactives en temps réel telles que les jeux vidéo et la réalité virtuelle a été limitée, principalement en raison des coûts de calcul élevés. Parmi les différentes techniques de modélisation acoustique des salles, le traçage du faisceau est la technique acoustique géométrique déterministe la plus rapide connue pour la modélisation des réflexions spéculaires. Elle est couramment utilisée dans divers moteurs d’auralisation acoustique des salles en temps réel. Cependant, en raison de ses coûts de calcul modérément élevés, il impose des limites strictes au taux de déplacement de la source sonore ainsi qu'aux changements géométriques de la salle pour une auralisation harmonieuse des environnements dynamiques. Dans cette thèse, nous proposons un traceur de faisceaux hiérarchisé prioritaire basé sur des informations physiques qui se concentre sur le traçage des faisceaux les plus pertinents afin de réduire davantage le coût de calcul global et donc d’atténuer certaines de ces limitations.L'algorithme proposé trace judicieusement les faisceaux en les hiérarchisant en fonction d'estimations de l'énergie qu'ils transportent, quel que soit leur ordre de réflexion. Nous utilisons trois facteurs pour déterminer la priorité d’un faisceau, à savoir la largeur du faisceau, l’atténuation de l’énergie due à la transmission dans l’atmosphère et la perte d’énergie sur les surfaces réfléchissantes, qui déterminent l’énergie d’un faisceau.Nous présentons une comparaison de performances entre le traceur de faisceau proposé et certaines approches classiques du traçage de faisceau publiées antérieurement dans la littérature scientifique. Les traceurs de faisceaux sont évalués dans trois modèles de salle de niveaux de complexité différents et sont comparés en fonction de deux aspects: le nombre de faisceaux requis et le temps nécessaire pour fournir un niveau de précision acceptable de l'énergie de réflexion spéculaire. Nous explorons également différentes conditions pour mettre fin au processus de traçage du faisceau, en évaluant les avantages et les inconvénients de chaque approche. Enfin, nous comparons les facteurs de priorité mentionnés concernant leur influence sur les performances du traceur de faisceau.Les résultats montrent un gain de calcul plus important pour des pièces plus complexes par rapport aux modèles de pièces simples et convexes, nécessitant jusqu'à 10 fois moins de faisceaux par rapport à l'approche conventionnelle de recherche de parcours en largeur et pseudo recherche de parcours en largeur pour détecter des trajets de réflexion spéculaires significatifs. Les traceurs de faisceaux sont également évalués pour une utilisation dans des simulations en temps réel avec un raffinement itératif de la solution obtenue. Les résultats de synchronisation montrent que le traceur de faisceaux hiérarchisé est jusqu'à 19 fois plus rapide que le traceur de faisceaux utilisant un pseudo algorithme de parcours en largeur</description><creator>Venkatesan, Harish Jayanth</creator><contributor>Esteban Maestre Gomez (Supervisor2)</contributor><contributor>Gary Scavone (Supervisor1)</contributor><date>2020</date><subject>Music</subject><title>A physically-informed prioritized beam tracer</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/fn107338m.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/ww72bh129</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Schulich School of Music</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:x633f567q</identifier><datestamp>2020-03-23T20:13:22Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Le rôle du facteur de croissance épidermique se liant à l'héparine (HB-EGF) exprimé dans les cellules T CD4 dans les réponses allergiques des voies respiratoires chez la sourisContexte: Les cellules T auxiliaires de type 2 (Th2) participent au développement de l'asthme déclenché par une allergie. L'une des caractéristiques les plus importantes de cet asthme à médiation de type 2 est le remodelage des voies respiratoires. Les modifications structurelles des voies respiratoires résultent de l'hypertrophie / hyperplasie des cellules musculaires lisses des voies respiratoires (ASM) et de la métaplasie des cellules caliciformes. Le facteur « Heparin binding epidermal growth factor » (HB-EGF), un puissant facteur mitogène et chimiotactique, pourrait favoriser la migration et la prolifération de cellules, y compris les cellules musculaires lisses et les cellules caliciformes, et est exprimé par les cellules T CD4 +. Hypothèse: Nous avons émis l'hypothèse que HB-EGF dérivé des cellules T CD4 participe au remodelage des voies respiratoires.Méthodes et résultats: Nous avons croisé des souris HB-EGF (flox) avec des souris CD4-Cre-ERT2 pour épuiser HB-EGF dans des cellules T CD4 et nous avons utilisé l'administration de tamoxifène pour supprimer HB-EGF dans des cellules T CD4. Nous avons établi un modèle allergique induit par les acariens de la poussière de maison (HDM) utilisant une exposition prolongée aux allergènes. L'inflammation, airway hyper-responsiveness (AHR), et les caractéristiques histologiques des voies respiratoires ont été mesurées afin d'explorer les effets du HB-EGF sur le remodelage des voies respiratoires. En outre, nous étudions la relation entre le remodelage des voies respiratoires et le niveau d'inflammation dans notre modèle chronique. Les résultats ont confirmé l'efficacité du modèle allergique et ont montré des cellules inflammatoires, AHR, métaplasie des cellules caliciformes et une augmentation de la masse de l'ASM dans le modèle induit par HDM chronique par rapport au groupe témoin. L'administration du même allergène à des souris knock-out CD4-HB-EGF pour l'évaluation des paramètres de progression du remodelage des voies respiratoires n'a révélé aucune différence significative entre les groupes de contrôle et de traitement. Cependant, nous avons montré que la métaplasie des cellules caliciformes et la masse de l’AMS étaient diminuées d’environ 2,5 fois par rapport aux souris du groupe témoin. En outre, quelle que soit la taille des voies respiratoires, il existait une corrélation positive entre la métaplasie massive et la métaplasie des cellules caliciformes et le degré d'inflammation dans une voie respiratoire donnée.Conclusions: Les voies respiratoires avec plus d'inflammation montrent plus de remodelage des voies aériennes en ce qui concerne leurs muscles lisses et leurs cellules caliciformes. Que l’effet soit médié directement par HB-EGF ou par modulation de l’inflammation nécessite des études complémentaires</description><description>The role of heparin binding epidermal growth factor (HB-EGF) expressed in the CD4 T cell in allergic airway responses in the mouseBackground: Type2 helper T (Th2) cells participate in the development of allergy-triggered asthma. One of the most important features in this type-2 mediated asthma is airway remodeling. Structural changes of the airway arise from hypertrophy/hyperplasia of airway smooth muscle (ASM) cells and metaplasia of goblet cells. Heparin binding epidermal growth factor (HB-EGF), a potent mitogen and chemotactic factor, could promote migration and proliferation of cells, including smooth muscle cells and goblet cells and is expressed by CD4+ T cells. Hypothesis: We hypothesized that CD4 T cell derived HB-EGF participates in airway remodeling. Methods and Results: We crossed HB-EGF (flox) mice with CD4-Cre-ERT2 mice to deplete HB-EGF in CD4 T cells and used tamoxifen administration to delete HB-EGF in CD4 T cells.  We established a house dust mite (HDM)-induced allergic model using prolonged allergen exposure. Inflammation, airway hyper-responsiveness (AHR), and histological features of the airways were measured to explore the effects of HB-EGF on airway remodeling. Also, we investigate the relation between airway remodeling and inflammation level in our chronic model. The results confirmed the efficiency of allergic model and showed inflammatory cells, AHR, goblet cells metaplasia, and increased ASM mass in the chronic HDM-induced model compared to the control group. Administration of the same allergen to CD4-HB-EGF knock out mice for evaluation of airway remodeling progression parameters indicated no significant difference between both control and treatment group. However, we showed that goblet cells metaplasia and ASM mass were diminished about 2.5-fold in compare to control group mice. In addition, regardless of the airway size there was a positive correlation between ASM mass and goblet cell metaplasia with the degree of inflammation in any given airway. Conclusions: Airways with more inflammation show more airway remodeling regarding their smooth muscle and goblet cells. Whether the effect is mediated directly by HB-EGF or through modulation of inflammation requires further study</description><creator>Khazaei, Niusha</creator><contributor>James G Martin (Supervisor)</contributor><date>2020</date><subject>Medicine</subject><title>The role of heparin binding epidermal growth factor (HB-EGF) expressed in the CD4 T cell in allergic airway responses in the mouse</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/pn89db85h.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/x633f567q</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Medicine</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:9019s6723</identifier><datestamp>2020-03-23T20:13:37Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Au niveau mondial, régional et local, les plans d’action pour le climat font de la neutralité carbone (état d'absence d'augmentation nette du carbone atmosphérique obtenu en équilibrant les émissions et la séquestration de carbone), un objectif clé afin d’atténuer le changement climatique. Les plans d'action visant à atteindre cette neutralité carbone mettent souvent l'accent sur la réduction des émissions et ne se concentrent que peu sur la quantification, la mesure et l’augmentation de la séquestration du carbone. Certaines formes de rétention du carbone comprennent le boisement, qui peut éliminer de manière rentable le carbone existant emprisonné dans l'atmosphère par la photosynthèse, tout en fournissant des services écosystémiques supplémentaires, tels que les loisirs ou le sirop d'érable. Les établissements d’enseignement supérieur, notamment les universités, jouent un rôle important dans les efforts d’atténuation du changement climatique en raison de leur taille, de leur population ainsi que de leur influence sur l’éducation durable. Dans cette étude de cas, je me concentre sur le plan de l’Université McGill qui vise à neutraliser ses émissions de carbone d’ici 2040. L’Université McGill a mis au point un inventaire annuel qui répertorie les principales sources et quantités d’émissions annuelles de GES provenant des déplacements, de la consommation et de la production d’énergie. Cependant, il manque à cet inventaire une mesure du carbone total retenu annuellement sur les propriétés de l’université. Afin de combler cette lacune dans nos connaissances, je mesure, quantifie et évalue les taux actuels de séquestration du carbone en surface sur les deux principales propriétés forestières appartenant à l’Université McGill : l’arboretum Morgan (240 ha) et la réserve naturelle Gault (1000 ha). J'évalue également deux scénarios différents qui pourraient augmenter la séquestration de carbone en boisant la plus grande propriété agricole de l'Université McGill : la ferme du campus Macdonald (200 ha). Afin d’estimer la séquestration du carbone, j'ai rassemblé des données sur les espèces, le diamètre et la croissance des arbres dans 71 parcelles de 400 m2 issues des deux forêts (34 à l'Arboretum Morgan et 37 à la réserve naturelle Gault). J'ai entré ces données dans des équations allométriques afin de calculer la séquestration du carbone dans chaque parcelle et je les ai multipliées par type de forêt afin d’estimer la retenue de carbone sur toute la superficie des deux forêts. Actuellement, ces deux propriétés forestières absorbent un peu moins de 5% des émissions annuelles de carbone de l’université, indiquant ainsi qu’il faut déployer des efforts importants pour augmenter la séquestration ou réduire les émissions afin d’atteindre la neutralité carbone d’ici 2040. Mes résultats montrent que l’Arboretum Morgan (géré, avec quelques plantations) séquestre le carbone à un taux plus élevé par hectare que la réserve naturelle Gault (vieux peuplement, principalement non géré). Les différences de séquestration du carbone entre les deux forêts semblent être principalement liées aux différences de gestion, d’âge, de mortalité et de densité des forêts, avec une légère influence due aux différences de composition de la forêt. Le boisement de la ferme du campus Macdonald pourrait augmenter la séquestration du carbone de 87% par rapport aux taux actuels et ainsi augmenter la capture des émissions de carbone à un peu plus de 9% comparé aux émissions actuelles de l’Université McGill. Bien que la séquestration nette sur le campus puisse être faible par rapport aux émissions, le potentiel éducatif des possibilités de compensation du carbone sur le campus est important. Ce projet permet de comprendre le potentiel de quantification et d’augmentation de la séquestration du carbone à McGill et sur d’autres établissements universitaires et institutionnels afin d’aider à atteindre les objectifs d’atténuation du changement climatique</description><description>Human-induced climate change is one of the biggest threats facing human-kind and the global environment today. Climate action plans at the global, regional, and local scales set C neutrality (a state of no net increase in atmospheric C achieved by balancing emissions and sequestration) as a key climate change mitigation target.  Action plans to achieve C neutrality often focus on emissions reduction, with limited focus on quantifying, measuring, and increasing C sequestration. Certain forms of C sequestration include afforestation, which can remove existing C trapped in the atmosphere through photosynthesis in a cost-effective way, while also providing additional ecosystem services, such as recreation or maple syrup. Higher education institutions, particularly universities, play an important role in climate change mitigation efforts due to their size, population, and influence in sustainable education. In this case study, I focus on McGill University’s plan to become C neutral by 2040. McGill has developed an annual inventory that tracks major sources and amounts of annual GHGs emissions at McGill from travel, energy consumption, and power generation. However, missing from this inventory is a measurement of total C sequestered annually on university properties. To fill this gap in our knowledge, I measure, quantify, and evaluate the current rates of aboveground C sequestration on the two main forested properties owned by McGill University, the Morgan Arboretum (240 ha) and the Gault Nature Reserve (1000 ha). I also evaluate two different scenarios that could increase C sequestration through afforestation on the largest agricultural property at McGill University, the Macdonald Campus Farm (200 ha). To estimate C sequestration, I gathered data on tree species, tree diameter, and tree growth in 71 plots of 400 m2 from both forests (34 at the Morgan Arboretum and 37 at the Gault Nature Reserve). I inputted this data into allometric equations to calculate the C sequestration in the plots and multiplied out by forest type to estimate C sequestration across the entire area of both forests. These two forested properties are currently capturing just under 5% of the university’s annual C emissions, indicating that there needs to be significant efforts to increase C sequestration or reduce C emissions to reach C neutrality by 2040. My results show that the Morgan Arboretum (managed, with some plantations) sequesters C at a greater rate per hectare and overall than the Gault Nature Reserve (old growth and primarily unmanaged). Differences in C sequestration between the two forests appear to be primarily related to the difference in management, forest age, tree mortality, and forest density, with little influence from differences in forest composition. Afforestation at the Macdonald Campus Farm could increase C sequestration by up to 87% over current rates and bring up the capture of C emissions to just over 9% of McGill University’s current emissions. While net sequestration on campus may be small relative to emissions, the educational potential of on-campus C offsetting opportunities is large. This project provides an understanding of the potential to quantify and increase C sequestration at McGill and on other university and institutional properties in order to help reach climate change mitigation targets</description><creator>Boushey, Isabella</creator><contributor>Elena Bennett (Supervisor)</contributor><date>2020</date><subject>Natural Resource Sciences</subject><title>Evaluation of aboveground forest carbon sequestration for climate change mitigation targets: a case study on McGill University properties</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/zc77sv376.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9019s6723</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Natural Resource Sciences</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:4f16c682k</identifier><datestamp>2020-03-23T20:13:59Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>L’apprentissage par renforcement est un cadre pour la prise de décision séquentielle qui est largement utilisé dans de nombreux domaines tels que la robotique et la conduite autonome. En raison de la nature séquentielle de l’apprentissage par renforcement, attribuer le crédit aux actions prises dans le passé est un problème compliqué. Ce problème est connu sous le nom d’affectation temporelle de crédits et est au coeur de nombreuses méthodes telles que les options ou l’apprentissage en ligne. Une mauvaise attribution du credit temporelle peut avoir multiple conséquence dans l’apprentissage par renforcement comme de la variance élevée dans les estimations de la fonction de valeur ou une politique sous optimale. Dans cette thèse, nous introduisons et examinons plusieurs techniques d’affectation temporelle de crédits. Plus précisément, nous atténuons le problème de la variance de la fonction de valeur en affectant efficacement le crédit. Nous présentons d’abord les concepts fondamentaux de l’apprentissage des signaux et du renforcement. Ensuite, nous introduisons l’apprentissage récurrent qui lisse la fonction de valeur le long de la trajectoire. Nous analysons ensuite les points forts de l’apprentissage récurrent de manière expérimentale. Enfin, nous introduisons les filtres, utilise pour le traitement du signal, comme cadre général pour diverses traces dans l’apprentissage par renforcement. Nous montrons l’efficacité des filtres avec quelques exemples simples</description><description>Reinforcement Learning is a framework for sequential decision making which is widely used in many domains such as robotics, autonomous driving, etc. Due to the sequential nature there exists the problem of assigning the credit to the actions taken in the past. This problem in reinforcement learning is known as temporal credit assignment. The problem of temporal credit assignment lies in the core of many methods such as options, online learning, off-policy learning, etc. within reinforcement learning framework. Several problems such as high variance in the value function estimates, sub-optimal policy, high sample complexity are a consequence of improper temporal credit assignment in reinforcement learning. In this thesis, we introduce and examine a couple of temporal credit assignment techniques. Specifically, we mitigate the problem of variance in value function by effectively assigning credit. First, we discuss the fundamental concepts of signals and reinforcement learning. Then, we introduce Recurrent Learning which smooths the value function along the trajectory. We then analyze the strengths of Recurrent Learning experimentally. Finally, we introduce filters from signal processing as a general framework for various traces in reinforcement learning. We show the effectiveness of filters with a couple of toy examples</description><creator>Vemgal, Nishanth</creator><contributor>Doina Precup (Supervisor)</contributor><date>2020</date><subject>Computer Science</subject><title>Temporal credit assignment via traces in reinforcement learning</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/b2774083m.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/4f16c682k</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:kd17cz714</identifier><datestamp>2020-03-23T20:14:09Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La reconstruction géométrique de direction de cascades de particules au système d’imagerie télescopique Cherenkov (IACT) de VERITAS souffre d’une dégradation substantielle aux grands angles zénithiques (φ &gt; 45◦). Une reconstruction basée sur l’apprentissage machine ne devrait pas souffrir des mêmes limitations car elle ne compte pas sur la géométrie del’observation. Dans ce travail, nous démontrons l’efficacité prévue d’une reconstruction de direction de cascades à l’aide de Boosted Decision Trees optimisés. Nous testons également dans quelle mesure cela se traduit par une analyse de données en effectuant une validation de principe avec des objets compacts et à source ponctuelle</description><description>The geometric reconstruction of shower direction at the VERITAS imaging atmospheric Cherenkov telescope (IACT) system sees a substantial degradation at large zenith angles (φ &gt; 45◦). A machine-learning-based reconstruction of this direction is not expected to suffer from the same limitations because it does not rely on the geometry of the observation. In this work, we demonstrate the predicted efficiency of a shower direction reconstruction using boosted decision trees. We also test how well this translates to a data analysis by performing a proof of concept with compact and point-source objects</description><creator>Das, Sreela</creator><contributor>Kenneth J Ragan (Supervisor)</contributor><date>2020</date><subject>Physics</subject><title>Reconstruction of gamma-ray direction using boosted decision trees and the disp parameter</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/jh343x16f.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/kd17cz714</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Physics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:cf95jg78f</identifier><datestamp>2020-03-23T20:14:23Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Biosolids are organic residuals from wastewater treatment facilities that could be reused after suitable treatment and stabilization. Biosolids are suitable for agricultural use because they contain organic matter and essential crop nutrients, primarily nitrogen (N) and phosphorus (P). Hence, biosolids have potential as an N fertilizer to improve corn production and increase corn yield. Like other N fertilizers, biosolids could stimulate biological reactions that produce gaseous byproducts like nitrous oxide (N2O).The N2O-producing reactions increase with higher soil NH4+ and NO3- concentrations, resulting from N fertilizer inputs, but they are also affected by the concentration of soluble organic substrates, soil pH and soil moisture content. Since biosolids application can affect all of these soil parameters, it could increase or reduce N2O emissions from corn agroecosystems. The objectives of my thesis were to 1) evaluate the effects of different biosolids sources and two application methods (surface spreading vs. incorporation) on corn yield and N2O emissions; and 2) to determine how biosolids sources and application methods affected the soil pH, plant available N (NO3--N and NH4+- N), and soil moisture, and relate these factors to the N2O emissions. The field experiment was conducted at the Lods Agronomy Research Centre of McGill University near Montreal, Canada from May to October, 2017. There were three biosolids sources: alkaline treated biosolids (AT), mesophilic anaerobic digested biosolids (MAD) and composted biosolids (COM),which were broadcast on the soil surface and left (surface spreading) or incorporated to a depth of 15 cm, for a total of 6 factorial treatments. Plots with biosolids and the urea-fertilized control received 120 kg N ha-1 (based on the estimated plant-available N content of biosolids and urea) but the unfertilized control received no supplemental N fertilizer. All treatments were replicated four times (n=32). The N2O flux varied temporally and was highest from6 July to16 August when soil moisture was low and air temperature was high. The N2O flux was affected by the application method in the first weeks, but dissipated with time. The highest N2O flux was from the MAD treatment and lowest N2O flux was produced by the unfertilized control, with a tendency for higher N2O emissions in the plots with fertilizer incorporated than surface spreading. There was a significant (p&lt;0.05) effect of fertilizer sources on N2O emissions during the growing season. The unfertilized control had the lowest cumulative N2O emission of 144 g N2O-N ha-1, which was similar to the N2O emissions from the AT and the COM treatments. The MAD treatment had significantly higher (p&lt;0.05) cumulative N2O emissions (1132 g N2O-N ha-1) than other treatments. Overall, the N2O emissions were greater with MAD &gt; urea fertilizer &gt; AT=COM=unfertilized. There was no effect of biosolids sources or application methods on soil pH, plant available N and soil moisture. The COM treatment produced the highest corn yield of 15 MT (dry matter) ha-1, which was similar to other fertilized treatments and greater than the unfertilized control. In conclusion, the application of composted biosolids through surface spreading could be a practice to achieve higher corn yield and lower N2O emissions. Farmers can use this information to select appropriate biosolids sources and application methods to achieve agronomic goals with low N2O emissions from corn agroecosystems</description><description>Les biosolides sont des résidus organiques extraits du traitement des eaux usées qui pourraient être réutilisés après un traitement et une stabilisation appropriés. Les biosolides conviennent à un usage agricole car ils contiennent de la matière organique et des nutriments essentiels pour les cultures, principalement de l'azote (N) et du phosphore (P). Par conséquent, les biosolides peuvent potentiellement servir comme engrais azoté pour améliorer la production de maïs et augmenter son rendement. Comme d’autres engrais azotés, il pourrait stimuler des réactions biologiques produisant des gaz à effet de serre tels que l’oxyde nitreux (N2O).Les réactions produisant du N2O augmentent avec les concentrations élevées de NH4+ et de NO3-dans le sol, résultant de l’application d'engrais azotés, mais ils sont également affectés par la concentration des substrats organiques solubles, le pH et la teneur en humidité du sol.Parce que l'application desbiosolides peut affecter tous ces paramètres de sol, il pourrait augmenter ou réduire les émissions de N2Oémis des agroécosystèmes de maïs. Les objectifs de ma thèse étaient les suivants: 1) évaluer les effets de différentes sources desbiosolides et de deux méthodes d’application (étalement en surface contre l’incorporation) sur les rendements de maïs et les émissions de N2O; et 2) déterminer comment les sources desbiosolides et les méthodes d'application ont affecté le pH du sol, l'azote disponible pour les plantes (NO3--N et NH4+- N), l'humidité du sol, et établir un lien entre ces facteurs et les émissions de N2O.L'expérience était située au Emile A. Lods centre de recherche agronomique de l'Université McGill, près de Montréal, Canada, de mai à octobre 2017. L'expérience a utilisé sources de biosolides: biosolides traités avec alcaline (AT), biosolidesmésophiles Digérésanaérobiquement(MAD) et biosolides compostés (COM), qui ont été diffusés à la surface du sol et laissés (épandage en surface) ou incorporés à une profondeur de 15 cm, pour un total de 6 traitements factoriels. Les parcelles contenant des biosolides et le témoin de fécondé à l'urée ont reçu 120 kgN ha-1(sur la base de la teneur estimée en azote disponible des biosolides et de l'urée), mais le témoin non fertilisé n'a reçu aucun engrais supplémentaire d'azote.Le flux de N2O a été affecté par la méthode d'application au cours des premières semaines mais s'est dissipé avec le temps. Le flux de N2O le plus élevé résultait du traitement MAD et le flux de N2O le plus faible était produit par le témoin non fertilisé, avec une tendance aux émissions de N2O plus élevées dans les parcelles contenant de l'engrais appliquer par l'épandage en surface. Les sources d'engrais ont eu un effet significatif (p &lt;0,05) sur les émissions de N2O pendant la saison de croissance.Le témoin non fertilisé avait l’émission cumulative de N2O la plus faible, soit 144 g de N2O -N h a-1, ce qui était statistiquement similaire aux émissions de N2O provenant des traitements AT et COM. Le traitement MAD avait des émissions cumulées de N2O (1132 g N2O-N ha-1) significativement plus élevées (p &lt;0,05) que les autres traitements. Globalement, les émissions de N2O étaient supérieures avec MAD&gt; engrais à base d'urée&gt; AT = COM = non fertilisé. Les sources desbiosolides ou les méthodes d'application n'ont eu aucun effet sur le pH du sol, l'azote disponible pour les plantes et l'humidité du sol. En conclusion, les résultats suggèrent que l'épandage en surface desbiosolides compostés pourrait être une pratique pour augmenter les rendements du maïs et réduire les émissions de N2O. Les agriculteurs peuvent utiliser ces informations pour sélectionner les sources desbiosolides appropriées et les méthodes d'application permettant d'atteindre les objectifs agronomiques avec de faibles émissions de N2O provenant des agro-écosystèmes du maïs</description><creator>Kamal, Ahammad</creator><contributor>Joann Karen Whalen (Supervisor1)</contributor><contributor>David Burton (Supervisor2)</contributor><date>2020</date><subject>Natural Resource Sciences</subject><title>Reduction of nitrous oxide emissions from biosolids-amended corn agroecosystems</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/dn39x559n.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/cf95jg78f</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Natural Resource Sciences</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:h989r7640</identifier><datestamp>2020-03-23T20:14:39Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Magnetohydrodynamics (MHD) equations are widely used to investigate the behaviour of the plasma in fusion reactors. One recalcitrant challenge in developing fusion reactors is the occurrence of instabilities in plasmas. High order numerical tools can provide significant insight into the instabilities that may occur during ignition and operation of a fusion reactor. Imposing proper boundary conditions is an essential part of such numerical codes. The accuracy of numerical simulations and their applications can indeed be limited by the quality of the applied boundary conditions.In this study, a set of characteristic boundary conditions scheme are developed for the compressible MHD equations. The complete set of characteristic waves is derived in the general curvilinear coordinates. The derived characteristic boundary conditions are implemented in a high order MHD solver. The sixth-order compact scheme is used for the spatial discretization. The fifth-order Weighted Essentially Non-Oscillating (WENO) scheme is used for problems which contain discontinuities. The third-order and fourth-order Runge-Kutta schemes are also implemented for time integration.We have validated the implemented numerical MHD solver by studying a set of benchmark problems in the literature. Several test cases were used to study the derived MHD characteristic boundary scheme in the general curvilinear coordinate system. Results were compared with the analytical ones. The numerical examples demonstrated the accuracy and robustness of the MHD characteristic boundary scheme</description><description>Les équations de magnétohydrodynamique (MHD) sont largement utilisées pour étudier le comportement du plasma dans les réacteurs à fusion. Un défi récalcitrant dans le développement de réacteurs à fusion est l’apparition d’instabilités dans le plasma. À l’aide d’un solveur d’ordre élevé, il est possible d’obtenir un aperçu significatif des instabilités qui peuvent survenir lors du démarrage et de l’opération d’un réacteur à fusion. Toutefois, l’imposition de conditions aux limites qui sontappropriées est essentielle au bon fonctionnement d’un tel solveur. D’ailleurs, la précision des simulations numériques peut être limitée par la qualité des conditions aux limites.Dans cette étude, un ensemble de conditions caractéristiques aux limites a été développé pour les équations de MHD de type compressible. L’ensemble complet des ondes caractéristiques est aussi dérivé pour le système de coordonnées curvilignes.De plus, ces conditions caractéristiques aux limites sont implémentées dans un solveur MHD d’ordre élevé. La méthode compact du sixième ordre est utilisée pour la discrétisation spatiale. La méthode Pondéré Essentiellement Non-oscillant (PENO) du cinquième ordre est utilisée pour les problèmes qui contiennent des discontinuités. Les méthodes Runge-Kutta du troisième et du quatrième ordre sont également employées pour l’intégration temporelle.Nous avons validé le solveur numérique MHD implémenté en étudiant un ensemble de problèmes de référence provenant de la littérature. Plusieurs cas type ont été utilisés pour étudier les conditions caractéristiques aux limites qui furentdérivées pour le système de coordonnées curvilignes. Les résultats ont été comparés aux résultats analytiques. Les exemples numériques ont démontré l’exactitude et la robustesse de la méthode et des conditions aux limites qui furent utilisées pour résoudre les équations de MHD</description><creator>Makaremi-Esfarjani, Paria</creator><contributor>Luc Mongeau (Supervisor1)</contributor><contributor>Alireza Najafi-Yazdi (Supervisor2)</contributor><date>2020</date><subject>Mechanical Engineering</subject><title>Characteristic boundary conditions for magnetohydrodynamics equations</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/6q182q57p.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/h989r7640</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Mechanical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:t722hf355</identifier><datestamp>2020-03-23T20:14:53Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Audio source separation is the act of extracting one or more sources of interest from a recording involving multiple sound sources. In recent years, remarkable progress has been made in the development of source separation techniques, enabling applications such as background noise reduction, separation of multiple speakers or multiple instruments, and creation of ‘karaoke’ tracks by separating vocals and accompaniment in songs.To our knowledge, this thesis is the first to study the application of source separation to choral music. Choral music recordings are a particularly challenging target for separation due to their inherent acoustical complexity. Every choir singer has a distinctive voice timbre, and the combination of multiple voices singing in harmony, with slight pitch mistunings and imperfect synchronization, creates a highly-variable ‘choral timbre’. While choir singers aim to blend their voices, source separation aims to undo that blend. Source separation of choral music enables applications such as fine-grained editing, analysis, and automatic creation of practice tracks (recordings of individual choir parts used by singers as an aid for learning new music) from professional choir recordings.In this thesis, we address choral music separation using a deep learning separation method called Wave-U-Net. To separate choral music, Wave-U-Net must be trained using a large dataset of choral recordings in which each choir part is recorded separately. Due to the scarcity of such recordings, we create a dataset of synthesized Bach chorale harmonizations. In a series of experiments on this dataset, we show that Wave-U-Net performs significantly better than a baseline technique that is based on non-negative matrix factorization (NMF). We propose a simple change in the way Wave-U-Net is trained that leads to a substantial improvement in separation of more than two sources.To further improve separation results, we introduce score-informed Wave-U-Net, a variant of Wave-U-Net that incorporates the musical score of the piece being separated. The musical score has potential to aid separation because it contains detailed pitch and timing information for every note in the piece. We experiment with different methods of representing the musical score and feeding it into Wave-U-Net. Experiment results show that score-informed Wave-U-Net attains significantly improved separation performance compared to the original Wave-U-Net. Moreover, for increased control over the separation process, we devise a ‘score-guided’ technique in which the user indicates which notes should be extracted from a recording by simply indicating the desired notes’ pitches and times</description><description>La séparation de sources sonores consiste à extraire une ou plusieurs sources présentant un attrait significatif d’un enregistrement contenant plusieurs sources sonores. Ces dernières années, de nombreux progrès ont été réalisés concernant le développement de techniques pour la séparation de sources sonores, permettant des applications telles que la réduction de bruit de fond, la séparation de plusieurs chanteurs ou instruments ainsi que la création de pistes « karaoké » en séparant les voix des instruments.À notre connaissance, cette thèse est la première à présenter une étude concernant l’application des techniques de séparation de sources à la musique chorale. La séparation d’enregistrements de musique chorale constitue une tâche particulièrement difficile du fait de leur complexité acoustique intrinsèque. Chaque chanteur a un timbre de voix distinctif et la combinaison de nombreuses voix chantant en harmonie, avec de légers désaccords et une synchronisation imparfaite, crée un « effet de chorus » extrêmement variable. Alors que les choristes cherchent à fusionner leurs voix, la séparation de sources vise à annuler cette fusion. La séparation de sources permet l’édition, l’analyse et la création automatique de pistes audio pour les séances de répétition (enregistrements de parties individuelles du chœur utilisés par les chanteurs pour faciliter l’apprentissage de nouvelles pièces) à partir d’enregistrements professionnels.Dans cette thèse, nous abordons la séparation de musique chorale en utilisant une méthode d’apprentissage profond pour la séparation de sources appelée Wave-U-Net. Pour sa phase d’apprentissage afin de séparer la musique chorale, Wave-U-Net nécessite une grande base de données contenant des enregistrements choraux avec chaque partie du chœur enregistrée séparément. En raison de la rareté de tels enregistrements, nous avons créé un ensemble de données à partir d’harmonisations de chœurs de Bach synthétisées. Dans une série d’expériences basées sur cet ensemble de données, nous montrons que Wave-U-Net est nettement plus performant qu’une technique basée sur une factorisation matricielle non négative (NMF). De plus, nous proposons un changement mineur dans la façon dont Wave-U-Net est formé, ce qui conduit à une amélioration substantielle de la séparation de deux ou plusieurs sources.Afin d’améliorer les résultats des techniques de séparation, nous introduisons score-informed Wave-U-Net, une variante de Wave-U-Net qui intègre la partition musicale de la pièce à séparer. La partition peut potentiellement aider à la séparation des sources du fait qu’elle contient des informations précises concernant la hauteur et le temps de chaque note. Nous expérimentons différentes méthodes de représentation de la partition musicale et de son intégration dans Wave-U-Net. Les résultats de ces expériences montrent que la technique Wave-U-Net intégrant les partitions musicales est significativement plus performante dans la séparation de sources que la méthode Wave-U-Net d’origine. De plus, afin d’avoir un meilleur contrôle du processus de séparation, nous avons développé une technique « guidée par la partition » dans laquelle l’utilisateur peut indiquer les notes à extraire d’un enregistrement en sélectionnant les hauteurs et temps des notes souhaitées</description><creator>Gover, Matan</creator><contributor>Philippe Depalle (Supervisor)</contributor><date>2020</date><subject>Music</subject><title>Score-informed source separation of choral music</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/wp988q23b.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/t722hf355</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Schulich School of Music</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:x059cc64d</identifier><datestamp>2020-03-23T20:15:10Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les antimicrobiens sont des outils importants dans l’agriculture depuis des décennies, utilisés pour le traitement et la prévention des maladies, ainsi que pour améliorer la croissance et l’efficacité alimentaire. Cependant, les mécanismes qui expliquent leur croissance et l'amélioration de l'efficacité alimentaire sont encore flous et donnent de nombreux résultats contradictoires. On pense qu'il est associé, du moins en partie, à des modifications des microbiomes intestinaux. Afin de mieux déterminer les effets des antimicrobiens sur les animaux et leur microbiome intestinal, une méta-analyse a été réalisée sur 20 études de porc et 19 études de poulet comportant des traitements antimicrobiens. Le gain quotidien moyen et l'efficacité alimentaire ont été évalués pour les paramètres de production. La diversité alpha et bêta ont été explorées pour déterminer les différences dans le microbiome intestinal. L'abondance différentielle a été calculée pour déterminer les espèces bactériennes spécifiques corrélées à l'utilisation d'antimicrobiens.Notre étude a révélé que l'utilisation globale d'antimicrobiens augmentait le gain quotidien moyen et l'efficacité alimentaire de moins de 2% pour les porcs et les poulets. En outre, l'utilisation d'antimicrobiens n'a que peu d'effet sur la diversité alpha des porcs et des poulets. Cependant, cela pourrait avoir un effet plus fort sur la diversité bêta. Plusieurs espèces ont été identifiées comme corrélées, de manière négative ou positive, avec l'utilisation d'antimicrobiens. Une famille de bactéries, Veillonellaceae du phylum Firmicutes, s'est avérée plus présente dans les échantillons dépourvus d'antimicrobiens chez les poulets et les porcs. Notre étude souligne également l’importance de la normalisation entre les études et la nécessité d’un enregistrement correct des données en vue d’une amélioration de l’analyse des données à l’avenir. En raison des gains négligeables apportés par les antimicrobiens et de leurs coûts associés, y compris les coûts économiques et sociaux, notre étude fournit une preuve supplémentaire de l'élimination des antimicrobiens en tant que facteurs de croissance</description><description>Antimicrobials have been an important tool in agriculture for decades, used for the treatment and prevention of diseases as well as to improve growth and feed efficiency. However, the mechanisms behind why they increase growth and improve feed efficiency are still unclear with many contradictory results. It is believed to be, at least in part, associated with changes to the gut microbiome. In order to better determine the effects of antimicrobials on animals and their gut microbiome, a meta-analysis was conducted across 20 pig studies and 19 chicken studies involving antimicrobial treatments. Average daily gain and feed efficiency were evaluated for production parameters. Alpha and beta diversity were explored to determine differences in the gut microbiome. Differential abundance was calculated to determine specific bacterial species that correlated with antimicrobial usage.Our study found that overall antimicrobial usage increased average daily gain and feed efficiency by less than 2% for both pigs and chickens. In addition, antimicrobial use had little to no effect on the alpha diversity for pigs and chickens. However, it may have a stronger effect on beta diversity. Several species were identified that correlated, negatively or positively, with antimicrobial usage. One family of bacteria, Veillonellaceae from the Firmicutes phylum, was shown to be more prominent in samples without antimicrobials in both chickens and pigs. Our study also emphasizes the importance of standardization between studies and the need for proper recording of data for improvement of data analysis in the future. Due to the negligible gain that antimicrobial contribute and their associated costs, including economical and societal costs, our study provides further evidence for the removal of antimicrobials as growth promoters</description><creator>Bippert, Clinton</creator><contributor>Xin Zhao (Supervisor)</contributor><date>2020</date><subject>Animal Science</subject><title>Meta-analysis of the effect of antibiotics on the production parameters and gut microbiome of chickens and pigs</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/dj52w8993.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/x059cc64d</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Animal Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:v405sg10x</identifier><datestamp>2020-03-23T20:15:27Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>During extinction training, animals form a new memory that inhibits the expression of a conditioned response arising from the association between conditioned stimulus (CS) and unconditioned stimulus (US). The extinguished conditioned response can, however, re-emerge upon exposure to the original conditioning context, a phenomenon known as renewal. Extinction memory is thus highly context sensitive, and renewal of conditioned responding will generally occur if extinction training and subsequent test occur in different contexts. Based on previous findings showing that memories for spatial context acquired during contextual fear conditioning decay over time, we examined whether the context-sensitivity of extinction memory for conditioned auditory fear also changes over time. When we waited 24 h between fear conditioning and extinction, animals that received extinction training in a novel context but were returned to the original training context for testing (A/B/A) showed renewal of conditioned freezing to the tone, while animals that received conditioning, extinction, and testing in the same context (A/A/A) did not. This difference disappeared when the period between conditioning and extinction was extended from 24 h to 7 d. That is, the expression of extinction memory was no longer context-dependent. To determine whether active decay was responsible for this loss of context-sensitivity, we infused the interference peptide GluA23Y into the hippocampus during the 7 d period between conditioning and extinction. GluA23Y prevents the removal of GluA2-containing AMPA receptors from post-synaptic sites, which in turn prevents the loss of memory, effectively blocking active decay of memory representations in the hippocampus. Behavior of animals treated with GluA23Y was indistinguishable from the behavior of those animals that received extinction training 24 h after conditioning: A/B/A animals showed an increase in conditioned responding during test, while A/A/A animals did not. By blocking the endocytosis of GluA2-containing AMPA receptors and thereby preventing active decay, we were able to preserve the context-specificity of extinction memory following auditory fear conditioning. Our findings suggest that active decay mechanisms are responsible for the loss of context sensitivity in extinction memory seen following a delay between conditioning and extinction training</description><description>Lors d’un entraînement par extinction, les animaux forment un nouveau souvenir qui inhibe l’expression de la réponse conditionnée préalablement établis par l’association d’un stimulus conditionné (CS) et d’un stimulus non-conditionné (US). La réponse conditionnée alors affaibli peut par contre ressurgir lors de l’exposition au contexte de conditionnement original. Ce phénomène est appelé renouvellement. Le souvenir lié à l’extinction est par conséquent fortement contextuel, et le renouvellement de la réponse conditionnée surviendra généralement si l’entraînement par extinction et les tests subséquents ont lieu dans des contextes différents. Des résultats antérieurs ont montrés que les souvenirs contextuels d’ordre spatial acquis lors de conditionnement de peur contextuel se détériorent avec le temps. Basé sur ces résultats, nous avons examinés si la sensibilité au contexte des souvenirs d’extinction lors de conditionnement de peur auditive change également avec le temps. Lorsque nous avons attendu 24 h entre le conditionnement et l’extinction, les animaux ayant reçu l’apprentissage de l’extinction dans un nouveau contexte, mais qui ont été testé dans le contexte de conditionnement original (A/B/A), ont montré un renouvellement de la réponse conditionnée au son. Par contre, cet effet n’est pas présent chez les animaux qui ont reçus le conditionnement, l’extinction et le test dans le même contexte (A/A/A). Cette différence est disparue lorsque la période entre le conditionnement et l’extinction a été prolongé de 24 h à 7 jours. C’est-à-dire, l’expression du souvenir d’extinction n’était plus dépendant du contexte. Afin de déterminer si la dégradation active du souvenir était responsable de cette perte de sensibilité au contexte, nous avons infusé le peptide d’interférence GluA23Y dans l’hippocampe pendant la période de 7 jours entre le conditionnement et l’apprentissage de l’extinction. GluA23Y prévient l’élimination des récepteurs AMPA contenant la sous-unité GluA2 des sites post-synaptiques, ce qui prévient alors la perte de mémoire, bloquant ainsi efficacement la dégradation active des représentations de souvenirs dans l’hippocampe. Le comportement des animaux traités avec GluA23Y était indiscernable du comportement des animaux ayant reçu l’entraînement par extinction 24 h après le conditionnement : les animaux A/B/A ont montrés une augmentation de la réponse conditionnée lors du test, mais ceci n’a pas été observé chez les animaux A/A/A. En bloquant l’endocytose des récepteurs AMPA contenant la sous-unité GluA2, et du même fait en prévenant la dégradation active des souvenirs, nous avons été capables de préserver la spécificité liée au contexte d’un souvenir d’extinction suite au conditionnement de peur auditive. Nos résultats suggèrent que les mécanismes de dégradation active sont responsables de la perte de sensibilité au contexte des souvenirs d’extinction observés après un délai entre le conditionnement et l’entraînement par extinction</description><creator>Weeks, Taylor</creator><contributor>Oliver Hardt (Supervisor)</contributor><date>2020</date><subject>Psychology</subject><title>Blocking synaptic removal of GluA2-containing AMPA receptors preserves the context-specificity of auditory fear memories during extinction training</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/z316q588w.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/v405sg10x</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Psychology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:n583z0401</identifier><datestamp>2020-03-23T20:15:57Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Le mixage multi-pistes est un processus itératif dans lequel divers paramètres de traitement, tels que l'équilibre de sonie, l'égalisation et la compression sont ajustés pour obtenir un signal de sortie cible conforme à des critères perceptifs et objectifs. La recherche sur les systèmes de mixage automatiques a connu une croissance rapide au cours des dix dernières années, proposant des systèmes intelligents pour presque tous les aspects de la production audio. Des outils intelligents analysant les liens entre tous les canaux audio afin d’en automatiser leur mélange ont été conçus.   Dans cette recherche nous étudions, développons et mettons en œuvre des stratégies de mixage automatisées en optimisant la localisation des sources sonores à l'aide d'approches innovatrices s'appuyant sur des propriétés de masquage perceptifs et/ou sur la directivité des sources musicales pour une spatialisation cohérente et flexible. Dans ma thèse, je me suis particulièrement intéressé aux aspects de spatialisation dans les mélanges multi-pistes selon deux approches: la première fondée sur un panoramique spectral qui repose sur une minimisation du masquage fréquentiel à l'aide de techniques d'optimisation afin d'obtenir un mixage stéréophonique non masqué et bien spatialisé; la seconde visant des systèmes multi-pistes au-delà de la stéréophonie pour lesquels le même cadre d’optimisation est utilisé mais contraint par la directivité des sources sonores.   L'objectif est de produire des sons pour un environnement immersif, où les sources peuvent apparaître à n'importe quelle position avec des motifs de directivité spécifiques qui caractérisent leur comportement anisotrope dans l'espace à deux ou trois dimensions entourant l'auditeur</description><description>Multitrack mixing is an iterative process in which various processing parameters such as loudness balance, EQing and compression are adjusted to achieve a certain target output mix that complies to perceptual and objective criteria. Research into automatic mixing systems has grown rapidly over the last ten years, with intelligent systems proposed for almost every aspect of audio production. Intelligent tools that analyze the relationships between all channels in order to automate the mixing of multitrack audio content have been devised.  This research investigates, develops and implements automated mixing strategies that optimize localization of sound sources in a multitrack mix using innovative approaches that rely on masking properties of perception and directivity of the musical source for coherent and flexible spatialization. The aim is to deliver sound for an immersive environment, in which sources can appear at any position with specific directivity patterns that quantify their directional dependent behaviour in the two or three-dimensional space around the listener. This thesis focuses particularly on spatialization aspects of multitrack mixing; one approach being frequency-based panning that relies on release from spectral masking using optimization techniques to obtain an unmasked and well-spatialized stereo mix. Another approach is aimed at multichannel systems beyond stereo for which the same optimization framework is used but with source directivity as constraints.   The proposed automix systems can be used in the mixing stage to place sources in the stereo/sound field, to produce a well spatialized mix with reduced auditory masking and improved perceived quality (clarity and intelligibility). The proposed algorithms for both techniques make use of a spectral panning linear system which generates optimized filters for each track, with constraints that comply to perception. The evaluation criteria involves both subjective as well as objective tests to obtain measures for unmasking amount and extent of spatialization. Audio samples generated by the proposed algorithms are available online. Both spatialization approaches proved to give a good sense of unmasking and spatialization. The proposed spatialization technique can be beneficial to design systems that create plausible 3D sound scapes. Using innovative audio effects/tools like source directivity coupled with optimization techniques can address how music can be meaningfully upmixed from the more common stereo to other playback formats like 5.1, 22.2 and Ambisonics</description><creator>Tom, Ajin</creator><contributor>Philippe Depalle (Supervisor)</contributor><date>2020</date><subject>Music</subject><title>Automatic mixing systems for multitrack spatialization based on unmasking properties and directivity patterns</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/th83m380r.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/n583z0401</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Schulich School of Music</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:05741x14q</identifier><datestamp>2020-03-23T20:16:07Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Le système INTRABEAM est une source miniature de rayons X en kilovoltage fabriquée par Zeiss (Carl Zeiss Meditech AG, Allemagne) et est spécialement conçu pour les applications de radiothérapie peropératoire. La nature de son utilisation dans le corps du patient suggère que son étude dosimétrique soit faite comme une source de curiethérapie électronique. En tant que source de curiethérapie, l’INTRABEAM représente une alternative pratique aux radionucléides conventionnels car il délivre un faisceau de rayons X à basse énergie (50 kVp), réduisant ainsi les exigences en matière de régulation et de protection sans compromettre les débits de dose.Malgré ses avantages et son utilisation étendue pour le traitement du cancer du cerveau et du sein, la source n’a pas été caractérisée conformément aux spécifications de l’AAPM TG-43, limitant ainsi sa modélisation dans les systèmes commerciaux de planification de traitement pour un calcul efficace de la dose. Dans le présent travail, une caractérisation dosimétrique par curiethérapie de la source INTRABEAM, basée sur le protocole AAPM TG-43, est présentée.La source INTRABEAM a été modélisée avec Monte Carlo (MC) en utilisant egs_brachy, un code utilisateur de EGSnrc, qui permet des calculs de dose rapides via un estimateur de longueur de « tracks ». Pour la validation du modèle MC, les calculs de dose en profondeur dans l’eau, le long de l’axe longitudinal de la source, ont été comparés aux mesures faites sur un fantôme d’eau, fourni par le fabricant de la source, à l’aide d’une chambre d’ionisation à faible rayons X et de deux sources INTRABEAM différentes. Des différences locales inférieures à 10%,  comprises dans l’intervalle de confiance de mesures, ont été observées pour les points situés à des distances supérieures à 1cm à partir de la source, correspondant à des situations pertinentes cliniquement. La pertinence d’un dosimètre alternatif, soit un diamant synthétique (microDiamond de PTW), a aussi été évaluée. Les résultats obtenus ont montré de meilleures performances que ceux obtenus avec la chambre d’ionisation aux points proches de l’extrémité de la source, où les gradients élevés dans les distributions de dose impliquent des effets de moyennage volumique importants pour les détecteurs avec présentant un plus grand volume de détection.Suite à la validation du modèle MC, les paramètres du TG-43 ont été obtenus. La fonction de la dose radiale a diminué près de la source (&lt; 1cm) avec un gradient plus grand que celle des radionucléides de curiethérapie classiques (Ir-192, Pd-103 and I-125). Cependant, le gradient est partiellement aplati sur de plus grandes distances et présente une chute similaire à celle de la source de curiethérapie électronique Xoft. Les valeurs simulées d’anisotropie polaire étaient principalement uniformes le long de θ= 0◦ et diminuaient progressivement près du bord de la source, en raison de l’atténuation du faisceau par les éléments des murs de la source. Les paramètres TG-43 fournis dans ce travail servent donc de données préliminaires pour les systèmes de planification de traitement tridimensionnels (3D)</description><description>The INTRABEAM system is a miniature kilovoltage x-ray source manufactured by Zeiss (Carl Zeiss Meditech AG, Germany) and is designed especially for intraoperative radiotherapy applications. The nature of its use inside the patient body suggests its dosimetric study as an electronic brachytherapy source.  As a brachytherapy source, the INTRABEAM represents a convenient alternative to conventional radionuclides since it delivers a low energy (50 kVp) x-ray beam, reducing the regulatory and shielding requirements without compromising the dose delivery rates.Despite its benefits and extended use for the treatment of brain and breast cancers, the source has not been characterized according to the AAPM TG-43 specifications, restricting its modeling in commercial treatment planning systems (TPS) for efficient dose calculations. In the present work, a brachytherapy dosimetry characterization of the INTRABEAM source based on the AAPM TG-43 protocol is presented.The INTRABEAM source was modeled with Monte Carlo (MC) using egs_brachy, a user code of EGSnrc, which allows rapid dose calculations via a tracklength estimator. For the validation of the MC model, depth dose calculations in water along the source longitudinal axis were compared with measurements in a water phantom provided by the source manufacturer using a soft x-ray ionization chamber and two different INTRABEAM sources resulting in local differences lower than 10%, laying within the measurement uncertainties for points located at distances higher than 1cm from the source tip, which represent the relevant situations for clinical cases. The suitability of an alternative radiation detector, a synthetic diamond (microDiamond from PTW) was assessed, resulting in a better performance than the air-filled ionization chamber at points close to the source tip where the high gradients in the dose distributions imply higher volume averaging effects for detectors with bigger radiation detection volumes.Following the validation of the MC model, the TG-43 parameters were retrieved. The radial dose function diminished close to the source (&lt;1cm) with a steep gradient higher than that of conventional brachytherapy radionuclides (Ir-192, Pd-103 and I-125), but it is partially flattened at larger distances with a similar fall-off as the Xoft electronic brachytherapy source. The simulated polar anisotropy values were mainly uniform along θ= 0◦ and gradually decreased close to the border of the source, affected by the beam attenuation in the elements of the source walls. The TG-43 parameters provided in this work serve as preliminary data required for tridimensional (3D) TPSs</description><creator>Ayala Alvarez, David</creator><contributor>Jan Peter Frans Seuntjens (Supervisor)</contributor><date>2020</date><subject>Medical Physics Unit</subject><title>Dosimetric studies on the INTRABEAM electronic brachytherapy source</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/w95054983.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/05741x14q</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Medical Physics Unit</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:hd76s463z</identifier><datestamp>2020-03-23T20:16:36Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>En pratique clinique, les médecins visent à offrir le meilleur traitement médical aux patients. Cela peut nécessiter une mise au point des traitements ou le choix de différents traitements pour deux patients ayant le même diagnostic, en raison de différences au niveau des caractéristiques des patient. L'utilisation des données afin d’élaborer des règles permettant de personnaliser les stratégies de traitement est connue sous le nom de médecine de précision, ou régimes de traitement dynamiques (RTD), où le traitement ou la recommandation d'un médecin est fondée sur les antécédents du patient (y compris les traitements antérieurs), les facteurs de risque et toute autre information propre au patient qui peut être prise en compte pour adapter les décisions thérapeutiques. Jusqu'à présent, relativement peu de méthodes ont été proposées afin d’estimer les RTD afin d'optimiser les résultats censurés. De toute évidence, des modèles de prédiction flexibles et efficaces sont souhaitables afin de maximiser la précision pour la prédiction de traitements optimaux pour chaque patient, tout en tenant compte des données censurées et des interactions complexes entre les caractéristiques du patient et le traitement. Les arbres additifs de régression bayésienne (AARB) est un cadre attrayant à cet égard, car il peut fournir une décision de traitement simple et interprétable sans connaître la vraie relation paramétrique ou fonctionnelle entre le résultat et le traitement ainsi que le résultat et les covariables. Dans ce mémoire, le AARB est utilisé afin de personnaliser le traitement en supposant une distribution log-normale de temps de défaillance accéléré (TDA) pour le résultat censuré dans un problème clinique en deux étapes. L'approche proposée fut comparée par simulation à l'approche bien établie de modélisation paramétrique d'apprentissage-Q. Dans le cas d'une spécification de modèle erronée, l'approche d'apprentissage-Q résulta en une performance médiocre. À l’inverse, le TDA-AARD performa adéquatement et s’améliora en fonction de la taille croissante d'échantillon. Les méthodes ont également été appliquées aux données de registres dans le contexte de la transplantation de cellules hématopoïétiques allogéniques, en mettant l'accent sur la question de quelle classe d'immunosuppresseurs utiliser dans le but de prévenir et traiter le développement de la maladie aiguë du greffon contre l'hôte afin de maximiser la survie sans maladie des patients atteints de leucémie myéloïde aiguë. Je conclus que le TDA-AARD offre une grande flexibilité et une sensibilité réduite aux erreurs dues à la mauvaise spécification de modèles</description><description>In clinical practice, physicians aim to provide the best medical therapy to patients. This may require fine-tuning treatments, or choosing different treatments for two patients who have the same diagnosis due to differences in patient-level characteristics. Using data to develop rules for personalizing treatment strategies is known as precision medicine, or dynamic treatment regimes (DTRs), where the treatment or recommendation of a physician is based on the patients’ history (including past treatments), risk factors, and any other patient-specific information that may be considered to tailor therapeutic decisions. To date, there are relatively few methods that have been proposed for estimating DTRs to optimize censored outcomes. Clearly, flexible and efficient prediction models are desirable, to maximize accuracy in predicting optimal treatments for individual patients while accommodating censored data and complex interactions between patient factors and treatment. The Bayesian additive regression tree (BART) is an attractive framework in this regard as it can provide simple and interpretable treatment decision without knowing the explicit parametric or functional relationship between the outcome and both treatment and covariates. In this thesis, BART is used to individualize treatment assuming a log-normal accelerated failure time (AFT) distribution for the censored outcome in a two-stage clinical problem. The proposed approach was compared with the well-known parametric modelling approach of Q-learning via simulation. In the case of model misspecification, Q-learning approach performed poorly where AFT-BART performed well and improved with increasing sample size. The methods were also applied to registry data in the context of allogeneic hematopoietic cell transplantation, focusing on the question of which class of immunosuppressants to use so as to prevent and treat the development of the acute graft-vs-host disease to maximize disease-free survival in acute myeloid leukemia patients. I conclude that AFT-BART offers great flexiblility and reduced sensitivity to model misspecification</description><creator>Hossain, S M Ferdous</creator><contributor>Erica Moodie (Supervisor)</contributor><date>2020</date><subject>Epidemiology and Biostatistics</subject><title>Flexible modelling of optimal dynamic treatment regimes for censored outcomes</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/qv33s179h.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/hd76s463z</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Epidemiology and Biostatistics</discipline></degree></thesis></metadata></record><resumptionToken completeListSize="47894">oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):37400</resumptionToken></ListRecords></OAI-PMH>