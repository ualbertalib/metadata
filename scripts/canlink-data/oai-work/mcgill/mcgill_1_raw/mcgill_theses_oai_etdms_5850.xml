<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/assets/blacklight_oai_provider/oai2-b0e501cadd287c203b27cfd4f4e2d266048ec6ca2151d595f4c1495108e36b88.xsl"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd"><responseDate>2020-07-24T23:13:01Z</responseDate><request resumptionToken="oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):5850" verb="ListRecords">https://escholarship.mcgill.ca/catalog/oai</request><ListRecords><record><header><identifier>oai:escholarship.mcgill.ca:td96k513f</identifier><datestamp>2020-03-21T13:51:20Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>In this study, we investigated the characteristics, corrosion rate and the biocompatibility of four (4) different magnesium-strontium (Mg-Sr) based alloys with the goal of developing a biodegradable, biocompatible cardiovascular implant material. The alloy compositions studied were Mg-0.5Sr, Mg-0.3. Sr-0.3Ca, Mg-0.3. Sr-0.3Ca-0.1Zn, Mg-0.3. Sr-0.3Ca-0.3Zn, and as controls, we used pure magnesium, the WE43 (Mg-0.4Y-4 Nd) commercial alloy and stainless steel 316L.The material characteristics and corrosion rate were evaluated using atomic force micsroscopy (AFM), scanning electron microscopy (SEM) and X-ray diffraction (XRD as well as in vitro immersion tests. Surface roughness was found to be alloy dependent with Mg-0.5Sr showing the highest decrease in roughness with polishing while stainless steel 316L the lowest. SEM analysis revealed that all Mg alloys studied exhibited cast dendritic structure with intermetallic second phases occupying the interdentritic regions. It was observed that zinc has a refining effect on dendrite size.In vitro corrosion experiments were evaluated using modified simulated-body fluid (m-SBF) which yielded slightly different ranking in corrosion resistance based on weight loss and hydrogen evolution. For weight loss measurements, the ranking was found to be WE43&lt;Mg-0.3Ca-0.3Sr-0.1Zn&lt;Mg-0.3Ca-0.3Sr-0.3Zn&lt;Mg-0.3Ca-0.3Sr&lt;Mg-0.5Sr. For hydrogen evolution, the ranking was WE43&lt;Mg-0.3Ca-0.3Sr-0.1Zn&lt;Mg-0.3Ca-0.3Sr-0.3Zn&lt;Mg-0.5Sr&lt;Mg-0.3Ca-0.3Sr. It was seen that the zinc addition to Mg-Ca-Sr alloy improved the corrosion resistance. Indirect in-vitro cytotoxicity tests were conducted using human umbilical vein endothelial cells (HUVECs) and mouse osteoblast precursor cells (MC3T3) with % cell viability measurements (hereafter referred to as % viability) taken at day 1, day 4 and day 7. Results of these experiments showed differences between the cell types. Noting that day 1 is the first exposure time that reflects directly the %viability of the alloys, we observed for HUVECs that the %viability in day 1 was significantly lower for WE43 compared to the other alloys. On the other hand, for MC3T3 cells, the highest % viability was observed for WE43 and pure magnesium. We observed that the cells recovered at day 4 and %viability increased for both HUVECs and MC3T3 cells. Noting that day 4 represents the values in % viability 4 days after the first exposure to the alloys, the highest increase in %viability observed for HUVECs was for the Mg-0.3Ca-0.3Sr alloy and for MC3T3 cells it was observed for pure magnesium and the WE43 alloy. At day 7, we observed a decrease in viability for HUVECs for all alloys and controls while for MC3T3 cells, % viability continued to increase for most of the alloys and controls. Overall, we observed that the % viability for MC 3T3 cells were higher compared to the HUVECs.  Hemolysis results showed that all our newly developed alloys caused less hemolysis compared to the WE43 commercial alloy. The hemolysis rate increased with the increase in alloy weight for all alloys. We also observed that the pH increase does not have a considerable effect on hemolysis rate. Platelet aggregation studies were initiated yet these have not been discussed in the results because sufficient number of repeats could not be made. Platelet aggregation has been briefly included in the Appendix. This may be an interesting future study on the effect of magnesium on platelet aggregation. </description><description>Nous avons étudié ici les propriétés de surface, la vitesse de corrosion et la biocompatibilité de quatre (4) différents alliages à base de magnésium-strontium (Mg-Sr) afin de développer un matériau pour implant cardiovasculaire biodégradable et biocompatible. Les compositions d'alliage Mg-0,5Sr, Mg-0,3. Sr-0.3Ca, Mg-0.3. Sr-0.3Ca-0.1Zn, Mg-0.3. Sr-0.3Ca-0.3Zn ont été étudiées, et du magnésium pur ainsi que l'alliage commercial WE43 (Mg-0.4Y-4 Nd) et l'acier inoxydable 316L ont été utilisés comme témoin.Les propriétés du matériau et la vitesse de corrosion ont été évaluées par microscopie à force atomique (AFM), microscopie électronique à balayage (MEB) et diffraction des rayons X (XRD) ainsi que par des tests d'immersion in vitro.Il a été montré qu la rugosité de surface était directement liée au choix de l'alliage avec Mg-0.5Sr montrant la plus forte diminution de la rugosité suite au polissage et l'acier inoxydable 316L la plus faible. L'analyse SEM a révélé que tous les alliages de Mg étudiés présentaient une structure dendritique avec des secondes phases intermétalliques occupant les régions interdentritiques. Il a été observé que le zinc permettait de rafiner la taille de la structure dendritique.Les expériences de corrosion in vitro ont été effectuées à l'aide d'un fluide de corps simulé modifié (m-SBF) et ont conduit à un classement légèrement différent de la résistance à la corrosion en fonction de la perte de poids et de l'évolution de l'hydrogène. Pour les mesures de perte de poids, l'ordre obtenu était WE43 &lt;Mg-0.3Ca-0.3Sr-0.1Zn &lt;Mg-0.3Ca-0.3Sr-0.3Zn &lt;Mg-0.3Ca-0.3Sr &lt;Mg-0.5Sr. Pour l'évolution de l'hydrogène, l'ordre était WE43 &lt;Mg-0.3Ca-0.3Sr-0.1Zn &lt;Mg-0.3Ca-0.3Sr-0.3Zn &lt;Mg-0.5Sr &lt;Mg-0.3Ca-0.3Sr. Il a été noté que l'addition de zinc à l'alliage de Mg-Ca-Sr améliorait sa résistance à la corrosion.Des tests indirects de cytotoxicité in vitro ont été effectués en utilisant des cellules endothéliales de la veine ombilicale humaine (HUVEC) et des cellules précurseurs d'ostéoblastes de souris (MC3T3) avec des mesures de viabilité cellulaire (ci-après définies par le % de viabilité) à J1, J4 et J7. Ces mesures ont montré des résultats différents en fonction du type de cellules.Considérant que J1 est la première mesure qui traduit directement le % de viabilité au contact des alliages, nous avons observé pour les HUVEC que le % de viabilité à J1 était significativement plus faible pour WE43 par rapport aux autres alliages. D'autre part, pour les cellules MC3T3, le % de viability le plus élevé a été observé pour WE43 et le magnésium pur. Nous avons observé un regain de viabilité à J4 avec une augmentation du % de viabilité pour les cellules HUVEC et MC3T3. Considérant que J4 représente la valeur du % de viabilité après 4 jours d'exposition aux alliages, la plus forte augmentation de % de viabilité observée pour les HUVEC concernait l'alliage Mg-0.3Ca-0.3Sr, et pour les cellules MC3T3, le magnésium pur et l'alliage WE43. À J7, il a été noté une diminution de la viabilité pour les HUVEC pour tous les alliages et contrôles, tandis que pour les cellules MC3T3, le % de viabilité continuait d'augmenter pour la plupart des alliages et des contrôles. Dans l'ensemble, le % de viabilité pour les cellules MC3T3 était plus élevé que celui des HUVEC. Les résultats de l'hémolyse ont montré que tous nos alliages récemment développés causaient moins d'hémolyse par rapport à l'alliage commercial WE43.Le taux d'hémolyse augmentait avec le poids des alliages pour tous les groupes. Nous avons également relevé que l'augmentation du pH n'avait pas d'effet significatif sur le taux d'hémolyse. Des études d'agrégation de plaquettes ont été initiées, mais celles-ci n'ont pas été discutées dans les résultats car un nombre suffisant de réplicats n'a pas pu être réalisé. L'agrégation des plaquettes est brièvement mentionnée dans l'annexe. Elle pourrait faire l'objet d'une future étude de l'effet du magnésium sur l'agrégation plaquettaire.</description><creator>Top, Meltem</creator><contributor>Mihriban Ozden Pekguleryuz (Internal/Cosupervisor2)</contributor><contributor>Maryam Tabrizian (Internal/Supervisor)</contributor><date>2017</date><subject>Dentistry</subject><title>Characteristics and biocompatibility of magnesium-strontium (Mg-Sr) based alloys</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/ng451m14z.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/td96k513f</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Faculty of Dentistry</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:1r66j3656</identifier><datestamp>2020-03-21T13:51:21Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Nuclear receptors are transcriptional factors that are essential for a wide range of biological processes. They are partly regulated through their interaction with co-regulatory proteins. Here, we focus on the orphan nuclear receptor ERRa and its potential new co-activator protein NCOA5. Using NCOA5 knockdown or overexpression via a lentiviral system, we investigated the role of NCOA5 in ERRa regulation in Her2-positive breast cancer cells and its effect on known targets of ERRa in this context, such as the ERBB2 amplicon transcription. We show that NCOA5 and ERRa can regulate each other, yet the precise mechanism remains to be elucidated. NCOA5 protein level affects ERRα transcription and protein level, also affecting the transcription of ERRa targets from the ERBB2 amplicon including the Her2 receptor itself. Modulation of NCOA5 levels leads to variation in cell proliferation and metabolism, thus revealing that NCOA5 is an important factor in the ERBB2 amplicon regulation.</description><description>Les récepteurs nucléaires sont des facteurs de transcription qui sont essentiels pour la régulation d'un grand nombre de procédés biologiques. Ils sont en partie régulés grâce à leurs interactions avec des protéines co-régulatrices. Dans ce projet, nous nous sommes intéressés plus particulièrement au récepteur nucléaire orphelin ERRa et à NCOA5, un nouveau co-activateur potentiel. En utilisant un système lentiviral pour inactiver ou surexprimer NCOA5, nous avons étudié son rôle dans la régulation de ERRa dans des cellules de cancer du sein positives pour le récepteur Her2, ainsi que son rôle dans la régulation de la transcription de cibles connues de ERRα dans ce contexte, comme les gènes de l'amplicon ERBB2. Nous avons observé que NCOA5 et ERRa peuvent se réguler l'un l'autre, même si le mécanisme précis reste inconnu. De plus, la modulation de l'expression de NCOA5 affecte la transcription et le niveau de protéines de ERRa, ce qui affecte aussi la transcription des gènes de l'amplicon de ERBB2, incluant le récepteur Her2 lui-même. La modulation du niveau de NCOA5 dans les cellules entraine des variations dans leur vitesse de prolifération et dans leur métabolisme, indiquant que NCOA5 est un facteur important dans la régulation de l'amplicon ERBB2.</description><creator>Laffitte, Amandine</creator><contributor>Vincent Giguere (Internal/Supervisor)</contributor><date>2017</date><subject>Biochemistry</subject><title>The Nuclear Receptor Co-Activator 5 is a potential new co-regulator of the Estrogen Related Receptor α in breast cancer</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/vd66w225w.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/1r66j3656</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Biochemistry</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:x920g018m</identifier><datestamp>2020-03-21T13:51:22Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Malaria affects more than a quarter of this planet's population with 214 million infections and 438,000 deaths annually. In the absence of an effective malaria vaccine, the rise and spread of drug resistant strains coupled with the slow development of new antimalarials is a potential human tragedy. Research to date has led to the identification of several proteins that can mediate parasite resistance to most antimalarials. Two of the latter proteins (e.g., PfMDR1 and PfMRP1) are members of a large and evolutionary conserved family of ATP-dependent membrane transporters (e.g., ABC transporters). The P. falciparum genome encodes 16 different ABC transporters, including one member of the ABCG subfamily (e.g., PfABCG). By contrast, the human genome encodes 48 members of the ABC transporters, including five members of the ABCG subfamily (huABCG1, G2, G4, G5 and G8). With the exception of huABCG2, which transports many anti-cancer drugs and some normal cell metabolites, huABCG1, G4, G5 and G8 mediate the transport of cholesterol and other sterols.  Earlier studies using PfABCG-knockout clones of P. falciparum have suggested that PfABCG may play a role in the parasite's sensitivity to ketotifen (an anti-histamine drug), and in the accumulation of neutral lipids in PfABCG-knockout clones. Moreover, we have shown that PfABCG shares 24.3 % and 26.5 % amino acid sequence identity with huABCG1 and huABCG2, respectively. Hence, it is presently not clear if PfABCG is functionally more like huABCG1, huABCG2, or both. In an effort to characterize the functions of PfABCG, it was of interest to compare its substrate specificity and subcellular localization to that of huABCG1 and G2 in the same expression system, using mammalian HEK-293 cells. Our results show the stable expression of PfABCG in HEK-293, as a fusion protein with GFP sequence linked to PfABCG N-terminal. In addition, relying on the fluorescence of GFP in PfABCG-HEK-293 transfectants, we have demonstrated the localization of GFP-PfABCG to the endosomal membranes, likely the endoplasmic reticulum. We also show that HEK-293 cells stably transfected with GFP-PfABCG are more sensitive to ketotifen in the presence of reseripine, a calcium channel blocker and an inhibitor of huABCB1 and huABCG2 expressed at low levels in HEK-293 cells. Efforts are on going to further characterize the functions of PfABCG and its substrate specificity and how these functions relate to those of huABCG1 and G2.</description><description>Le paludisme affecte plus d'un quart de la population de cette planète avec 214 millions d'infections et 438 000 décès chaque année. De plus, en l'absence d'un vaccin efficace contre le paludisme, l'augmentation et la propagation de souches résistantes aux médicaments associées au développement lent de nouveaux antipaludiques est une tragédie humaine potentielle. La recherche à ce jour a permis d'identifier plusieurs protéines qui peuvent servir de médiateur à la résistance des parasites à la plupart des antipaludiques. Deux de ces protéines (par exemple, PfMDR1 et PfMRP1) sont des membres d'une importante famille évolutivement conservée de transporteurs membranaires dépendant de l'ATP (par exemple, des transporteurs ABC). Le génome de P. falciparum code pour 16 transporteurs ABC différent, y compris un seul membre de la sous-famille ABCG (par exemple, PfABCG). En revanche, le génome humain code pour 48 membres des transporteurs ABC, dont cinq membres de la sous-famille ABCG (huABCG1, G2, G4, G5 et G8). À l'exception de huABCG2 qui transporte de nombreux médicaments anti-cancéreux et certains métabolites cellulaires normaux, huABCG1, G4, G5 et G8 font la médiation du transport du cholestérol et d'autres stérols. Des études antérieures utilisant des clones de PfABCG-knock-out de P. falciparum ont suggéré que PfABCG peut jouer un rôle dans la sensibilité du parasite au ketotifène (un médicament anti-histaminique) et à l'accumulation de lipides neutres dans des clones PfABCG-knock-out. En outre, nous avons montré que PfABCG partage 24,3% et 26,5% de séquence d'acides aminés identique avec huABCG1 et huABCG2, respectivement. Par conséquent, il n'est présentement pas encore clair si PfABCG du point de vue fonctionnelle est comme huABCG1, huABCG2 ou les deux. Dans le but de caractériser les fonctions de PfABCG, il était intéressant de comparer sa spécificité de substrat et sa localisation à celle de huABCG1 et G2 dans le même système d'expression, en utilisant des cellules HEK-293 de mammifères. Nos résultats montrent une expression stable de PfABCG dans HEK-293, en tant que protéine de fusion avec une séquence de la GFP liée à une portion N-terminale de PfABCG. De plus, en prenant avantage de l'auto fluorescence de la GFP dans les transfectants PfABCG-HEK-293, nous avons démontré la localisation de GFP-PfABCG aux membranes endosomales, probablement le réticulum endoplasmique. Nous avons montré également que les cellules HEK-293 transfectées de manière stable avec GFP-PfABCG sont plus sensibles au kétotifène en présence de la réserpine, un bloqueur des canaux calciques et un inhibiteur de huABCB1 et huABCG2 qui sont exprimés à des niveaux faibles dans les cellules HEK-293. Des expériences sont en cours pour caractériser davantage les fonctions de PfABCG et sa spécificité de substrat ainsi que la façon dont ces fonctions se rapportent à celles de huABCG1 et G2.</description><creator>AlSulami, Khlood Ali</creator><contributor>Elias Georges (Internal/Supervisor)</contributor><date>2017</date><subject>Parasitology</subject><title>Heterologous expression and functional characterization of «Plasmodium falciparum» ABCG in mammalian cells</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/nv935544p.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/x920g018m</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Institute of Parasitology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:6395wb00k</identifier><datestamp>2020-03-21T13:51:23Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Muscle stem cells (MuSC) are essential for proper muscle regeneration, and aging is associated with a progressive decline in MuSC number and regenerative capacity. Arginine methylation is a post-translational modification of proteins that have major impacts on cellular processes. Recently, we reported that mice with protein arginine methyltransferase 7 (PRMT7) and PRMT1 null muscle stem cells display a severe regeneration impairment in skeletal muscle supporting a role for arginine methylation in the maintenance of the MuSC regenerative function in adult mice. We showed that PRMT7 is required to preserve regenerative function during aging (Chapter 2). PRMT7 null MuSCs enter premature senescence and consequently fail to regenerate muscle and self-renew. This is explained by the regulation of Dnmt3b and Cdkn1a by PRMT7. PRMT1 is required to ensure proper MuSC cell fate decision and differentiation progression following activation. PRMT1-deficient MuSCs display sustained proliferation and repression of differentiation resulting in several regeneration defects. These findings are essential to understanding the epigenetic events regulating MuSC functions during adult regenerative myogenesis in the purpose of manipulating their fate for a therapeutic approach in the future, especially against aging and MuSC-associated diseases.</description><description>Les cellules souches musculaires (CSM) sont essentielles pour assurer la régénération des muscles squelettiques, et le vieillissement est associé à un déclin progressif du nombre CSM ainsi que de leur capacité régénératrice. La méthylation des résidus arginine est une modification post-traductionnelle des protéines qui a un impact majeur dans plusieurs processus cellulaires. Nous avons démontré que les souris avec des cellules souches musculaire manquant la Méthyltransférase d'Arginine de Protéine 7 (PRMT7) et PRMT1 montrent une incapacité sévère de la régénération des muscles squelettiques, prouvant ainsi le rôle de la méthylation de l'arginine dans le maintien de la fonction régénérative CSM chez les souris adultes. Premièrement, nous avons montré que PRMT7 est nécessaire pour préserver la fonction régénérative pendant le vieillissement (Chapitre 2). Les CSMs manquant PRMT7 entrent en sénescence prématurée et par conséquent ne parviennent pas à régénérer le muscle et à s'auto-renouveler pour maintenir le réservoir de CSM. Ceci s'explique par la régulation de Dnmt3b et Cdkn1a par PRMT7. Secondement, PRMT1 est nécessaire pour assurer les choix de la destiné des CSMs notamment durant la progression de la différenciation après l'activation. Les CSMs déficientes en PRMT1 présentent une prolifération accrue et une répression de la différenciation entraînant une augmentation de l'auto-renouvèlement des CSMs et une prolifération permanente de leur progéniteurs, menant à plusieurs défauts de régénération.Ces résultats sont essentiels pour comprendre les événements épigénétiques régulant les fonctions des CSMs au cours de la myogénèse régénérative adulte dans le but de manipuler leur destin en vue d'une approche thérapeutique à l'avenir, en particulier contre le vieillissement et les maladies associées au CSM.</description><creator>Blanc, Roméo</creator><contributor>Stephane Richard (Supervisor)</contributor><date>2017</date><subject>Medicine</subject><title>Arginine methylation in muscle stem cell during skeletal muscle regeneration</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/3r074x65p.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/6395wb00k</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Medicine</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:73666724z</identifier><datestamp>2020-03-21T13:51:24Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Introduction: An understanding and approach to health research and health care has been dominated by a uni-professional and, at times, individualist, perspective. Yet, care coordination is crucial for patient safety, especially for an aging population. Health care workers have needed to try to transcend their particular communities of practice, in which they work and learn. One of the sharpest and least explored needs for care coordination is where complex patients are categorized in the emergency department (ED), which brings together emergency medicine (IM) doctors and internal medicine (IM) doctors. The latter group takes on the task of classifying and treating complex cases as a relatively generalist specialty. However, there is little foundation in theory or practice to understand the roles between these two important players, despite their importance in care coordination. Therefore, the aim of this study is to understand the similarities and differences in the roles and priorities of EM and IM doctors in the ED, and its implications for care coordination. Methods: The understanding of roles and priorities calls forth qualitative methods, which focus on language. The study was set in a university health system, in which 14 attending physicians were interviewed, representing both EM and IM doctors based in the ED. The audio-recordings were transcribed and individually, and then collaboratively, the researchers categorized the talk into themes which are exemplified in the Findings Findings: The participants' clinical work was shaped strongly by the communities of practice they inhabited, and which gave them the benefits and tensions of their community's organizational position. There was a high level of mutual empathy across the two teams, despite having different priorities on a spectrum of diagnostic accuracy versus organizational efficiency. Participants sought to solve conflict through organizational mechanisms to preserve interpersonal relationships. This allowed participants to navigate different criteria over the appropriateness of a patient for a particular service. Ultimately, the ED was held responsible for the length of patient stay, even where they were "boarding" admitted patients who had no in-patient bed. Discussion and conclusion: This study showed that a community of practice perspective is a compelling way to characterize clinical work at critical points of the tight rationing of health services. Such a perspective needs to be adopted in government incentives for other health services to share the consequences of ED over-crowding. A similar communitarian perspective is needed to appreciate the clinical, organizational and educational priorities IM juggles system-wide in accommodating patients. Quality and efficiency are not opposing concepts. Efficiency benefits from careful decision-making, and careful-decision-making helps direct patients to transfer or discharge. More research is needed on patient categorization and care rationing from the perspectives of nurses, allied health and consumers.</description><description>Introduction: La compréhension ainsi que l'approche adoptées par le domaine de la recherche et des soins médicaux sont dominées par la perspective d'un seul professionnel, parfois même par un individu. La coordination de soins est cruciale pour la sécurité d'un patient, spécialement en présence d'une population vieillissante. Les travailleurs du domaine de la santé ont besoin de transmettre leur pratique. L'un des besoins de coordination de soins le moins explorés est lorsque des patients présentant des situations complexes sont catégorisés au département d'urgence (ED), ce qui réunit les urgentologues (EM) et les médecins internes (IM). Les médecins à l'interne prennent la tâche de classifier et traiter les cas plus complexes. Cependant, il y a peu de fondations théoriques ou pratiques qui permettent de distinguer et comprendre les différents rôles de ces deux catégories de professionnel. Ainsi, le but de cette étude est de comprendre les similarités et différences des rôles et priorités entre un médecin EM et IM en ED, sans oublier ce que cela implique pour la coordination de soins. Méthodes: La compréhension des rôles et priorités est l'objet de méthodes qualitatives qui se concentrent sur la langue. L'étude a pris place dans le pavillon de la santé d'une université, où 14 médecins, certain IM d'autres EM, tous basé en ED, ont passés une entrevue. Les enregistrements sonores ont été transcrits de manière individuelle, ils ont été catégorisés par la suite en thématique par les chercheurs. Voir section résultat pour de plus amples explications. Résultats: Le travail clinique des participants était pris en considération. Il y avait un haut niveau d'empathie entre les deux équipes, malgré le fait qu'ils ont chacun différentes priorités : le spectre de l'exactitude d'un diagnostic et l'efficacité organisationnel. Les participants ont essayé de résoudre un conflit à travers le mécanisme organisationnel afin de préserver les relations interpersonnelles.  Cette dernière méthode a permis aux participants d'explorer différents critères au lieu de l'aptitude d'un patient pour un service particulier. Inévitablement, les médecins ED ont été portés responsables de la durée du séjour du patient, même lorsqu'il était question de « boarding » des patients admis alors qu'il n'y avait pas de lit pour patient. Discussion et conclusion: Cette étude a su démontrer qu'une communauté de pratique perspective est une manière intéressante de caractériser le travail clinique au point critique des services de santés limitées. Une telle perspective se devrait d'être adoptée et donc devrait être poussée par une motivation gouvernementale pour d'autres services de santé pour partager les conséquences de l'ED encombré. Une perspective similaire est nécessaire pour apprécier la facette clinique, organisationnelle et éducative des priorités de médecins IM qui tente d'accommoder les patients. La qualité et l'efficacité ne sont pas des concepts opposés. L'efficacité bénéficie d'une prise de décision minutieuse et prudente, ce qui permet de diriger un patient vers un transfert ou l'acquittement. Plus de recherche est nécessaire sur la catégorisation de patient et le rationnement de soins de la perspective des infirmiers, autres professionnelles de la santé et des consommateurs.</description><creator>Banik, Rakhee</creator><contributor>Peter Nugus (Internal/Supervisor)</contributor><date>2017</date><subject>Family Medicine</subject><title>Coodinating flow across practice boundaries: the collaborative work of emergency and internal medicine</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/nk322g94x.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/73666724z</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Family Medicine</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:2j62s738d</identifier><datestamp>2020-03-21T13:51:25Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Le papier émerge en tant que substrat de choix pour le développement de composantes électroniques et de capteurs flexibles puisqu'il offre un éventail d'avantages tels qu'un faible coût, et qu'il est biodégradable, jetable, facile à fabriquer, flexible et léger. De plus, par l'intégration de nanomatériaux fonctionnels tels que des nanofils d'oxyde de zinc (NFs de ZnO) en utilisant une approche chimique en solution liquide à basse température sur un substrat de papier, la fonctionnalité et le potentiel d'utilisation du papier comme capteur s'en voient augmentés. Cette thèse traite de la conception et de la caractérisation d'un accéléromètre et d'un pavé tactile, tous deux à base de papier. Les deux prototypes utilisent les propriétés piézoélectriques des NFs de ZnO intégrés au papier : les charges piézoélectriques sont générées lors de la déformation mécanique des NFs sur le substrat de papier. Puisque le courant généré par les NFs de ZnO était typiquement de l'ordre des pico-ampères, des circuits amplificateurs de charges ont été conçus pour les deux protoypes. La première partie de cette thèse décrit l'accéléromètre à base de papier. Celui-ci a une configuration en porte-à-faux, une masse d'essai de 61 mg, une sensibilité de 16 mV/g, et une fréquence naturelle de 74.85 Hz. La seconde partie de cette thèse décrit le pavé tactile à base de papier. Ce dernier est un dispositif à couche unique avec des pixels de capteurs tactiles (essentiellement des îlots de NFs de ZnO) pour capter la force.</description><description>Paper has emerged as a desirable substrate material for the development of flexible electronics and sensors as it offers several advantages such as low cost, biodegradability, disposability, ease of fabrication, good printability, high flexibility and light weight.  Moreover, by integrating functional nanomaterials such as zinc oxide nanowires (ZnO NWs) through a low temperature wet chemical approach on paper substrates, it expands the functionalities and potential of utilizing paper as a sensing element. In this work, a paper-based accelerometer and a paper-based touch pad were developed and characterized. Both prototypes utilized the piezoelectric properties of ZnO NWs on paper: piezoelectric charges are generated as the NWs on the paper substrate experience mechanical deformation. As the electrical output of the ZnO NWs were typically on the order of pico- amperes, charge amplifier circuits were designed for both prototypes. For the first part of the thesis, the paper-based accelerometer employs a cantilever-based configuration, and with a proof mass of 61 mg, a sensitivity of 16 mV/g and a natural frequency of 74.85 Hz were achieved. For the second part of the thesis, the paper-based touch pad is a monolithic single-layer device with pixels of touch sensors (essentially islands of ZnO NWs) on it for touch sensing. </description><creator>Wang, Yu-Hsuan</creator><contributor>Xinyu Liu (Internal/Supervisor)</contributor><date>2016</date><subject>Mechanical Engineering</subject><title>Paper-Based physical transducers integrating zinc oxide nanowires</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/q237hv18b.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/2j62s738d</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Mechanical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:f7623g09q</identifier><datestamp>2020-03-21T13:51:26Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Il y a eu une tendance au début de l'IVe siècle avant notre ère qui a vu l'émergence du culte du souverain. Quand un roi mortel a été assimilé avec le divin au cours de sa vie. Malheureusement, seulement des fragmentaires incertaines survivent pour ces rois. Pourtant, nous commençons vraiment à voir une réémergence de cette idée par Alexandre le Grand. Le chemin de la divinité a commencé à prendre forme à travers lui, mais n'a pris forme que sous les successeurs d'Alexandre et l'établissement de leurs cultes.</description><description>There was a trend in the early fourth century BCE that saw the emergence of the ruler cult. Where a mortal king was assimilated with the divine during their lifetime. Unfortunately, only fragmentary, uncertain, evidence survives for these kings. Yet, we truly begin to see a re-emergence of this idea through Alexander the Great. The journey to divinity started to take form through him, but only took shape under the successors of Alexander and the establishment of their cults.</description><creator>Farrington, John</creator><contributor>Michael Fronda (Internal/Supervisor)</contributor><date>2017</date><subject>History and Classical Studies</subject><title>Then let him be a God: the origin of the Hellenistic ruler cult</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/8g84mp987.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/f7623g09q</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of History and Classical Studies</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:9k41zg941</identifier><datestamp>2020-03-21T13:51:27Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>L' étude présentée dans cette thèse explore les effets du stress de privation de nourriture chez le jeune C. elegans sur son comportement de recherche de nourriture à l'âge adulte. Lorsqu'il fait face à des conditions environnement difficiles telles que la rareté de la nourriture lors de premiers stades larvaires, C. elegans entre dans une stase de développement nommée stade dauer, dont ils peuvent en sortir lorsque la nourriture redevient disponible. Nous avons évalué dans quelle mesure les caractéristiques du comportement de recherche de nourriture observes chez C. elegans adulte sont affectées chez les animaux ayant traversé le stade dauer au cours des phases précoces de leur vie. Nous avons dmontr que les animaux post-dauer prsentent des comportements explorateurs réduits. Nous avons aussi montré cette plasticité comportementale, en réponse au stress précoce, observée chez le nématode sauvage isolé CB4856, est toutefois absente chez la lignée N2 adaptée aux laboratoires.</description><description>The work presented in this thesis explores the effect of early-life starvation stress on adult foraging behavior in the nematode C. elegans. When faced with stringent environmental conditions like scarcity of food in early larval stages, C. elegans go into an arrested developmental stage called dauer from which they can recover when food becomes available again. We examined if the characteristic foraging behavior seen in C. elegans adults are in any way changed in animals experiencing dauer earlier in their lifetime. We established that post-dauer animals show reduced exploratory foraging behavior and that this behavioral plasticity in response to early life stress is seen in a wild isolate, CB4856 but not in the lab-adapted N2 strain.</description><creator>Pradhan, Sreeparna</creator><contributor>Shelton Hendricks (Internal/Supervisor)</contributor><date>2016</date><subject>Neuroscience</subject><title>Effects of early life starvation stress on adult foraging behavior in «Caenorhabditis elegans»</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/dn39x396c.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9k41zg941</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Integrated Program in Neuroscience</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:2j62s739p</identifier><datestamp>2020-03-21T13:51:28Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Hydroxymethylfurfural (HMF) and levulinic acid (LA) are two promising biorefinery chemicals that can be produced from carbohydrate or lignocellulosic feedstock. Despite their potential importance and extensive research on them conducted at the laboratory level, few commercial production plants have been reported. This work aims to accelerate the deployment of HMF and LA in a sustainable manner by optimising feedstock consumption and the use of catalysts, solvents and heating media.The significant research interest in HMF and LA has resulted in a wide range of feedstocks, catalysts, solvents and heating mechanisms being investigated. These prior studies were examined in a comprehensive literature review (Chapter 2). It was observed that the use of polysaccharides like starch and cellulose is preferable to glucose and fructose from both economic and environmental standpoints. However, the efficient use of these feedstocks requires an understanding of how the composition and the structure of the polysaccharides affect product yields. The link between starch composition and LA yields was studied in Chapter 3. Corn starch was fractionated into its constituents, amylose and amylopectin. These fractions, as well as the unfractionated starch, were converted to LA using aqueous HCl as the catalyst. It was demonstrated that amylopectin was converted more readily to LA due to its greater water solubility, and due to the formation of a resistant complex inhibiting amylose hydrolysis. This implied that starches containing a higher proportion of amylopectin would be more suitable for LA synthesis. This was confirmed by comparing LA yields from starches with different amylose to amylopectin ratios (Chapter 4). A multi-reaction model was created using MATLAB to calculate the kinetic parameters of hydrolysis. The results obtained corroborated the earlier findings, with conversion of waxy (high amylopectin) corn starch to LA proving more facile than normal or high amylose corn starch. Alongside, the effect of the heating media was also studied. Microwave heating was found to give yields similar to those obtained using an oil bath, but at a lower equivalent temperature and a shorter reaction time.Previous studies have shown that the conversion of polyglucan feedstocks to HMF can be achieved at a high conversion and selectivity in the presence of metal salt Lewis acids and ionic liquids. The combination of boric acid and choline chloride was investigated as a cheaper, non-toxic and a more environment friendly alternative to such systems (Chapter 5). The effect of using a biphasic medium of either water-methyl isobutyl ketone (MIBK) or water-tetrahydrofuran (THF) as the solvent was also evaluated. A Central Composite Design-based Response Surface Methodology was used to optimise the reaction parameters. A maximum yield of 35.9 mol% was obtained for water-MIBK, while for the water-THF system, the highest yield was 60.3 mol%. The advantage of using water-MIBK was the minimal decrease in HMF yields observed after ten rounds of catalyst reuse, indicating greater system recyclability. Alongside starch, cellulose is an ideal feedstock for biorefineries owing to its wide availability. Ferric sulphate has been used to depolymerise cellulose in prior works, and being an inexpensive Lewis acid, was identified as a potential catalyst for converting hardwood and softwood pulp to HMF and furfural (Chapter 6). It was found that the use of ferric sulphate alone gave a yield of 31.6 mol% from hardwood pulp, and that the yield was not increased by the addition of the Brønsted acid HCl or the ionic liquid [BMIM]Cl. For softwood pulp, a combination of ferric sulphate and dilute HCl gave the maximum HMF yield (37.9 mol%). In conclusion, this work has provided an insight into the roles played by four important factors: feedstocks, catalysts, solvents and heating media - on the synthesis of HMF and LA, and provided a foundation for further research in this field.</description><description>L'hydroxyméthylfurfural (HMF) et l'acide lévulinique (LA) sont deux produits chimiques prometteurs pouvant être synthétisés à partir de biomasse. Par contre, seulement quelques usines produisent ces produits chimiques à l'échelle commerciale. Cette thèse à visé à accélérer le développement du HMF et LA de façon durable en optimisant la consommation de matières premières ainsi que l'utilisation de catalyseurs, solvants ainsi que de la source de chaleur utilisée lors de leur synthèse.Le chapitre 2 est une revue de la littérature portant sur la synthèse du HMF et LA. Il a été conclu que l'utilisation de polysaccharides est préférable au glucose et au fructose, des points de vue tant économiques qu'environnementaux. Toutefois, l'utilisation de ces matières exige une compréhension de la façon dont la composition et la structure des polysaccharides affectent les rendements, ce qui fut étudié au chapitre 3. L'amidon de maïs a été fractionné en ses constituants, l'amylose et l'amylopectine. Ces fractions, ainsi que l'amidon non fractionné, ont été converti à l'aide d'HCl aqueux. Il a été démontré que l'amylopectine est transformée plus facilement en raison de sa plus grande solubilité dans l'eau par comparaison à l'amylose. De plus, la formation d'un complexe résistant inhibe l'hydrolyse de l'amylose. Cela implique que les amidons contenant une proportion plus élevée en amylopectine seraient plus aptes à la synthèse de LA.Ceci fut confirmé en comparant les rendements en LA en utilisant de l'amidon de maïs ayant différentes proportions en amylose et amylopectine (chapitre 4). Un modèle de réactions multiples a été créé à l'aide de MATLAB afin de calculer les paramètres cinétiques de l'hydrolyse. Les résultats obtenus ont corroborés les conclusions antérieures puisque la conversion de l'amidon de maïs cireux en LA s'est avérée plus facile qu'avec la fécule de maïs ayant une concentration en amylose normale ou élevée. L'effet des méthodes de chauffage a également été étudié. Les rendements obtenus par chauffage micro-ondes furent similaires à ceux obtenus à l'aide d'un bain d'huile, mais à une température équivalente inférieure et un temps de réaction plus court.Des études antérieures ont montré que la conversion de polyglucanes en HMF est possible à un taux de conversion élevé en présence de sels métalliques, d'acides de Lewis, et de liquides ioniques. La combinaison d'acide borique et de chlorure de choline a été étudiée comme une alternative moins coûteuse et non toxique pour l'environnement (chapitre 5). L'effet de l'utilisation d'un milieu biphasique (eau-MIBK ou eau-THF) comme solvant a également été évalué. Un plan composite centré a été utilisé comme plan de surface de réponse afin d'optimiser les paramètres de la réaction. Le rendement maximal obtenu fut de 35,9 % (mole) avec le système eau-MIBK, tandis que pour le système eau-THF, le rendement le plus élevé fut de 60,3 % (mole). Le système eau-MIBK a l'avantage de pouvoir être recyclé plusieurs fois. L'utilisation de la biomasse lignocellulosique pour la synthèse d'HMF fut l'objet du chapitre 6. Le sulfate ferrique a été identifié comme un catalyseur peu coûteux pour la conversion de pâte à papier provenant de feuillus et de résineux en HMF et en furfural. L'utilisation de sulfate ferrique seul a donné un rendement de 31,6 % (mole) pour le bois dur. Il a été constaté que le rendement n'a pas augmenté par l'ajout d'acide chlorhydrique ou de liquide ionique [BMIM]Cl. Un rendement maximal de 37,9 % (mole) a été obtenu pour la pâte de résineux lorsqu'un mélange de sulfate ferrique et d'acide chlorhydrique dilué fut utilisé. En conclusion, cette thèse a donné un aperçu du rôle joué par les matières premières, les catalyseurs, les solvants ainsi que le mode de chauffage utilisé lors de la synthèse d'HMF et de LA.  La grande diversité d'options pour chacun de ces facteurs présente à la fois des défis et des opportunités liés à la commercialisation de ces produits chimiques.</description><creator>Mukherjee, Agneev</creator><contributor>Marie-Josee Dumont (Supervisor)</contributor><date>2017</date><subject>Bioresource Engineering</subject><title>Sustainable synthesis of 5-hydroxymethylfurfural and levulinic acid</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/sb397b77x.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/2j62s739p</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Bioresource Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:dj52w711r</identifier><datestamp>2020-03-21T13:51:29Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les inhibiteurs d'intégrase (INIs) sont la classe de médicaments antirétroviraux approuvée le plus récemment. Ils agissent en inhibant l'intégrase (IN), l'enzyme essentielle du VIH qui sert à faciliter l'insertion du génome viral dans la chromatine des cellules cibles. Trois médicaments de cette classe sont disponibles pour le traitement des personnes séropositives: raltégravir (RAL), elvitégravir (EVG) et dolutégravir (DTG). Les deux premiers INIs sont relativement efficaces en clinique mais ils ont des barrières génétiques relativement faibles contre la résistance. Aussi, ils partagent un haut degré de résistance croisée entre eux, ce qui a nécessité le développement d'INIs de deuxième génération qui pourraient conserver l'activité contre les virus résistants. DTG a été approuvé en 2013, est capable de supprimer la grande majorité des virus résistants RAL/EVG, et sélectionne la nouvelle mutation de résistance R263K à la fois en culture de tissus et chez les patients lors des rares cas d'échec virologique avec cet inhibiteur.Cette thèse caractérise en détail la mutation de résistance R263K contre le DTG. J'ai établi le rôle de la régulation de l'acétylation cellulaire dans la susceptibilité du VIH à cet INI, ainsi que l'indépendance du R263K et des voies classiques de résistance aux INIs de première génération. Comme l'utilisation de DTG pour traiter à la fois des patients naïfs et expérimentés augmente chaque jour dans le monde entier, l'importance de comprendre comment et pourquoi la résistance se développe contre ce médicament ne peut pas être sous-estimée. Ce n'est qu'en améliorant nos connaissances sur les mécanismes de la résistance du VIH que les cliniciens pourront concevoir les meilleurs traitements pour leurs patients et que les chimistes seront capables de créer des médicaments antirétroviraux plus puissants. Il s'agit de deux étapes essentielles pour atteindre l'objectif de l'ONUSIDA de 90-90-90 et de contrôler la pandémie du VIH.</description><description>Integrase strand transfer inhibitors (INSTIs), the newest class of antiretroviral drugs to be approved for the treatment of HIV-infected individuals, act by inhibiting the essential HIV protein integrase (IN) from inserting the viral DNA genome into the host cell's chromatin. Three drugs of this class are currently approved for use in HIV-positive individuals: raltegravir (RAL), elvitegravir (EVG), and dolutegravir (DTG). The former two compounds have been reasonably successful in clinical settings but have relatively low genetic barriers to resistance. Furthermore, they share a high degree of cross resistance, which necessitated the development of so-called second-generation drugs of this class that could retain activity against these resistant variants. DTG was approved in 2013, is able to suppress the vast majority of RAL/EVG resistant viruses, and selects for the novel R263K resistance substitution both in tissue culture selection studies and in patients during  rare cases of virological failure with this inhibitor. This thesis characterizes the clinically significant R263K resistance pathway for DTG. It establishes a role of the regulation of cellular acetylation in the susceptibility of HIV to this INSTI, and shows the distinctness of R263K versus classical pathways of resistance towards first-generation INSTIs. As the use of DTG to treat both naïve and experienced patients increases worldwide, the importance of understanding how and why resistance develops in response to this compound cannot be understated. Only through enhancing our knowledge of mechanisms of HIV-1 drug resistance will clinicians be able to design better treatments for their patients and chemists be able to engineer more potent antiretroviral drugs. This will be essential in reaching the UNAIDS goal of 90-90-90 and bringing the HIV pandemic under control.</description><creator>Anstett, Kaitlin</creator><contributor>Mark Wainberg (Supervisor1)</contributor><contributor>Chen Liang (Supervisor2)</contributor><date>2017</date><subject>Microbiology &amp; Immunology</subject><title>Cellular and virological mechanisms of HIV-1 dolutegravir-specific resistance</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/bc386m94j.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/dj52w711r</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Microbiology and Immunology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:s4655k03k</identifier><datestamp>2020-03-21T13:51:30Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les mutations du canal de potassium génétique humain (HERG) de Ether-à-go-go prolongent la repolarisation du ventricule cardiaque, qui se présente cliniquement comme un syndrome de QT prolongé. Les arythmies ventriculaires résultent du repliement de hERG au réticulum endoplasmique (ER) et entravent le trafic sur la surface de la cellule. Un écran indépendant à haut débit a identifié 153 composés qui régule les niveaux de HERG à la surface de la cellule dans des mutants hERG (WT) et de type sauvage sélectionnés. Par conséquent, ces médicaments peuvent fournir des outils thérapeutiques pour traiter le syndrome du QT long. D'autres expériences de dépistage, pour exclure le blocage du pore du canal hERG, ont réduit la liste à deux composés candidats qui provoquent une régulation significative de la hERG: 5,6-dichloro-3-éthyl-lH-benzoimidazol-2-one (DCEBIO) , Un activateur de canal de potassium, et anagrelide, usind dans le traitement de la thrombocytose. Pour déterminer si ces médicaments candidats peuvent sauver des propriétés d'expression et de gating de type sauvage de divers mutants hERG, une analyse fonctionnelle a été effectuée en utilisant la technique de la pince de patch à cellules entières. Cette approche électrophysiologique fournit des informations concernant à la fois la magnitude actuelle et la cinétique de canalisation. Dans la présente étude, il est démontré que le traitement pendant la nuit avec DCEBIO ou anagrelide augmente de manière significative le HERG fonctionnel de la surface cellulaire dans les populations de cellules HeLa exprimant WT et divers mutants hERG. Cependant, aucun médicament n'était capable de sauver des gingissements défectueux de mutants hERG. Ces résultats démontrent qu'il est possible que les médicaments augmentent l'expression fonctionnelle des mutants hERG en augmentant l'expression de la surface cellulaire sans affecter le déclenchement hERG.</description><description>Mutations of the human Ether-à-go-go-Related Gene (hERG) potassium channel prolong cardiac ventricular repolarization, which presents clinically as Long QT Syndrome.  Ventricular arrhythmias result from the misfolding of hERG at the endoplasmic reticulum (ER), and impaired trafficking to the cell surface. An independent high throughput screen identified 153 compounds that up-regulate hERG levels at the cell surface in both wild-type (WT) and selected hERG mutants. Consequently, these drugs might provide therapeutic tools for treating Long QT Syndrome. Further screening experiments, to rule out block of the hERG channel pore, reduced the list to two candidate compounds that cause significant up-regulation of hERG: 5,6-dichloro-3-ethyl-1H-benzoimidazol-2-one (DCEBIO), a potassium channel activatior, and anagrelide, usind in the treatment of thrombocytosis. To determine whether these candidate drugs can rescue wild-type hERG expression and gating properties of various hERG mutants a functional analysis was performed using the whole-cell patch clamp technique. This electrophysiological approach provides information concerning both hERG current magnitude and channel gating kinetics. In the present study, it is shown that overnight treatment with either DCEBIO or anagrelide significantly increase functional cell-surface hERG in HeLa cell populations expressing WT and various hERG mutants. However, neither drug was capable of rescuing defective gating of hERG mutants. These results demonstrate that it is possible for drugs to increase functional expression of hERG mutants by increasing cell surface expression without affecting hERG gating.</description><creator>Solomon, Joshua</creator><contributor>Alvin Shrier (Internal/Supervisor)</contributor><date>2017</date><subject>Physiology</subject><title>Electrophysiological assessment of two potential hERG correctors</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/rx913s352.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/s4655k03k</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Physiology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:37720g44j</identifier><datestamp>2020-03-21T13:51:34Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>L'engagement problématique (PG) envers les jeux vidéo peut être défini comme une forme d'engagement qui interfère avec les responsabilités personnelles et sociales.  Cet engagement problématique a été associé à plusieurs indicateurs de fonctionnement mésadapté incluant un niveau réduit de bien-être subjectif, des symptômes de dépression, et des problèmes de succès académique parmi d'autres, ce qui suggère que ceci mérite l'attention de professionnels de la santé.  Un besoin urgent dans le domaine est l'identification de facteurs théoriques qui expliquent l'émergence d'un engagement problématique envers les jeux vidéo.  L'application antérieure de théories et de modèles pertinents décrit bien PG envers les jeux vidéo mais n'explique pas sa présence au-delà d'un déficit dans la capacité de gérer l'utilisation de jeux vidéo.  La recherche a démontré l'utilité de la théorie de l'autodétermination (SDT) pour identifier les facteurs qui prédisent plus de plaisir de jeu et de temps à jouer, mais n'a pas encore appliqué cette théorie pour expliquer PG envers les jeux vidéo. De plus, malgré que la satisfaction de trois besoins psychologiques de base (la compétence, l'autonomie, et le rapprochement) favorise et maintient le bien-être, de récents progrès en SDT suggèrent que l'expérience d'obstacles à la satisfaction de besoins prédit une réduction de bien-être.  L'expérience continue de tels obstacles, aussi connu sous le nom de frustration de besoins, peut résulter en une dépendance trop importante sur une activité qui satisfait les besoins afin de satisfaire des besoins qui ne le sont pas autrement.  Par conséquent, le programme de recherche actuel applique la SDT à l'étude de PG envers les jeux vidéo au cour de trois études séparées, en mettant l'emphase sur le rôle de la frustration des besoins.  La première étude a fourni de l'évidence préliminaire d'une association positive entre la frustration quotidienne de chaque besoin de base et PG envers les jeux vidéo.  La modélisation par équation structurelle a également révélé que la frustration de la compétence et du rapprochement a un effet indirect sur PG envers les jeux vidéo à travers les affects négatifs, tandis que la frustration de l'autonomie a un effet direct.  La deuxième étude a fourni un appui supplémentaire pour l'association positive entre la frustration quotidienne de chaque besoin de base et PG envers les jeux vidéo ainsi que pour l'association entre les motivations et PG envers les jeux vidéo.  Finalement, la troisième étude a utilisé une conceptualisation longitudinale de plusieurs cycles au cour d'un semestre académique afin d'évaluer le rôle de la frustration de besoins dans la stabilité et le profil de PGenvers les jeux vidéo du début à la fin du semestre.  Deux cent quatre-vingt-dix étudiants universitaires ont participé dans cette étude.  Les résultats d'une analyse décalée croisée ont indiqué que PG envers les jeux vidéo était relativement stable du début à la fin du semestre académique.  Par contre, une médiation partielle significative de la frustration des besoins en mi-semestre suggère que la stabilité de PG envers les jeux vidéo est maintenu en partie par une expérience élevée de frustration des besoins.  Les résultats d'une analyse multi niveaux ont révélé que la frustration quotidienne de besoins et le temps passé à jouer n'étaient pas significativement associé à part pour les individus qui reportaient un engagement problématique plus élevé envers les jeux vidéo.  Les résultats de ce programme de recherche indiquent que la frustration des besoins joue un rôle important dans l'explication de PG envers les jeux vidéo.  </description><description>Problematic gaming (PG) is defined as a continued pattern of video game engagement that interferes with personal and social responsibilities.  It has been linked with numerous indicators of maladaptive functioning including lower subjective well-being, depressive symptoms, and poorer academic achievement as well as others suggesting it merits the attention of mental health professionals.  An urgent need within the field is to identify theoretically-derived factors that explain how PG emerges.  Previous application of theories and relevant models do well in further describing PG, but fail to explain its presence beyond a deficit in the ability to manage gaming engagement.  Research has shown the utility of Self-Determination Theory (SDT) in identifying factors predicting greater game enjoyment and time spent gaming, but has not yet been applied to PG.  Moreover, though the satisfaction of three basic psychological needs (competence, autonomy, and relatedness) promote and maintain well-being, recent advances in SDT suggest the continued experience of active impediments to needs satisfaction predicts greater ill-being.  Referred to as needs frustration, it has been additionally proposed that continued experience of such impediments may result in an overreliance toward a needs-satisfying activity to satisfy needs that are not met elsewhere.  Therefore, the present program of research applies SDT to the study of PG across three separate studies with a particular interest in the role of needs frustration.  Study 1 provided initial evidence of a positive association between the daily frustration of each basic need and PG.  Structural equation modeling further revealed indirect effects for both competence and relatedness frustration through general negative affect with a direct association between autonomy frustration and PG.  Study 2 provided further support of the positive association between the daily frustration of each basic need and PG as well as the association between gaming motivations and PG.  Finally, Study 3 employed a multi-wave design over the course of one academic term to assess the role of needs frustration in potentially explaining the stability of PG from the beginning to the end of the term as well as the pattern of video game engagement of problematic video game users.  Two hundred ninety university students were included in the study.  Results from a cross-lagged analysis indicated that PG was relatively stable from the beginning to the end of the academic term, however, a significant partial mediation of reports of needs frustration at a mid-point in the academic term suggests the stability of PG is maintained in part by an increased experience of needs frustration.  Results from a multilevel analysis revealed daily needs frustration and time spent gaming are not significantly associated except for individuals reporting greater PG.  Taken together, the results from the present program of research indicate that needs frustration plays a meaningful role in explaining PG.  </description><creator>Mills, Devin</creator><contributor>Nancy Lee Heath (Supervisor)</contributor><date>2017</date><subject>Educational and Counselling Psychology</subject><title>Problematic gaming and the role of needs frustration: An application of the self-determination theory</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/pz50gz73v.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/37720g44j</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Educational and Counselling Psychology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:ms35tb85q</identifier><datestamp>2020-03-21T13:51:35Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>En tant que paradigme émergent au cours des dernières années, Networking Défini par Logiciel (SDN) promet une programmation flexible et une gestion simplifiée des réseaux, et elle a gagné un élan considérable dans les milieux universitaires et l'industrie. Bien que le découplage du plan de contrôle et du plan de données contribue aux avantages importants de SDN, il crée également des défis dans le contrôle du réseau de manière cohérente et efficace. Tout d'abord, le plan de contrôle manipule fréquemment les tables de flux dans le plan de données, mais les délais d'application des mises à jour dans les commutateurs varient, de sorte que l'ordre de mise à jour inapproprié entraînerait des comportements de traitement incorrects. Deuxièmement, avec divers programmes de contrôle de différents domaines exécutés simultanément pour contrôler le réseau, il est inévitable que les programmes de contrôle puissent prendre des décisions contradictoires, ce qui pourrait provoquer un chaos dans la configuration du réseau sans rapprochement. Troisièmement, comme SDN est toujours dans un stade relativement précoce, la mise à niveau d'un réseau traditionnel vers un déploiement complet de SDN est habituellement un processus incrémental, ce qui nécessite le contrôle SDN centralisé et les protocoles de réseau traditionnels distribués travaillant dans le même réseau harmonieusement avec une coordination considérable. Un contrôle SDN correct et constant est essentiel pour assurer des comportements de réseau efficaces et efficients. Cependant, la maintenance de la cohérence nécessite toujours des frais généraux supplémentaires en introduisant une vérification supplémentaire, ce qui retarde les réactions aux événements du réseau. En outre, les exigences de cohérence limitent la flexibilité de SDN en interdisant certaines décisions de contrôle avec des performances élevées potentielles mais violant les propriétés de cohérence. Dans cette dissertation, nous proposons des approches systématiques pour améliorer la cohérence du contrôle et réduire les frais généraux et les limites de la maintenance de la cohérence. 1) Pour maintenir une vue cohérente entre les tables de flux lors de la mise à jour, nous organisons une commande de mise à jour rapide et efficace pour les mises à jour des chemins de routage. Nous concevons une approche de partage et de conquête pour surmonter la longue latence de commande dans les méthodes antérieures et améliorer le parallélisme de mise à jour. 2) Nous proposons une approche de coordination de contrôle avec des langages déclaratifs pour composer des programmes de contrôle et concilier facilement les conflits. Il garantit l'efficacité des décisions de contrôle générées et maximise l'utilité de contrôle en satisfaisant les objectifs de contrôle maximum. 3) Pour gérer l'hétérogénéité des périphériques réseau dans le SDN hybride, nous concevons une série de mécanismes pour adapter le contrôle SDN centralisé à la technologie de réseau traditionnelle restante, allant de la planification de placement des commutateurs SDN à l'ingénierie du trafic hybride. Ces mécanismes ne collaborent pas seulement avec le protocole SDN avec les protocoles réseau traditionnels, mais aussi exercer les avantages de la SDN.Ensemble, ces systèmes proposent une plate-forme de contrôle SDN cohérente. Cette plate-forme de contrôle possède les propriétés d'une mise à jour rapide du plan de données, d'une résolution de conflits élégante et d'un contrôle hybride efficace afin de garantir une application efficace des politiques de contrôle.</description><description>As an emerging paradigm in recent years, Software-Defined Networking (SDN) promises flexible programmability and simplified management of networks, and it has gained considerable momentum in both academia and industry. Although the decoupling of the control plane and data plane contributes to the significant benefits of SDN, it also creates challenges in controlling the network consistently and efficiently. First, the control plane manipulates flow tables in the data plane frequently, but the timescales of applying updates in switches vary, such that inappropriate update order would lead to incorrect processing behaviors. Second, with various control programs from different domains running simultaneously to control the network, it is inevitable that control programs may make contradictory decisions, which could cause chaos in configuring the network without reconciliation. Third, as SDN is still in a relatively early stage, the upgrade from a traditional network to a full SDN deployment is usually an incremental process, which necessitates the centralized SDN control and the distributed traditional network protocols working in the same network harmoniously with considerable coordination. A correct and consistent SDN control is essential to ensure the effective and efficient network behaviors. However, the consistency maintenance always requires extra overhead by introducing further checking, which delays the reactions to network events. Moreover, the consistency requirements restrict the flexibility of SDN by prohibiting some control decisions with potential high performance but violating consistency properties. In this dissertation, we propose systematic approaches to enhance the control consistency and reduce the overhead and limitations of consistency maintenance. 1) To maintain a consistent view among flow tables during data plane updating, we schedule a fast and efficient update order for forwarding path updates while preserving throughputs of flows. We design a divide-and-conquer approach to overcome the long ordering latency in prior methods and improve the update parallelism. 2) We propose a control coordination approach with declarative languages to compose control programs and reconcile conflicts conveniently. It guarantees the effectiveness of generated control decisions and maximizes the control utility by satisfying the maximum control objectives. 3) To handle the heterogeneity of network devices in hybrid SDN, we design a series of mechanisms to adapt the centralized SDN control to the remaining traditional networking technology, ranging from the placement planning of SDN switches to hybrid traffic engineering. These mechanisms not only coordinate the SDN control with traditional network protocols consistently, but also exert the benefits of SDN.Together these systems propose a consistent SDN control platform. This control platform has the properties of fast data plane updating, elegant conflicts resolution and effective hybrid control to promise correct enforcement of control policies.</description><creator>Wang, Wen</creator><contributor>Xiao-Wen Chang (Supervisor2)</contributor><contributor>Wenbo He (Supervisor1)</contributor><date>2017</date><subject>Computer Science</subject><title>Enhancing control consistency of software-defined networking</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/rv042w48x.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/ms35tb85q</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:4t64gq74h</identifier><datestamp>2020-03-21T13:51:36Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Salivary hypofunction is a major side effect of radiotherapy for patients with head and neck cancer. Our group used a cell extract from whole bone marrow (BM) cells, named BM Soup, which contains numerous cytokines, growth factors, and other paracrine factors, to rescue the function of irradiation (IR)-injured salivary glands (SGs). The results demonstrated that BM Soup restored the salivary flow rate, protected salivary cells from IR damage, and upregulated the expression of genes related to tissue repair/ regeneration. However, the components of BM Soup which are responsible for the therapeutic effects remain unknown. The first aim of this thesis was to demonstrate that proteins are the active ingredients. We devised a method using proteinase K followed by heating to deactivate proteins and for safe injections into mice. BM Soup and "deactivated BM Soup" were injected into mice that had their salivary glands injured with 15Gy IR. Results at week 8 post-IR showed the 'deactivated BM Soup' was no better than injections of saline, while injections of native BM Soup restored saliva flow, protected salivary cells and blood vessels from IR-damage. Protein arrays detected several angiogenesis-related factors (CD26, FGF, HGF, MMP-8, MMP-9, OPN, PF4, and SDF-1) and cytokines (IL-1ra, IL-16) in BM Soup. In conclusion, the native proteins are the bioactive ingredients in BM Soup for functional salivary restoration following IR.For any given therapy, the frequency and timing of treatment are the important parameters in the restoration of salivary glands. The second aim of this thesis was to optimize the frequency and timing of BM Soup injection in mice with IR-damaged SGs. The results showed that BM Soup injections initiated between 1-3 weeks mitigated the IR-induced injury to SGs, while delayed treatment had no saliva secretion improvement. In addition, although the therapeutic effect of BM Soup lessened after 8 weeks, it can be sustained by increasing the frequency of weekly injections.BM cell harvesting remains an invasive procedure and can lead to donor discomfort and in severe cases, to life-threatening complications, such as cardiopulmonary problems, bacterial infections, and cerebrovascular accidents. The third aim of this thesis was to test if other types of tissues, which were either clinically easier to harvest (such as the adipose tissue) or regarded as 'dispensable organ' (such as the spleen), could be used as alternate sources of "Cell Soup" for the repair of IR-injured salivary glands. The results demonstrated that both Adipose-derived stromal cell Soup and Spleen Soup showed comparable therapeutic effects with BM Soup at eight weeks post-IR, but BM Soup and Spleen Soup maintained the therapeutic effects for a longer follow-up time (16 weeks).In summary, BM Soup can mitigate ionizing radiation injury to salivary glands. The native protein components are the bioactive ingredients for this therapeutic effect. Starting injections of BM Soup within three weeks post-IR improves the restoration of salivary glands, and the effect can be sustained by increasing the frequency of weekly injections. In addition, alternate "Cell Soups", such as ADSC Soup and Spleen Soup, have comparable therapeutic effects with BM Soup. This molecular therapy approach has great potential for future clinical application.</description><description>L'hypofonction salivaire est un effet secondaire majeur de la radiothérapie pour les patients atteints des cancers de la tête et du cou. Pour rétablir la fonction des glandes salivaires lésées par irradiation (IR) notre groupe utilise un extrait cellulaire des cellules de la moelle osseuse (BM, pour Bone Marrow), nommée Soupe BM qui contient de nombreuses cytokines, facteurs de croissance et autres facteurs paracrine. Les résultats ont démontré que la soupe BM rétablit le débit salivaire, protège les cellules salivaires des lésions de l'IR et augmente l'expression des gènes liés à la réparation et la régénération des tissus. Cependant, les composantes de la soupe BM qui sont responsables des effets thérapeutiques restent inconnues. Le premier objectif de cette thèse est de démontrer que les protéines sont les ingrédients actifs dans ce processus thérapeutique. Nous avons mis au point une méthode utilisant la protéinase K suivie d'un chauffage pour désactiver les protéines, ainsi que pour assurer la sécurité des injections dans la souris. La soupe BM et la « soupe BM désactivée » sont injectées dans les souris qui ont leurs glandes salivaires lésées avec 15Gy d'IR. Huit semaines après l'IR, les résultats montrent que la « soupe BM désactivée » n'est pas meilleure que les injections de saline (contrôle négatif), alors que les injections de soupe BM rétablissent le flux salivaire, protègent les cellules salivaires et les vaisseaux sanguins contre les lésions IR. Avec un immunobavardage de style « array » commercial, les anticorps sur la membrane ont détecté plusieurs facteurs liés à l'angiogenèse (CD26, FGF, HGF, MMP-8, MMP-9, OPN, PF4 et SDF-1) et des cytokines (IL-1ra, IL-16) dans la soupe BM. En conclusion d'après nos résultats les protéines sont les ingrédients bioactifs dans la soupe BM pour la restauration salivaire après IR.Pour toute thérapie, l'initiation et la fréquence du traitement sont des paramètres importants dans la restauration des glandes salivaires. Le deuxième objectif de cette thèse est d'optimiser le début et la fréquence d'injection de soupe BM chez la souris avec des glandes salivaires endommagées par IR. Les résultats montrent que les injections de soupe BM initiées entre 1 et 3 semaines atténuent la lésion induite par IR aux glandes salivaires, alors que retarder le traitement mène à une absence d'amélioration de la sécrétion salivaire. De plus, bien que l'effet thérapeutique de la soupe BM diminue après 8 semaines, il peut être maintenu en augmentant la fréquence des injections hebdomadaires.La collecte de cellules BM reste une procédure invasive et peut mener à l'inconfort du donneur et, dans des cas graves, à des complications potentiellement mortelles, telles que des problèmes cardiopulmonaires, des infections bactériennes et des accidents vasculaires cérébraux. Le troisième objectif de cette thèse est de tester si d'autres types de tissus, cliniquement plus faciles d'accès (tels que le tissu adipeux) ou considérés comme des « organes dispensables » (tels que la rate) peuvent être utilisés comme des sources alternatives à la moelle osseuse pour la réparation des glandes salivaires blessées. À huit semaines après l'IR, les résultats démontrent que les cellules stromales dérivées du tissu adipeux (ADSC) et les cellules de la rate possèdent des effets thérapeutiques comparables avec la soupe BM. Cependant, seulement la soupe BM et la soupe de la rate maintiennent leurs effets thérapeutiques pour une durée de suivi plus long (16 semaines) que la soupe ADSC.En conclusion, suivant un traitement d'IR, la soupe BM peut atténuer les dommages des glandes salivaires. Les composants protéiques naturels sont les ingrédients bioactifs qui produisent l'effet thérapeutique. Le début des injections de soupe BM dans les trois semaines suivant IR améliore la restauration des glandes salivaires, et l'effet peut être maintenu en augmentant la fréquence des injections hebdomadaires. </description><creator>Fang, Dongdong</creator><contributor>Simon Tran (Supervisor)</contributor><date>2017</date><subject>Dentistry</subject><title>Cell extracts functionally restore irradiation-injured salivary glands</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/2v23vw54d.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/4t64gq74h</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Faculty of Dentistry</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:8k71nk712</identifier><datestamp>2020-03-21T13:51:37Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Duration between discovery of a mineral deposit and delivery of the material (e.g. metal or concentrate) yielded from this deposit to the market can take several years. After the discovery, a feasibility study is conduced to see if the mining operation on this deposit is economically viable. This feasibility study is exposed to two types of uncertainties, which add to risks to the mining project. These are (1) technical risks arising from sparse data (e.g. grade, recovery and geotechnical characterization)  and (2) financial risks arising from unknown future events (e.g. commodity price, discount rate and exchange rate). Among the others, commodity price is a significant concern for the executives of mining enterprise. Given that mining products and their derivatives are traded in commodity, stock and future markets, market dynamics are very complex. Furthermore, it is very sensitive to politics of global world and very open to speculation and manipulation as well as demand and supply. In the past, the mining industry witnessed that many mining operations were suspended or ceased due to unresponsiveness to price fluctuations. Project valuation based on log-term price is a quite naive approach at present day.  This can jeopardize the financial resources of the investor company. Therefore, the risks associated with commodity price are assessed, quantified, mitigated, diversified or managed. The analysis of commodity prices starts with the study of historical transactions in financial markets. To facilitate the analysis, it is often necessary to convert commodity prices into returns. Then, the next task is to model the distribution of returns using a statistical distribution. One of the main characteristics of the distribution of commodity price returns is that it tends to have excess kurtosis. This can be explained either by a stochastic volatility or jump component in the diffusion equation describing the evolution of prices. For this reason, it is necessary to consider other models than the Geometric Brownian Motion and Mean-Reverting price models when modeling the dynamics of commodity prices. The objective of this thesis is to construct a robust workflow capable of reproducing the observed price dynamics in the commodity markets. With such calibrated models, it is possible to value mining projects or estimate their exposure to market risk. In the first case, the valuation process is made in a risk-neutral framework using a Real Options approach. In the second case, real world probabilities are used to simulate commodity price paths and assess how a mining project may be exposed to market price fluctuations. Following an introduction and a Literature review, the thesis is divided in four additional parts, corresponding to four different publications. In the first publication, the use of robust estimators for the detection and mitigation of outliers is investigated. The paper starts with an overview of multiple linear regression and assess how the model assumptions can be violated. The second part of the paper deals with detecting outliers the Mahalanobis distance. Then robust regression is used to diminish the effects of outliers in mining engineering data including price. The second paper investigates how the dynamics of iron ore future can be modeled with a dynamic linear model. Traditionally, iron ore futures have been traded using long-term commitment contracts. This paper investigates how relatively recent financial instruments such as futures on iron ore can affect the NPV profile of an iron ore project. The third paper deals with the optimization of the parameters in a commodity model using a genetic algorithm. With correctly calibrated parameters, Monte Carlo simulations of commodity spot and futures are performed and an active trading strategy is implemented in an NPV valuation framework. The last publication deals with the choice of the stochastic process when measuring market risk of a mining project.</description><description>Plusieurs années se produisent habituellement entre la découverte d'un nouveau gisement minéral et la livraison des matériaux produits sur les marchés financiers. Une étude de faisabilité est généralement effectuée pour évaluer la viabilité du projet minier. L'une des tâches les plus importantes est d'évaluer la valeur actuelle nette du projet minier. Cette variable est la somme des flux de trésorerie actualisés que le projet minier générera au cours de sa durée de vie. Les flux de trésorerie sont actualisés à un niveau approprié pour refléter le risque du projet. Quantifier le risque des projets miniers peut être une tâche encombrante. En effet, les projets miniers sont soumis à de multiples sources d'incertitudes qui doivent être estimées à l'aide de modèles stochastiques. L'une de ces inconnues est le prix des produits de base, qui doit être estimé sur toute la durée du projet minier. L'objectif de cette thèse est de construire un algorithme robuste capable de reproduire la dynamique des prix observée sur les marchés des matières premières. Avec ces modèles calibrés, il est possible d'évaluer les projets miniers ou d'estimer leur exposition au risque de marché. Dans le premier cas, le processus d'évaluation est effectué dans un cadre risque-neutre en utilisant une approche axée sur les options réelles. Dans le second cas, les probabilités réelles sont utilisées pour simuler les scénarios de prix des produits de base et pour évaluer comment un projet minier  être exposé aux fluctuations des prix du marché. La thèse est divisée en quatre parties, correspondant à  quatre publications différentes. Dans la première publication, l'utilisation d'estimateurs robustes pour la détection et l'atténuation des valeurs aberrantes est étudiée. L'article commence par un aperçu de la régression linéaire multiple et évalue comment les hypothèses du modèle peuvent être violées. Le second article étudie comment la dynamique du minerai de fer peut être modélisée avec un modèle linéaire dynamique. Traditionnellement, les contrats à  terme de minerai de fer ont été négociés à  l'aide de contrats d'engagement à  long-terme. Cet article étudie comment des instruments financiers relativement récents comme les contrats à  terme sur le minerai de fer peuvent affecter le profil de la VAN d'un projet de minerai de fer. Le troisième article traite de l'optimisation des paramètres dans un modèle de marchandise utilisant l'algorithme génétique. Avec des paramètres correctement étalonnés, des simulations Monte Carlo de spot et de contrats à  terme sur matières premières sont effectuées et une stratégie de négociation active est mise en oeuvre dans un cadre d'évaluation VAN. La dernière publication traite du choix du processus stochastique lors de la mesure du risque de marché d'un projet minier. Plusieurs processus stochastiques sont étalonnés sur des données historiques et utilisés pour calculer le flux de trésorerie à  risque d'un projet minier. Les modèles sont calibrés en utilisant une stratégie de calibration métaheuristique hybride. L'optimisation des essaims de particules est d'abord utilisée pour trouver une solution proche du minimum global. Ensuite, une routine basée sur le gradient est utilisée pour trouver la solution optimale.</description><creator>Sauvageau, Mathieu</creator><contributor>Mustafa Kumral (Supervisor)</contributor><date>2017</date><subject>Mining and Materials</subject><title>Modeling commodity prices for valuation and hedging of mining projects subjected to volatile markets</title><language>fre</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/qr46r353x.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/8k71nk712</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Mining and Materials</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:h989r561r</identifier><datestamp>2020-03-21T13:51:38Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Cette thèse de doctorat s'attache à explorer la fonctionnalisation des nanoflocons de graphène (NFG) par plasma thermique. Les NFGs sont synthétisés par une méthode existante et développée par Pristavita et al. en 2011. À l'intérieur du même réacteur à plasma thermique servant à la synthèse des nanoflocons, les conditions plasma sont modifiées pour l'injection de précurseurs conduisant à la fonctionnalisation des nanoparticules. La synthèse et fonctionnalisation des NFGs est ainsi réalisée dans un processus batch en deux étapes, la première étape étant la synthèse des NFGs et leur dépôt sur la paroi du réacteur, la deuxième étape étant la fonctionnalisation. En suivant cette méthode, une étape de fonctionnalisation au fer est réalisée sur des NFGs préalablement fonctionnalisés à l'azote, ayant pour but la réalisation de catalyseur à base de métaux non-nobles pour la réaction de réduction de l'oxygène. En premier lieu, une solution de fer aqueuse, ainsi que des poudres de fer sont testées comme précurseurs dans l'étape de fonctionnalisation, conduisant au dépôt de nanoparticules d'oxyde de fer sur les nanoflocons. L'addition des nanoparticules de fer provoque une augmentation de l'activité électrocatalytique des échantillons, lorsque comparé aux échantillons non-fonctionnalisés. Ensuite, une solution de phtalocyanine de fer (II) est utilisée comme précurseur de fer afin de créer une dispersion atomique de fer à la surface des NFGs. De nouveau, une amélioration de l'activité électrocatalytique des échantillons est observée, avec des performances légèrement meilleures qu'avec les nanoparticules d'oxyde de fer. La fonctionnalisation au soufre des NFGs est aussi étudiée afin de créer des catalyseurs non-métalliques pour la réaction de réduction de l'oxygène. Les échantillons possèdent une composition relativement complexe, avec des atomes de soufre intégrés dans la structure graphitique, mais aussi un polymère à base de soufre couvrant partiellement les NFGs, ainsi que des traces de soufre solide orthorhombique. Les catalyseurs à base de graphène et de soufre présentent eux aussi une amélioration de leur activité électrocatalytique, mais dans une moindre mesure comparée aux catalyseurs à base de fer. Finalement, des groupes fonctionnels d'oxygène sont ajoutés à la surface des NFGs. Les nanoflocons sont naturellement hydrophobes, et les groupes fonctionnels d'oxygène transforment les nanoparticules en matériau parfaitement hydrophile. Les NFGs fonctionnalisés à l'oxygène sont capables d'être dispersés en un nanofluide stable sans l'addition de molécules tensio-actives. Les nanofluides à base de graphène fonctionnalisés restent stable sur une période de plusieurs mois, et résistent à une température jusqu'à 90°C dans le cas de nanofluides à base d'eau.</description><description>This Ph.D. thesis explores the functionalization of graphene nanoflakes (GNFs) through a thermal plasma process. The GNFs are grown following an existing method developed by Pristavita et al. in 2011. Using the same thermal plasma reactor used to grow the GNFs, the plasma conditions are modified to introduce specific precursors, leading the GNFs functionalization. The growth and functionalization of the GNFs follow a single batch process in two steps, where the growth and deposition of the nanoparticles on the walls of the reactor represent the first step, and the functionalization the second step. Following this method, iron functionalization is performed on nitrogen functionalized GNFs, for the synthesis of non-noble metal catalyst for the oxygen reduction reaction. First, aqueous iron salts and iron powders are tested as precursors for the functionalization step, leading to the deposition of iron oxide nanoparticles on the surface of the GNFs. The addition of iron oxide nanoparticles enhances the electrocatalytic activity of the samples compared to the non-functionalized samples. Then, iron (II) phthalocyanine solution is tested as the precursor to induce atomically dispersed iron on the surface of the GNFs. Again, an enhancement of the electrocatalytic activity of the functionalized samples is observed, with slightly higher performances than the iron oxide nanoparticles. Sulphur functionalization of the GNFs is also described to make non-metal catalysts for the oxygen reduction reaction. The samples exhibit a complex composition, with sulphur atoms incorporated to the graphitic structure, but also sulphur based polymer partially covering the GNFs, and traces of orthorhombic sulphur. The resulting catalysts see an enhancement of their electrocatalytic activity, but lower compared to the iron based catalysts. Finally, oxygen functionalities are added on the surface of the GNFs. The graphene nanoflakes are naturally hydrophobic, and the oxygen functionalities transform the nanoparticles into fully hydrophilic material. The functionalized GNFs can be dispersed to form a stable nanofluid without the addition of surfactants. The resulting nanofluids are stable over months, and resist to a temperature up to 90°C in the case of water based nanofluids.</description><creator>Legrand, Ulrich</creator><contributor>Dimitrios Berk (Supervisor2)</contributor><contributor>Jean-Luc Meunier (Supervisor1)</contributor><date>2017</date><subject>Chemical Engineering</subject><title>Functionalization of graphene nanoflakes through thermal plasma</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/hh63sz49s.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/h989r561r</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Chemical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:cc08hj06s</identifier><datestamp>2020-03-21T13:51:38Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Cu2ZnSnS4 (CZTS) in its kesterite crystal phase, a semiconductor with earth-abundant, non-toxic composition, is a promising candidate for new generation photovoltaics to power a sustainable energy future. However, the issue of impurities and defects that form during CZTS crystallization has retarded the development of standard CZTS thin film solar cells as those of CIGS and CdTe. In this work, CZTS is investigated in an alternative solar cell type that is known from recent emerging photovoltaic technologies - dye-, quantum dots-, and perovskite- sensitized solar cells – to have high tolerance to imperfection of photo-absorbing crystals. More specifically, the thesis evaluates CZTS as nanoscale light absorber coated on a charge conductor structure (in this case TiO2) and assembled in liquid junction or solid state hole-transport incorporating photoelectrochemical cells. The work involved varying the TiO2 substrate and method of CZTS deposition, in-depth study of annealing, and comprehensive nanoscale and optical property characterization of photoanodes and devices   To fabricate this light absorber-conductor nanostructure, firstly, CZTS was deposited as binary metal sulfide precursor on a pre-sintered TiO2 mesoporous film via an aqueous solution successive-ionic-layer-adsorption-reaction (SILAR) method followed by annealing to induce its crystallization. Composition control was realized by the step-by-step solution deposition-exchange sequence and homogeneity was improved by employing a post-annealing hydrochloric acid etching step. Optical measurements confirmed the light absorbing functionality of the nanostructured TiO2@CZTS film. Subsequently, the focus was directed in understanding the CZTS crystal phase formation during annealing of CZTS-TiO2 film via the employment of in-situ Raman spectroscopy. It was found that annealing at 400 °C is sufficient for stabilizing the kesterite phase, but it is only at 500 °C that complete reactive crystallization takes place leading to elimination of the undesirable copper tin sulfide (CTS) impurity phase. More importantly, this in-situ study revealed the real-time dependence of Raman peak intensity enhancement, shift and broadening for CZTS at 500 °C that is critical in the further development of CZTS sensitized devices.  In parallel to the TiO2 mesoporous electron conductor structure, a hydrothermally synthesized rutile TiO2 nanorod-structured film grown on FTO glass was used to form the absorber-conductor structure with SILAR processed CZTS nanoscrystallites. Of the two TiO2 sub-structures was the latter that yielded photovoltaic response, proving the feasibility of the electron injection/collection of the CZTS/TiO2 photoelectrode and was retained for further investigation. The initial proof-of-concept photoelectrochemical cell featuring rutile nanorod (NR) arrays covered with CZTS nanocrystallites yielded a rather modest efficiency of 0.25 %. It was concluded that the amount of CZTS nanocrystal loading on the rutile nanorod sub-structure should be increased and interfacial CZTS/TiO2 recombination suppressed by modifying the solution deposition approach. To this end a water/ethanol direct solution coating method was developed to deposit CZTS on TiO2 NRs resulting in improved kesterite quality film as characterized via high resolution (HR) SEM, TEM, XPS, optical and electrochemical (impedance spectroscopy) techniques. Eventually a solid-state TiO2NR@CZTS sensitized solar cell, featuring spiro-OMeTAD as hole-transporting medium and CdS as buffer layer, was successfully assembled delivering a 10 fold improvement in power conversion efficiency (2 %), opening the avenue for further developments in alternative CZTS-TiO2 optoelectronic applications.</description><description>Cu2ZnSnS4 (CZTS) sous sa phase kësterite crystalline est un semiconducteur constitué d'élément abondant, non-toxique,et un candidat prometteur pour la nouvelle génération de cellules photovoltaïques afin de promouvoir un futur basé sur des énergies renouvelables. Pourtant, tout comme les CIGS and CdTe, les impuretés et les défauts engendré lors de la cristallisation retarde le développement des cellules photovoltaïque CZTS. Dans cette thèse, CZTS est étudié comme un type alternatif de cellules solaires reconnu par les récentes technologies photovoltaïques émergentes comme les cellules solaires à colorant, à boîte quantique, à base de pérovskite qui a par ailleurs la plus grande tolérance contre les défautscristallins des cristaux photo-absorbants. Plus précisément, cette thèse étudie le CZTS comme absorbeur de lumière nanométrique qui est enduits sur une structure de conducteur de charges (dans ce cas TiO2). Par la suite, la cellule photovoltaïque est créée en ajoutant une jonction liquide photoélectrochimique ou une jonction solide de conducteurs de trous. La thèse étudiera aussi les effets apportés par d'autre type de substrat de TiO2, le changement de la méthode de déposition du CZTS et élaborera une étude approfondie du recuit en utilisant des techniques de caractérisations sur la propriété nanométrique et optique des photos anodes et des dispositifs.  Pour fabriquer une nanostructure absorbant-conducteur, le CZTS a été déposé sous forme de précurseur de sulfure bimétallique sur une couche de TiO2 mésoporeuse pré-fritté via des réactions successives d'adsorption-couche-ionique (SILAR) en milieu aqueux qui est suivie par un recuit pour initier une cristallisation. La composition chimique de la couche est contrôlée par la séquence de déposition-échange choisi, et l'homogénéité est améliorée par l'addition d'une étape de gravure de l'acide chlorhydrique après le recuit. Les tests optiques confirment la fonctionnalité de la couche nanostructuré de TiO2@CZTS et les subséquents travaux ont été dirigé vers la compréhension de la formation de la phase cristalline de CZTS durant le processus du recuit de couche CZTS-TiO2 en utilisant de la spectroscopie Raman in situ. Le plus important, les études in situ à démontrerune dépendancedans le temps lors d'un recuit à 500 °C par l'augmentation de l'intensité maximale, le décalage, l'élargissement du spectre Raman de CZTS. Cette propriété est indispensable pour le développement futur des dispositifs sensibilisés au CZTS.   Parallèlement, la variation du conducteur d'électron a étéétudié en synthétisanthydro thermiquement sur des verres FTO des nanobâtons (NR) comme substitue de la couche mésoporeuse de TiO2. De ces deux substructures de TiO2 c'était la dernière qui a montré la performance photovoltaïque la plus forte. Prouvant ainsi, la confirmation de l'hypothèse d'injection collection d'électron pour la photodiode de CZTS/TiO2 et a donc été retenue pour la suite de l'étude. Les prototypes de cellules photoélectrochimiques utilisant des nanobâtons de TiO2 ont démontré une efficacité relativement modeste de 0.25 %. Il a été conclu qu'il faut augmenter la quantité de nanocristal de CZTS déposé sur la substructure de nanobâton rutile et diminuer la recombinaison interfaciale de CZTS/TiO2 en modifiant l'approche de la technique de déposition en solution. Par conséquent une méthode revêtement utilisant un mélange d'eau/éthanol comme solvant a été développé pour déposer le CZTS sur NRs de TiO2 qui aboutis à une meilleure qualité de couche de kësterite. Finalement une cellule solaire solide sensibilisée de TiO2NR@CZTS, avec spiro-OMeTAD comme le médium de transport de trous et CdS comme le couche de tampon, a été assemblé avec succès qui a montré une augmentation 10 fois supérieur en efficacité de conversion de puissance (2 %), et il ouvre le chemin à un développement d'application optoélectronique alternative de CZTS-TiO2.</description><creator>Wang, Zhuoran</creator><contributor>George Demopoulos (Supervisor)</contributor><date>2017</date><subject>Mining and Materials</subject><title>Solution processed kesterite light absorber on titania electron conductor for photovoltaic application</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/vm40xv33w.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/cc08hj06s</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Mining and Materials</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:pc289m52s</identifier><datestamp>2020-03-21T13:51:39Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La redondance cinématique est une caractéristique importante permettant aux tâches motrices d'être accomplies dans différentes situations, aussi appelée équivalence motrice, telles que lorsque des perturbations sont appliquées ou que des degrés de liberté (DL) supplémentaires sont imposés pendant la tâche. La capacité d'utiliser l'équivalence motrice lors des mouvements d'atteinte suite à un accident vasculaire cérébral (AVC) demeure inconnue. Cette thèse comprend une revue de littérature et trois études expérimentales. Le premier manuscrit propose une définition opérationnelle de la coordination interarticulaire et examine les mesures existantes de la coordination. Ce manuscrit illustre également l'écart de connaissance entre la pratique clinique et la recherche au niveau de l'évaluation de la coordination interarticulaire, en soulignant la nécessité d'une mesure fonctionnelle de la qualité de mouvement lors des mouvements d'atteinte prenant en compte les mouvements compensatoires chez les individus ayant subi un AVC. L'objectif de la première étude expérimentale était d'étudier si et dans quelle mesure le système nerveux sain peut préserver la trajectoire finale du mouvement malgré des perturbations posturales impliquant des DF supplémentaires. Avec les yeux fermés et en position debout, dix sujets ont pointé l'emplacement rappelé d'un objet placé au-delà de la longueur du bras. Dans des essais choisis aléatoirement, la flexion des hanches a été restreinte de façon inattendue, obligeant les sujets à faire un pas vers l'avant pour éviter une chute (condition - hanches bloquées). La tâche fût, ensuite, répétée en demandant aux sujets de prendre un pas vers l'avant, de façon intentionnelle, lors du pointage. Dans la plupart des cas, la précision de la trajectoire et la courbure fût préservées en raison de changements adaptatifs dans la coordination interarticulaire propres à la condition dans laquelle la tâche fût réalisée. Dans la deuxième étude expérimentale, la capacité d'utiliser l'équivalence motrice a été évaluée en utilisant la même tâche que la première étude chez des sujets ayant subi un AVC (n = 19) et chez des sujets sains (N = 12). Pour cette deuxième étude, deux objectifs étaient visés. Le premier objectif était d'étudier l'influence de l'AVC sur la capacité de maintenir la performance du point final lors de perturbations (adaptabilité du mouvement). Le deuxième objectif était d'étudier la relation entre les mouvements compensatoires et la capacité d'adaptation du mouvement chez les sujets ayant subi un AVC. Cependant, la capacité de produire des solutions motrices équivalentes était réduite chez les sujets ayant subi un AVC, ce qui a fût démontré par des erreurs substantielles dans la position du point final (dépassement), une diminution de la fluidité du mouvement et une coordination interarticulaire entre l'épaule et le coude moins adaptée. L'adaptabilité du mouvement était plus limitée chez les sujets ayant subi un AVC, puisqu'ils utilisaient plus de mouvements compensatoires lors du mouvement d'atteinte sans perturbation. Dans la troisième étude expérimentale, nous avons étudié la relation entre les ajustements anticipés modifiés (APM) suite à un AVC et la performance lors de l'atteinte avec tout le corps. Dix-huit sujets ayant eu un AVC et douze sujets sains d'âge équivalent ont atteint une cible située au-delà de la portée du bras en faisant un pas vers l'avant volontairement. L'amplitude et la vitesse des APM fût considérablement réduites chez les sujets ayant eu un AVC. Les résultats de l'analyse de régression linéaire multiple démontrent que la réduction de l'amplitude et la vitesse des APM est corrélée avec une performance réduite lors de l'atteinte.</description><description>Kinematic redundancy is an important characteristic by which motor tasks can be accomplished in different situations, referred to as motor equivalence, such as when perturbations are applied and additional kinematic degrees of freedom (DFs) are imposed during the task. Motor equivalence during reaching under additional DFs is achieved by task-specific changes of interjoint coordination to preserve the performance of the reaching task (e.g., accuracy). It remains unknown whether and to what extent stroke affects the capacity of motor equivalence during standing reach. In the application of rehabilitative strategies to enhance UL motor function after stroke, the assessment of interjoint coordination is important to identify movement quality, defined as how well a person performs a motor action. Despite its importance, interjoint coordination has been defined and measured differently in research and clinical settings. This thesis includes one review paper and three experimental studies. The first manuscript proposes an operational definition of interjoint coordination and reviews existing measures of coordination. This manuscript also highlights the knowledge gap between clinical practice and research evidence about the measurement of interjoint coordination, postulating the need for a more relevant functional measure of movement quality and compensations during reaching in subjects with stroke. The objective of the first experimental study was to investigate whether and to what the extent the healthy nervous system preserves the endpoint trajectory despite challenges to postural stability when additional DFs are involved subsequent to perturbations. With eyes closed, ten subjects reached from a standing position to a remembered target located beyond arm length. In randomly chosen trials, hip flexion was unexpectedly prevented, forcing subjects to take a step during pointing to prevent falling (Blocked-hip condition). The task was repeated when subjects were instructed to intentionally take a step during pointing. In most cases, reaching accuracy and trajectory curvature were preserved due to adaptive condition-specific changes in interjoint coordination. In the second experimental study, the capacity for motor equivalence was tested using the same task in subjects with stroke (n=19) and age-matched healthy subjects (n=12). There were two objectives for the second study. The first objective was to investigate the influence of stroke on the ability to maintain the endpoint performance under the perturbations (movement adaptability). The second objective was to investigate the relationship between compensatory movement and the capacity of movement adaptability in subjects with stroke. We found that the ability to produce motor equivalent solutions was reduced in subjects with stroke, evidenced by substantial overshoot errors in endpoint position, reduced movement smoothness and less adaptive elbow-shoulder interjoint coordination. Movement adaptability was more limited in stroke subjects who used more compensatory movements for unperturbed reaching. In the third experimental study, we investigated the relationship between altered anticipatory adjustments (APAs) after stroke and performance of whole-body reaching. Eighteen subjects with stroke and 12 age-matched healthy subjects reached a target beyond arm reach while taking a voluntary step. APA amplitude and velocity were significantly reduced in stroke subjects and these were correlated with reduced reaching performance. The results of multiple linear regression analysis showed that APA velocity and arm impairments were correlated with reaching performance. Results of these studies suggest that stroke subjects, especially those who exhibited compensatory movements and altered postural adjustments, had a limited ability to maintain stable endpoint performance during reaching from standing when additional DFs are involved. </description><creator>Tomita, Yosuke</creator><contributor>Mindy Levin (Supervisor)</contributor><date>2017</date><subject>Physical &amp; Occupational Therapy</subject><title>Motor equivalence during reaching from standing in subjects with and without stroke</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/gm80hz02g.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/pc289m52s</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>School of Physical and Occupational Therapy</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:w3763943t</identifier><datestamp>2020-03-21T13:51:40Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Research Abstract Title: IMPACT OF WATER-ELECTROLYTE IMBALANCE ON MORTALITY RISK AFTER MAJOR ABDOMINAL OR THORACIC SURGERIES Background Electrolytes and water play vital roles in maintaining homeostasis within the body. They help to regulate myocardial and neurological functions, fluid balance, oxygen delivery, acid-base balance among others. Major surgeries are one of the important causes of water-electrolyte imbalance. Because of fasting before surgery and large amount of bleeding and transfusion during the operation, the possibility of imbalance is very high; therefore, the possibility of disturbance in myocardial and neurological functions as well as death increases.  Methods This is a case-referent (case-control) retrospective study.  Definitions: Cases are patients who died after major abdominal or thoracic surgery. Controls are people who survived to discharge after major abdominal or thoracic surgery.  Data sources: Beheshti Hospital, Kashan, Iran  Exposure: presence or absence of water-electrolyte balance based on assessments and treatments as recorded in the patient's chart. The data required to assess water-electrolyte balance consists of serum glucose, serum osmolality, serum sodium level, serum potassium level, BUN and creatinine. In this case-referent study, we chose 124 files of patients who died after abdominal or thoracic surgery as cases and 248 files of patients who survived to discharge after major abdominal or thoracic surgery. Water-electrolyte imbalance was assessed in both groups. Each case was matched with controls with respect to age, type and duration of surgery and underlying diseases.  The odds ratio was used to estimate the relative risk for dying related to electrolyte imbalance. Logistic regression was used to adjust the odds ratio for potential confounders.  vi  Results This study demonstrated that water-electrolyte imbalance significantly increased morality risk of major abdominal or thoracic surgeries. We had 72 (58%) cases of water-electrolyte imbalance and 52 (42%) of balance in cases.  We had 68 (27%) cases of water-electrolyte imbalance and 180 (73%) balance in controls. Odds ratio for death in patients with electrolyte imbalance was 3.665 and 95% confidence interval was 2.330-5.764  Conclusion One of the potentially important preventable complications that increases mortality risk in surgery, is water-electrolyte imbalance. Therefore, by strict control of water-electrolyte balance, we can reduce the mortality of surgeries. Key words: Major surgery, Water-electrolyte imbalance, Mortality risk </description><description>Recherche Résumé : Titre : IMPACT DE L'IMBALANCE DE L'EAU ET DE L'ELECTROLYTE SUR LE RISQUE DE MORTALITÉ APRÈS LES GRANDES CHIRURGIES ABDOMINALES OU THORACIQUES Contexte Les électrolytes et l'eau jouent un rôle vital dans le maintien de l'homéostasie dans le corps. Ils aident à réguler les fonctions myocardiques et neurologiques, l'équilibre des fluides, l'apport d'oxygène, l'équilibre acide-base entre autres. Les chirurgies majeures sont l'une des causes importantes du déséquilibre eau-électrolyte. En raison du jeûne avant la chirurgie et une grande quantité de saignement et de transfusion pendant l'opération, la possibilité de déséquilibre est très élevée ; Par conséquent, la possibilité de perturbation dans les fonctions myocardiques et neurologiques ainsi que la mort augmentent. Méthodes Il s'agit d'une étude rétrospective cas-référent (cas-témoins). Définitions : Les cas sont des patients qui sont morts après la chirurgie majeure abdominale ou thoracique. Les contrôles sont des personnes qui ont survécu à la décharge après une chirurgie majeure abdominale ou thoracique. Sources des données : Hôpital Beheshti, Kashan, Iran Exposition : la présence ou l'absence d'équilibre eau-électrolyte sur la base des évaluations et des traitements indiqués dans le tableau du patient. Les données nécessaires à l'évaluation de l'équilibre eau-électrolyte sont le glucose sérique, l'osmolalité sérique, le taux de sodium sérique, le taux de potassium sérique, l'azote urinaire et la créatinine. Dans cette étude cas-référent, nous avons choisi 124 dossiers de patients décédés après la chirurgie abdominale ou thoracique comme cas et 248 dossiers de patients qui ont survécu à la sortie après chirurgie abdominale ou thoracique majeure. viii  Le déséquilibre eau-électrolyte a été évalué dans les deux groupes. Chaque cas a été apparié avec des témoins en ce qui concerne l'âge, le type et la durée de la chirurgie et des maladies sousjacentes. L'odds ratios a été utilisé pour estimer le risque relatif de décès lié au déséquilibre électrolytique. La régression logistique a été utilisée pour ajuster l'odds ratios pour les facteurs de confusion potentiels. Résultats Cette étude a démontré que le déséquilibre eau-électrolyte augmentait de façon significative le risque de la mortalité de chirurgies abdominales ou thoraciques majeures. Nous avons eu 72 (58%) cas de déséquilibre eau-électrolyte et 52 (42%) d'équilibre dans les cas. Nous avons eu 68 (27%) cas de déséquilibre eau-électrolyte et 180 (73%) déquilibre dans les témoins. L'odds ratios de décès chez les patients présentant un déséquilibre électrolytique était de 3,665 et l'intervalle de confiance à 95% était 2,330-5,764. Conclusion L'une des complications importantes potentiellement évitables qui augmente le risque de mortalité en chirurgie, est le déséquilibre eau-électrolyte. Par conséquent, par un contrôle strict de l'équilibre eau-électrolyte, nous pouvons réduire la mortalité des chirurgies.   </description><creator>Masror, Hamidreza</creator><contributor>John Sotirios Sampalis (Internal/Supervisor)</contributor><date>2017</date><subject>Surgery</subject><title>Impact of water-electrolyte imbalance on mortality risk after major abdominal or thoracic surgeries</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/d217qs14b.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/w3763943t</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Surgery</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:kp78gj96b</identifier><datestamp>2020-03-21T13:51:41Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Improved HDL cholesterol efflux capacity in morbidly obese individuals after bariatric surgeryBackground. Obesity has become a global epidemic and carries excess cardiovascular (CV) morbidity and mortality. Bariatric surgery was shown to improve significantly CV outcome. HDL cholesterol efflux capacity (CEC) was shown to be inversely correlated with cardiovascular risk (CVR), both in the acute and the chronic phases. Our aim is to assess if HDL CEC is improved 6 months post bariatric surgery in comparison to baseline, as a surrogate marker for the increased CVR reduction in the morbidly obese population. Methods. HDL CEC via ATP-binding cassette A1 (ABCA1), ATP-binding cassette G1 (ABCG1) and scavenger receptor BI (SR-BI) was measured for morbidly obese individuals prior to and 6 months after bariatric surgery. HDL CEC was measured using radioactive cell-based assays. Results. Plasma from 36 morbidly obese patients was analyzed. The mean age of the patients was 43.2±12.2 years, 30.6% of the patients were males, 61.1% had undergone sleeve gastrectomy (SG) and 38.9% Roux-en-Y gastric bypass. HDL CEC improved 6 months post-bariatric surgery in comparison to baseline for all 3 transporters as well as unstimulated total CEC; efflux via ABCA1 increased by 9.5% (14.35±1.85 vs. 13.1±2.63, P=0.004), via ABCG1 by 14% (4.38±0.95 vs. 3.84±0.84, P=0.001), via SR-BI by 14.1% (5.96±0.99 vs. 5.23±0.89, P&lt;0.001) and unstimulated total efflux increased by 14.8% (8.82±1.3 vs. 7.68±0.93, P&lt;0.001). Discussion. In the current study, we found that HDL CEC through ABCA1, ABCG1 and SR-BI improved significantly in morbidly obese individuals 6 months after bariatric surgery. Efflux is an ongoing process, hence even a small improvement in CEC can have a substantial effect on the atherosclerotic plaque. Given that HDL CEC has an inverse correlation with CVR, these findings may explain, at least in part, the improvement in CVR in morbidly obese patients post-bariatric surgery. Conclusion. HDL CEC improves after bariatric surgery, and may play an important role in the favorable CV outcome seen in obese patients post-bariatric surgery. If the same is proven in larger clinical studies, decreased HDL CEC might serve as another indication for bariatric surgery in obese individuals.</description><description>L'amélioration de la capacité d'efflux du cholestérol LHD chez les personnes obèses morbides après la chirurgie bariatriqueContexte. L'obésité est devenue une épidémie mondiale et entraîne un excès de morbidité et de mortalité cardiovasculaire (CV). Il a été démontré que la chirurgie bariatrique améliore de manière significative les issues CV. La capacité d'efflux du cholestérol LHD (CEC) s'est révélée inversement corrélée au risque cardiovasculaire (RCV), tant dans les phases aiguës que chroniques. Notre objectif est d'évaluer s'il y a amélioration de la CEC LHD 6 mois après chirurgie bariatrique par rapport au niveau de base, et d'utiliser la CEC LHD comme un marqueur de substitution pour la réduction du RCV dans la population de personnes atteintes d'obésité morbide. Méthodes. La CEC LHD via l'ATP-binding cassette A1 (ABCA1), l'ATP-binding cassette G1 (ABCG1) et le scavenger receptor BI (SR-BI) a été mesurée à l'aide des tests cellulaires radioactifs chez 36 personnes obèses morbides avant et 6 mois après la chirurgie bariatrique. Résultats. Le plasma des 36 patients atteints d'obésité morbide a été analysé. L'âge moyen des patients était de 43,2 ± 12,2 ans, 30,6% des patients étaient des hommes, 61,1% ont subi une gastrectomie longitudinale et 38,9% ont subi un by-pass gastrique par une anastomose en Roux-en-Y. Comparé au niveau de base, la CEC LHD a augmenté 6 mois après la chirurgie bariatrique pour tous les 3 transporteurs, de même que la CEC non-stimulée. L'efflux via l'ABCA1 a augmenté de 9,5% (14,35 ± 1,85 vs 13,1 ± 2,63, P =0,004), via l'ABCG1 de 14% (4,38 ± 0,95 vs 3,84 ± 0,84, P =0,001), via le SR-BI de 14,1% (5,96 ± 0,99 vs 5,23 ± 0,89, P &lt;0,001) et l'efflux total non stimulé a augmenté de 14,8% (8,82 ± 1,3 vs 7,68 ± 0,93, P &lt;0,001). Discussion. Dans la présente étude, nous avons démontré que la CEC LHD par l'ABCA1, l'ABCG1 et le SR-BI s'améliore de façon significative 6 mois après la chirurgie bariatriques chez les individus atteints d'obésité morbide. L'efflux est un processus continu, donc même une petite amélioration de la CEC peut avoir un effet marqué sur la plaque d'athérome. Étant donné que la CEC LHD a une corrélation inverse avec le RCV, ces résultats peuvent expliquer, au moins en partie, l'amélioration du RCV chez les patients obèses morbides post-chirurgie bariatrique. Conclusion. La CEC LHD s'améliore après une chirurgie bariatrique, et peut jouer un rôle important au niveau des issues CV favorables vues chez les patients obèses post-chirurgie bariatrique. Si notre hypothèse est prouvée dans de plus grandes études cliniques, la diminution de la CEC LHD pourrait servir comme une autre indication pour la chirurgie bariatrique.</description><creator>Dotan, Idit</creator><contributor>Mark Sherman (Internal/Supervisor)</contributor><contributor>Jacques Jean Genest (Internal/Cosupervisor2)</contributor><date>2017</date><subject>Medicine</subject><title>Improved HDL cholesterol efflux capacity in morbidly obese individuals after bariatric surgery</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/pk02cd40g.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/kp78gj96b</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Medicine</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:0g354h84s</identifier><datestamp>2020-03-21T13:51:42Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Social networks are essential tools for  modeling social dynamics. Their  structure affects and is affected by  the behavior of individuals that constitute them. Many studies have related the structure of social networks to various social and individual outcomes. In many studies, the first step towards network analysis is to observe the network. If the full network is infeasible to acquire, network sampling methods are employed. Sampling offline social networks involves interviewing people. Since respondent fatigue is a pressing problem, standard practice is to ask each respondent only a  limited number of names. This throws away much information about the network structure.  In this thesis, we focus on the problem of estimating the structural properties of the original social network from such survey data. We provide reliable estimators that  incorporate link heterogeneity. We then focus on applications where knowledge over the global structure of the social network is unfeasible, and efficient methods are needed to identify nodes with certain properties without having to sample the network. We focus on a method called Alter Sampling, which was originally introduced in network epidemiology. We demonstrate its effectiveness in various social networks with different structural properties. Then we highlight insights that this ubiquitous effectiveness provides about how social networks are organized. We discuss the relations to the so-called Friendship Paradox and its generalized version, and provide metrics to quantify how local structural and non-structural properties of nodes compare with their neighbors. </description><description>La mod\'elisation des dynamiques sociales dépend étroitement sur la structure des réseaux sociaux qui influe sur et est également influencée par le comportement des individus qui composent le réseau. De nombreuses études constatent qu'il existe des liens serrés entre les réseaux sociaux et divers résultats sur non seulement le plan individuel, mais aussi le plan social. En générale, l'observation du réseau est la première étape de son analyse. Par la suite, si la consitution du réseau complet est impossible à déterminer, les méthodes d'échantillonage en  réseaux   sont  souvent employées. Pour réaliser un échantillonge des réseaux sociaux hors lignes et pour réduire l'effet de la fatigue sur les personnes interrogées, des entretiens sont effectuées desquelles la pratique habituelle est de demander un nombre limité de noms, ce qui gâche une bonne partie de l'information sur la structure sous-jacente du réseau. Dans cette thèse, nous nous concentrons sur comment estimer les caractéristiques structurelles du réseau social original à partir de telles données. Ainsi, nous fournissons des estimateurs fiables qui intègrent l'hétérogénéité des liens. Motivés par le besoin de développer des méthodes efficaces pour identifier des noeuds ayant certaines caractéristiques sans devoir échantilloner le réseau au complet, nous nous avons ensuite tournés vers les réseaux sociaux pour lesquels il est impossible de cerner leur structure globale. Nous nous sommes penchés sur la méthode « d'échantillonage altérée» (ou Alter Sampling en anglais), qui a d'abord été introduit dans le domaine de l'épidémiologie des réseaux, et nous montrons son efficacité dans divers réseaux dont les caractéristiques structurales sont toutes différentes. Finalement, nous soulignons comment l'efficacité de l'échantillonage altérée nous informe sur l'organisation sociale de ces mêmes réseaux. Nous élaborons sur les relations entre le Paradoxe de l'amitié et sa généralisation, et nous proposons des indicateurs pour quantifier les caractéristiques (non-)structurales locales par rapport à leurs voisins.</description><creator>Momeni Taramsari, Naghmeh</creator><contributor>Michael Rabbat (Supervisor)</contributor><date>2017</date><subject>Electrical and Computer Engineering</subject><title>The structure of social networks: modeling, sampling, and inference</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/5h73pz57q.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/0g354h84s</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:zs25xc04g</identifier><datestamp>2020-03-21T13:51:42Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Dans cette these, nous presentons une analyse complete de la photometrie infrarouge et de la spectroscopie optique de l'echantillon le plus grand (716) et le plus eloigne (z ~ 1,8) des Galaxies de Cluster Plus Brillantes (BCGs), ceux selectionnes a partir de l'adaptation Spitzer De l'enquete Red-Sequence Cluster Survey (SpARCS). Le but de cette campagne etait de determiner le mecanisme physique dominant guidant la croissance de la masse stellaire dans ces galaxies les plus massives de l'Univers. En raison de leur habitat unique au centre de gravite des grappes de galaxies, la formation et l'evolution des BCG sont inextricablement liees a la formation de grandes structures dans l'Univers. Afin de decouvrir la nature reelle de ce groupe special de galaxies et leur relation avec des grappes de galaxies, nous avons effectue une analyse sans precedent de leurs distributions d'energie spectrale infrarouge complete (SED), en utilisant des donnees infrarouges (3.6-500 μm) obtenus par les telescopes spatiaux de la NASA Spitzer et Herschel. Nous avons egalement etudie les donnees spectroscopiques optiques (3000-7000$ Å) d'un sous-echantillon representatif (93/716) de SpARCS BCG a z = 1,1 obtenu avec le telescope Anglo-Australien. Grace a une comparaison des SED infrarouges BCG a une variete de modèles SED dans la litterature, nous identifions les principales sources d'emission de leur energie infrarouge, a des redshifts multiples entre 0&lt;z&lt;1,8. Nous obtenons des estimations de divers parametres physiques des SED, en deduisant un star-forming, par opposition a une population de galaxies "rouges et mortes", tout au long de 0 &lt; z &lt; 2 , une periode au cours de laquelle les BCG sont prevus etre principalement depourvu du materiel pour former des etoiles. Il est remarquable que l'application des diagnostics optiques de formation d'etoile a leur spectre optique confirme la presence de cette activite de formation d'etoiles inattendue a z &lt;1,1, ce qui donne des gains d'efficacite de la formation d'etoiles (sSFR) qui correspondent au sSFR derive independamment des SED infrarouges. Cette decouverte conteste la croyance acceptee que les BCG ne devraient evoluer que passivement par une serie de fusions mineures pauvres en gaz avec d'autres galaxies depuis z ~ 4 (De Lucia &amp; Blaizot 2007), mais est d'accord avec le modele semi-analytique ameliore de formation de structure hierarchique de Tonini et al. (2012), qui predit les BCG formant des etoiles tout au long de l'epoque consideree. Nous attribuons cette formation d'etoiles aux fusions "humides" majeures et mineures, en fonction du manque de signatures (a ce jour) du flux de gaz froid au centre du cluster, generalement associe a la formation d'etoiles BCG, ainsi qu'un nombre des etudes d'observation et de simulation qui soutiennent ce scenario. Le BCG conservateur et median les taux de formation d'etoiles que nous tirons dans ce travail suggerent que 40,8% de la masse stellaire de BCG peut etre gagne a z&lt;2. Enfin, compte tenu des sources possibles de gaz formant des etoiles dans SpARCS BCGs a z=0, nous estimons que la mediane SpARCS BCG peut gagne a peu pres un quart de sa masse stellaire a z&lt;1 a travers des fusions majeures, seule, purement de l'approvisionnement en gaz depose par des galaxies fusionnees e ce moment-la.</description><description>In this thesis we present a comprehensive infrared photometric and optical spectroscopic analysis of the largest (716) and highest-redshift (z ~ 1.8) sample of Brightest Cluster Galaxies (BCGs), those selected from the Spitzer Adaptation of the Red-Sequence Cluster Survey (SpARCS). The aim of this campaign was to determine the dominant physical mechanism(s) guiding the buildup of stellar mass in these most massive galaxies in the Universe. Given their unique habitat at the gravitational centres of the largest collapsed structures known, galaxy clusters, BCG formation and evolution is inextricably linked to the formation of large-scale structure in the Universe. In an effort to illuminate the true nature of this special class of galaxies and their relationship to their host clusters, we conducted an unprecedented analysis of their broadband, infrared spectral energy distributions (SEDs), utilising mid- and far-infrared imaging data (3.6-500 μm) obtained by the NASA Spitzer and Herschel space telescopes. We also studied the optical spectroscopic data (3000-7000 Å) of a representative subsample (93/716) of SpARCS BCGs out to z=1.1 obtained with the ground-based Anglo-Australian Telescope. Through a comparison of the infrared BCG SEDs to a variety of SED model templates in the literature, we identify the major sources of their infrared energy output, in multiple redshift bins between 0 &lt; z &lt; 1.8.  We derive estimates of various physical parameters from the stacked rest-frame SEDs, from which we infer a star-forming, as opposed to a 'red and dead' population of galaxies, vigorously producing stars with high efficiency at z &gt; 1, and maintaining a non-negligible pulse of star formation activity down to z=0. Remarkably, the application of optical emission-line star-formation diagnostics to their stacked optical spectra confirms the presence of this unexpected star formation activity at z&lt;1.1, yielding star formation efficiencies (specific star formation rates) that lie within the uncertainties of those independently derived from the infrared SEDs.  This discovery challenges the accepted belief that BCGs should only passively evolve through a series of gas-poor, minor mergers since z ~ 4 (De Lucia &amp; Blaizot 2007), but agrees with the improved semi-analytic model of hierarchical structure formation of Tonini et al. (2012), which predicts star-forming BCGs throughout the epoch considered. We attribute this star formation to both major and minor 'wet' mergers, based on a lack of key signatures (to date) of the cluster cooling flows to which star formation in BCGs is typically attributed, as well as a number of observational and simulation-based studies that support this scenario. The conservative, median BCG star formation rates we derive in this work suggest that 40.8% of BCG stellar mass can be gained at z&lt;2. Finally, considering the possible sources of star-forming gas in SpARCS BCGs down to z=0, we estimate that the median SpARCS BCG can gain roughly one quarter of its stellar mass at z&lt;1 through major-merger-induced star formation, alone, purely from the gas supply deposited by massive merging galaxies at this epoch.</description><creator>Bonaventura, Nina</creator><contributor>Tracy Webb (Supervisor)</contributor><date>2017</date><subject>Physics</subject><title>A multiwavelength exploration of unexpected star formation activity in SpARCS brightest cluster galaxies</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/nz8062545.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/zs25xc04g</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Physics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:wm117r446</identifier><datestamp>2020-03-21T13:51:43Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les méthodologies d'évaluation de l'endommagement des structures, spécifique à un bâtiment ou à l'échelle de la ville, sont essentielles pour prédire et gérer les conséquences socio-économiques d'un tremblement de terre dans une région. Ainsi, plusieurs approches et outils, avec ou sans modélisation de l'ouvrage, ont été largement utilisés. Ces approches peuvent faciliter la prise de décision pour déployer les forces de secours en cas d'urgence et minimiser les pertes d'exploitation dues à la cessation d'activité. L'objectif d'ensemble de cette thèse est de développer un cadre efficace de prise de décision pour évaluer rapidement les risques et les pertes causés par les séismes sur les bâtiments en acier. Le deuxième objectif est de développer des outils et des métriques qui permettent une estimation fiable des pertes dues aux séismes à l'échelle du bâtiment. Le premier but a été atteint en combinant des concepts issus de la surveillance de l'état des structures et de la conception parasismique axée sur la performance. Afin de développer un cadre d'évaluation du risque sismique pour les bâtiments à ossature métallique sans recourir à des modèles, de nombreux indicateurs d'endommagement, calculés avec des techniques d'identification de système sans modèle et des méthodes d'analyse en ondelettes, ont été évalués. Nous avons constaté que les indicateurs d'endommagement déterminés par ondelettes sont bien corrélés avec des paramètres de demande sismique inter-étages courants. Une méthodologie non-basée sur la modélisation de l'ouvrage a été développée ; elle utilise l'indicateur amélioré déterminé par ondelettes et des propriétés géométriques basiques du bâtiment pour en déduire l'état d'endommagement de la structure à une intensité sismique donnée. Il est montré que des paramètres de demande sismique tels que les déformations inter-étages maximales, les accélérations absolues des planchers maximales et les déformations inter-étages résiduelles sont prédites avec une précision convenable. La méthodologie sans modèle est également étendue à l'échelle de la ville par le développement de cartes de dommages et de pertes post-séisme généralisées. La même méthodologie peut faciliter la prise de décision pour des mesures préventives efficaces afin de gérer les risques de désastre sismique concernant les infrastructures. Afin de fournir des indications pour les approches nécessitant un modèle, pour estimer le risque sismique et les pertes touchant un bâtiment particulier, l'influence des hypothèses de modélisation sur l'évaluation des pertes causées par les séismes sur les bâtiments en acier a été examinée. Nous avons montré que pour les séismes avec une faible probabilité d'occurrence, les pertes dues à la ruine de la structure et à sa démolition peuvent être surestimées de manière significative lorsque les calculs d'endommagement proviennent de modèles numériques qui ignorent les effets de poutre composite et l'action du système de descente des charges verticales. Pour les séismes fréquents, les réparations des composants non-structuraux sont prépondérantes dans les pertes du bâtiment. Dans ce cas, le choix de la représentation du modèle numérique du bâtiment en acier devient négligeable. Les pertes annuelles prévisionnelles sont dominées par les réparations des composants non-structuraux sensibles aux accélérations, suivies par celles des composants non-structuraux sensibles au déplacement. Il est préférable de combiner les métriques d'estimation d'endommagement, en fonction du niveau de performance sismique attendu, pour évaluer les dommages causés par les tremblements de terre sur les bâtiments en acier. </description><description>Building-specific and city-scale structural damage assessment methodologies are essential in order to predict and manage the socio-economic consequences within a region in the aftermath of an earthquake. In that respect, nonmodel-based as well as model-based approaches and tools have been widely used. Such approaches can facilitate the decision-making for emergency rescue force allocation and the minimization of business interruption due to downtime. The first overarching goal of this thesis is to develop an efficient decision-making framework for rapid earthquake-induced risk and loss assessment of steel frame buildings. The second one is to develop tools and metrics that facilitate reliable building-specific earthquake-induced loss assessment. The first goal is accomplished by combining concepts from structural health monitoring and performance-based earthquake engineering.In order to develop a nonmodel-based framework for seismic risk assessment of steel frame buildings, an extensive number of damage indicators computed based on nonmodel-based system identification techniques and wavelet analysis are evaluated. It is found that wavelet-based damage-sensitive features (DSFs) are well correlated with commonly used story-based engineering demand parameters (EDPs). A nonmodel-based framework is developed that utilizes the refined wavelet-based DSF and basic building geometric information to infer the building damage state at a given seismic intensity. It is shown that story-based EDPs such as peak story drift ratios, peak absolute floor accelerations and residual story drift ratios are predicted with a reasonable accuracy. The nonmodel-based framework is also extended at the city-scale through the development of generalized earthquake-induced damage and loss maps. The same framework can facilitate the decision-making for effective pre-disaster measures for earthquake disaster risk management of building assets.In order to provide guidance in model-based approaches for building-specific seismic risk and loss assessment, the influence of modeling assumptions on the earthquake-induced loss assessment of steel frame buildings is examined. It is shown that for seismic events with low probabilities of occurrence, losses due to demolition and collapse may be significantly overestimated when the loss computations are based on numerical models that ignore the composite beam effects and the interior gravity framing system. For frequent seismic events, building losses are dominated by non-structural content repairs. In this case, the choice of the numerical model representation of the steel frame building becomes insignificant. The expected annual losses are dominated by repairs of acceleration-sensitive non-structural content followed by repairs of drift-sensitive non-structural components. It is advisable to employ a combination of loss metrics to assess the earthquake-induced losses in steel frame buildings depending on the seismic performance level of interest.</description><creator>Hwang, Seong-Hoon</creator><contributor>Dimitrios Lignos (Supervisor2)</contributor><contributor>Colin Andrew Rogers (Supervisor1)</contributor><date>2017</date><subject>Civil Engineering &amp; Applied Mechanics</subject><title>Framework for earthquake-induced loss assessment of steel frame buildings–from building-specific to city-scale approaches</title><language>fre</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/1r66j366g.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/wm117r446</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Civil Engineering and Applied Mechanics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:2b88qf55k</identifier><datestamp>2020-03-21T13:51:44Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>This thesis describes how positron emission particle tracking (PEPT) was used to obtain detailed information on ore particle behaviour within a mineral spiral concentrator.A review of literature has shown a number of experimental measurements of clear water flow in spiral concentrator. However, this review highlighted the lack of quantitative information on the particle behaviour within a dense pulp, used in the operation of this equipment. Thus, for the first time, observations of separation of minerals at the flow scale were undertaken and are reported in this thesis. The description of mineral particle flow field in the spiral concentrator was made possible by the following work. First, large mineral particles (larger than 1000 micrometer) were activated via direct activation in a MC40 cyclotron (35 mega-electron volt Helium-3 beam). Second, a new procedure was developed for subsequent breakage, sizing and selection of surface fragments of a large particle in order to obtain small activated mineral tracers (approx. 100 micrometer). This is the first time such small representative mineral tracers were produced and enabled the observation of particle behaviour in dense and opaque pulp. Considering the low amount of activity carried by these small tracers, a high performance tracking system consisting of modular positron emission detector was designed and built. Subsequently, this new modular detector assembly was compared to an established detection system and tracking error was determined for particles of different mineral composition, size, speed and activity. Finally, the modular detector system was used ￼to observe, for the first time, the characteristic flow of hematite (5260 kilogram per cubic meter) and quartz (2650 kilogram per cubic meter) particles with size ranging between 90 and 1400 micrometer within a spiral concentrator. All measurements were carried out in a mineral (iron ore) pulp consisting of 20 percent solids by mass.In this thesis, the results describing mineral particle flow fields are presented in the form of trajectories, velocities, accelerations and resultant forces on the mineral tracer particle. Of key importance is the particle behaviour within the spiral secondary flow. For quartz particle of size 300 to 355 micrometer, radial velocity magnitude within the secondary flow ranged from 0.1 metre per second in the lower inward moving layer of the flow and reached up to 0.2 meter per second in the upper outward moving layers. This information is critical for the development of more efficient spiral concentrator since ore separation is a direct result of particle behaviour in this secondary flow. The new quantitative information obtained from this work will be used for the improvement and validation of particle and fluid flow simulations, now possible thanks to the advances in computational power.</description><description>Cette thèse présente comment la technique de traçage de particule par émission de positron (positron emission particle tracking, PEPT) a été utilisée pour obtenir de l'information détaillée sur le comportement de particules de minerai de fer à l'intérieur d'une spirale de concentration gravimétrique.Une revue de la littérature a montrée que plusieurs expériences ont ciblés l'écoulement d'eau claire dans une spirale de concentration. Cependant, elle a aussi mis en évidence un manque d'information quantitative sur le comportement des particules à l'intérieur d'une pulpe minérale dense, tel qu'utilisée lors de l'opération de cet  équipement. Pour la première fois, l'observation de la séparation des minéraux à l'échelle de l'écoulement de la pulpe a  été réalisé et est présenté dans cette thèse.La description de l'écoulement de particules minérales dans la spiral a été rendue possible par les travaux suivants. Premièrement, des particules de minerai de fer grossières (plus de 1000 micromètre) ont été activées directement dans un cyclotron MC40 (rayon d'hélium-3 de 35 mega-électron volt). Deuxièmement, une méthode a été développée pour la fragmentation, la classification et la sélection d'éclats provenant de la surface des particules grossières permettant d'obtenir de petits traceurs activés (environ 100 micromètre). Il s'agit de la première fois que de si petits traceurs représentatifs sont produits et permettent l'observation du comportement des particules dans une pulpe dense et opaque. En considérant le niveau d'activité des petits traceurs, un système de détection de haute performance composé de détecteurs de positron modulaires a  été conçu et construit. Ensuite, ce ￼nouvel assemblage de détecteurs a été comparé à un système de détection connu et la précision du traçage a été déterminée pour des particules de différentes compositions minérales, tailles, vitesses et activitées. Finalement, ce système de détecteurs modulaires a été utilisée pour observer, pour la première fois, l'écoulement typique de particules d'hematite (5260 kilogramme par mètre cube) et de quartz (2650 kilogramme par mètre cube) de dimensions variant entre 90 et 1400 micromètre à l'intérieur d'une spirale de concentration. Ces mesures ont été réalisées dans une pulpe minérale (minerai de fer) ayant un contenu solide massique de 20 pourcent. Dans cette thèse, les résultats décrivant le flux de particules minérales sont présentés sous la forme de trajectoires, vitesses, accélérations et forces résultantes sur les particules minérales. Un des résultats ayant une très grande importance est le comportement des particules dans l'écoulement secondaire de la pulpe. Pour une particule de quartz d'une taille de 300 à 355 micromètre, la vitesse radiale à l'intérieur de l'écoulement secondaire a été mesurée entre 0.1 mètre par seconde dans la couche inférieure s'écoulant vers le centre de la spirale et jusqu'à 0.2 mètre par seconde dans la couche supérieure s'écoulant vers l'extérieure. Cette information est critique pour le développement de spirales de concentrations plus efficaces car la séparation minérale est directement reliée au mouvement des particules dans cette écoulement secondaire.Les nouvelles informations quantitatives obtenues à partir de ce travail seront utilisées pour l'amélioration et la validation de simulations de l'écoulement de la pulpe, maintenant possibles grâce aux avancées dans la puissance de calcul par ordinateur.</description><creator>Boucher, Darryel</creator><contributor>Agus Sasmito (Supervisor2)</contributor><contributor>Kristian Waters (Supervisor1)</contributor><date>2017</date><subject>Mining and Materials</subject><title>Observation of iron ore particle flow in a mineral spiral concentrator by positron emission particle tracking (PEPT)</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/cn69m662w.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/2b88qf55k</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Mining and Materials</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:xd07gw200</identifier><datestamp>2020-03-21T13:51:45Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Computer systems have gone through tremendous changes in the past fewdecades. Relatively large general purpose computers dominated the early daysof computers. With time, demand increased for smaller, more dedicated computersystems, called embedded systems. These systems perform a specificset of functions interacting with the physical environment, often in real-time.Real-time embedded systems are found today in many application domainssuch as the automotive domain, avionics, and control systems. Real-time systemsdiffer from traditional computer systems in their dependence on time asa correctness criteria, i.e., a late correct answer is useless for these systems.Embedded real-time systems today are more integrated, more parallel, andmore complex than ever before. In this thesis, we discuss limitations thataffect the applicability of real-time models, analysis methods, and schedulingapproaches to the realities of today's embedded systems and propose solutionsto address these challenges. We first look into the issue of shared resources and its effect on the mapping and scheduling of software tasks in a real-time system. Most task mappingapproaches proposed in the literature perform task mapping assuming independenttasks that do not share resources. Managing shared resources andtheir protection mechanisms is performed later. However, this approach mightrequire several rounds of iteration and can lead to inefficient results. In thisthesis, we explore the possibility of using different resource protection mechanismswithin a single system, and propose to tackle the design problem moreefficiently by jointly performing task allocation, scheduling, and resource protection mechanism selection. Two approaches are presented to solve this optimizationproblem: an optimal Mixed Integer Linear Programming (MILP)approach and an efficient heuristic. The proposed work is shown to significantly improve system schedulability. Experimental results indicate that theminimum utilization at which at least 95% of systems become scheulable canbe improved from 65%-70% for the best published task allocation algorithmsto 76%-85% using our heuristic with minimal memory cost. Even better resultscan be achieved using the MILP approach.Next, we look into the design of systems composed of components thathave different levels of criticality. Mixed-Criticality Systems (MCS) receivedmuch attention recently to due their industrial relevance. We focus on threechallenges in MCS design: task allocation, fault-tolerance, and model-baseddesign. For task allocation, we show that traditional task allocation algorithmscan be inefficient in a mixed-criticality context, and propose an alternative thatwe call dual-partitioned task allocation. Experiments show that for systemsthat have a utilization of 80% or higher, we can schedule 17% more systemson a given multicore platform using the dual-partitioned approach. Fault-tolerance is an important issue for MCS since these systems containa safety critical part. To design MCS that tolerate hardware transient faults,we propose a new mixed-criticality model that simultaneously addresses criticality,reliability, and Quality of Service (QoS). A schedulability test for thenew model is derived. Furthermore, to allow designers to incorporate the newmodel and analysis in their design process, we propose a design space explorationframework based on the new model that supports various fault-tolerancemechanisms. QoS improvements of up to 42.9% can be achieved using the newmodel compared to the traditional MCS model extended to support transientfaults.For model-based design, we propose algorithms to generate optimized semantic-preserving implementationsfor MCS specified using the SR model, with minimal functional delay addition.An optimal Branch-and-Bound based algorithm and an efficient heuristicare proposed for this purpose.</description><description>Les systemes informatiques ont subi des changements enormes au cours des dernieres decennies. Dans leurs debuts, les ordinateurs, de grande taille et a usage general, etaient dominants. Avec le temps, la demande pour des systemes informatiques plus petits et dedies pour des taches plus specifique, appeles systemes embarques, a augmente. Ces systemes executent un ensemble de fonctions specifique interagissant avec l'environnement physique, souvent en temps reel. Les systemes embarques temps-reel se trouvent aujourd'hui dans de nombreux domaines d'application tels que l'automobile, l'avionique et les systemes de controle. Les systemes temps-reel different des systemes informatiques traditionnels dans leur dependence au temps qui est utilise comme critere de correction. C'est-a-dire qu'une reponse correcte tardive est inutile pour ces systemes. Les systemes embarques temps-reel sont aujourd'hui plus integres, plus paralleles et plus complexes que jamais. Dans cette these, nous discutons des limites qui affectent l'applicabilite des modeles temps-reel, des methodes d'analyse et des approches d'ordonnancement aux realites des systemes embarques d'aujourd'hui et nous proposons des solutions pour relever ces defis. En premier lieu, nous examinons la question des ressources partagees et leurs effets sur la cartographie et l'ordonnancement des taches logicielles dans un systeme temps-reel. La plupart des approches de cartographie des taches proposees dans la litterature effectuent la cartographie des taches en assumant des taches independantes qui ne partagent pas les ressources. La gestion des ressources partagees ainsi que leurs mecanismes de protection sont effectues plus tard. Cependant, cette approche peut necessiter plusieurs cycles d'iteration et peut mener a des resultats inefficaces. Dans cette these, nous explorons la possibilite d'utiliser differnents mecanismes de protection des ressources au sein d'un meme systeme et proposons d'aborder plus efficacement le probleme de conception en executant conjointement l'attribution des taches, l'ordonnancement et la selection des mecanismes de protection des ressources. Deux approches sont presentees pour resoudre ce probleme d'optimisation: une approche doptimisation lineaire a nombres entiers mixtes optimale (MILP) etune heuristique efficace. Le travail propose permet d'ameliorer considerablement lordonnancabilite du systeme. Les resultats experimentaux indiquent que l'utilisation minimale a laquelle au moins 95% des systemes deviennent ordonnancables peut etre amelioree de 65%-70%, dans les meilleurs algorithmes d'allocation de tache publies, a 76%-85% en utilisant notre heuristique avec un cot memoire minime. Des resultats encore meilleurs peuvent etre obtenus en utilisant l'approche MILP. Ensuite, nous examinons la conception de systemes formes de composants qui ont differents niveaux de criticite. Nous nous concentrons sur trois defis en matiere de conception MCS: l attribution des taches, la tolerance aux pannes et la conception basee sur modele. Pour l'attribution des taches, nous proposons l'allocation detaches a double partition. Les experiences montrent que pour les systemes dont l'utilisation est superieure ou egale a 80%, qu'on peut ordonnancer 17% de systemes sur une plate-forme multicur donnee en utilisant l'approche a deux partitions. Pour concevoir des MCS qui tolerent les defauts transitoires, nous proposons un nouveau modele de criticite mixte qui aborde simultanement la criticite, la abilite et la qualite de service (QoS).  Nous proposons un cadre d'exploration d'espace de conception base sur le nouveau modele qui prend encharge divers mecanismes de tolerance de pannes. Des ameliorations de la qualite de service jusqu'a 42.9% peuvent être obtenues.</description><creator>Al-bayati, Zaid</creator><contributor>Brett Meyer (Supervisor1)</contributor><contributor>Haibo Zeng (Supervisor2)</contributor><date>2017</date><subject>Electrical and Computer Engineering</subject><title>Design and scheduling of effcient real-time embedded systems</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/j6731654t.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/xd07gw200</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><resumptionToken completeListSize="47894">oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):5875</resumptionToken></ListRecords></OAI-PMH>