<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/assets/blacklight_oai_provider/oai2-b0e501cadd287c203b27cfd4f4e2d266048ec6ca2151d595f4c1495108e36b88.xsl"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd"><responseDate>2020-07-25T03:29:04Z</responseDate><request resumptionToken="oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):36900" verb="ListRecords">https://escholarship.mcgill.ca/catalog/oai</request><ListRecords><record><header><identifier>oai:escholarship.mcgill.ca:t722hf045</identifier><datestamp>2020-03-23T05:02:47Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The main objective of this project was to investigate and model phosphorus (P) transport in soil column studies. A model named HYDRUS-NICA was developed, by coupling a hydrological and transport model (HYDRUS-1D model) with an aqueous chemical model (non-ideal competitive adsorption - NICA), to improve the predictions of P transport in soil and water. The HYDRUS-NICA model was developed by replacing the non-linear empirical (Freundlich and Langmuir) equations of the HYDRUS-1D model with the NICA model equations. The numerical accuracy of the HYDRUS-NICA model was then evaluated by comparing the relative errors produced by the HYDRUS-NICA and HYDRUS-1D models. The results showed that the numerical schemes of the HYDRUS-NICA code are stable. The ability of the NICA model to describe phosphate (PO4) adsorption to soil particles was tested using soils collected from agricultural fields in southern Quebec. The surface charge and PO4 adsorption capacity of these soils were measured. Results were used to estimate the NICA model parameters using a non-linear fitting function. The NICA model accurately described the surface charge of these soils and the PO4 adsorption processes. The HYDRUS-1D model was applied to simulate water flow and PO4 transport in re-constructed soil column experiments. The HYDRUS-1D model was calibrated based on physical and chemical parameters that were estimated from different experiments. Overall, the HYDRUS-1D model successfully simulated the water flow in the columns; however, it overestimated the final adsorbed PO4 concentrations in the soil. The discrepancies in the results suggested that the HYDRUS-1D model could not account for the differences in the soil structure found in the columns, or that the Freundlich isotherm could not adequately describe PO4 adsorption. The HYDRUS-NICA model was calibrated and validated with results from re-packed column experiments. The simulated results were then compared with results obtained by the HYDRUS-1D model. The overall goodness-of-fit for the HYDRUS-1D model simulations was classified as poor. The HYDRUS-NICA model improved significantly the prediction of PO4 transport, with the coefficient of modeling efficiency values being close to unity, and the coefficient of residual mass values being close to zero. The HYDRUS-NICA model can be used as a tool to improve the prediction of PO4 transport at the field scale.</description><creator>Abou Nahra, Joumana.</creator><date>2006</date><subject>Phosphorus -- Environmental aspects -- Mathematical models.</subject><subject>Water -- Phosphorus content.</subject><subject>Soils -- Phosphorus content.</subject><title>Modeling phosphorus transport in soil and water</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>© Joumana Abou Nahra, 2006</rights><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/4m90f0422.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/t722hf045</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Bioresource Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:4f16c6691</identifier><datestamp>2020-03-23T05:02:47Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Anthropologists have long recognized the central role of social systems in enhancing environmental sustainability, but few have attempted to accurately assess the conditions under which traditional social institutions can equitably and effectively manage access to natural resources for the purposes of their use and conservation. By failing to look closely at how resource management practices are shaped both by local-level cultural institutions and the political and economic forces of government policies and markets, anthropologists have compounded the confusion surrounding the functions and capacities of traditional resource management institutions. This dissertation examines the connections between institutional and economic incentives and resource use and management decisions among the Naso indigenous people in Bocas del Toro, Panama. The study incorporates insights from development anthropology, common property systems and political ecology to develop a multi-sited approach that uses multiple research methods. A detailed household survey (n=54 or 18% of Naso households located within the eight villages surveyed in 2004) was used to obtain socio-demographic data and to establish patterns of land tenure and resource use. Preliminary and follow-up interviews were also conducted with community leaders, government officials and representatives of various national and international organizations with a stake in the conservation and/or development of the Naso region. As a group, the Naso were found to use both indigenous and imported technologies to manage a wide range of natural resources towards ensuring the economic, cultural and ecological viability of their communities. However, recent legislation intended to recognize Naso land rights and a hydroelectric project nearing construction on Naso lands have sought to modify the formal rules and organizations that have traditionally served to order local resource tenure and management practices. This thesis analyses the guidelines and criteria invoked by the various stakeholders involved with these projects in order to assess the equity of the distribution of their social and environmental impacts. It highlights the need to become more sceptical and sophisticated when assessing the objectives and justifications provided by the academics, government agencies, local authorities and private companies involved in the conservation and development of indigenous peoples' territorial resources.</description><creator>Paiement, Jason Jacques.</creator><date>2007</date><subject>Terraba Indians -- Legal status, laws, etc. -- Panama -- Bocas del Toro (Province)</subject><subject>Terraba Indians -- Panama -- Bocas del Toro (Province) -- Economic conditions.</subject><subject>Terraba Indians -- Ethnobotany -- Panama -- Bocas del Toro (Province)</subject><title>The tiger and the turbine : indigenous rights and resource management in the Naso territory of Panama</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>© Jason Jacques Paiement, 2007</rights><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/z890rz77n.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/4f16c6691</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Anthropology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:d504rq45s</identifier><datestamp>2020-03-23T05:02:48Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Despite many efforts to promote the importance of considering consumer experience, few studies have provided empirical evidence of their impact on immediate consumption outcomes and on their relationship with existing product/service design attributes, while considering the subjective nature of consumer experiences. In the present dissertation, we propose that important insights could be gained in building such evidence by considering research on emotions and rigorous empirical approaches that account for the subjectivity of the experience. Specifically, we propose a framework that builds on the consumption emotion literature and on functional theories of emotions and that is based on a Bayesian approach that takes into consideration individual differences in emotional experience. The framework rests on four core elements: (1) assessment of emotional experience emerging over the consumption episode, (2) link between this experience and immediate evaluative and behavioral outcomes, (3) exhaustive consideration of potential eliciting factors among elements of the consumption object and environment, and (4) assessment of the added value of the experience elicited by the consumption offering and consideration of alternative influences of consumption emotions on consumption outcomes consistent with their functional values. The framework was applied in the context of extended health services in which repeated consumption episodes were observed. Results show that emotional states that arise during consumption do impact satisfaction measures, but have a limited impact on consumers' immediate consumption behavior. These relationships however could not be explained by the added value brought by the experience, as no evidence for mediation by emotional experience was found between service attributes and consumption outcomes. Emotional states experienced either prior or immediately following consumption showed a superior ability to predict consumption outcomes, with their influence being tied to their respective informational and, to some degree, motivational functions. We also provide evidence that emotions experienced before and elicited during consumption moderated the impact of service attributes on both satisfaction and immediate consumption behavior. Results highlight the importance of considering emotional states experienced at any stage during consumption, but also the challenge of doing so with existing resources in the present context. Contributions, limitations, and future directions are also discussed.</description><creator>Paquet, Catherine, 1977-</creator><date>2007</date><subject>Customer services -- Psychological aspects.</subject><subject>Consumer satisfaction -- Psychological aspects.</subject><title>Consumption emotional experiences : an investigation of their design, outcomes, and underlying mechanism of action in the context of repeated services episodes</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>© Catherine Paquet, 2007</rights><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/rb68xh237.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/d504rq45s</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Desautels Faculty of Management</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:3n2043262</identifier><datestamp>2020-03-23T05:02:48Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>How "social change organizations" balance organizational imperatives with progressive, or "principled," values is a dilemma commonly addressed in the sociological literature (cf. Minkoff, 2002; Ostrander, 2004). This challenge is particularly important where organizations are undergoing a process of change (Kelley et al., 2005). However, few studies have used internal working conditions as a dynamic on which to measure this balance. Thus, using the internal dynamics of two contemporary human rights organizations, Amnesty International and Human Rights Watch, as a means of understanding these challenges, the broadest objective of this dissertation is to understand how organizations with principled values do or do not construct "exemplary" workplaces (Lofland, 1996). Changes to the gendered nature of the organizations are examined as a specific indicator of this exemplary behaviour. Using new institutionalist literature as a guide, I demonstrate the ways in which isomorphic pressures shaped human rights organizations throughout the 1990s. Specifically, I show that Amnesty International and Human Rights Watch shared a shifting institutional environment, including political climate favourable toward the human rights discourse, increased attention from media, increased pressure to professionalize, the need to present themselves as legitimate and accountable, and the need to respond to competitive pressures. I found that as both organizations responded to these pressures and opportunities in their institutional environment, they adapted internal structures, strategies, and behaviours. The result was increased hierarchy, competition between employees, performance pressures, and emotionally repressive workplace norms. Moreover, men and women often experienced these changes differently. The investigation of two organizations, however, revealed that this connective chain was also shaped by the specific histories, structures, and cultures of each organization.</description><creator>Rodgers, Kathleen.</creator><date>2006</date><subject>Sociology, Organizational.</subject><title>The challenges of &amp;quot;Walking the principled walk&amp;quot; : how human rights organizations experience organizational change</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>© Kathleen Rodgers, 2006</rights><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/b2774068h.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/3n2043262</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Sociology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:mg74qr290</identifier><datestamp>2020-03-23T05:02:48Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>This dissertation explores the discursive voices present in a late Qing inner alchemy (neidan) compilation, the Nudan hebian. Inner alchemy is a meditation/visualization practice centered on purification of the physical body as the essential element in gaining physical immortality; therefore the physical body is of utmost importance. Yin-yang theory associates male with heaven and yang, and female with earth and yin. (Kunjue 1a) In neidan, both men and women must purge the earthly elements from their mind-body matrix to create a 'golden yang immortal's body' (Hutian xingli nudan shize 463a). This process can be accomplished by men through self-cultivation, but in mainstream Qing Daoism, women were limited by their gender, and could not attain complete mind-body purification without resort to outside assistance from the gods. The theoretical consequences of these limitations notwithstanding, many women practiced neidan and were thought to have reached the highest states of perfection. The symbolic processes through which this becomes possible are complex and often contradictory. Some Nudan hebian texts reveal many levels of discursive play, rendering new meanings for old symbols and revealing rifts and commonalities in the tradition. Exploration of these rifts and commonalities reveals important dilemmas and understandings operative in the particular socio-historical contexts in which they were drafted, and offers a gender-sensitive historical perspective on the development of neidan during the late Qing period.</description><creator>Neswald, Sara.</creator><date>2007</date><subject>Taoism -- China.</subject><subject>Taoist women -- China.</subject><subject>Qi gong.</subject><title>Rhetorical voices in the neidan tradition : an interdisciplinary analysis of the Nüdan hebian (pref. 1906) compiled by He Longxiang (fl. 1900-1906)</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>© Sara Neswald, 2007</rights><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/gt54ks24g.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/mg74qr290</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of East Asian Studies</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:9019s662v</identifier><datestamp>2020-03-23T05:02:49Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The French Popular Front was a coalition of left-wing political parties (Communists, Socialists, and Radicals) united through a common desire to combat fascism and improve the living conditions of France's workers. Between 1935 and 1938, the ideology of the Popular Front, largely informed by that of the Parti Communiste Francais (PCF), exerted tremendous influence on the cultural life of the French nation. Many cultural and musical organizations heeded the Popular Front's call for broad-based anti-fascist solidarity among intellectuals, artists, and the working class. In the realm of culture, this translated into multiple initiatives designed to bring art to the masses and to encourage the proletariat to become more active in the cultural life of the nation. Sympathetic to the Popular Front's larger political aims, a number of French musicians and composers became affiliated with the Communist-sponsored Maison de 1a Culture and its affiliated musical organizations, the most prominent of which was the Federation Musicale Populaire (FMP). They participated in the administrative, cultural and intellectual life of the FMP; they took part in conferences, wrote articles on the theme of "music for the people," and were advocates for the organization within French musical life at large. Furthermore, these composers wrote works for government-commissioned events, for amateur groups, and for spectacles designed for mass audiences. Some of the FMP's most prominent proponents (Darius Milhaud, Georges Auric, and Arthur Honegger) were former members of Les Six, a group that had been particularly interested in borrowing music derived from "popular" sources like the music hall and the circus following World War I. This study argues that the aesthetic approach of Les Six, which found support in FMP presidents Albert Roussel and Charles Koechlin, was reinvigorated during the Popular Front for a much more clearly defined political purpose. While the general interest in "popular" sources was still maintained, composers at the FMP now sought to integrate folklore and revolutionary music into their works "for the people" in an attempt to create and underline cultural links between workers and intellectuals---a compositional approach for which this dissertation coins the expression "populist modernism." This study, the first book-length examination of French musical culture in light of Popular Front politics, concentrates on some of the period's most significant populist modernist works and draws upon contemporaneous journalistic coverage and archival documents that in many cases have hitherto never been the object of musicological study. The research shows that in 1936, following an initial infatuation with the genres and styles of socialist realist Soviet works, French left-wing composers developed a more inclusive view of what constituted music "for the people." Composers continued to write music indebted to politically resonant popular sources like folklore and revolutionary songs, but they also drew upon these genres in works (like the collaborative incidental music for Romain Rolland's Le 14 Juillet) that employed modernist compositional techniques. Though this approach was most obviously felt in the numerous works composed for organizations like the FMP, populist modernism also emerged in works performed at the Theatre de l'Opera-Comique and the 1937 Paris Exposition. By cutting across musical genres as well as institutional and social contexts, populist modernism emerges as the dominant aesthetic trend in French music during the years of the Popular Front.</description><creator>Moore, Christopher Lee.</creator><date>2006</date><subject>Music -- Social aspects -- France.</subject><subject>Front populaire -- Influence.</subject><subject>Music -- France -- History -- 1914-1945.</subject><title>Music in France and the Popular front (1934-1938) : politics, aesthetics and reception</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>© Christopher Lee Moore, 2006</rights><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/zp38wh72k.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9019s662v</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Schulich School of Music</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:8336h585j</identifier><datestamp>2020-03-23T05:02:49Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Through the evidence of the court records (sijill s), this dissertation examines the interplay between Islamic jurisprudence (fiqh), codified sultanic law (qanun ) and customary law in the shari`a courts of Ottoman-Cairo in the sixteenth and seventeenth centuries. The thesis forwarded suggests that custom was a declining source of law in these centuries as a result of two factors: the imposition of a codified qanun, and a redacted fiqh. Conflict between Egyptian and Ottoman jurists, a well-documented feature of the sixteenth century, is often depicted as a by-product of the tension between qanun and fiqh. Questioning this framework of analysis, this study views the conflict between Egyptian jurists and their Ottoman counterparts as an exemplar of 'antagonistic shari`as.' The Ottoman shari`a, defined by 'universalism,' entailed a redacted fiqh in which Ḥanafism was privileged above the other schools of law, and a qanun in which sultanic customs were imposed in lieu of local custom. The 'Egyptian shari`a,' on the other hand, was defined by pluralism as it envisioned parity between the schools of law while upholding the role of local custom over and above the authority of the imported qanun¯. At the core of this antagonism, therefore, are two cross-cutting predispositions: one, a propensity for legal orthodoxy; and, two, a propensity (on the part of the Egyptian judiciary) to retain the traditional features of Islamic legal orthopraxy. At the heart of the state's endeavour to construct a legal orthodoxy was a desire to promote a model of 'correct outward conduct' that would generate cultural parity between the empire's myriad ethnic communities. Such an undertaking fostered more than a growing social homogeneity, however. Positioned as the final arbiters of social justice and morality, the state and its courts were able to realign the social contract between the state and its subjects to strengthen the ties binding the individual to the state while weakening communal bonds. In the final analysis, the increasingly assimilative role of an Ottoman-defined shari`a over local custom, diminished the communities' roles in the arbitration of justice and led to the making of a proto-citizen in the Ottoman Empire.</description><creator>Meshal, Reem A.</creator><date>2006</date><subject>Courts -- Egypt -- History -- 16th century.</subject><subject>Justice, Administration of -- Egypt -- History -- 16th century.</subject><subject>Courts -- Egypt -- History -- 17th century.</subject><subject>Islamic law -- Egypt -- History.</subject><subject>Justice, Administration of -- Egypt -- History -- 17th century.</subject><title>The state, the community and the individual : local custom and the construction of orthodoxy in the Sijills of Ottoman-Cairo, 1558-1646</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>© Reem A. Meshal, 2006</rights><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/9p290f77f.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/8336h585j</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Institute of Islamic Studies</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:k930c2455</identifier><datestamp>2020-03-23T05:02:50Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The ability to invent new solutions to old or novel problems is often equated with intelligence, both in humans and non-human animals. Behavioural flexibility can be defined operationally by looking at the frequency of novel or unusual behaviours, i.e. innovations, in different taxa. Despite the potential survival benefits of behavioural flexibility in the face of changing conditions, there is variation among taxa in the propensity to innovate. Here, I examine in detail one foraging innovation, dunking behaviour (the immersion of food items in water) in Carib grackles (Quiscalus lugubris) of Barbados. I show that the rarity of dunking behaviour in the field is not due to the inability of most individuals to learn and/or perform it, but rather to the balance of costs and benefits not being favourable to its expression in most field conditions. In this population, dunking functions as a proto-tool food-processing technique speeding the ingestion of items that are difficult to swallow. The frequency of the behaviour depends on food characteristics, travel costs between the food source and water, and the probability of losing items to conspecifics. Dunking renders grackles vulnerable to food theft because it involves releasing food items in water, where there is often a build-up of conspecifics. When faced with a high risk of kleptoparasitism, grackles reduce the frequency of dunking, engage in aggressive displays, and keep items in the bill while dunking. Kleptoparasitism not only reduces the rate of dunking by increasing costs to the behaviour, but also by constituting an alternative foraging tactic. The payoffs to this tactic are frequency-dependent; i.e. they decrease as the frequency of kleptoparasites increases in the group. A comparative study on ecological, morphological and behavioural predictors of the occurrence of kleptoparasitic tactics among bird families point to an important role of predation and cognitive abilities in favouring the evolution of kleptoparasitism. Thus, avian food-stealing should not be regarded as a "cognitively simpler" alternative to intelligent behaviour, but as another form of behavioural flexibility. Large-brained primates and birds share the ability to learn quickly, innovate, use tools and engage in exploitative tactics, suggesting that these abilities have not been traded-off against each other, but have instead evolved together.</description><creator>Morand-Ferron, Julie.</creator><date>2007</date><subject>Quiscalus -- Behavior -- Barbados.</subject><subject>Quiscalus -- Food -- Barbados.</subject><title>Foraging innovations and kleptoparasitism in birds</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>© Julie Morand-Ferron, 2007</rights><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/s4655m58c.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/k930c2455</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Biology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:h989r742z</identifier><datestamp>2020-03-23T05:02:50Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The Hereditary Spastic Paraplegias (HSP) comprise a group of neurodegenerative diseases characterized by progressive lower limb spasticity. This disease, with a prevalence ranging from 1 to 20 in 100,000 individuals, is currently untreatable. The neuropathological hallmark is axonal degeneration of motor neurons in the corticospinal tract. However, the mechanisms of pathogenesis underlying this neurodegeneration remain poorly understood. Over the last decade, genetic studies of HSP have identified 33 loci including 14 genes. The main objective of this dissertation was to identify and characterize genes in a large North American HSP cohort. Mutation analysis of the two most common genes implicated in HSP, SPG3 and SPG4, led to the detection of nine novel mutations, including an ancestral SPG4 mutation in five French Canadian families. This screen also allowed for the molecular characterization of the p.del436N mutation in SPG3, which suggests a previously unidentified dominant-negative mechanism. Furthermore, a novel deletion in the VPS9 domain of the ALS2 gene was identified in a family with severe infantile onset HSP. In addition, linkage analysis and whole genome scan efforts resulted in the successful mapping of two novel HSP loci, SPG27 and SAX1. SAX1 represents the first locus for autosomal dominant spastic ataxia, a complicated form of HSP, with a common ancestor in Newfoundland. Finally, a positional candidate gene strategy at the SPG8 locus identified three missense mutations in a novel gene encoding strumpellin. Two mutations failed to rescue an axonal phenotype induced by morpholino knock-down of the SPG8 gene in zebrafish. Our efforts to identify and characterize HSP genes determined the underlying genetic cause in 36% of our cohort. These genetic causes include two novel loci and a novel gene. The findings are a major contribution to the characterization of the pathophysiology of HSP and significantly broaden the knowledge in the field of motor neuron disease. Analysis of the 15 known HSP genes suggests a common disease mechanism involving disrupted axonal membrane protein trafficking. Unraveling this mechanism will elucidate the functional maintenance of neurons in the corticospinal tract and will facilitate the development of therapies for HSP and related diseases.</description><creator>Meijer, Inge A.</creator><date>2006</date><subject>Paralysis, Spastic -- Genetic aspects.</subject><subject>Spastic Paraplegia, Hereditary -- genetics.</subject><title>Genetic analysis of the hereditary spastic paraplegias</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><rights>© Inge A. Meijer, 2006</rights><identifier>https://escholarship.mcgill.ca/downloads/t435gj12m.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/h989r742z</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Biology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:sf268938w</identifier><datestamp>2020-03-23T05:02:51Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The purpose of this study was to address two specific issues related with the clinical application of Modulated Electron Radiation Therapy (MERT). The first was to investigate radiation-tolerant solutions for automated motion control of a Few Leaf Electron Collimator. Secondly, we implemented a fast, Monte Carlo-based, parameterized beam model for characterization of the electron beam in modulated deliveries.Two approaches were investigated for the implementation of a radiation-tolerant position feedback system: (i) the use of CMOS-based optical encoders protected by a prototype shield and (ii) the use of an analog device, such as a potentiometer, whose radiation tolerance is significantly higher. The two approaches were implemented and their performance tested. Results indicated that the optical encoders could not be safely used under radiation even with the presence of a shield. The analog position feedback system showed to be a viable solution. Future work will be focused towards the direction of implementing an analog position feedback system suitable for clinical use.The MC-based, parameterized beam model is based on the idea of deriving the scattered electron beam characteristics directly on the exit plane of the linear accelerator by the use of source scatter fluence kernels. Primary beam characteristics are derived by fast Monte Carlo simulations. The novelty of the method is that arbitrary rectangular fields can be recreated fast by superposition of the appropriate source kernels directly on the output plane. Depth, profile dose distributions and dose output, were derived for three field sizes (8 x 8, 2 x 2 and 2 x 8 cm^2) and energies of 6 MeV and 20 MeV electron beams by the beam model and compared with full Monte Carlo simulations. The primary beam showed excellent agreement in all cases. Scattered particles agreed well for the larger field sizes of 8 x 8 and 2 x 8 cm^2, while discrepancies were encountered for scattered particles for the smaller field size of 2 x 2 cm^2. Sources of errors were identified and future work will focus on the improvement of the beam model.</description><description>L'objectif primaire du projet est d'explorer des solutions de radiation dures pour le contrôle dynamique d'un collimateur d'électrons à lames dans le contexte de la radiothérapie par modulation d'électrons. De plus, un modèle de faisceau paramétrique basé sur la méthode Monte-Carlo (MC) a été implémenté pour la caractérisation du faisceau d'électrons durant les traitements modulés. Deux approches ont été étudiées pour le développement d'un système de positionnement à boucle rétroactif pour la radiation dure : (i) des encodeurs optique CMOS protégés par un bouclier prototype (ii) et des composantes analogues telles que les potentiomètres avec une tolérance de radiation relativement élevée. La comparaison des deux méthodes montre que les encodeurs optiques ne peuvent subir de radiation, même en présence d'un bouclier adapté. De ce fait, pour l'utilisation clinique, les solutions basées sur les composantes analogues sont plus prometteuses et doivent être étudiées en détails à l'avenir.Le model MC de faisceau paramétrique vise la caractérisation du faisceau d'électrons diffusé directement sur la surface de sortie de l'accélérateur linéaire à l'aide de noyaux de fluence pour la diffusion des sources. Les caractéristiques primaires du faisceau sont obtenues par les méthodes de MC rapides. La nouveauté de la méthode réside dans la reproduction rapide de champs rectangulaires par la superposition de noyaux appropriés directement sur la surface de sortie. Profondeur, distribution dosimétrique de profil, et résultat de dose, sont calculés à partir de trois champs (8 x 8, 2 x 2, 2 x 8 cm^2) et des énergies de 6 MeV et 20 MeV, et sont comparés aux simulations MC. Le faisceau primaire montre une excellente cohérence dans tout les cas. Les résultats pour les particules diffusées étaient consistants pour les deux méthodes dans le cas de champs plus larges (8 x 8 et 2 x 8 cm^2) alors que des divergences ont été notées pour les petits champs (2 x 2 cm^2). Les sources d'erreurs ont été identifiées et la recherche ultérieure visera donc l'amélioration du modèle de faisceau. </description><creator>Papaconstadopoulos, Paul</creator><contributor>Jan Peter Frans Seuntjens (Internal/Supervisor)</contributor><date>2012</date><subject>Health Sciences - General</subject><title>Modulated electron radiation therapy: an investigation on fast beam models and radiation-tolerant solutions for automated motion control of a few leaf electron collimator</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/v405sf67v.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/sf268938w</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Medical Physics Unit</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:h415pf66t</identifier><datestamp>2020-03-23T05:02:53Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les applications commerciales courantes utilisent une architecture multi-tiers où le traitement logique est effectué en un groupe de serveurs qui accèdent à une seule base de données partagée, ce qui la rend un point d'encombrement. Une solution répandue qui réduit la charge sur la base de données est la sauvegarde des résultats de requetes à la base de données au niveau des serveurs d'applications comme des entitiés logiques. Tandis que chaque cache local de chaque serveur est limité et est indépendant des autres, un algorithme naïve de balancement de la charge, comme round-robin, résultera en des duplications de copies dans les différents caches et mènera à des explusions de ceux-ci. En regroupant ces caches, nous formons un seul cache distribué avec une large capacité, où un objet est extrait à partir d'un cache distant s'il n'est pas trouvé localement. Cet approche élimine la redondance et réduit considérablement la charge sur la base de données. Cependant, accéder à des objets distants encours une latence au niveau du réseau ce qui affecte les temps de réponses.Dans cette thèse, nous transformons le cache distribué en un cache hybride qui supporte la duplication ce qui permet de servir les requêttes les plus populaires localement par plusieurs serveurs d'applications. Nous prenons avantage de cette structure hybride du cache en developpant une infrastructure holistique du cache. Cette infrastrcuture comprend un outil de surveillance et une infrastructure d'analyse qui fonctionne d'une façon continue et parallèle avec l'application afin de générer un contenu qui prend en considération la distribution de requêtes et les politiques du cache. Les politiques sont générées par des stratégies orientées requêtes qui visent à localizer les requêtes populaires à des serveurs spécifiques et ce pour réduire les appels distants. Ces stratégies sont flexibles et peuvent être ajustées facilement pour different charges de travail et besoins d'applications. Des résultats expérimentaux montrent qu'effectivement nous dérivons un gain substantial en utilisant notre infrastructure. Nos stratégies ont resulté en des temps de réponses rapides sous une charge de travail normale et donnent des bons résultats lors d'un débit élevé comparativemnt à d'autres approches sous des charges de travail de pointe.</description><description>Current business applications use a multi-tier architecture where business processing is done in a cluster of application servers, all querying a single shared database server making it a performance bottleneck. A prevalent solution to reduce the load on the database is to cache database results in the application servers as business entities. Since each of the in-memory application cache is small and independent of each other, a naïve load balancing algorithm like round-robin would result in cache redundancy and lead to cache evictions. By clustering these caches, we get a distributed cache with a larger aggregate capacity, where an object is retrieved from the remote cache if it is not found in local cache. This approach eliminates redundancy and reduces load on the database by a great extent. However, accessing remote objects incurs network latency affecting response time. In this thesis, we transform the distributed cache into a hybrid one that supports replication so that popular requests could be served locally by multiple application servers. We take advantage of this hybrid cache by developing a holistic caching infrastructure. This infrastructure is comprised of an application monitoring tool and an analysis framework that work continuously alongside live application to generate content-aware request distribution and caching policies. The policies are generated by request-centric strategies that aim to localize popular requests to specific servers in order to reduce remote calls. These strategies are flexible and can be adapted easily for various workloads and application needs. Experimental results show that we indeed derive substantial gain in performance using our infrastructure. Our strategies resulted in faster response time under normal workload and scaled much better with higher throughput than existing approaches under peak workload.</description><creator>Maredia, Rizwan</creator><contributor>Bettina Kemme (Internal/Supervisor)</contributor><date>2012</date><subject>Applied Sciences - Computer Science</subject><title>Automated application profiling and cache-aware load distribution in multi-tier architectures</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/gq67jw19c.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/h415pf66t</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:h415pf673</identifier><datestamp>2020-03-23T05:02:54Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>An exponential growth in internet usage and penetration amongst the general population has led to an ever increasing demand for e-commerce applications and other internet-based services. E-commerce applications must provide high levels of service that include reliability, low response times and scalability. Most e-commerce applications follow a multi-tier architecture. As they are highly dynamic and data-intensive, the database is often a bottleneck in the whole system as most systems deploy multiple application servers in the replicated application tier, while only deploying a single database as managing a replicated database is not a trivial task. Hence, in order to achieve scalability, caching of data at the application server is an attractive option.In this thesis, we develop effective load balancing and caching strategies for read-only transaction workloads that help scaling multi-tier architectures and improve their performance. Our strategies have several special features. Firstly, our strategies take into account statistics about the objects of the cache, such as access frequency. Secondly, our algorithms that generate the strategies, despite being object-aware, are generic in nature, and thus, not limited to any specific type of applications. The main objective is to direct a request to an appropriate application server so that there is a high probability that the objects required to serve that request can be accessed from the cache, avoiding a database access. We have developed a whole suite of strategies, which differ in the way they assign objects and requests to application servers. We use distributed caching so as to make better utilization of the aggregate cache capacity of the application servers. Experimental results show that our strategies are promising and help to improve performance.</description><description>Une croissance exponentielle de l'utilisation d'Internet et sa pénétration dans la population générale ont conduit à une demande toujours croissante d'applications de commerce électronique et d'autres services basés sur l'internet. Les applications de commerce électronique doivent fournir des niveaux élevés de services qui comprennent la fiabilité, un court temps de réponse et de la variabilité dimensionnelle. La plupart des applications de commerce électronique suivent une architecture multi-niveau. Comme elles sont très dynamiques et possèdent une forte intensité de données, la base de données est souvent un goulot d'étranglement dans le système en entier comme la plupart des systèmes déploient des serveurs d'applications  multiples dans l'application tierce reproduite. D'un autre côté, le déploiement d'une base de données unique pour la gestion d'une base de données répliquée n'est pas une tâche simple. Ainsi, afin de parvenir à une variabilité dimensionnelle, la mise en cache des données au serveur d'applications est une option attrayante.Dans cette thèse, nous développons un équilibrage de charge efficace et des stratégies de mise en cache qui aident à échelonner les architectures multi-niveaux et à améliorer leurs performances. Nos stratégies ont plusieurs caractéristiques particulières. Premièrement, nos stratégies prennent en compte les statistiques sur les objets de la mémoire cache, comme la fréquence d'accès. Deuxièmement, nos algorithmes qui génèrent les stratégies, tout en étant conscients des objets, sont de nature générique, et donc, ne se limitent pas à un type spécifique d'applications. L'objectif principal est de diriger une requête au serveur d'applications approprié afin qu'il y ait une forte probabilité que les objets requis pour servir cette demande puissent être consultés à partir de la mémoire cache, évitant un accès à la base de données. Nous avons développé toute une série de stratégies qui différent dans leur façon d'assigner des objets et des requêtes aux serveurs d'applications. Nous utilisons une mise en cache distribuée de manière à mieux utiliser la capacité totale de la mémoire cache des serveurs d'applications. Les résultats expérimentaux montrent que nos stratégies sont prometteuses et permettent d'améliorer les performances.</description><creator>Joshipura, Sanket Manjul</creator><contributor>Bettina Kemme (Internal/Supervisor)</contributor><date>2012</date><subject>Applied Sciences - Computer Science</subject><title>Scalable object-based load balancing in multi-tier architectures</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/k930c2323.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/h415pf673</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:bn999b80c</identifier><datestamp>2020-03-23T05:02:54Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Security has emerged as the most feared aspect of cloud computing and a major hindrance for the customers. Current cloud framework does not allow encrypted data to be stored due to the absence of efficient searchable encryption schemes that allow query execution on a cloud database. Storing unencrypted data exposes the data not only to an external attacker but also to the cloud provider itself. Thus, trusting a provider with confidential data is highly risky. To enable querying on a cloud database without compromising data confidentiality, we propose to use data obfuscation through visual cryptography. A new scheme for visual cryptography is developed and configured for the cloud for storing and retrieving textual data. Testing the system with query execution on a cloud database indicates full accuracy in record retrievals with negligible false positives. In addition, the system is resilient to attacks from within and outside the cloud. Since standard encryption and key management are avoided, our approach is computationally efficient and data confidentiality is maintained.</description><description>La sécurité a émergé comme l'aspect le plus redouté de l'informatique en nuage et comme un obstacle majeur pour les clients. Le cadre actuel de l'informatique en nuage ne permet pas que les données chiffrées soient stockées en raison de l'absence de schémas efficaces de cryptage qui permettent l'exécution des requêtes sur une base de données des nuages. Le stockage des données non cryptées expose les données non seulement à un agresseur extérieur, mais aussi au fournisseur de nuage lui-même. Ainsi, faire confiance à un fournisseur avec des données confidentielles est très risqué.Afin de permettre des requêtes sur une base de données des nuages sans compromettre la confidentialité des données, nous proposons d'utiliser l'obscurcissement des données à travers la cryptographie visuelle. Un nouveau schéma pour la cryptographie visuelle est développé et configuré pour le nuage pour stocker et récupérer des données textuelles. Tester le système avec l'exécution des requêtes sur une base de données nuée indique une grande précision dans la récupération des enregistrements avec négligeables faux positifs. En outre, le système est résistant aux attaques de l'intérieur et l'extérieur du nuage. Parce que le cryptage standard et la gestion des clés sont évités, notre approche est mathématiquement efficace et la confidentialité des données est assurée.</description><creator>Maheshwari, Varun</creator><contributor>Muthucumaru Maheswaran (Internal/Supervisor)</contributor><date>2012</date><subject>Applied Sciences - Computer Science</subject><title>Data confidentiality and keyword search in the cloud using visual cryptography</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/0g354k315.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/bn999b80c</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:5x21tk60g</identifier><datestamp>2020-03-23T05:02:55Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Lattice basis reduction is a powerful tool for solving complex problems both in pure mathematics and practical applications. In this thesis, we use lattice basis reduction as a preconditioning technique to accelerate the real relaxation based branch and bound (RRBB) method for solving integer least squares (ILS) problems. We give theoretical arguments and simulation results to show that applying lattice preconditioning to the RRBB method can greatly reduce the size of the RRBB tree for ordinary ILS problems, making the method more efficient. We then propose new reduction strategies, which are more effective than some typical existing reduction strategies for lattice preconditioning. Finally we extend the preconditioning techniques to the RRBB method for box-constrained and more general linear-inequality constrained ILS problems. Numerical test results indicate lattice preconditioning is also very effective to reduce the computation time of the RRBB method for these constrained problems.</description><description>Les techniques de réduction de réseaux est un outil puissant pour résoudre des problèmes complexes tant en mathématiques pures et les applications pratiques. Dans cette thèse, nous utilisons reduction de réseaux comme une technique de préconditionnement pour accélérer la branche réelle détente et de base lié (RRBB) méthode pour résoudre les problèmes de moindres carrés en nombres entiers (ILS). Nous donnons des arguments théoriques et des résultats de simulation pour montrerque l'application de treillis de préconditionnement de la méthode RRBB peut réduire considérablement la taille de l'arbre RRBB pour des problèmes ILS ordinaires, cequi rend la méthode plus efficace. Nous proposons ensuite de nouvelles stratégies de réduction, qui sont plus efficaces que certaines stratégies de réduction de type existants pour le préconditionnement treillis. Enfin nous étendons les techniques de préconditionnement de la méthode RRBB pour la contrainte des boîtes et des contraintes linéaires-inégalité plus générales des problémes ILS. Les résultats des simulations numériques indiquent que le préconditionnement treillis est également très efficace pour réduire le temps de calcul de la méthode RRBB pour ces problèmes contraints.</description><creator>Ku, Wen-Yang</creator><contributor>Xiao-Wen Chang (Internal/Supervisor)</contributor><date>2012</date><subject>Applied Sciences - Computer Science</subject><title>Lattice preconditioning for the real relaxation based branch and bound method for integer least squares problems</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/n296x319j.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/5x21tk60g</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:4q77fw678</identifier><datestamp>2020-03-23T05:02:55Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Ce mémoire examine le concept du noyau irréductible en droit des trusts, ainsi que les raisons justifiant l'élaboration et la réalisation du concept dans les juridictions éminentes du Commonwealth de l'Angleterre et du Pays de Galle, de l'Australie, du Canada, et de la Nouvelle-Zélande. Une étude comparative du régime de règles impératives en droit des trusts américains est également entreprise afin de comparer et de mettre en contraste la nature juridique fondamentale du trust dans la tradition de common law. Ce mémoire porte également une attention particulière aux développements dans la pratique extraterritoriale des trusts et tente d'adresser certains défis contemporains reliés au droit des trusts qui remettent en question la compréhension conventionnelle des trusts. Une revue exhaustive de la littérature et de la jurisprudence internationale sur l'approche du noyau irréductible aux trusts est présentée. Ces secteurs d'intérêt sont explorés davantage afin d'articuler de manière complète et précise le concept du noyau irréductible du trust. Une théorie relationnelle des trusts est proposée dans ce mémoire. Cette théorie s'inspire en grande partie du schéma Hohfeldien des relations juridiques, dont un aperçu est également présenté. Ensuite, le mémoire identifie et examine chacune des relations juridiques essentielles constituant le noyau irréductible du trust en appliquant la théorie relationnelle des trusts. Ce mémoire propose que le concept du noyau irréductible en droit des trusts puisse être appliqué hors du contexte de la dynamique interne fiduciaire-bénéficiaire pour rejoindre l'externalité du trust, qui reflète les effets significatifs des trusts sur les tiers. Ceci représente un nouveau développement important sur le sujet. Selon ce mémoire, chacune des relations juridiques identifiées qui sont comprises dans le noyau irréductible du trust sert l'ambition importante de garantir la sécurité juridique des trusts et assiste à la classification juridique des trusts dans un cadre rationnel et cohérent du droit privé.</description><description>This thesis examines the irreducible core concept in trust law, as well as the justifications for its further development and realisation throughout the prominent Commonwealth jurisdictions of Australia, Canada, England &amp; Wales and New Zealand. A comparative analysis of the mandatory rules regime in United States trust law is also undertaken in order to compare and contrast the essential, juridical nature of the trust throughout the common law tradition. This thesis also pays particular attention to developments in the offshore practice of trusts and attempts to work through some of the contemporary challenges in trust law that strain the orthodox understanding of the trust. A comprehensive overview of the existing literature and international case law on the irreducible core approach to trusts is provided. Those lines of enquiry are then extended further in order to articulate more fully and precisely the irreducible core content of the trust. A relational theory of trusts is proposed in this thesis that draws heavily from the Hohfeldian schema of jural relations–an overview of which is also provided. The thesis then goes on to identify and explore each of the essential legal relations that comprise the irreducible core of the trust by applying the relational theory of trusts. A significant new development that is proposed in this thesis is that the irreducible core concept in trust law logically extends beyond the internal dynamic of trustee-beneficiary to embrace the externality of the trust, which reflects the important effects that trusts have on third parties. It is argued that each of the legal relations identified as forming part of the irreducible core of the trust serve the important juristic ambitions of ensuring that trustees are accountable and that trusts are enforceable as a matter of law and assist in the juridical classification of trusts within a rational and coherent structure of the private law. </description><creator>Clarry, Daniel</creator><contributor>Lionel David Smith (Internal/Supervisor)</contributor><date>2012</date><subject>Social Sciences - Law</subject><title>The irreducible core of the trust</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/fq978005j.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/4q77fw678</identifier><degree><name>Master of Laws</name><grantor>McGill University</grantor><discipline>Faculty of Law</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:sx61dr18g</identifier><datestamp>2020-03-23T05:02:55Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>L'immense croissance de l'utilisation des données mobiles a placé les opérateurs mobiles dans une position difficile. L'expérience utilisateur est menacée de se dégrader en raison de problèmes de capacité du réseau. La route vers la mise à niveau du réseau est coûteuse en particulier en raison des frais de licence élevés attachés à l'acquisition du spectre. Nous proposons un schéma basé sur l'identification communautaire pour la distribution de gros fichiers à des abonnés en utilisant la communication opportuniste. Le système est capable de se décharger de gros fichiers sur le réseau cellulaire et sans avoir à investir dans n'importe quelle infrastructure. Le réseau cellulaire d'abord les graines du fichier à l'abonné la plus centrale dans chaque communauté, qui est ensuite étendue à tous les abonnés via des contacts opportunistes. Réseau de codage est utilisé pour l'échange de paquets de fichiers opportunistes entre les abonnés. Nous montrons que l'ensemencement du fichier dans chaque communauté est important pour assurer une meilleure délais de livraison du fichier et réduit également la surcharge du nombre d'échanges de paquets nécessaires pendant la diffusion de fichiers. Notre programme prévoit également des incitations pour les abonnés influents dans le réseau qui contribuent davantage vers la diffusion opportuniste de fichier.</description><description>The immense growth in mobile data usage has placed mobile operators in a challenging position. User experience is threatened to degrade due to network capacity issues. The route towards network upgrades is an expensive one especially due to the high licensing fees attached to spectrum acquisition. We propose a scheme based on community identification for distributing large files to subscribers using opportunistic communication. The scheme is able to offload large files from the cellular network and without having to invest in any infrastructure. The cellular network initially seeds the file to the most central subscriber in each community which is then spread to all subscribers via opportunistic contacts. Network coding is utilized for the opportunistic exchange of file packets between subscribers. We show that seeding the file in each community is important to ensure better file delivery times and also reduces the overhead of the number of packet exchanges required during file dissemination. Our scheme also provides incentives for influential subscribers in the network which contribute more towards the opportunistic dissemination of file.</description><creator>Masood, Syed Haani</creator><contributor>Mark Coates (Internal/Supervisor)</contributor><date>2012</date><subject>Engineering - Electronics and Electrical</subject><title>Distribution of files using network-coding in opportunistic networks</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/gf06g6545.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/sx61dr18g</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:5999n729n</identifier><datestamp>2020-03-23T05:02:56Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Hans Werner Henze's active engagement in socialist politics began in 1967 when he joined the Socialist League of German Students in Berlin. Most scholars who write about him as a political figure focus on his involvement after this time. They tend to overlook the earlier years, when Henze was far less involved in socialist politics and far more concerned with the resurgence of fascism — a term he associated with "hatred, deception, betrayal, racism, the loss of human dignity," not to mention "xenophobia, provincialism, and militarism." Like many artists and intellectuals in his generation, Henze felt the direct influence of fascism on his community as he watched his fellow countrymen succumb to National Socialist ideology. After the war, he was disappointed to see fascism continue to live on in society, as well as in Darmstadt's dogmatic control over the postwar music scene. In light of his strong antifascist convictions, Henze broke away from the Darmstadt elite, who wished to distance music from society, and instead advocated for the redemptive value of music as politically committed art. Although the antifascist politics of his early career and how it plays out in his works have been given little focus in current scholarship, Henze's relationship to fascism is central to his identity as a composer in the postwar years and to understanding his later political journey. Taking that as its point of departure, this thesis explores some of Henze's earliest attempts to engage with his antifascist politics in his compositions. Looking specifically at the years 1960 to 1965, it is structured around case studies of three works: Jüdische Chronik (1960–61), a cantata that responds to acts of anti-Semitic vandalism; Der Junge Lord (1963–64), a comic opera that warns of a dark future for Germany; and In memoriam: Die Weiße Rose (1964–65), a double fugue for chamber ensemble written in honor of the Munich resistance movement. While the particularities of these works make it difficult to construct a precise representation of Henze's political development, they do project a general trajectory in his career from a state of political insecurity to a feeling of social responsibility. Furthermore, the three case studies — a statement of protest, a social critique, and a memorial — shed light on the composer's thoughts, as well as on the people and circumstances that shaped his outlook on the world. By revealing these early examples of politically committed works, this thesis demonstrates that Henze's turn to socialist activism in the late 1960s was not as precipitous as it is often portrayed.</description><description>La participation active de Hans Werner Henze dans la politique socialiste débute en 1967 lorsqu'il se joint à l'Union socialiste allemande des étudiants à Berlin. La plupart des chercheurs qui se sont intéressés aux activités politiques de Henze se sont concentrés sur son implication après cette période. Peu d'attention a été accordée aux premières années, durant lesquelles Henze était moins préoccupé par le socialisme que par la résurgence du fascisme — un terme qu'il associait à d'autres comme « haine, déception, trahison, racisme, perte de la dignité humaine », sans mentionner « xénophobie, provincialisme et militarisme ». Comme plusieurs artistes et intellectuels de sa génération, Henze a pu observer l'effet direct du fascisme dans sa communauté, alors qu'il voyait ses compatriotes se tourner vers l'idéologie national-socialiste. Après la guerre, il est déçu de voir le fascisme toujours vivant au sein de la société, notamment à travers le contrôle dogmatique exercé par Darmstadt sur la scène musicale de l'après-guerre. À la lumière de ses fortes convictions anti fascistes, Henze s'éloigne de l'élite de Darmstadt, qui souhaite séparer la musique de la société, et choisit plutôt de prôner le caractère rédempteur de la musique en tant qu'art politique. Malgré que la recherche actuelle ne se soit pas encore concentrée sur la pensée anti fasciste de Henze aux débuts de sa carrière et ses conséquences sur son œuvre, l'attitude de Henze vis-à-vis du fascisme fait partie intégrante de son identité de compositeur dans les années d'après-guerre, en plus d'être un aspect crucial dans la compréhension de ses activités politiques ultérieures. Partant de ce point, cette thèse examine certaines des premières œuvres de Henze reflétant sa pensée anti fasciste. Traitant particulièrement des années 1960 à 1965, le travail s'articule autour de trois études de cas: Jüdische Chronik (1960–61), une cantate écrite en réponse à des actes de vandalisme antisémites; Der Junge Lord (1963–64), un opéra comique qui prédit un avenir sombre pour l'Allemagne; et In memoriam: Die Weiße Rose (1964–65), une double fugue pour orchestre de chambre écrite en l'honneur du mouvement de résistance de Munich. Si les caractéristiques individuelles de ces œuvres rendent difficile toute représentation précise du développement politique de Henze, elles témoignent cependant d'une trajectoire générale qui le mènera d'un état d'insécurité politique à un sentiment de responsabilité sociale. De plus, les trois cas à l'étude — une déclaration de protestation, une critique sociale, et une commémoration — font la lumière sur la pensée du compositeur ainsi que sur les personnes et les circonstances qui ont façonné sa vision du monde. En révélant ces exemples précoces d'œuvres engagées politiquement, cette thèse démontre que Henze n'a pas embrassé l'activisme socialiste aussi précipitamment qu'il est généralement admis.</description><creator>Cooperman, Daniel</creator><contributor>Lloyd Whitesell (Internal/Supervisor)</contributor><date>2012</date><subject>Communications And The Arts - Music</subject><title>Hans Werner Henze's early political thought: three case studies</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/j67318130.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/5999n729n</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Schulich School of Music</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:7s75dh54q</identifier><datestamp>2020-03-23T05:02:56Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Historique : Comparé aux systèmes de déclaration gouvernementaux traditionnels, les sources d'information non gouvernementales (ou informelles) sont réputées produire des avertissements plus précoces en terme d'éclosion de maladies, facilitant ce faisant la reconnaissance rapide et une réponse prompte aux flambées épidémiques naissantes et aux potentielles pandémies. Malgré un recours accru aux systèmes de déclaration informels, il existe peu de preuves empiriques pour supporter cette affirmation. Dans ce projet, nous avons examiné (1) si la source originale de l'information sur une flambée épidémique (gouvernemental ou non gouvernementale) était un facteur explicatif dans la déclaration précoce de flambées épidémiques et (2) l'évolution des communications sur les flambées épidémiques par les sources gouvernementales et non gouvernementales.Méthodes : En utilisant une base de données comptant 398 flambées épidémiques infectieuses distinctes sélectionnées à partir du « Disease Outbreak News » de l'Organisation Mondiale de la Santé de 1996 à 2009, nous avons identifié la ou les sources et la date de la première communication au sujet de cette flambée épidémique, au moyen des archives de ProMED-mail. Des modèles de régression négative binomiale ont été utilisés pour évaluer les différences et améliorations en terme de déclaration rapide de flambées épidémiques (comparé à la date présumée de leur début), par type de sources.Résultats : Nous n'avons trouvé aucune différence statistiquement significative dans la rapidité des communications au sujet des flambées épidémiques entre celles rapportées en premier par des sources non gouvernementales comparées à celle déclarées en premier par des sources gouvernementales pour la période 1996-2009 (IRR=0.95, 95% CI [0.77, 1.18]). De plus, bien que les deux types de sources rapportent les flambées épidémiques plus rapidement, une amélioration statistiquement significative n'a été notée que pour les sources gouvernementales (IRR=0.94, 95% CI [0.91, 0.97]). Conclusion : À notre connaissance, il s'agit de la première étude à quantifier la rapidité des communications au sujet de flambées épidémiques provenant des sources gouvernementales et non gouvernementales, touchant une période étendue et une variété de maladies. Bien qu'aucune différence statistiquement significative n'a été démontrée entre ces deux types de sources, nos résultats sont limités à un petit échantillon de flambées épidémiques confirmées par l'OMS.  D'autres études sont nécessaires pour confirmer ces résultats.</description><description>Background: Nongovernmental (or informal) information sources have been credited with raising earlier warnings of disease threats than traditional governmental reporting systems, thus facilitating the rapid recognition and response to potential pandemics and emerging disease outbreaks.  Despite an increased global reliance on informal reporting systems, little empirical evidence exists to support this assertion. In this project we examined (1) whether the original source of outbreak information (governmental or nongovernmental) was an explanatory factor in the timely reporting of outbreaks, and (2) trends in outbreak communication by governmental and nongovernmental sources. Methods: Using a database of 398 unique human infectious disease outbreaks reported in the World Health Organization's "Disease Outbreak News" from 1996-2009, we identified the source(s) and date of the earliest outbreak communication from ProMED-mail's archives. Negative binomial regression models were used to estimate the effect of reporting source (i.e., governmental or nongovernmental) on the timeliness of outbreak communication. Results:  Over the period 1996–2009, we found no statistically significant difference in communication timeliness for outbreaks reported first by nongovernmental sources compared to outbreaks communicated first by governmental sources (IRR=0.95, 95% CI [0.77, 1.18]). We observed a trend towards communicating outbreaks more quickly over time for both governmental and nongovernmental sources, but this trend was statistically significant only for governmental sources (IRR=0.94, 95% CI [0.91, 0.97]). Conclusion: To our knowledge, this study is the first to quantify the timeliness of outbreak communications from governmental and nongovernmental sources over time and across a range of diseases.  While we observed no statistically significant differences in reporting speed between these sources, our study was limited to a small sample of WHO-confirmed outbreaks.  Further research is therefore needed to build upon our results.</description><creator>Mondor, Luke</creator><contributor>Timothy Brewer (Supervisor1)</contributor><contributor>David Buckeridge (Supervisor2)</contributor><date>2012</date><subject>Health Sciences - Epidemiology</subject><title>Does source matter? Using ProMED-mail to compare the timeliness of outbreak communications from governmental and nongovernmental sources</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/h415pf65j.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/7s75dh54q</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Epidemiology and Biostatistics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:mp48sh83b</identifier><datestamp>2020-03-23T05:02:57Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Over the last two decades, a large amount of research has focused on natural cellulose fibers, since they are "green" and renewable raw materials. Recently, nanomaterials science has attracted wide attention due to the large surface area and unique properties of nanoparticles. Cellulose certainly is becoming an important material in nanomaterials science, with the increasing demand of environmentally friendly materials.In this work, a novel method of preparing cellulose nanofibers (CNF) is being presented. This method contains up to three oxidation steps: periodate, chlorite and TEMPO (2,2,6,6-tetramethylpiperidinyl-1-oxyl) oxidation. The first two oxidation steps are investigated in the first part of this work. Cellulose pulp was oxidized to various extents by a two step-oxidation with sodium periodate, followed by sodium chlorite. The oxidized products can be separated into three different fractions. The mass ratio and charge content of each fraction were determined. The morphology, size distribution and crystallinity index of each fraction were measured by AFM, DLS and XRD, respectively. In the second part of this work, CNF were prepared and modified under various conditions, including (1) the introduction of various amounts of aldehyde groups onto CNF by periodate oxidation; (2) the carboxyl groups in sodium form on CNF were converted to acid form by treated with an acid type ion-exchange resin; (3) CNF were cross-linked in two different ways by employing adipic dihydrazide (ADH) as cross-linker and water-soluble 1-ethyl-3-[3-(dimethylaminopropyl)] carbodiimide (EDC) as carboxyl-activating agent. Films were fabricated with these modified CNF suspensions by vacuum filtration. The optical, mechanical and thermo-stability properties of these films were investigated by UV-visible spectrometry, tensile test and thermogravimetric analysis (TGA). Water vapor transmission rates (WVTR) and water contact angle (WCA) of these films were also studied.</description><description>Au cours des deux dernières décennies, une grande quantité de recherches ont portées sur les fibres de cellulose naturels, car ils sont «verts» et de matières premières renouvelables. Récemment, la science des nanomatériaux a attiré l'attention en raison de la gamme grande surface et les propriétés uniques des nanoparticules. La cellulose est en train de devenir un matériau important dans la science des nanomatériaux, à la demande croissante de matériaux écologiques. Dans ce travail, un nouveau procédé de préparation de cellulose nanofibres (CNF) est présenté. Cette méthode contient un maximum de trois étapes d'oxydation: oxydations au periodate, au chlorite et au TEMPO (2,2,6,6-tétraméthylpipéridinyle-1-oxyle). Les deux premières étapes d'oxydation sont étudiées dans la première partie de ce travail. La pâte de cellulose a été oxydée à des degrés divers par un à deux étapes d'oxydation au periodate de sodium, suivi par le chlorite de sodium. Les produits oxydés peuvent être séparés en trois fractions différentes. Le ratio de la masse et le contenu de charge de chaque fraction ont été déterminés. La morphologie, la distribution de la taille et l'indice de cristallinité de chaque fraction ont été mesurés par l'AFM, DLS et XRD, respectivement. Dans la seconde partie de ce travail, des CNF ont été préparés et modifiés dans diverses conditions, y compris (1) l'introduction de diverses quantités de groupes aldéhyde sur les CNF par oxydation au periodate, (2) les groupes carboxyle sous forme de sodium sur les CNF ont été convertis à leur forme acide par traitement avec un type d'acide résine échangeuse d'ions; (3) ces CNF ont été réticulés de deux manières différentes en employant dihydrazide adipique (ADH) en tant que cross-linker et soluble dans l'eau 1-éthyl-3-[3- (diméthylaminopropyl)] carbodiimide (EDC) comme agent activateur de carboxyle. Les films ont été fabriqués avec ces suspensions de CNF modifiés par filtration sous vide. Les propriétés optiques, mécaniques et la thermo-stabilité de ces films ont été étudiées par spectrométrie UV-visible, essai de traction et de l'analyse thermogravimétrique (TGA). Les taux de transmission de vapeur d'eau (WVTR) et l'angle de contact de l'eau (WCA) de ces films ont également été étudiés.</description><creator>Yang, Han</creator><contributor>Theodorus G Van de Ven (Internal/Supervisor)</contributor><date>2012</date><subject>Chemistry - Polymer</subject><title>Investigation and characterization of oxidized cellulose and cellulose nanofiber films</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/5712mb94g.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/mp48sh83b</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Chemistry</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:8p58pj001</identifier><datestamp>2020-03-23T05:02:57Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The Internet has broadened the meaning of identity. In real life, we normally have fixed identities. Earlier on the Internet, pseudonym was invented to identify users. As social networks came into play, social identity was introduced. While fixed identity is the most secure one, it restricts the freedom people have on the Internet. Although pseudonym is the easiest one to create among the three identity types, it makes it equally easy for malicious users to cheat on other people. One way malicious users can perform attacks on others with pseudonym is by whitewashing, where the malicious user takes advantage of the victim, with either pre-designed plots or simply by breaking pre-defined rules, and disappear on the network but later re-join the network with a new identity so that no one would know about his previous activities. Social identity differs from the other two by making use of the relations between two people and protecting both the individual user's privacy and the organization's security. This thesis studies the effect of whitewashing under different identity types and compares their behaviors of resisting whitewashing. We use game theory to model the process of whitewashing and compute its effect upon the whole population for each identity type. In most of the cases, social identity is better at eliminating whitewashers. Besides, the Matlab simulation experiments reveal additional interesting facts about the three identity types that might shed light on future identity management schemes.</description><description>Le sens du mot "identité" s'élargit dans le contexte d'Internet. Dans la vraie vie, sauf dans des cas très particuliers, nous avons une identité fixe. Très tôt sur Internet, on a eu recours aux pseudonymes pour identifier les usagers. Avec l'évolution des réseaux sociaux est venue l'identité sociale ("social identity" en Anglais). Bien qu'elle représente le mode d'identité le plus sécuritaire, l'identité fixe impose des limites importantes qui la rendent difficile d'utilisation sur Internet. Parmi les trois modes d'identité, le pseudonyme est le plus facile à créer, mais il permet aussi aux usagers malveillants de facilement abuser de la confiance des autres. Suite aux actes malhonnêtes (arnaques ou  non respect des règles établies, par exemple), un usager malveillant peut changer de pseudonyme pour blanchir son identité ("whitewashing" en anglais). Il disparaît donc du réseau pendant un certain temps pour réapparaitre plus tard sous une nouvelle identité aucunement liée à l'ancienne. L'identité sociale diffère de l'identité fixe et des pseudonymes en se basant sur les relations entre deux personnes tout en protégeant la vie privée de l'utilisateur et la sécurité de l'organisation.Cette thèse analyse les effets du blanchissage selon le mode d'identité utilisé et compare les différents comportements de résistance au blanchissage. La théorie des jeux est utilisée pour modéliser le blanchissage et calculer son effet sur la population pour chaque mode d'identité utilisé. Dans la majorité des cas, l'identité sociale est plus apte à éliminer les blanchisseurs. Des simulations Matlab révèlent aussi des faits intéressants au sujet des trois modes d'identité qui pourraient aider à l'élaboration de futurs systèmes de gestion d'identité.</description><creator>Xu, Yijia</creator><contributor>Muthucumaru Maheswaran (Internal/Supervisor)</contributor><date>2012</date><subject>Applied Sciences - Computer Science</subject><title>Resisting whitewashing: a comparative study of fixed identity, pseudonym, and social identity</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/pz50h146j.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/8p58pj001</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:5712mb95r</identifier><datestamp>2020-03-23T05:02:58Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Breast cancer is considered the second most commonly diagnosed type of cancer across the world.  The common modes of treatment are limited by severe side-effects that hinder the efficacy of the drugs, compromise the patients' quality of life and often lead to other disorders. One of the main focuses of nanobiotechnology research is to develop novel anti-cancer drug delivery systems that improve the drug efficacy, limit harmful side effects and also allow for the delivery of developing therapeutics that are rapidly degraded in circulation, such as small interfering RNA (siRNA). Nano-carriers are helpful particularly in anti-cancer drug delivery due to the Enhanced Permeability and Retention (EPR) effect. In the current research study, we developed and investigated the use of surface modified HSA nanoparticles for the delivery of anti-cancer therapeutics in breast cancer applications.  Results showed formation of modified HSA nanoparticles of sizes below 150 nm and contained a positive surface charge. The cellular uptake of the nanoparticles was higher in coated particles (average: ~70%) than uncoated particles. Furthermore, the cytotoxicity assessment of modified HSA nanoparticles suggested that empty particles are biocompatible and non-toxic to cells.  Therefore, the presented PEI-enhanced and TAT-coated HSA nanoparticles form an appealing delivery system for anti-cancer therapeutics with a potential for clinical application.</description><description>Le cancer du sein est considéré comme le deuxième type de cancer le plus couramment diagnostiqué à travers le monde. La plupart des traitements sont characterisés par des effets secondaires nocifs qui limitent l'efficacité des médicaments, compromettent la qualité de vie des patients et conduisent souvent à d'autres troubles nocifs. L'un des principaux axes de recherche en nanobiotechnologie est de développer un nouveaux système de délivrance qui permet d'améliorer l'efficacité du médicament, de limiter les effets secondaires nocifs et aussi de permettre la livraison de molecules qui sont rapidement dégradées dans la circulation, tels que les petits ARN interférents (siRNA). Les nano-transporteurs sont utiles en particulier dans l'administration de médicaments anticancerigenes en raison de leur perméabilité accrue et de leur conservation (EPR). Dans l'étude de la recherche actuelle, nous avons développé et étudié l'utilisation de nanoparticules HSA à surface modifiée pour la livraison de médicaments anticancéreux dans les applications de cancer du sein. Les résultats ont montré la formation de nanoparticules HSA de tailles modifiées en dessous de 150 nm contenant une charge de surface positive. L'absorption cellulaire des nanoparticules est plus élevée dans les particules enrobées (moyenne: ~ 70%) que les particules non enrobée. Par ailleurs, l'évaluation de la cytotoxicité des nanoparticules HSA modifiées a suggéré que les particules vides sont biocompatibles et non toxiques pour les cellules. Par conséquent, les nanoparticules HSA revêtues de TAT et PEI-améliorée forment un système de prestation idéale pour les thérapies anti-cancereuses avec un potentiel d'application clinique. </description><creator>Abbasi, Sana</creator><contributor>Satya Prakash (Internal/Supervisor)</contributor><date>2012</date><subject>Biology - General</subject><title>Preparation and in vitro characterization of modified bio-degradable albumin-based nanoparticles for the efficient delivery of therapeutic drugs and genes in breast cancer applications</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/000004081.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/5712mb95r</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Biomedical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:kk91fq94p</identifier><datestamp>2020-03-23T05:02:58Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Infants understand others' goals and use them to predict others' actions. Do 9.5-month-olds understand that others can act on the basis of goals not tied to specific objects? Particularly, do infants understand that a person's goal could be to select either the bigger (smaller) of two objects, a goal based on object relations? Across 4 familiarization trials, each with a different pair of objects differing only in size, an Experimenter selected either the bigger (Big object condition) or smaller (Small object condition) of two objects. In test trials with new objects, in the Big object condition, infants looked longer when the Experimenter selected the smaller than the bigger object, but in the Small object condition they looked about equally at the two test events (Experiment 1). Conditions under which the goal of smaller could be understood were further explored. Infants provided with additional information about the Experimenter's goal still looked equally at the two test events (Experiment 2), while those encouraged to compare object size both within and between pairs, looked longer when the Experimenter selected the bigger object than the smaller object (Experiment 3). 9.5-month-olds seem to understand that a person's goal can be to select either the bigger or smaller of two objects. The goal of smaller seems to be more difficult, perhaps due to infants' own preference for larger quantities or because their understanding of the size concept of small. The results suggested that infants' understanding of size relational goals involves the comprehension of the relational category of the object (big or small) and the ability to use that information to make sense of others' actions.</description><description>Les jeunes enfants comprennent les buts des autres et prédisent leurs actions en se basant sur cette compréhension. Les enfants de 9,5 mois comprennent-ils que les autres peuvent agir en fonction d'un but relationnel (des buts qui ne sont pas liés à un objet spécifique)? En particulier, est-ce que les enfants comprennent que l'expérimentateur veut toujours prendre l'objet le plus grand (ou le plus petit), un but basé sur des relations entre objets? Pendant 4 événements de familiarisation, chacun avec une paire d'objets identiques mais de différentes tailles, l'Expérimentateur choisi soit le plus grand (Condition du grand objet) ou le plus petit (Condition du petit objet) des deux objets. Dans les événements tests avec de nouveaux objets, dans la Condition du grand objet, les enfants regardent plus longtemps lorsque l'Expérimentateur choisi le plus petit des deux objets. Par contre, dans la Condition du petit objet, les enfants ont regardé à peu près également dans les deux tests (Expérience 1). Deux autres expériences avec le but du petit objet ont été explorées. Les enfants ayant obtenu des informations supplémentaires sur le but de l'Expérimentateur regardaient toujours également aux deux événements tests (Expérience 2). Contrairement, ceux invités à comparer la taille des objets de chaque paire et entre les paires, ont regardé plus longtemps lorsque l'Expérimentateur choisi le plus grand objet des deux objets (Expérience 3). Les enfants de 9,5 mois semblent comprendre que le but d'une personne peut être de choisir les plus grands ou plus petits objets. Comprendre que l'Expérimentateur a le but de choisir un petit objet semble être plus difficile, peut-être à cause de la préférence pour les grandes quantités chez les enfants eux-mêmes, ou pour leur compréhension du concept de petit. Les résultats suggèrent que la compréhension des buts relationnels implique la compréhension de la catégorie relationnelle de l'objet (grand ou petit) et la possibilité d'utiliser cette information pour comprendre les actions des autres.</description><creator>Horcasitas-Ruiz, Denisse</creator><contributor>Kristine Onishi (Supervisor)</contributor><date>2012</date><subject>Psychology - Developmental</subject><title>Infants' understanding of relational goals</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/8c97kv45c.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/kk91fq94p</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Psychology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:vt150p152</identifier><datestamp>2020-03-23T05:02:58Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Bone tissue engineering (BTE) has emerged as a promising solution to heal the millions of people worldwide that suffer from bone degenerative pathologies and bone fractures. Since bone is a biocomposite of type I collagen nanofibres (namely osteoid) reinforced with nanocrystals of carbonated hydroxylapatite (CHA), reconstituted type I collagen gels are an attractive choice as scaffolds for BTE. However, to date, the design of a collagenous bone-like construct ready to be implanted is far from being accomplished, as collagen matrices are difficult to mineralize. The aim of this doctoral research was to design and evaluate strategies to rapidly achieve an acellular mineralization of an osteoid-like dense collagen gel for potential applications in bone regeneration. It was hypothesized that the collagen fibrillar density (CFD) affects the microenvironment and the physical properties of the framework of collagen gels.  To test this hypothesis, and as a first objective, the mineralization of collagen gel with increasing CFDs was investigated in simulated body fluid (SBF). Collagen gels with physiologically relevant CFDs led to greater extent of mineralization, when compared to highly hydrated gels. It was therefore proposed that the increase in gel CFD led to a more physiological microenvironment, which facilitated the mineral formation and validated the proposed osteoid model. As a second objective, the mineralization of dense collagen (DC) gels was enhanced and accelerated by mimicking the role of anionic non collagenous proteins (NCPs) in the native osteoid, which act as CHA nucleators. Two strategies were implemented: first, the influence of collagen fibrillization pH on the extent of DC gel mineralization was investigated. Since the collagen molecule is slightly positively charged at physiological pH, it was hypothesized that it would be more negatively charged if formed in an alkaline environment, i.e., above its isoelectric point.  This hypothesis was validated by investigating the electrostatic properties of collagen gels formed at physiological pH (7.4) and at pH values of 8.2 and 9.0. The effect of alkaline fibrillization pH on DC gel mineralization was evident by the extensive mineralization and the soft to hard transition of the gels by day 14 in SBF. Second, anionic fibroin derived polypeptides (Cs) were introduced, for the first time as easily produced alternatives to NCPs.  Apatite was formed within 6 hours in SBF and by day 7, CHA crystals were homogenously distributed throughout the roll gels resulting also in a transition from soft-to-hard tissue-like response to compressive testing. As a third objective, a bioinorganic approach to enhance and accelerate the mineralization of collagen was developed. DC gels were combined with silica-based 45S5 bioactive glass of micron- and nano-sized particles (μBG and nBG, respectively) to investigate the effect of an osteoconductive and osteoinductive bioactive glass on collagen mineralization. DC-μBG gels conditioned in SBF resulted in the extensive mineralization of the collagenous framework. Furthermore, the effect of nBG on the mineralization of DC and its effect on seeded pre-osteoblastic cells, were also investigated. Compared to μBG, nBG particles resulted in an enhanced and accelerated mineralization of the collagen matrix when immersed in SBF. Apatite formation was immediately detected within as processed DC-nGB hybrid gels, and by day 7 there was a 13 fold increase in the hybrid gel scaffold compressive modulus. The metabolic activity of MC3T3-E1 cells was affected by the presence of nBG, indicating accelerated osteogenic differentiation in the absence of osteogenic supplements, suggesting the potential of DC-nBG scaffolds to be used as cell-seeded constructs. In conclusion, since the role of the collagen framework microstructure on its mineralization has been previously ignored, the present doctoral dissertation provides new insights into collagen mineralization.</description><description>Des millions de personnes dans le monde souffrent de maladies osseuses. Les techniques chirurgicales actuelles font appel à l'autogreffe, à l'allogreffe, à la xénogreffe et à la greffe de matériaux artificiels. Cependant, comme ces interventions comportent plusieurs inconvénients, l'ingénierie tissulaire de l'os (ITO) est apparue comme une solution prometteuse. Comme l'os est un biocomposite constitué de nanofibres de collagène de type I renforcées de nanocristaux d'hydroxylapatite carbonatée (HAC), les gels de collagène de type I représentent un choix attrayant pour la production de ces matrices. Toutefois, la minéralisation in vivo de ces matrices de collagène est difficile et la minéralisation in vitro n'est obtenue qu'après avoir soustrait les matrices des contraintes physiologiques, ce qui limite leur utilisation.Ces travaux s'appuyaient sur l'hypothèse selon laquelle la densité en fibrine du collagène (DFC) influe sur le microenvironnement et les propriétés physiques de la charpente de gels de collagène. Afin de vérifier cette hypothèse, et d'atteindre l'objectif premier de l'essai, la minéralisation de gel de collagène d'une DFC croissante a été réalisée dans du liquide organique simulé (LOS). Les gels de collagène d'une DFC physiologique ont permis d'obtenir une plus grande minéralisation et a aussi influé sur les propriétés électrostatiques des gels. Cette découverte suggère donc que l'augmentation de la DF du gel de collagène a permis de créer un microenvironnement plus physiologique, ce qui a facilité la formation minérale et a permis de valider le modèle proposé. Comme deuxième objectif, la minéralisation de gels de collagène dense a été améliorée et accélérée en reproduisant le rôle des protéines anioniques (PANC) au sein des ostéoïdes indigènes. Deux stratégies ont été mises en œuvre : étude de l'influence du pH des fibrines du collagène et de polypeptides anioniques dérivés de la fibroïne. Premièrement, la charge de la molécule de collagène étant légèrement positive dans un milieu doté d'un pH physiologique l'hypothèse est que un milieu dont le pH se situe au-dessus de son point isoélectrique, a été posée et validée. L'effet du pH alcalin durant la formation de fibrines sur la minéralisation du gel de collagène dense a été constaté par la quantité d'HAC formée; la matrice s'était largement minéralisée au jour 3. De plus, la minéralisation a significativement augmenté le module apparents des gels, rendant les structures autoportantes. Deuxièmement, la minéralisation de gels de collagène dense additionnés de 10 % poids de polypeptides anioniques dérivés de la fibroïne a été évaluée dans du LOS. De l'apatite s'était formée dans les 6 heures et des cristaux d'HAC étaient distribués de façon homogène dans les rouleaux de gels au jour 3.Le troisième objectif a été la mise au point d'une approche bio-inorganique en vue d'améliorer et d'accélérer la minéralisation du collagène. Des gels de collagène dense ont été additionnés de micro- et de nanoparticules de verre bioactif (μBG et nBG, respectivement) 45S5 à base de silice. Les gels de collagène dense additionnés de μBG préparés dans un LOS ont produit une importante minéralisation de la matrice de collagène. De plus, l'effet des nBG sur la minéralisation du collagène dense et son effet sur des cellules préostéoblastiques ensemencées ont aussi été étudiés. La formation d'apatite a immédiatement été détectée par la présence de gels hybrides de collagène dense contenant des nBG. Au jour 7, le module à la compression de la construction de gel hybride était 13 fois plus élevé. De plus, l'activité métabolique des MC3T3 cellules a été altérée par la présence des nBG, indiquant une différenciation ostéogénique accélérée en l'absence de suppléments ostéogéniques.En conclusion, le rôle des matrices de collagène à microstructures dans la minéralisation ayant été ignoré jusqu'ici, la présente dissertation doctorale jette un nouvel éclairage sur la minéralisation du collagène.</description><creator>Marelli, Benedetto</creator><contributor>Showan Nazhat (Internal/Supervisor)</contributor><contributor>Jake Barralet (Internal/Cosupervisor2)</contributor><date>2012</date><subject>Engineering - Materials Science</subject><title>In vitro mineralization of an osteoid-like dense collagen construct for bone tissue engineering</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/df65vc758.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/vt150p152</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Mining and Materials</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:qr46r508h</identifier><datestamp>2020-03-23T05:02:59Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>De nos jours, la réflexion instationnaire de choc est un domaine de recherche en plein essor dans lequel subsistent de nombreuses questions qui demeurent sans réponses. Un des aspects non résolus de la réflexion instationnaire de choc est la relation entre le rattrapage et les points soniques. Dans une expérience récente, Skews et Kleine ont constaté que le point de rattrapage est atteint à un angle de paroi plus élevé que le point sonique théorique prédit par la théorie de l'état stationnaire de deux-chocs. Cette thèse tente de faire la lumière sur ces questions via lanalyse numérique d´ecoulement des réflexions instationnaires de choc. Les calculs 2D sont effectués en utilisant un code localement adaptif non structuré pour la résolution numérique des équations d'Euler/Navier-Stokes instationnaire. A la première étape, un cadre général est présenté pour la modélisation numérique de la structure de l'onde de choc en utilisant les équations de Navier-Stokes sur un maillage adaptatif non structuré. Les résultats ainsi obtenus sont directement utilisés afin de choisir une grille de résolution nécessaire lorsque l'on étudie les problèmes de réflexion de choc dans un écoulement visqueux. Par la suite, diverses techniques basées sur l'analyse numérique d'écoulement sont introduites pour localiser le point sonique/rattrapage dans la réflexion instationnaire de choc. En vue de la localisation du point sonique/rattrapage les résultats obtenus avec ces techniques ne sont pas en accord avec les résultats expérimentaux de Skews et Kleine. Les raisons de ce désaccord entre les résultats expérimentaux et les études CFD actuelles sont étudiées en imitant la technique expérimentale utilisée pour la détermination du point de rattrapage. Il est démontré que la raison de ce désaccord réside dans le fait que l'épaisseur de choc sur les images expérimentales dépasse l'épaisseur physique de choc de quelques ordres de grandeur, ce qui entraîne une prédiction du point de rattrapage à des angles de paroi supérieur. Trois modèles d'écoulement sont étudiés afin de localiser le point sonique/rattrapage sur un cylindre circulaire. Le premier modèle est basé sur les équations d'Euler (non visqueux, non conducteur de chaleur) et les équations d'une surface réfléchissante idéale (conditions aux limites de paroi imperméable). L'expérience numérique sur ce cas montre que les points soniques et rattrapages sont identiques, convergeant vers le point sonique théorique après le raffinement de maillage. Les deux autres modèles sont destinés à étudier l'effet de la viscosité sur le point soniques / rattrapage. Dans un premier temps, la surface réfléchissante idéale (condition de glissement) est considérée. Il est démontré que pour ce cas, les points sonique et rattrapage sont encore les mêmes, mais les effets visqueux (l'épaisseur finie de choc) provoquent le point sonique/rattrapage d'être retardé (de se produire à des angles paroi inférieure) par rapport aux prédictions de la théorie de deux-chocs. Le modèle final utilise la surface réfléchissante réelle (condition non-glissement). Etant donné que la vitesse d'écoulement à la paroi est nulle dans ce modèle, le point sonique ne peut être obtenu sur la surface de réflexion. Cependant, le point de rattrapage peut être déterminé et analysé. Les résultats des simulations montrent quun retard encore plus grand est obtenu pour le point de rattrapage pour le cas visqueux avec la surface réfléchissante réelle (en présence de la couche limite) par rapport au cas visqueux avec la surface réfléchissante idéale.</description><description>A current literature review revealed that unsteady shock reflection is an active research field in terms of the number of still unanswered questions in this area. One of the unresolved aspects of unsteady shock reflection is the relationship between the catch-up and sonic points. In a recent experiment, Skews and Kleine found that the catch-up point is reached at a higher wall angle than the theoretical sonic point predicted by the steady-state two-shock theory. This thesis attempts to shed some light on these matters via numerical flowfield analysis of unsteady shock reflections. Two-dimensional computations are performed using a locally adaptive unstructured unsteady Euler/Navier-Stokes code. At the first stage, a general guideline for numerical modeling of shock wave front structure using the Navier-Stokes equations on adaptive unstructured grid is presented. Obtained results can be directly used for selection of grid resolution required to study shock reflection problems in a viscous flowfields. Then, various techniques for determination of the location of the sonic/catch-up points in unsteady shock reflection based on numerical flowfield analysis are introduced. The results obtained with these techniques regarding the sonic/catch-up points locations are not in agreement with the experimental results of Skews and Kleine. The causes of this disagreement between the experiments and the present CFD study are studied by imitating the experimental technique used for catch-up point determination. It is shown that the reason for this disagreement is that the shock thickness captured in experimental images exceeds the shock physical thickness by a few orders of magnitude, which leads to detection of the catch-up point at higher wall angles. Three flow models are studied to investigate the location of the sonic/catch-up points on a circular cylinder. The first model is based on the Euler (inviscid, non-heat-conducting) equations and an ideal reflecting surface (impermeable wall boundary condition). The computational experiment for this case shows that the sonic and catch-up points are actually the same points, which approach to the theoretical sonic point with grid refinement. The other two models are intend to study the effect of viscosity on the sonic/catch-up points. At first, the ideal reflecting surface (slip boundary condition) is considered. It is shown that for this case the sonic and catch-up points are again the same points, but the viscous effects (finite shock thickness) cause the sonic/catch-up point to be delayed (to occur at lower wall angles) as compared to the two-shock theory predictions. The final model employs the non-slip reflecting surface. Since in this model the flow velocity at the wall is zero, the sonic point cannot be obtained on the reflection surface; however, the catch-up point can be defined and analyzed. The results of the simulations show that even larger delay for the catch-up point is obtained for the viscous case with the non-slip reflecting surface (in the presence of the boundary layer) as compared to the viscous case with the ideal reflecting surface. </description><creator>Hakkaki-Fard, Ali</creator><contributor>Evgeny Timofeev (Supervisor)</contributor><date>2012</date><subject>Physics - Fluid and Plasma</subject><title>Study on the sonic point in unsteady shock reflections via numerical flowfield analysis</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/8910jz50r.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/qr46r508h</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Mechanical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:8c97kv46n</identifier><datestamp>2020-03-23T05:02:59Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>In North America, research on the issues surrounding first language (L1) literacy, English literacy, and computer literacy has tended to focus on the learning needs of either adult literacy learners whose L1 is English or ESL learners who are literate in their L1. ESL Literacy adults, who have limited or no L1 or English (L2) literacy, have fallen in the gap created by language policy and the resulting language programs and services provided at the federal, state/provincial, and local levels. This study explores what ESL Literacy adults believe their needs are in relation to L1, English, and computer literacy. The context is the existing ESL programs at two schools in the metro area of a large U.S. city in Massachusetts. Participants across the two schools included 19 females and 2 males with limited or no literacy in their first language and in English: five students were enrolled at a school that offered computer literacy as part of its curriculum. In a mixed methods research design, participants were administered a pre-class questionnaire and then a post-class questionnaire to determine if their attitudes and opinions regarding their L1, English (L2), and computer literacy needs had changed after 12 weeks of ESL instruction. The results were triangulated with interview and observation data and revealed that ESL Literacy adults at both schools considered computer literacy to be a basic tool for survival in today's digital society. The intent is that the results may be used as guidelines by ESL educators and program administrators in the modification of existing curricula or in the development of new ESL Literacy curricula that incorporate reading and writing through the use of computers and the internet in an authentic way.</description><description>En Amérique du Nord, la recherche touchant la littératie en première langue (L1), la littératie en anglais et la littératie informatique ont tendance à porter principalement sur les besoins des apprenants en littératie adultes dont la L1 est l'anglais ou des apprenants en ALS (anglais langue seconde) dont le niveau de littératie en L1 est adéquat. Les apprenants adultes en littératie en ALS, dont le niveau de littératie en L1 ou en anglais est limité ou inexistant, sont tombés par la brèche créée par les politiques linguistiques et les programmes et services en découlant fournis au niveau national, état/provincial et local. Cette étude explore ce que les apprenants adultes de littératie en ALS perçoivent comme étant leurs besoins en matière de littératie en L1, en anglais et en informatique. Elle s'est déroulée dans le contexte de deux écoles de la région métropolitaine d'une grande ville du Massachusetts offrant des programmes d'ALS. Pour ces deux écoles, 19 femmes et 2 hommes ont participé, dont le degré de littératie pour leur première langue et en anglais était limité ou inexistant : cinq étudiants étaient inscrits à une école qui offrait des cours de littératie informatique dans le cadre de leur curriculum. Dans un modèle de méthodes de recherches mixte, les participants ont reçu un questionnaire avant le début des cours et un questionnaire à la fin des cours afin de déterminer si leurs attitudes et leurs opinions au sujet de la littératie en L1, la littératie en anglais et la littératie informatique avaient changé après 12 semaines d'apprentissage en ALS. Les résultats ont été triangulés avec les données obtenues lors d'interviews et d'observations et ont révélé que les adultes de littératie en ALS aux deux écoles considéraient la littératie informatique comme étant un outil de base pour la survie dans la société numérique d'aujourd'hui. Le but est de permettre aux enseignants et aux administrateurs de programmes d'ALS d'utiliser ces résultats comme lignes directrices pour la modification de curriculums existants ou pour le développement de nouveaux curriculums de littératie en ALS qui intègrent la lecture et l'écriture grâce à l'utilisation authentique d'ordinateurs et de l'Internet.</description><creator>Thieves, Cleide</creator><contributor>Carolyn E Turner (Internal/Supervisor)</contributor><date>2012</date><subject>Education - Bilingual and Multicultural</subject><title>Identifying the real and perceived needs of ESL adult learners with limited or no literacy in their L1</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/r494vq02q.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/8c97kv46n</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of Integrated Studies in Education</discipline></degree></thesis></metadata></record><resumptionToken completeListSize="47894">oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):36925</resumptionToken></ListRecords></OAI-PMH>