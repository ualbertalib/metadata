<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/assets/blacklight_oai_provider/oai2-b0e501cadd287c203b27cfd4f4e2d266048ec6ca2151d595f4c1495108e36b88.xsl"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd"><responseDate>2020-07-24T23:01:58Z</responseDate><request resumptionToken="oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):3125" verb="ListRecords">https://escholarship.mcgill.ca/catalog/oai</request><ListRecords><record><header><identifier>oai:escholarship.mcgill.ca:44558g40v</identifier><datestamp>2020-03-21T04:56:49Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Currently, McGill is collaborating with University of Western Australia, Moratuwa Univeristy (Colombo, Sri Lanka), and Waste for Life to create affordable eco-friendly building products for Sri Lanka. By using recycled LDPE waste plastics as well as banana fibers made from waste banana trees, composites can be made for basic housing applications. The composite material is to be made using methods easily reproducible in Sri Lanka at a low cost. Tensile properties, flame retardancy and moisture absorption were investigated to create a strong, safe, and durable product. First the plastic matrix (from Sri Lankan and Canadian sources) and banana fiber reinforcement were characterized using differential scanning calorimetry, thermogravimetric analysis, and Fourier-transform infrared spectroscopy. This is to ensure that the processing parameters can be generalized to both countries. Then a manufacturing method using compression molding was developed. Fibers of different length were used to assess their effect on manufacturing and strength. Panels made with 40 wt% of 20 cm long fibers in a random orientation yielded the best results. Then, UL94 fire tests were conducted with ATH mineral filler as a flame retardant. Integrating the flame retardant directly into the composite's layers is the most efficient way of reducing flame spread. Then, different commercially available waterproofing solutions were used to prevent moisture absorption into the composite panels. Sealing the composite with an outer layer of at least 0.3 mm of LDPE was the cheapest and most effective way to prevent water intrusions. Finally, the three aspects of the project (tensile strength, fireproofing, water absorption) were combined in a final product and characterized.</description><description>En collaboration avec l'Université McGill, l'University of Western Australia, Moratuwa University, et l'organisme Waste For Life, ce présent projet avait pour but de concevoir des matériaux de construction en composite à partir de plastiques recyclés et de fibres naturelles. Pour ce faire, il était essentiel de tenir compte du contexte particulier de l'étude, soit les communautés du Sri Lanka, en n'utilisant que des procédés abordables et consciencieux de l'environnement.En utilisant les déchets de plastique polyéthylène à basse densité (PEBD) ainsi que des fibres naturelles provenant des déchets agricoles de bananiers, des matériaux composites peuvent alors être créés. Un procédé de fabrication facilement reproductible au Sri Lanka doit être conçu, et ce, à faible coût. Les propriétés de traction, l'amélioration de propriétés ignifuges, et l'absorption d'humidité furent étudiés afin de créer un matériau fort, sécuritaire et durable. Tout d'abord, la matrice thermoplastique (de sources sri lankaises et canadiennes) et le renfort de fibres de bananes furent caractérisés par calorimétrie différentielle à balayage, analyse thermogravimétrique et spectroscopie infrarouge à transformée de Fourier. Cette étape permettra de déterminer les paramètres de fabrications et si ceux-ci pourront être applicables au Sri Lanka. Ensuite, un procédé de fabrication usant le moulage à compression fût développé. Des fibres coupées de différentes longueurs furent utilisées afin d'évaluer leurs effets sur les propriétés mécaniques et la vitesse de fabrication. Par ailleurs, l'usage de fibres de 20 cm sans orientations prédéterminées/fixes avec une charge de 40% par poids ont fournis les meilleurs résultats. Par la suite, des tests de feux suivant le standard UL94 furent effectués avec la présence d'hydroxyde d'aluminium, soit un retardant à flamme. À cet effet, l'addition du retardant à flamme directement entre les couches du matériau composite s'avère la méthode la plus efficace pour ralentir la propagation des flammes. Enfin, pour améliorer l'imperméabilité du composite, différents scellants commerciaux furent utilisés. D'ailleurs, l'addition d'une couche protectrice de PEBD de 0.3 mm fut la méthode la plus économique et efficace pour assurer l'étanchéité du matériau. Finalement, les trois aspects du projets (propriétés des tractions, feu, et absorption d'humidité) furent intégrés pour créer un produit final.</description><creator>Bolduc, Sean</creator><contributor>Larry Lessard (Internal/Supervisor)</contributor><date>2019</date><subject>Mechanical Engineering</subject><title>Banana fiber-LDPE recycled composites for low-cost eco-friendly construction applications</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/wd375z65g.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/44558g40v</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Mechanical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:1g05ff12d</identifier><datestamp>2020-03-21T04:56:50Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Objectifs : Au Canada, l'octroi de fonds pour les services de soutient aux familles d'enfants présentant des troubles neurologiques incombe aux collectivités provinciales ou territoriales. Par conséquent, la façon dont les services de soutient sont financés et fournis varie en fonction de la juridiction. Cette étude documente les moyens d'accès au financement de l'aide à domicile dans chaque province ou territoire et analyse les écarts. Méthodes : Cette étude a été menée en 3 phases. Au cours de la première phase, une analyse environnementale des sites Internet gouvernementaux a été réalisée pour chaque province (n = 10) et chaque territoire (n = 3) au Canada. Des informations ont été recueillies sur les critères d'admissibilité, les processus de demande, les processus d'évaluation, les modèles de programmes de prestations et les montants de financement. Des trajectoires vers les services de soutient ont été créées en langage clair à partir des informations obtenues. La deuxième phase a consisté en des entretiens avec des informateurs clés (n = 27) dans chaque juridiction afin de valider ces trajectoires. La troisième phase a consisté en une analyse comparative des données.Résultats : Des différences nettes dans la formulation des critères d'éligibilité, la présence de seuils de revenus et, le cas échéant, leur nature, les restrictions d'âge, le montant du financement auquel les familles sont admissibles et les modèles de prestation de services ont été observées d'une juridiction à l'autre. Conclusion : Les familles d'enfants atteints de troubles neurologiques bénéficient de mesures différentes pour les services de soutient en fonction de leur lieu de résidence au Canada. La variabilité des critères d'admissibilité, des options de prestation du programme et du montant de l'aide fournie présente un problème d'inégalité et de justice sociale pour le Canada, pays signataire de la Convention des Nations Unies relative aux droits des personnes handicapées et de la Convention des Nations Unies relative aux droits de l'enfant. Il n'y a actuellement aucun mécanisme d'harmonisation des processus d'accès entre les juridictions, ce qui suggère que cette inégalité persistera probablement. Mots-clés : assistance; enfants; déficience intellectuelle; trouble neurologique ; assistance familiale; Canada</description><description>Objectives: In Canada, provision of funding for respite care to families of children with neurodisabilities, is a provincial/territorial responsibility, with the exception of children living on reserve. As a result, there is variability in how respite is funded and provided, depending on the jurisdiction. This study documents the pathways for accessing in home respite funding in each province/territory and analyzes the discrepancies. Methods:  This study was conducted in 3 phases. During the first phase, an environmental scan of government websites was conducted for each province (n=10) and territory (n=3) in Canada. Information was gathered on eligibility criteria, application processes, assessment processes, program delivery models, and funding amounts. Plain language pathways to respite services were created based on the information obtained. The second phase involved interviews with key informants (n=27) in each jurisdiction to validate these pathways. The third phase was a comparative analysis of the data.Results: Distinct differences in how criteria for eligibility were articulated, whether there were income cut offs and if so, what those were, age restrictions, amount of funding for which families were eligible, and models of service delivery, were seen between jurisdictions. Conclusion: Families of children with neurodisabilities experience disability supports for respite care differently based on where they live in Canada.  Variability in eligibility criteria, program delivery options and amount of support provided represents an inequality and social justice issue for Canada, a country that is a signatory to the UN Convention on the Rights of Persons with Disabilities and the UN Convention on the Rights of the Child. There is currently no mechanism for harmonizing processes for access across jurisdictions, suggesting that this inequality will likely persist. Key Words:  Respite; Children; Developmental Disability; Neurodisability; Family support; Canada. </description><creator>Johnston, Phoebe</creator><contributor>Lucyna Maria Lach (Internal/Supervisor)</contributor><date>2019</date><subject>Social Work</subject><title>An issue of transparency: comparing respite funding programs for families raising a child with a neurodisability across Canada</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/ww72bd96q.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/1g05ff12d</identifier><degree><name>Master of Social Work</name><grantor>McGill University</grantor><discipline>School of Social Work</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:4x51hm459</identifier><datestamp>2020-03-21T04:56:51Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Alors que l'individu évolue dans son environnement, une grande partie des gestes qu'il pose dans son univers sensoriel est traitée sans conscience réfléchie. Sa perception des choses se fait majoritairement de façon implicite. La prédiction intuitive repose sur l'usage du procédé de traitement de l'information de notre subconscient et de nos observations passées pour cerner une attente et orienter toute action future. Les personnes avec trouble autistique luttent contre le processus de fonctionnement exécutif et ont des perceptions différentes des individus au développement dit normal. Dans cette analyse, la recherche visuelle, qui évalue l'utilisation non formulé de l'information sensorielle, de la prédiction, des aspects de base de la perception ainsi que de l'attention, a été utilisée comme méthode pour comprendre la manière dont les autistes se servent de la prédiction intuitive pour influencer leur action future. Vingt-quatre enfants avec trouble du spectre de l'autisme (TSA) et vingt-huit enfants sans trouble quelconque ont été choisis pour faire partie de l'étude. Les participants autistes ont accompli la tâche de recherche visuelle avec succès. Ces derniers ont démontré qu'ils ont la capacité d'utiliser des repères implicites pour diriger leur recherche et améliorer leur performance lors de ce type de recherche. De plus, ils ont prouvé qu'ils peuvent faire usage de plusieurs processus cognitifs sans difficulté, contrairement à ce qui est présenté dans la littérature courante au sujet des autistes et du fonctionnement cognitif. Ces résultats soulignent que les individus avec TSA sont en mesure de traiter certains types de traitements cognitifs importants. Les études ultérieures devraient porter sur la compréhension plus approfondie du développement cognitif chez les personnes autistes</description><description>As individuals navigate through their environment, much of their sensory world is processed without conscious awareness. The vast majority of our perception occurs implicitly. Implicit prediction involves using subconscious processing and past observations to form an expectation, and guide future action. Individuals with autism, struggle with executive functioning and engage in perception differently than typically developing individuals. A visual search task, assessing implicit usage of sensory information to predict future sensory input was used to compare the ability of individuals with ASD to typically developing individuals to recover from an interrupted search task. Twenty-four children with ASD and 28 typically developing children were recruited. Participants with ASD successfully completed the visual search task, and demonstrated they were able to use implicit perceptual processing to form predictions to direct and improve their performance on a search task following an interruption. These results highlight that individuals with ASD are able to engage in effective and implicit cognitive processing. Future research should focus on improving our understanding of cognitive development in individuals with ASD. </description><creator>Keskin, Eric</creator><contributor>Jacob A Burack (Internal/Supervisor)</contributor><contributor>Darlene Brodeur (Internal/Cosupervisor2)</contributor><date>2019</date><subject>Educational and Counselling Psychology</subject><title>The role of rapid resumption in the cognitive and attentional processes of individuals with autism spectrum disorder</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/n296x142x.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/4x51hm459</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>Department of Educational and Counselling Psychology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:1n79h6692</identifier><datestamp>2020-03-21T04:56:52Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les hélicoptères volent à des altitudes relativement basses susceptibles à la formation de glace sur les composantes portantes. Ce cumul peut entraîner une augmentation du poids et une dégradation des performances du rotor qui soit obligent les pilotes à atterrir ou, pire, peuvent causer des accidents. En raison du coût élevé des campagnes de certification pour vol en mode givrant, rares sont les hélicoptères certifiés pour de tels vols. La simulation numérique du givrage en vol est capable de réduire les coûts en remplaçant efficacement certains essais physiques et en vol.Au cours des deux dernières décennies, la simulation numérique du givrage en vol s'est considérablement améliorée, en parallèle à l'augmentation ahurissante de la puissance des ordinateurs. Toutefois, les simulations de givrage en hélicoptère n'en demeurent pas plus faciles en raison de la nature instationnaire du phénomène et d'écoulements compliqués régis par les tourbillons et le mouvement relatif entre pales et fuselage. Cette thèse présente une technique de manipulation de maillage qui remet à jour de manière robuste le domaine de calcul à chaque étape d'une simulation en tenant compte du mouvement relatif entre les pales et le fuselage, ainsi que les changements de forme de lame dus au cumul de glace. Le schéma utilise une triangulation de type Delaunay avec contraintes pour assembler les parties rotatives et non-rotatives du maillage pour en créer un maillage combiné pour le solveur. Cette approche ancrée dans un solveur par éléments finis conserve les flux entre les différents domaines. De plus, une déformation du maillage prend en compte les mouvements des pales, ainsi que les changements de leur profil aérodynamique dus au givrage. La méthode démontre une bonne comparaison avec les résultats expérimentaux, ainsi que la préservation de la qualité du maillage tout au long des simulations.</description><description>Helicopters fly at relatively low altitudes compared to fixed-wing aircraft as a result of the different methods these vehicles use to generate lift. Due to higher levels of moisture in this region of the atmosphere, coupled with cold temperatures, helicopters are susceptible to the formation of ice on critical aerodynamic parts. This build-up can result in increased weight and degradation of rotor performance which may force pilots to land, or worse, cause accidents. Presently, few helicopters are certified for flight in icing conditions, limiting their speed and maneuverability for time-critical missions such as search and rescue.Computational Fluid Dynamics and icing (CFD-Icing) simulations are currently being used to help design rotorcraft for icing certification. Over the last thirty years CFD-Icing capabilities have significantly improved along with computational power. Nevertheless, helicopter icing simulations remain difficult due to the unsteady (at most, steady-periodic) nature of the problem, complex flow patterns governed by blade tip vortices, multiphase flow (air and water), and relative motion between rotor blades and fuselage. This Thesis presents a mesh manipulation technique for helicopter CFD-Icing that robustly updates the computational domain at each time step of a simulation to account for relative motion between blades and fuselage, as well as blade geometry changes due to ice accumulation. The technique uses constrained Delaunay triangulations to stitch together rotating and non-rotating meshes and creates a combined watertight mesh for use by the solver at each time step. Mesh deformation is incorporated to displace the mesh for relative motions within the rotating reference frame. It will be shown that this "stitching" approach, coupled with a finite-element solver, makes the technique conservative in the propagation of flow variables between the various mesh domains.The method has been applied to several test cases and has shown good comparison to experimental results. The method is also shown to preserve mesh quality throughout the manipulations as required for accurate simulations.</description><creator>Nathoo, Munir</creator><contributor>Wagdi George Habashi (Internal/Supervisor)</contributor><date>2019</date><subject>Mechanical Engineering</subject><title>Stitching and deformation of non-overlapping meshes for the simulation of helicopter aerodynamics in icing</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/rf55z998x.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/1n79h6692</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Mechanical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:br86b559z</identifier><datestamp>2020-03-21T04:56:53Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>This dissertation explores the political history of Germany's highest award for military excellence during the Second World War: the Knight's Cross of the Iron Cross, or "Ritterkreuz." Expanding upon a limited foundation of existing scholarly research, its primary focus is to examine the role played by this famous medal as a vessel of "symbolic capital" for the National Socialist regime. Designed not only as a tool to help forge a new archetype for military heroism, it was also to represent the "revolution" that the Party claimed to have produced in German society and politics. Using this function as a framework, the component chapters of this study document different ways in which it informed or affected official usages of the Ritterkreuz and the activities of its recipients – called "Ritterkreuzträger" – during the war years. Through this investigation, the dissertation argues that while achieving an impact on wartime culture that continues to be felt in Germany today, both medal and men proved as much a source of frustration and embarrassment to the regime as they did ideological success. As such, it challenges several existing assumptions regarding the role of orders and decorations created by National Socialism while highlighting an underrecognized layer of complexity in its "Heldenpolitik" (Hero Politics).</description><description>Cette thèse explore l'histoire politique de la plus haute distinction militaire accordée en Allemagne durant la Seconde Guerre mondiale : la croix de chevalier de la croix de fer, la « Ritterkreuz ». En s'appuyant sur une littérature scientifique limitée, l'objectif principal de cette thèse est d'examiner le rôle joué par cette célèbre médaille en tant que véhicule porteur de « capital symbolique » pour le régime national-socialiste. Conçues non seulement pour permettre au régime de façonner un nouvel archétype d'héroïsme militaire, ces médailles ont aussi été exploitées comme emblèmes de  la « révolution » sociopolitique qu'il prétendait avoir accomplie en Allemagne. En utilisant cette fonction comme cadre analytique, les chapitres de cette étude documentent les différentes manières qu'elle contribue à influencer l'utilisation de la Ritterkreuz et les activités de ses récipiendaires – nommés « Ritterkreuzträger » – durant les années de guerre. Dans le cadre de cette recherche, nous argumentons que bien que les effets culturels de cette campagne militaire soient toujours ressentis en Allemagne aujourd'hui, les médailles et les récipiendaires se sont avérés être autant une source de frustration et d'embarras que de succès idéologique. En tant que telle, notre étude remet en question plusieurs des hypothèses concernant le rôle des ordres et des décorations créés par le régime national-socialiste tout en levant le voile sur la complexité sous-estimée de l'« Heldenpolitik » (la politique centrée sur les héros).</description><creator>Gilmour, Colin</creator><contributor>Peter C W Hoffmann (Supervisor)</contributor><date>2019</date><subject>History and Classical Studies</subject><title>Ritterkreuz, ideology and the complexities of hero culture under national socialism</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/w3763921s.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/br86b559z</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of History and Classical Studies</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:1n79h670t</identifier><datestamp>2020-03-21T04:56:53Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>L'interprétation juridique de la technologie tire de l'histoire et de la théorie littéraire une approche interprétative à l'étude du droit et de la technologie. Elle postule que la signification de la technologie ne réside pas dans les technologies elle-même, mais résulte de son interprétation. La thèse ne cherche pas à favoriser une interprétation plutôt qu'une autre, mais à examiner comment les interprétations sont formulées et qu'est-ce qui détermine leur crédibilité. Plus spécifiquement, elle soutient que les agents juridiques interprètent la technologie en accord avec les conceptions dominantes du droit. La 'nouveauté' de la technologie illustre ce type particulier d'interprétation. La nouveauté n'est pas une caractéristique strictement temporelle des technologies. Elle est plutôt une étiquette que les agents juridiques apposent sur une technologie pour signifier qu'elle dévie suffisamment du droit pour justifier un traitement particulier. La neutralité et la forme déterminée de la technologie sont d'autres importants exemples. Elles garantissent que la métaphysique de la technologie n'interfère pas avec l'autonomie humaine. L'interprétation juridique de la technologie patrouille donc la frontière entre le droit et la technologie, préservant l'autorité du premier sur la seconde.Prenant pour acquis l'interprétation juridique de la technologie, la thèse revisite l'histoire du livre pour réfléchir au droit et à sa formation. À l'Angleterre du dix-septième siècle, deux factions du marché du livre distinguées par des régimes règlementaires se disputent le privilège d'imprimer les livres de la common law. S'inspirant de cette saga judiciaire et de la philosophie de Thomas Hobbes, la thèse présente le droit comme les commandements a-rationnels d'une autorité linguistique souveraine. En France du dix-huitième siècle, Diderot et les encyclopédistes défient la censure royale pour publier l'Encyclopédie. La raison est présentée en contraste au droit : les commandements du souverain sont toujours ambigus et nécessitent des clarifications et réaffirmations constantes. Dans la Grande Bretagne du dix-huitième et dix-neuvième siècle, le « copyrighted work », une matière autrefois déterminée, se transforme en substance intangible. L'ambiguïté et la pluralité du droit sont des caractéristiques du droit et non des déficiences. Les conflits qui opposent le droit et la technologie résultent en fait des contradictions internes du premier, y compris sa conception du temps.</description><description>The Legal Interpretation of Technology draws from history and literary theory to study law and technology. The thesis postulates that technological meaning does not reside within technologies themselves, but stems from interpretation. It investigates how interpretations of technology come to be and what makes some interpretations more persuasive than others. The thesis argues that legal agents interpret technology in a manner that reflects and is compatible with prevalent conceptions of law. The 'newness' of a technology, for example, is not a strictly temporal characteristic, but a label affixed to a technology in order to signify its deviancy and justify special treatment. The alleged neutrality and determinacy of technologies constitute other important examples: they ensure that the metaphysics of technology do not interfere with human agency and, therefore, preserve the possibility of obedience to law. Law and technology literature's reliance on speculation and contingency to regulate technological change derive from the rotes of legal prescriptivism. Interpretation thus polices the boundary between law and technology in order to preserve the authority of the former over the latter.Taking the legal interpretation of technology for granted, the thesis revisits episodes from the history of the book to reflect on law and lawmaking. Its first case study takes place in seventeenth-century England, when two factions of the book trade, divided along regulatory lines, fought in courts over the exclusive right to print common law books. Drawing from this judicial saga and from Thomas Hobbes' philosophy of language, the thesis portrays law as the arational commands of a sovereign linguistic authority. The thesis' second case study takes place in eighteenth-century France, when Diderot and his allies challenged royal censorship in order to publish the Encyclopédie. Reason is presented therein as law's foil: the sovereign's commands are always ambiguous; they require constant clarification and restatements to prevent semantic evasion. The last case study takes place in eighteenth- and nineteenth-century Great Britain, when the copyrighted work evolved from a determinate matter to an intangible substance. The thesis argues that ambiguity and plurality are essential features of law, not defects. In conclusion, its author proposes that apparent conflicts between law and technology result, in fact, from the inner contradictions of law and its relation to time.</description><creator>Lord, Francis</creator><contributor>Antoine Latreille (Supervisor2)</contributor><contributor>Pierre-Emmanuel Moyse (Supervisor1)</contributor><date>2018</date><subject>Law</subject><title>The legal interpretation of technology</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/2f75r996v.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/1n79h670t</identifier><degree><name>Doctor of Civil Law</name><grantor>McGill University</grantor><discipline>Faculty of Law</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:mc87ps79j</identifier><datestamp>2020-03-21T04:56:54Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The impact of Averroes on Jewish philosophy is best attested in Sefer Tiqqun ha-de'ot (Correcting the Opinions), a Hebrew translation with commentarial notes on the encyclopedic work of the Muslim theologian Abu Hamid al-Ghazāli (d. 1111), kitāb Maqāsid al-Falāsifa. Isaac Albalag, the author of the Tiqqun, lived in the second half of the thirteenth century either in Catalonia or Provence. In the Tiqqun, Albalag takes upon himself the task of purging philosophy from what he regards as misconceptions and absurdities that entered philosophy at the hands of flawed philosophers such as al-Farābi, Avicenna, and al-Ghazāli. To this group of philosophers belongs Maimonides with whom Albalag disputes over the question of the origin of the world and his understanding of religion. The form of philosophy that Albalag aims to restore is Aristotelianism, which he understands through the lens of Averroes' commentaries on Aristotle and independent treatises.  Although the Tiqqun is structurally based on the Maqāsid and draws its basic critiques and arguments from Averroes' works, it does not lack originality. In dealing with the question of the relationship between religion and philosophy, Albalag advances a view that marks a conspicuous deviation from the Maimonidean-Averroists harmony view which was fairly standard in his intellectual milieu. Religion and philosophy, Albalag claims, contradict each other, yet they are simultaneously true. This view, which Albalag enhances through an unusual conception of prophecy, prompted scholars to read his thought in light of the double truth doctrine, which was advocated by Medieval Latin Averroists. The present thesis proposes to offer a comprehensive and contextualized study of the Tiqqun. By examining Albalag's double truth claim against the Tiqqun's fundamental epistemological and metaphysical premises and against the backdrop of contemporary philosophical theories, the present study proves that the double truth doctrine, rather than being an actual dogma, represents for Albalag a practical solution for the implications of the tension between religion and philosophy for the masses' beliefs and the autonomy of philosophy. In reality, Albalag remained faithful to philosophy, namely Aristotelianism, which he deemed the truth. </description><description>L'influence  d'Averroès sur la philosophie juive est le plus prononcé dans Sefer Tiqqun ha-de'ot (Correction des opinions), une traduction en hébreu commenté sur le travail encyclopédique du théologien musulman Abu Hamid al-Ghazāli (d. 1111), kitāb Maqāsid al-Falāsifa. Isaac Albalag, l'auteur du Tiqqun, vivait dans la deuxième moitié du treizième siècle, soit en Catalogne ou en Provence.  Dans le Tiqqun, Albalag s'est pris la tache de purger la philosophie de ce qu'il voyait comme des idées fausses et absurdes qui sont entrées dans la philosophie aux mains des philosophes imparfaits tels que al-Farābi, Avicenna et al-Ghazali.  Appartenait à ce groupe de philosophes, Maimonides avec qui Albalag avait des différends sur l'origine du monde et sa compérhension de la religion. La forme de philosophie qu'Albalag voulait restaurer  est l'Aristotelianisme, qu'il a compris à travers  les commentaires d'Averroes sur Aristote et les traités d'indépendants. Bien que le Tiqqun est structurellement basé sur le Maqāsid et tire ses critiques de base et ses arguments du travail d'Averroes, ceci ne manque pas d'originalité. En abordant la question du rapport entre la religion et la philosophie, Albalag met en avant un point de vue qui marque une déviation remarquable de l'harmonie entre le Maïmonide et l'Averroïsme ce qui était assez courant dans son milieu intellectuel. Selon Albalag, la religion et la philosophie se contredisent, mais sont simultanément vraies.  Ce point de vue, qu'Albalag accroit par une conception peu commune de la prophétie, a incité les savants à lire ses pensées à la lumière de la doctrine à deux vérités, lequel a été recommandé par les Averroïstes latins médiévaux. Le rapport qui suit présente en détail une étude complète et contextualisée du Tiqqun. En examinant la double revendication d'Albalag contre les prémisses épistémologiques et métaphysiques fondamentales du Tiqqun et sur fond de théories philosophiques contemporaines, la présente étude prouve que la double doctrine de la vérité, plutôt que d'être un dogme réel, représente pour Albalag une solution pratique aux implications de la tension entre religion et philosophie pour les croyances des masses et l'autonomie de la philosophie. En réalité, Albalag est resté fidèle à la philosophie, à savoir l'Aristotélisme, qu'il a considéré comme la vérité.</description><creator>Abdalla, Bakinaz</creator><contributor>Lawrence Kaplan (Supervisor2)</contributor><contributor>Carlos Fraenkel (Supervisor1)</contributor><date>2019</date><subject>Jewish Studies</subject><title>One truth or two? Jewish averroists on the truth of the philosophers and the truth of the prophets: the case of Isaac Albalag</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/h989r530r.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/mc87ps79j</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Jewish Studies</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:0p0969464</identifier><datestamp>2020-03-21T04:56:55Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les systèmes temps-réel embarqués modernes sont de plus en plus interconnectés avec une multitude d'appareils sensoriels, d'autres systèmes embarqués et du "cloud". L'adoption de processeurs monocœurs et multicœurs haut de gamme dans les applications embarquées émane des exigences de traitement d'applications complexes. La pérennité, la sécurité et les systèmes déterministes sont des obligations de conception et de fonctionnement de longue date des systèmes embarqués. Récemment, la mobilité, l'efficacité énergétique et la dissipation de chaleur sont des exigences de conception tout aussi cruciales dans les applications comprenant les robots mobiles autonomes, les appareils portables et les réseaux sensoriels. Les processeurs embarqués haut de gamme utilisent des techniques de réduction d'énergie telles que le voltage dynamique, la mise à l'échelle de la fréquence (DVFS) et la gestion dynamique de la puissance (DPM). Une stratégie efficace de gestion de l'énergie exploite simultanément les techniques de réduction de l'énergie au niveau matériel et logiciel.Initialement, cette thèse aborde le problème de la réduction de la consommation d'énergie sur les systèmes monocœurs avec matériel DVFS et périphériques. Nous considérons un problème de minimisation à l'échelle du système où nous examinerons simultanément DVFS et DPM. Étant donné que l'affectation de fréquence à la tâche est un problème NP-difficile, nous avons adaptés deux métaheuristiques à notre approche d'affectation de fréquence: l'évolution différentielle et l'algorithme génétique. Nous analyserons les performances des métaheuristiques en fonction de diverses conditions initiales. Nous montrerons dans nos simulations que notre approche donne de meilleurs résultats que deux heuristiques bien connues.En outre, bien que les simulateurs à temps-discret sont suffisants pour analyser la faisabilité des emplois du temps en temps réel, ils sont insuffisants pour évaluer des emplois du temps qui économisent l'énergie. Cela est dû à une modélisation incorrecte de processeurs (en raison des droits de propriétés intellectuelles, conceptions de processeurs complexes) et à l'incapacité de capturer un comportement réaliste des tâches. La littérature présente souvent des études de cas de "real-hardware" pour corroborer des simulations. Cependant, ces approches sont souvent ambiguës. Nous proposons une méthodologie qui facilite le portage de simulations sur la "real-hardware" a l'aide des "benchmarks" embarqués en tant que tâches système.Comme pour les simulations logicielles, notre méthodologie aborde la question de l'examen du système à différents points d'utilisation.Nous nous appuyons sur des travaux antérieurs qui évaluent la WCET des tâches, génèrent des périodes des tâches et attribuent des utilisations des tâches. Les trois paramètres sont interconnectés, ce qui limite la possibilité de modifier l'un sans affecter les autres. Nous proposons un ensemble d'algorithmes efficaces qui associent des tâches à des périodes délimitées pour répondre à l'utilisation totale du système avec un minimum d'erreurs relatives.Enfin, nous abordons la question de l'ordonnancement optimal énergétique sur des plateformes hétérogènes groupées. Nous nous concentrons sur la répartition énergétique efficace des tâches à des groupes hétérogènes ayant un impact direct sur l'énergie totale du système. Dans cette thèse, nous associerons le problème de répartition énergétique efficace sur des plateformes hétérogènes mono-ISA à un ordonnancement conscient de la tâche. Nous utilisons davantage les fréquences de "l'hardware" et les états de veille pour minimiser l'énergie du système. Nous proposons deux variantes de notre algorithme de répartition conscient de l'hétérogénéité de tâches et de cluster ciblant les plateformes ARM big.LITTLE. Nous montrons que nos algorithmes permettent de réduire de 13% à 23% la consommation moyenne d'énergie par rapport à des systèmes à la pointe de la technologie.</description><description>Modern embedded real-time systems are increasingly interconnected with a multitude of sensory devices, other embedded systems, and the cloud.  The adoption of high-end embedded single core processors and multiprocessors emanates from complex application processing requirements. Timeliness, safety, and deterministic systems are long-standing design and operational requirements of embedded systems. Recently, mobility, energy-efficiency, and heat dissipation are equally crucial design requirements in applications including autonomous mobile robots, wearable devices, and sensor networks. High-end embedded processors employ energy-reduction techniques like Dynamic Voltage and Frequency Scaling (DVFS) and Dynamic Power Management (DPM). An effective energy-management strategy simultaneously exploits hardware- and software-level energy-reduction techniques.Initially, this thesis addresses the issue of energy-reduction on DVFS-capable single core systems with peripheral devices.  We consider a system-wide minimization problem where we concurrently consider DVFS and DPM. Given that the frequency to task assignment is an NP-hard problem, we appropriate and adapt two metaheuristics in our approach to frequency assignment; namely the differential evolution and genetic algorithms. We analyze the performance of the metaheuristics given various initial conditions and show in our simulations that our approach yields better results than two well-known heuristics.Further, even though discrete-time simulators are sufficient for analyzing real-time schedule feasibility, they fall short when evaluating energy-efficient scheduling. This is due to incorrect processor modeling (i.e. due to IP rights, complex processor designs) and the inability to capture realistic task behavior. The literature often presents case studies on real hardware to corroborate simulations. However, these approaches are often ambiguous. We propose a methodology that facilitates evaluating real-time systems on real hardware using available embedded benchmarks as system tasks at various system load points. Similar to software simulations, our methodology tackles the issue of examining the system at different utilization points. We build on previous work that estimates task WCET, generates task periods, and assigns task utilizations. The three parameters are interlocked, which limits the flexibility of changing one without affecting the others. We propose a set of efficient algorithms that pair tasks with bounded or discrete periods to meet the total system utilization with minimal relative errors.Finally, we address the issue of energy-efficient scheduling on clustered heterogeneous platforms. We focus on energy-efficient partitioning where task allocation to heterogeneous clusters directly impacts the total system energy. In this thesis, we couple the problem of energy-efficient partitioning on single-ISA heterogeneous platforms with task-aware scheduling. Tasks differ in their instruction mix, cache behavior, memory and I/O access, execution path, and active processing and SoC circuitry. This affects their power demand. We make further use of underlying frequency scaling hardware and sleep states to minimize the system energy. We propose two variants of our Task and Cluster Heterogeneity Aware Partitioning (TCHAP) algorithm targeting ARM big.LITTLE platforms.  Based on our methodology for simulation on real hardware, we show that our algorithms achieve between 13% to 23% energy-reduction on average compared to a state-of-the-art schemes.</description><creator>Suyyagh, Ashraf</creator><contributor>Zeljko Zilic (Supervisor)</contributor><date>2019</date><subject>Electrical and Computer Engineering</subject><title>Towards energy-effcient real-time computing in embedded systems</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/2b88qf24k.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/0p0969464</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Electrical and Computer Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:m900nw767</identifier><datestamp>2020-03-21T04:56:56Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Le diagramme de phase et les propriétés thermodynamiques du système Al2O3-CaO-FeO-Fe2O3-MgO-MnO-Mn2O3-SiO2-Ti2O3-TiO2 sont importants dans diverses applications telles que la sidérurgie, les réfractaires, les céramiques avancées, pétrologie et la géochimie. Dans le présent travail, la base de données thermodynamiques disponible pour le système Al2O3-CaO-FeO-Fe2O3-MgO-MnO-Mn2O3-SiO2-Ti2O3-TiO2 a été étendue aux systèmes à oxydes de Mn et de Ti afin de développer une base de données thermodynamique précise pour le système à dix composants. À cette fin, une revue complète de la littérature, une évaluation critique et une optimisation thermodynamique des diagrammes de phase et des propriétés thermodynamiques des systèmes à 1 atm ont été réalisées. Dans le cadre de l'étude thermodynamique, des expériences clés ont été réalisées dans l'air dans les diagrammes de phase des systèmes Fe-Ti-O, Mn-Ti-O, Al-Ti-O, Fe-Mn-Ti-O, Mg-Mn-Ti-O, Mn-Si-Ti-O, et Mn-Al-Ti-O afin d'obtenir des équilibres de phase inconnus entre la phase liquide et les solutions solides complexes pour résoudre les incohérences existant entre les données expérimentales présentes dans la littérature.Les expériences de diagramme de phase ont été réalisées en utilisant la technique classique d'équilibre et de trempe. L'analyse de phase a été réalisée à l'aide de la microanalyse à sonde électronique (EPMA, en anglais) et de la diffraction des rayons X (XRD, en anglais) sur tous les échantillons trempés. Dans le système Al-Ti-O, la solubilité d'Al2O3 dans la solution solide de rutile (TiO2) a été mesurée à haute température. Dans le système Fe-Ti-O, le liquidus, la solubilité de Fe2O3 dans la solution de rutile (TiO2) et les plages d'homogénéité des solutions d'ilménite Fe2O3-FeTiO3 et de pseudobrookite Fe2TiO5-Ti3O5 ont été déterminées à haute température. Dans le système Mn-Ti-O, le liquidus, la solubilité de MnO dans le rutile et la plage d'homogénéité du spinelle Mn3O4-Mn2TiO4 ont été mesurés. Dans les systèmes Mg-Mn-Ti-O et Fe-Mn-Ti-O, les équilibres de phases complexes entre solutions liquides et solides ont été élucidés expérimentalement pour la première fois.Pour l'optimisation thermodynamique, la phase liquide a été décrite à l'aide du Modèle quasichimique modifié en considérant un ordre à courte portée dans l'oxyde fondu et les énergies de Gibbs des solutions solides complexes de pseudobrookite, ilménite et spinelle ont été décrites à l'aide du Formalisme énergétique des composés en tenant compte de la structure cristalline de chaque solution solide. En utilisant les modèles thermodynamiques avec des paramètres de modèle optimisés dans les systèmes binaires et ternaires, les diagrammes de phase et les propriétés thermodynamiques des systèmes d'ordre supérieur du système Al2O3-CaO-FeO-Fe2O3-MgO-MnO-Mn2O3-SiO2-Ti2O3-TiO2 ont été bien calculés.La base de données contenant les paramètres de modèle optimisés dans cette étude est compatible avec les autres bases de données thermodynamiques FactSage et peut être utilisée pour calculer tout diagramme de phase non exploré et ses propriétés thermodynamiques au sein du système à dix composants. La base de données peut être utilisée pour les calculs thermodynamiques complexes applicables à la pyrométallurgie et aux céramiques avancées, ainsi que pour l'optimisation des processus industriels et le développement de nouveaux matériaux.  </description><description>The phase diagram and thermodynamic properties of the Al2O3-CaO-FeO-Fe2O3-MgO-MnO-Mn2O3-SiO2-Ti2O3-TiO2 system are important in various applications such as steelmaking, refractories, advanced ceramics, petrology and geochemistry. In the present work, the available thermodynamic database for the Al2O3-CaO-FeO-Fe2O3-MgO-SiO2 system was expanded toward the Mn and Ti oxide systems to develop an accurate thermodynamic database for the ten-component system. For this purpose, a complete literature review, critical evaluation and thermodynamic optimization of the phase diagrams and thermodynamic properties of related systems at 1 atm was performed. As part of the thermodynamic study, key phase diagram experiments were performed in the Fe-Ti-O, Mn-Ti-O, Al-Ti-O, Fe-Mn-Ti-O, Mg-Mn-Ti-O, Mn-Si-Ti-O, and Mn-Al-Ti-O systems in air to obtain unknown phase equilibria between the liquid phase and complex solid solutions and resolve any inconsistencies among existing experimental data in the literature.Phase diagram experiments were performed using the classical equilibration and quenching technique. Phase analysis was performed using Electron Probe Microanalysis (EPMA) and X-ray Diffraction (XRD) on all the quenched samples. In the Al-Ti-O system, the solubility of Al2O3 in the rutile (TiO2) solid solution was measured at high temperature. In the Fe-Ti-O system, the liquidus, solubility of Fe2O3 in the rutile (TiO2) solution, and the homogeneity ranges of Fe2O3-FeTiO3 ilmenite and Fe2TiO5-Ti3O5 pseudobrookite solutions were determined at high temperature. In the Mn-Ti-O system, the liquidus, MnO solubility in rutile and the homogeneity range of Mn3O4-Mn2TiO4 spinel were measured. In the Mg-Mn-Ti-O, Fe-Mn-Ti-O and Mn-Si-Ti-O systems, the complex phase equilibria between liquid and solid solutions were experimentally elucidated for the first time in air atmosphere. For the thermodynamic optimization, the liquid phase was described using the Modified Quasichemical Model considering short-range ordering in the molten oxide and the Gibbs energies of the complex solid solutions pseudobrookite, ilmenite and spinel were described using the Compound Energy Formalism considering the crystal structure of each solid solution. Using the thermodynamic models with optimized model parameters in binary and ternary systems, the phase diagrams and thermodynamic properties of higher order systems in the Al2O3-CaO-FeO-Fe2O3-MgO-MnO-Mn2O3-SiO2-Ti2O3-TiO2 system were well calculated. The database containing the optimized model parameters in this study is compatible with the other FactSage thermodynamic databases and can be used to calculate any unexplored phase diagram and thermodynamic properties within the ten-component system. The database can be used for the complex thermodynamic calculations applicable to pyrometallurgy and advanced ceramics and used for the optimization of industrial processes and the development of new materials. </description><creator>Panda, Sourav</creator><contributor>In-Ho Jung (Supervisor1)</contributor><contributor>Mathieu Brochu (Supervisor2)</contributor><date>2019</date><subject>Mining and Materials</subject><title>Coupled experimental and thermodynamic modeling of A12O3-CaO-FeO-Fe2O3-MgO-MnO-Mn2O3-SiO2- TiO3-TiO2 system</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/4q77ft684.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/m900nw767</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Mining and Materials</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:tm70mx730</identifier><datestamp>2020-03-21T04:56:57Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>In this thesis, we consider inter-robot communication in robot convoying settings. In particular, we investigate passive communication for radio-denied environments by using whole-body gestures performed by an underwater robot to provide cues regarding future actions. We first focus on visually detecting and tracking the 3D pose of autonomous underwater vehicles to enable robust multi-robot convoying. We follow the approach of tracking-by-detection, which combines the robust, drift-free nature of object detection with the temporal consistency of tracking algorithms. Our approach relies on a multi-output convolutional network that jointly predicts the target robot's presence in the image, its 2D bounding box, and its 3D orientation. This, combined with camera intrinsic parameters and prior knowledge of the robot's scale, allows us to recover the full 6-degree-of-freedom pose of the target robot. We then leverage the tracked pose to develop a visual communication protocol whereby information is transmitted through codewords: a series of actions executed by the swimming robot. These sequences are chosen to optimize robustness and transmission efficiency given the observability, natural activity of the robot and the frequency of different messages. The observer robot then uses an adaptation of classical decoding methods to infer the transmitted message. To train our network, we rely exclusively on synthetic images and we test our system on underwater datasets in both pool and ocean settings. Our evaluation demonstrates successful generalization of both the learned tracking model and the visual communication protocol to real underwater footage of the target robot. </description><description>Dans cette thèse, nous considérons la communication inter-robot dans les environnements de convoi de robots. En particulier, nous étudions la communication passive pour les environnements sans radio en utilisant des gestes du corps entier exécutés par un robot sous-marin afin de fournir des indices sur les actions à venir. Nous nous concentrons d'abord sur la détection visuelle et le suivi de la pose 3D de véhicules sous-marins autonomes afin de permettre un convoyage multi-robot robuste. Nous suivons l'approche du suivi par détection, qui conjugue la nature robuste et sans dérive de la détection d'objet et la cohérence temporelle des algorithmes de suivi. Notre approche repose sur un réseau convolutionnel à plusieurs sorties qui prédit conjointement la présence du robot dans l'image, son cadre de délimitation 2D et son orientation 3D. Ceci, combiné aux paramètres intrinsèques de la caméra et à la connaissance préalable de la taille du robot, nous permet de récupérer la pose complète à 6 degrés de liberté du robot. Nous exploitons ensuite la pose suivie pour développer un protocole de communication visuelle dans lequel de l'information est transmise via des mots de code (ou codewords): une série d'actions exécutées par le robot nageur. Ces séquences sont choisies pour optimiser la robustesse et l'efficacité de la transmission en fonction de l'observabilité, de l'activité naturelle du robot et de la fréquence des différents messages. Le robot observateur utilise ensuite une adaptation des méthodes de décodage classiques pour déduire le message transmis. Pour entraîner notre réseau, nous nous basons exclusivement sur des images synthétiques et nous testons notre système sur des jeux de données sous-marins en piscine et en océan. Notre évaluation démontre la généralisation réussie du modèle de suivi appris et du protocole de communication visuelle sur de vraies images sous-marines du robot.</description><creator>Koreitem, Karim</creator><contributor>Gregory L Dudek (Internal/Supervisor)</contributor><date>2019</date><subject>Computer Science</subject><title>3D visual tracking and inter-robot communication through full-body gestures</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/kw52jb19q.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/tm70mx730</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Computer Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:vx021h41h</identifier><datestamp>2020-03-21T04:56:58Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Tous les organismes multicellulaires débutent par le zygote, une cellule non différenciée qui dans le développement embryonnaire se différencie en multiples types cellulaires spécialisés. La spécification du destin cellulaire est un processus fondamental par lequel la cellule s'engage en différenciation. Les transitions de destin cellulaire durant le développement sont mal comprises. Mon travail s'est concentré sur le rôle des facteurs pionniers durant la différenciation. Ces facteurs sont capables de trouver leurs cibles même lorsque l'ADN est inaccessible dans de la chromatine fermée et permettent l'ouverture de la chromatine et la liaison de facteurs non-pionniers.D'abord, nous avons étudié l'implication de l'action pionnière lors de la différenciation de deux lignées hypophysaires, les mélanotropes et les corticotropes, qui expriment toute deux le gène de la pro-opiomelanocortine. Nous avons montré que l'action pionnière de Pax7 dirige la spécification des mélanotropes in vivo en ouvrant un nouveau répertoire d'enhancers. Nous avons découvert la dynamique de l'action pionnière à l'aide d'une version inductible de Pax7. Pax7 trouve ses cibles rapidement (moins de 30 minutes) mais initialement les lie faiblement. Pax7 est ensuite stabilisé sur ses sites en moins de 24h alors que l'ouverture de la chromatine est lente et progressive sur plus de trois jours. Après retrait de Pax7, l'action pionnière de Pax7 est stable et associées à une perte de la méthylation de l'ADN.Nous avons ensuite étudié le rôle des facteurs non-pionniers dans l'ouverture de la chromatine dépendante des facteurs pionniers. Le modèle classique de l'action pionnière présume que les non-pionniers sont passifs dans le processus et lient la chromatine nouvellement accessible de manière opportuniste, mais cela n'a jamais été testé. Le facteur pionnier Pax7 agi comme spécificateur du destin mélanotrope alors que le facteur non pionnier Tpit agi comme facteur de détermination pour les mélanotropes et les corticotropes. L'accessibilité de la chromatine est affectée dans les souris déficientes pour Pax7 ou Tpit, chacun est requis pour l'ouverture de son programme respectif. De manière remarquable, Pax7 ne déclenche pas l'ouverture de ses régions cibles en l'absence de Tpit. L'expression ectopique de Pax7 en présence/absence de Tpit confirme que Pax7 lie de manière stable la chromatine fermée en présence/absence de Tpit alors que Tpit ne lie pas la chromatine fermée en l'absence de Pax7. En revanche, en l'absence de Tpit, la liaison de Pax7 ne permet pas l'ouverture de la chromatine. Nous proposons qu'une coopération entre pionniers et non-pionniers permet l'ouverture de la chromatine.</description><description>Complex organisms begin as a single undifferentiated cell, the zygote, which derives a multitude of highly specialized cell types through sequential rounds of differentiation. Cell fate specification is the fundamental process by which cells engage towards specialization. Cell fate transitions during normal development are poorly understood. My work focused on the role of pioneer factors during differentiation. These transcription factors find their target sites even concealed in closed chromatin leading to chromatin opening and binding of nonpioneer transcription factors.We first studied pioneer driven cell differentiation of two pituitary lineages, melanotropes and corticotropes, that both express the pro-opiomelanocortin (POMC) gene. We showed that Pax7 pioneer action drives melanotrope specification in vivo by opening a new enhancer repertoire. We uncovered pioneer action dynamics using an engineered inducible Pax7. Pax7 can locate its target rapidly (less than 30 minutes) but initially binds weakly. Then, Pax7 binds strongly in less than 24h while chromatin opening is slow and progressive over more than three days. Following Pax7 withdrawal, long-term memory of pioneer action is associated with loss of DNA methylation.We then, investigated the role of nonpioneers during pioneer driven chromatin opening. The typical model of pioneer factor action assumes that nonpioneers are passive in this process and that they opportunistically bind newly accessible chromatin, yet this was never tested. The pioneer factor Pax7 acts as the specifying factor for melanotropes fate while the nonpioneer Tpit acts as the determining factor of both melanotropes and corticotropes. Chromatin accessibility is affected in Pax7 or Tpit deficient mice; they are required for the opening of their cognate program. Strikingly, in the absence of Tpit, Pax7 fails to drive melanotrope chromatin opening. Ectopically expressed Pax7 confirmed that Pax7 bind closed chromatin regardless of Tpit expression while Tpit is unable to bind closed chromatin in absence of Pax7. However, in the absence of Tpit, Pax7 does not open chromatin. In summary, we propose that cooperation between a pioneer factor and a nonpioneer factor drives lineage specific chromatin opening.</description><creator>Mayran, Alexandre</creator><contributor>Vincent Giguere (Supervisor2)</contributor><contributor>Jacques Drouin (Supervisor1)</contributor><date>2019</date><subject>Biochemistry</subject><title>Interplay between chromatin and transcription factors drives pituitary cell fate specification</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/sx61dp599.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/vx021h41h</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Biochemistry</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:b5644t81q</identifier><datestamp>2020-03-21T04:56:59Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Assurer un accès fiable à l'eau potable reste un défi aujourd'hui. Les technologies de filtration d'eau basées sur des éponges en oxyde de graphène sont utiles dans ce contexte grâce à la structure hiérarchique des pores, la grande surface, et la bonne adsorption de divers contaminants chimiques et métalliques. Cependant, les propriétés antimicrobiennes et la capacité d'élimination des bactéries par les éponges en oxyde de graphène ne sont pas bien comprises. Bien que des systèmes composites aient été développés pour améliorer les propriétés antimicrobiennes, la plupart de ces systèmes se concentrent sur la conjugaison d'antibiotiques puissants ou de biocides de métaux qui posent des problèmes de cytotoxicité. Les agents antimicrobiens biologiquement dérivés tels que les enzymes, peptides et polymères antimicrobiens sont prometteurs, en raison de leur coût relativement peu élevé, de leur biodégradabilité, de leur biocompatibilité et de leur capacité à fonctionnaliser facilement les surfaces en oxyde de graphène par la formation de liaisons covalentes avec des groupes fonctionnels contenant de l'oxygène. Dans le présent travail, l'enzyme antimicrobienne lysozyme, le peptide antimicrobien nisin et le polyamide antimicrobien ε-poly-L-lysine ont été utilisés pour fonctionnaliser de manière covalente la surface d'une éponge d'oxyde de graphène. L'activité antimicrobienne de la nouvelle surface a été démontrée contre deux organismes modèles : B. subtilis en tant que Gram-positif et E. coli K12 en tant que Gram-négatif. La performance des matériaux dans un contexte de filtration simulé a été évaluée par des expériences sur colonne et une rétention bactérienne améliorée des deux espèces par l'éponge fonctionnalisée a été démontrée. En outre, les échantillons de l'éponge après utilisation ont été évalués et l'activité antimicrobienne en mode flux continu a été démontrée.</description><description>Ensuring safe, reliable access to potable water remains a challenge today. Water filtration technologies based on graphene oxide sponges or hydrogels show promise in this field due to their high surface area, and versatile functionality yielding excellent adsorption affinity for different contaminants. However, the capacity for removal of bacteria and the intrinsic antimicrobial properties of graphene oxide sponges are not well understood. While composite antimicrobial systems have been successfully developed, many of these systems focus on the conjugation of antibiotics or potent metal biocides that pose cytotoxicity concerns. Natural, biologically derived antimicrobial agents such as antimicrobial enzymes, peptides and polymers hold promise in this respect due to their relatively low cost, biodegradability, biocompatibility and ability to easily functionalize graphene oxide surfaces by covalent bond formation with oxygen-containing functional groups. In the present work, the antimicrobial enzyme lysozyme, antimicrobial peptide nisin, and antimicrobial polyamide ε-poly-L-lysine were used to covalently functionalize the surface of a hierarchically porous graphene oxide sponge. The antimicrobial activity of the functionalized material was demonstrated against two model organisms: the Gram-positive B. subtilis and Gram-negative E. coli. The material performance in a simulated filtration context was evaluated using column experiments, and improved bacterial retention of both strains by the functionalized sponge was demonstrated. Furthermore, core samples of the sponge after filtration were evaluated with a membrane integrity assay and antimicrobial activity in a continuous flow mode was demonstrated. </description><creator>Filina, Anna</creator><contributor>Nathalie Tufenkji (Internal/Supervisor)</contributor><date>2019</date><subject>Chemical Engineering</subject><title>Antimicrobial graphene oxide sponge for water treatment applications</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/vd66w2044.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/b5644t81q</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Chemical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:x346d6451</identifier><datestamp>2020-03-21T04:56:59Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La coquille de l'œuf aviaire et l'otoconie de mammifère sont constituées de structures complexes organisées hiérarchiquement à partir d'une échelle allant de longueur nanométrique à des longueurs micrométriques. La biominéralisation des structures nanocristallines de carbonate de calcium (calcite) dans la coquille de l'œuf et dans l'otoconie est le résultat de processus complexes d'interaction et d'occlusion de la matrice protéique organique dans le minéral. Durant cette période de biominéralisation, l'ostéopontine (OPN), une glycoprotéine de structure considérablement désordonnée faisant partie des protéines SIBLING (Small, Integrin-Binding LIgand N-linked Glycoprotein) joue un rôle essentiel. L'OPN possède un caractère très acide (protéine chargée négativement) puisqu'elle contient des acides aminés glutamiques et aspartiques en abondance ainsi que des sérines phosphorylées. Ceci permet à l'OPN de se lier activement aux atomes de calcium parvenant des cristaux de calcite. De plus, les propriétés mécaniques et fonctionnelles des biominéraux sont grandement influencées par leur organisation hiérarchique structurale. À cet effet, l'objectif de ce travail de recherche est d'examiner la structure et la composition de la coquille de l'œuf de poule ainsi que celles de l'otoconie de souris à l'échelle nanoscopique afin de mieux comprendre son fonctionnement.Dans la coquille de l'œuf, nous avons trouvé, dans les couches (strates) principales, une nanostructure minérale de taille variable provenant vraisemblablement de processus d'occlusion de la matrice organique. Une biomacromolécule résidante de la coquille avec une propriété inhibitoire de croissance minérale, l'OPN peut aussi être incorporée à l'intérieur des cristaux de calcite synthétiques, créant de nanostructures similaires à celles observées dans la coquille de l'œuf. Ainsi, une haute teneur en OPN mènera à une nanostructure avec des cristallites de plus petite taille. Les propriétés mécaniques (la dureté et le module de Young) et fonctionnelles (la dissolution) des cristaux calciques synthétiques qui incorporent l'OPN sont en corrélation avec la nanostructure observée. Les nanostructures ayant des cristallites plus petites possèdent une dureté et un module de Young plus élevés, alors que la dissolution fractionnaire de la nanostructure des œufs fertilisés incubés semble essentielle à l'approvisionnement du squelette de l'embryon de la poule en croissance avec du calcium.Semblable aux résultats obtenus pour la coquille d'œuf, l'analyse structurale des otoconies des souris C57BL/6 a démontré que l'otoconie est composée de nanocristaux de calcite autant à l'extérieur qu'à l'intérieur. D'autres protéines occluses, incluant éventuellement l'OPN, participent vraisemblablement au développement de la nanostructure interne. En conclusion, ces résultats fournissent des détails sur la nanostructure et la composition de la coquille d'œuf d'une poule et celle de l'otoconie de mammifère, suggérant un autre rôle pour l'OPN dans les processus de biominéralisation qui pourrait éventuellement contribuer au développement de biomatériaux nanocomposites. </description><description>Avian eggshell and mammalian otoconia have complex structures that are hierarchically organized from nanometer to micrometer length scales. Biomineralization of calcium carbonate (calcite) nanostructure in eggshell and otoconia involves the interaction and occlusion of organic protein matrix within the mineral. One of the proteins associated with these processes during biomineralization (including in bones and teeth) is osteopontin (OPN), a secreted highly disordered glycoprotein belonging to the SIBLING (Small, Integrin-Binding LIgand N-linked Glycoprotein) family of proteins. OPN is a highly acidic (negatively charged) protein containing abundant glutamic and aspartic amino acids, and phosphorylated serines, enabling OPN to bind strongly to calcium atoms of calcite crystals. Furthermore, it is well-known that the functional and mechanical properties of biominerals are strongly influenced by the hierarchical structural organization of the biomineral. The goal of this dissertation research was to investigate the structure of chicken eggshell (Gallus gallus domesticus) and mouse otoconia at the nanoscale.In the eggshell, we identified a mineral nanostructure throughout the major eggshell layers that varied in size, presumably arising from the occlusion of organic matrix. OPN – an eggshell-resident inhibitory biomacromolecule – could also be incorporated within synthetic calcite crystals to create a similar nanostructure as that observed in eggshell, with higher OPN concentration leading to a smaller nanostructure size. Mechanical (hardness and elastic modulus) and functional (dissolution) properties were associated with the observed nanostructure. Decreased nanostructure was associated with increased eggshell hardness and elastic modulus, whereas in fertilized incubated eggs, fractional nanostructure dissolution appeared critical for providing calcium to the growing skeleton of the chick embryo.Similar to chicken eggshell, a structural analysis of otoconia in C57BL/6 mice showed an external and internal calcitic nanostructure. OPN was detected at the surface of otoconia and there correlated with surface nanostructure. Other occluded proteins, possibly including OPN, likely participate in producing the internal nanostructure.    In conclusion, these findings provide details on the nanostructure and composition of chicken eggshell and mammalian otoconia, suggesting also another possible role for OPN in biomineralization processes, which in turn might guide nanocomposite materials development.  </description><creator>Athanasiadou, Dimitra</creator><contributor>Marc D McKee (Supervisor)</contributor><date>2019</date><subject>Dentistry</subject><title>Nanostructure of calcareous biominerals and osteopontin</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/db78tf26w.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/x346d6451</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Faculty of Dentistry</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:n009w464r</identifier><datestamp>2020-03-21T04:57:00Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The high frequency of pedestrian crash injuries and the great possibility of fatal consequences have made pedestrian safety a great focus in road safety research. Pedestrian safety becomes even more of a problem at non-signalized locations when compared to signalized crosswalk locations, due to the absence of traffic lights controlling the traffic. This dissertation aims to improve data collection methods for pedestrian safety analysis and to develop a methodological framework to investigate pedestrian safety at non-signalized crosswalk locations.The work started with reviewing methodologies and data collection methods in previous studies. Methods used in past studies were classified into five different approaches: the crash data approach and four surrogate safety approaches (the traffic data approach, the conflict event approach, the behavioral analysis approach, and the perception analysis approach). Issues in the methodologies applied, and data used were summarized. To overcome the limitations that regular visible spectrum cameras have encountered during the data collection process, the thermal camera was introduced and its performance in road user detection, classification, and speed measurement was validated through its comparison to the use of the regular camera. Results showed an evidently better performance from thermal camera for low visibility and shadow conditions. For speed measurements, the thermal camera was consistently more accurate than the regular camera at daytime and nighttime. A study was conducted to investigate pedestrian safety at crosswalks at nighttime using existing measures. Although, the methodology performed well, further limitations of using safety measure methods were discovered upon the completion of the study. A novel framework which looks at the interaction between the pedestrian and the vehicle, and their behavior during the interactions, was proposed and illustrated through a case study. The framework was further tested through a study to compare the performance of three main non-signalized crosswalk types (uncontrolled, marked, and stop sign controlled crosswalks) on pedestrian safety in Montreal. Stop sign controlled crosswalks had the best performance in protecting pedestrians while uncontrolled crosswalks performed the worst. To explore the extensive applications of the framework, the investigation of cyclist-pedestrian interactions was introduced as it has been a major but underestimated safety problem. Marked crosswalks alone fail to protect pedestrians from passing cyclists. Besides, pedestrian safety at crossings on cycling facilities with downhill grades was found to be a great issue. The dissertation will: provide a comprehensive literature review that acts as a practical reference to investigating pedestrian safety at non-signalized crosswalk locations; introduce a promising alternative, the thermal camera, to overcome the limitations of using the visible camera for automated traffic data collection; propose a new framework that describes pedestrian-vehicle interactions more precisely, compared to previous studies. This framework is promising for different purposes in road safety on various topics, such as the analysis of interactions between different types of road users, road user interaction simulation, safety treatments validations, and the performance evaluations of autonomous vehicles. </description><description>La fréquence élevée des accidents impliquant des piétons et le grand risque de conséquences mortelles ont fait de la sécurité des piétons un élément central de la recherche sur la sécurité routière. La sécurité des piétons devient encore plus problématique aux endroits non signalés par rapport aux passages pour piétons signalés, en raison de l'absence de feux de circulation contrôlant le trafic. Cette thèse vise à améliorer les méthodes de collecte de données pour l'analyse de la sécurité des piétons et à développer un cadre méthodologique pour étudier la sécurité des piétons aux passages pour piétons non signalés.Le travail a débuté par la révision des méthodologies et des méthodes de collecte de données lors d'études précédentes. Les méthodes utilisées dans les études antérieures ont été classées en cinq approches différentes: l'approche par les données sur les accidents et quatre approches de sécurité de substitution (l'approche par les données de trafic, l'approche par conflit, l'approche par analyse comportementale et l'approche par analyse de perception). Les problèmes posés par les méthodologies appliquées et les données utilisées ont été résumés. Afin de surmonter les limites rencontrées par les caméras à spectre visible ordinaires lors du processus de collecte de données, la caméra thermique a été introduite et ses performances en matière de détection, de classification et de mesure de la vitesse des usagers de la route ont été validées par comparaison avec l'utilisation de la caméra classique. Les résultats ont montré que la caméra thermique offrait de meilleures performances dans les conditions de faible visibilité et d'ombre. Pour les mesures de vitesse, la caméra thermique était toujours plus précise que la caméra normale jour et nuit. Une étude a été menée pour examiner la sécurité des piétons aux passages pour piétons la nuit en utilisant les mesures existantes. Bien que la méthodologie ait donné de bons résultats, l'utilisation de méthodes de mesure de la sécurité a encore été limitée au terme de l'étude. Un nouveau cadre qui examine l'interaction entre le piéton et le véhicule et leur comportement lors de ces interactions a été proposé et illustré à travers une étude de cas. Le cadre a ensuite été testé dans le cadre d'une étude comparant les performances de trois principaux types de passages pour piétons non signalés (passages pour piétons non contrôlés, balisés et contrôlés par des panneaux d'arrêt) en matière de sécurité des piétons à Montréal. Les passages pour piétons contrôlés par des panneaux d'arrêt ont eu la meilleure performance en matière de protection des piétons, tandis que les passages pour piétons incontrôlés ont donné les meilleurs résultats. Pour explorer les applications étendues du cadre, la recherche sur les interactions cyclistes-piétons a été introduite car il s'agissait d'un problème de sécurité majeur mais sous-estimé. Les passages pour piétons marqués ne suffisent pas à protéger les piétons des cyclistes de passage. En outre, la sécurité des piétons aux passages à niveau sur des installations cyclables avec des pentes en descente s'est avérée être un problème majeur.La thèse: fournira une revue de la littérature complète qui servira de référence pratique pour enquêter sur la sécurité des piétons aux passages pour piétons non signalés; introduire une alternative prometteuse, la caméra thermique, afin de surmonter les limites de l'utilisation de la caméra visible pour la collecte automatisée de données sur la circulation; proposer un nouveau cadre décrivant plus précisément les interactions entre piétons et véhicules par rapport aux études précédentes. Ce cadre est prometteur pour différents objectifs en matière de sécurité routière sur différents sujets, tels que l'analyse des interactions entre différents types d'usagers de la route, la simulation d'interactions d'usagers de la route, la validation de traitements de sécurité et les évaluations de performances de véhicules autonomes.</description><creator>Fu, Ting</creator><contributor>Nicolas Saunier (Supervisor2)</contributor><contributor>Luis Miranda-Moreno (Supervisor1)</contributor><date>2019</date><subject>Civil Engineering &amp; Applied Mechanics</subject><title>A novel approach to investigate pedestrian safety in non-signalized crosswalk environments and related treatments using trajectory data</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/3t945t134.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/n009w464r</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Civil Engineering and Applied Mechanics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:z316q3698</identifier><datestamp>2020-03-21T04:57:01Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>In this thesis, Michel Henry's doctrine of bodily self-knowledge is comprehended and articulated, and placed within the context of his ontology of subjectivity. This is completed through an account of the first section of L'essence de la manifestation and the establishment of the context of Maine de Biran's work. As regards the latter, I triangulate Biran's reading of Kant with Henry. This is followed by an exposition of the section of Philosophie et phénoménologie du corps that bear on corporeal self-knowledge. It is argued that the content and purposes of the body in Henry's early work is not an incidental application to a new topical foci, but rather serves a central conceptual purpose as the completion of L'essence de la manifestation, whereby the subjective body is the concrete content of subjectivity. Finally, the importance of this early work for Henry's latter theological trilogy — in particular Incarnation — is suggested as a direction for future work.  </description><description>Dans cette thèse, la doctrine de l'auto-connaissance corporelle de Michel Henry est saisie et exprimée, ainsi qu'elle est située dans le contexte de son ontologie de la subjectivité. Ceci est fait à travers une explication de la première section de L'essence de la manifestation et du contexte de l'oeuvre de Maine de Biran. En ce qui concerne Maine de Biran, je triangule son interprétation de l'oeuvre de Kant avec Henry. Ceci est suivi d'une exposition de la section de Philosophie et phénoménologie du corps qui porte directement sur la question du l'auto-connaissance corporelle. Cette thèse soutient que le contenu et l'objet du concept du corps dans les premiers écrits de Henry n'est pas une application accessoire de L'essence de la manifestation au nouveau sujet, mais fonctionne plutôt comme son achèvement, où le corps subjectif est défini comme le contenu concret de la subjectivité. Finalement, l'importance des premiers écrits de Henry pour sa trilogie théologique, notamment Incarnation, est proposé comme une question pour les travaux futurs.</description><creator>Smith, Adam</creator><contributor>Garth Green (Internal/Supervisor)</contributor><date>2019</date><subject>Religious Studies</subject><title>Michel Henry's ontology of corporeal self-knowledge: an interpretation of Philosophie et phénoménologie du corps</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/x633f353z.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/z316q3698</identifier><degree><name>Master of Arts</name><grantor>McGill University</grantor><discipline>School of Religious Studies</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:41687k43f</identifier><datestamp>2020-03-21T04:57:02Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Composite polymers in the form of multilayer laminates are used to produce multifunctional surfaces such as food packaging, pool linings, or automotive interiors. Individual sheets provide antimicrobial properties, water resistance, or mechanical properties and require a sound union for robust composite performance. Current industrial processes use toxic isocyanate containing adhesives to bind the multiple layers together, which could be replaced with plasma deposition of nitrogen-rich organic adhesive coatings. Here, atmospheric-pressure dielectric barrier discharge (DBD) plasma is shown to enhance adhesion between a Thermoplastic Polyolefin (TPO) substrate and Polyurethane (PU) coating in an industrially suitable process. Sample production begins by treating TPO with two stages of DBD, operating at 18.7 kHz and 9.9 kVpp. Initial plasma treatment within a simulated air mixture achieves surface activation of TPO through oxidative reactions. A nitrogen-rich organic film is then deposited in the form of a plasma polymer through further DBD treatment using a mixture of nitrogen and either ethylene or butadiene. XPS characterization of samples at this stage showed up to 25 at% Nitrogen incorporated in produced plasma polymers. Following plasma treatment of TPO, solvent based polyurethane is then twice brush coated onto the modified substrate and cured in an oven at 95 ℃. Samples are finally assessed for the quality of adhesion between TPO and PU layers by qualitative and quantitative peel testing. Analysis of peel tests has shown clear improvements over samples without plasma polymer deposition, but lower delaminating loads than for samples produced with PECVD. Significant improvements including additional steps for quality control are required at lab scale to meet industrial standards. Nevertheless, the demonstrated adhesion enhancement, using an atmospheric pressure DBD plasma system, is a promising concept for polymer production. </description><description>Les polymères composites sous la forme de multicouches stratifiées sont utilisés pour produire des surfaces multifunctionelles telles que des revêtements de piscine et des intérieurs d'automobiles. Les couches individuelles confèrent des propriétés antimicrobiennes , des à la résistance à l'eau ou des propriétés mécaniques améliorés, et nécessitent une union solide pour des performances robustes. Les procédés industriels actuels utilisent des adhésifs contenant des isocyanates toxiques pour lier les multiples couches. Ces adhésifs pourraient être remplacés par un dépôt par plasma de couches organiques riches en azote adhésives. Ici, une décharge à barrière diélectrique à pression atmosphérique (DBD) permet d'obtenir une amélioration de l'adhérence entre un substrat de polyoléfine thermoplastique (TPO) et un revêtement de polyuréthanne (PU) dans un procédé convenant à l'industrie. La production d'échantillons consiste à traiter un substrat de TPO en deux étapes par DBD fonctionnant à 18,7 kHz, 9,9 kVpp. Le traitement plasma initial dans un mélange d'air synthétique permet d'obtenir une activation de la surface du TPO via des réactions oxydatives. Un film organique riche en azote est ensuite déposé sous la forme d'un polymère plasma par un second traitement DBD en utilisant un mélange d'azote et d'éthylène ou de butadiène. La caractérisation XPS des échantillons a montré jusqu'à 25% d'azote incorporé dans les polymères plasma produits. Après le traitement au plasma du TPO, un polyuréthane est appliqué deux fois au pinceau sur le substrat modifié et est par la suite cuit dans un four à 95 ° C. Les échantillons sont ensuite évalués en fonction de la qualité de l'adhérence entre les couches TPO et PU par des tests d'adhérences qualitatifs et quantitatifs. Ces tests ont montré des améliorations claires pour les échantillons avec dépôt de polymère plasma, mais des charges de délaminage plus faibles que pour les échantillons produits avec PECVD. Des améliorations importantes, notamment des étapes supplémentaires de contrôle de la qualité, sont nécessaires pour répondre aux exigences industrielles. Néanmoins, l'amélioration de l'adhérence démontrée avec un système plasma DBD à pression atmosphérique est un concept prometteur pour la production de polymères multicouches.</description><creator>Weeber, Dominic</creator><contributor>Pierre-Luc Girard-Lauriault (Internal/Supervisor)</contributor><date>2019</date><subject>Chemical Engineering</subject><title>Atmospheric pressure plasma deposition of thin organic films for improved adhesion in polymer composites</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/4j03d224q.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/41687k43f</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Chemical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:v405sc64m</identifier><datestamp>2020-03-21T04:57:03Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Over the last several years advances in the field of mine planning have led to the development of cutting-edge simultaneous stochastic optimization frameworks for mining complexes. The latest methods consider mining operations as a resource-to-market integrated mineral value that transforms raw in-situ materials into sellable products, a mining complex. Simultaneous stochastic optimization frameworks make use of a paradigm shift that considers the value of the sellable products, as opposed to economic block values, to drive the optimization process and capitalize on the synergies between the central, interrelated components of a mining complex. These methods maximize the value of mining operations and manage technical risk by incorporating uncertainty directly into unified optimization formulations. This thesis studies the simultaneous stochastic optimization framework through two real-world case studies, applying the methods and assessing their characteristics and limitations.  The second chapter of this thesis presents an application of a stochastic framework that simultaneously optimizes mining, destination and processing decisions for a multi-pit, multi-processor gold mining complex with challenging geochemical processing constraints. The framework accounts for supply and market uncertainty via stochastic orebody and commodity price simulations as inputs to a unified optimization model. The case study notably assesses the impacts of integrating market uncertainty as input that influences all components of the production schedule. Additionally, cut-off grade decisions are determined by the simultaneous optimization process, considering material variability and operating constraints while reducing the number of a-priori decisions to be made. This approach generates solutions that capitalize on the synergies between extraction sequencing, cut-off grade optimization, blending and processing while managing and quantifying risk in strategic plans. Which ultimately leads to more metal production and higher NPVs than traditional methods. The third chapter applies an extension of the generalized simultaneous stochastic optimization formulation that considers capital expenditure (CapEx) options as part of the life-of-asset planning process.  Enabling the case study to consider environmental issues relating to tailings management and model a tailings facility expansion. The application at a multi-element open pit mining complex simultaneously optimizes the extraction sequence, cut-off grades, and downstream decisions from two open-pits with a set of stockpiling options, an autoclave and a tailings storage facility. The project bottleneck is the tailings facility volume because it stores both process tails, and potentially acid-generating waste rock from the mines. Results show that, when given the option, the optimizer chooses to make a significant CapEx investment to expand the tailings storage facility 25% by volume. This expansion allows for a meaningful expansion of both pit limits, 40% by mass, resulting in an extended metal production and revenue generation horizon that yields 14% more gold ounces and a 4% improvement in NPV for the mining complex. The framework provides decision makers with a realistic evaluation of the investment's impact on the mining complex.</description><description>Au cours des dernières années, les progrès réalisés dans le domaine de la planification minière ont conduit à l'élaboration de modèles d'optimisation stochastique simultanée de pointe pour les complexes miniers. Les méthodes les plus récentes considèrent les activités minières comme une chaîne de valeur allant des ressources minérales au marché financier, transformant les matières brutes in-situ en produits vendables. Les modèles d'optimisation stochastique simultanée utilisent ce paradigme qui prend en compte la valeur des produits, par opposition à la valeur économique d'un bloc seul, pour piloter le processus d'optimisation et capitaliser sur les synergies entre les composants centraux et interdépendants d'un complexe minier. Ces méthodes maximisent la valeur des opérations minières et contrôlent les risques techniques en incorporant directement l'incertitude dans des formulations d'optimisation unifiées. Cette thèse étudie un modèle d'optimisation stochastique simultanée à travers deux études de cas réels, appliquant des méthodes de résolution et en évaluant leurs caractéristiques et leurs limites. Le deuxième chapitre de cette thèse présente l'application d'un modèle stochastique qui optimise simultanément les décisions d'extraction, de destinations et de traitement pour un complexe aurifère à plusieurs fosses et à plusieurs processeurs soumis à des contraintes de traitement géochimique complexes. Le modèle d'optimisation unifié prend en compte les incertitudes de l'offre et du marché au moyen de simulations stochastiques du gisement et du prix de la marchandise comme données d'entrée. L'étude de cas évalue notamment les effets de l'intégration de l'incertitude du marché sur toutes les composantes du calendrier de production. De plus, les décisions concernant le niveau de la teneur limite sont déterminées par le processus d'optimisation simultanée, en tenant compte de la variabilité des matériaux et les contraintes de fonctionnement, tout en réduisant le nombre de décisions à prendre a-priori. Cette approche génère des solutions qui capitalisent sur les synergies entre la séquence d'extraction, l'optimisation du niveau de la teneur limite, le mélange et le traitement, tout en gérant et quantifiant les risques dans des plans stratégiques. Cela conduit finalement à une plus grande production de métal et à un NPV plus élevé par rapport aux résultats obtenus par des méthodes traditionnelles. Le troisième chapitre considère une extension du modèle précédent mais qui inclue des options de dépenses en capital (CapEx) dans le processus de planification de la durée de vie des actifs. Cela permet à l'étude de cas de considérer les problèmes environnementaux liés à la gestion des résidus et de modéliser l'agrandissement d'un entrepôt à résidus. L'application à un complexe minier à ciel ouvert multi-éléments optimise simultanément la séquence d'extraction, le niveau de la teneur limite et le flux de matériau provenant de deux fosses avec un ensemble d'options de stockage, un autoclave et une pile de stockage de résidus. Le goulot du projet est le volume de l'entrepôt à résidus car il stocke à la fois les résidus et les résidus potentiellement acidogènes des mines. Les résultats montrent que, lorsqu'il en a la possibilité, l'optimiseur choisit de faire un investissement important en CapEx pour agrandir de 25% en volume le local de stockage des résidus miniers. Cet agrandissement permet une expansion significative des deux limites de la fosse, 40% en masse, ce qui entraîne une augmentation de la production de métal et un allongement de l'horizon de génération de revenus. Cela se traduit par une production de 14% d'onces d'or supplémentaires et une amélioration de 4% du NPV du complexe minier. Le système fournit aux décideurs une évaluation réaliste de l'impact de l'investissement sur le complexe minier.</description><creator>Saliba, Ziad</creator><contributor>Roussos G Dimitrakopoulos (Internal/Supervisor)</contributor><date>2019</date><subject>Mining and Materials</subject><title>A study of simultaneous stochastic optimization of open pit mining complexes</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/3j333457d.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/v405sc64m</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Mining and Materials</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:x346d6469</identifier><datestamp>2020-03-21T04:57:04Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Genetic leukoencephalopathies are considered rare in the adult population. However, several lines of evidence suggest that there is a larger than expected number of adult patients with genetic leukoencephalopathies who are currently not diagnosed. The study of leukoencephalopathies - either genetically-proven or unsolved - relies greatly on MRI pattern-recognition, which allowed the characterization of the majority of genetic white matter disorders. The advent of next generation sequencing (NGS) revolutionized the field, by disclosing new phenotypes associated to known genetic white matter conditions and identifying novel genes responsible for unsolved leukoencephalopathies. The goals of my study were1.the application of advanced neuroimaging tools to define and characterize white matter abnormalities of known and novel genetic leukoencephalopathies2.the clinical and demographic characterization of subjects with adult genetic leukoencephalopathies3.the identification of genes responsible for new forms of hereditary white matter disorders, using NGS techniques.We applied an integrated approach which combined clinical phenotyping with MRI pattern-recognition and NGS data. This work led to a) the description of a cohort of 68 adult subjects with leukoencephalopathy of probable genetic origin, 59 of which were included in our study, b) the identification of the causal mutations (16 in total, 11 novel) in genes known to be associated with leukoencephalopathies in 14/59 subjects (23.7%), and c) the broadening of clinical and imaging phenotypes of known disorders: POLR3-related disorders, vanishing white matter disease, Krabbe disease, MTFMT-related disorders. We demonstrated that MRI family studies can be crucial in adult leukoencephalopathies to define the modality of transmission of unclear white matter disorders within families. In conclusion, we documented that adult genetic leukoencephalopathies are an emerging problem in clinical neurosciences. MRI family studies and the recognition of disease-specific MRI features are critical to guide the diagnostic process. Despite the access to NGS techniques, more than 70% of our subjects remain without a diagnosis. The international sharing of MRI and NGS on adult leukoencephalopathies will allow the identification of subjects with same phenotypes or mutated genes and ultimately lead to the description of new genetic entities.</description><description>Les leucoencéphalopathies génétiques sont considérées rares dans la population adulte. Cependant, plusieurs sources de données suggèrent qu'il existe un nombre plus élevé qu'attendu de patients adultes atteints par une leucoencéphalopathie qui n'ont pas encore de diagnostic. L'étude des leucoencéphalopathies – autant confirmées génétiquement que non résolues – dépend grandement de l'identification de caractéristiques diagnostiques obtenues par IRM, qui permettent la caractérisation de la majorité des maladies génétiques de la substance blanche. L'avènement du séquençage de dernière génération (NGS) a révolutionné ce domaine, en permettant la découverte de nouveaux phénotypes associés à des maladies génétiques connues de la substance blanche et l'identification de nouveaux gènes responsables pour des formes non résolues.  Les objectifs de mon étude ont été1.l'application de techniques de neuroimagerie avancées dans le but de définir et caractériser les anomalies de la substance blanche de leucoencéphalopathies connues et nouvelles ;2.la caractérisation clinique et démographique des sujets adultes atteints de leucoencéphalopathies génétiques ;3.l'identification de gènes responsables de nouvelles formes de maladies héréditaires de la substance blanche, en utilisant des techniques NGS.Nous avons appliqué une approche intégrée combinant phénotypage clinique et identification de critères obtenus par IRM et données générées par NGS. Cette étude a permis l'obtention de données concernant a) la description d'une cohorte de 68 sujets adultes atteints d'une leucoencéphalopathie d'origine supposée génétique, dont 59 ont été inclus dans notre étude, b) l'identification de mutations causales (16 au total, dont 11 nouvelles) dans des gènes connus pour être associés à des leucoencéphalopathies dans 14/59 sujets (23.7%), c) l'expansion des phénotypes cliniques et radiologiques de leucoencéphalopathies connues: les désordres associés à POLR3, maladie VWM (Vanishing White Matter disease), maladie de Krabbe, les désordres associés à MTFMT. Nous avons démontré que les études familiales par IRM sont un outil crucial dans le domaine des leucoencéphalopathies adultes pour la définition de la modalité de transmission – quand cette dernière était jusqu'à lors inconnue.En conclusion, nous avons documenté que les leucoencéphalopathies génétiques chez les patients adultes sont un problème émergeant dans les neurosciences cliniques. Les études familiales par IRM et l'identification de caractéristiques IRM spécifiques de chaque maladie  sont déterminantes pour guider le processus diagnostique. Malgré l'accès aux techniques NGS, une grande majorité (plus de 70%) de nos sujets demeure sans diagnostic. Le partage de données IRM et NGS de leucoencéphalopathies adultes dans des réseaux internationaux permettra l'identification de sujets avec les mêmes phénotypes ou gènes mutés, et portera finalement à la description de nouvelles entités génétiques. </description><creator>La Piana, Roberta</creator><contributor>Bernard Brais (Supervisor1)</contributor><contributor>Donatella Tampieri (Supervisor2)</contributor><date>2019</date><subject>Neuroscience</subject><title>Adult genetic leukoencephalopathies: identifying new entities using advanced MRI techniques, next generation sequencing and clinical profiling</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/kp78gj642.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/x346d6469</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Integrated Program in Neuroscience</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:rj4306946</identifier><datestamp>2020-03-21T04:57:04Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Comment multiples molécules de polymère interpénétrantes se comportent dans un espace confiné est un problème d'intérêt d'un point de vue biologique et aussi technologique. Nous étudions une solution de molécules d'ADN confinée dans une lamelle sur une puce nanofluidique. Dans la lamelle de dimensions nanométriques, les molécules d'ADN sont comprimées par un courant hydrodynamique contre une barrière perméable seulement au solvant; le profil de la solution d'ADN comprimée ainsi obtenu est enregistré en fonction de sa position dans la lamelle. Nous développons un model théorique pour ce profil de concentration basé sur l'assomption du champ moyen et utilisant le principe de variation «Onsager». Ce model produit une équation non-linéaire de type «Schrödinger» pour le profil de concentration. Nous ajustons ce model à nos données et trouvons que celles-ci conforment bien à notre prédiction quand la concentration d'ADN est suffisante.</description><description>How multiple interpenetrating polymer molecules behave in a confined space is a problem of interest both from a biological and a technological standpoint. We probe a solution of DNA molecules confined in a slit-like geometry on a nanofluidics chip. Inside the nanoscale slit, the DNA molecules are compressed via hydrodynamic flow against a barrier permeable only to solvent; the resulting compressed DNA solution concentration profile is recorded as a function of position in the slit. We develop a theoretical model for this concentration profile based on mean-field assumptions and using the Onsager Variational Principle. We find that this model yields a nonlinear Schrödinger type equation governing the concentration profile. We fit this model to our experimental data and we find good agreement for high enough DNA concentration.</description><creator>Zeng, Lili</creator><contributor>Walter Reisner (Internal/Supervisor)</contributor><date>2019</date><subject>Physics</subject><title>Compression of nanoslit confined polymer solutions</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/hd76s241h.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/rj4306946</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Physics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:gh93h181v</identifier><datestamp>2020-03-21T04:57:05Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Laser powder bed fusion (LPBF) of Ti6Al4V has become the subject of considerable attention in recent years in a variety of disciplines, notably those of the aerospace and biomedical domains. In either case, Ti6Al4V is an extremely high importance alloy due to its light weight and formidable mechanical and physical properties. With the advent of LPBF processes, it has become possible to create highly complex components that could otherwise not be constructed by conventional means, and with little to no wasted material. In order for LPBF of this alloy to become a viable processing route however, its properties and proper functioning must be ascertained. The following work explores the thermal behavior of Ti6Al4V both during and after processing by LPBF. It is well known that laser-based melting processes produce a great deal of thermal and residual stresses. The detrimental effects of these stresses were measured for a series of samples with differing geometrical features to better understand the various design constraints to consider. In parallel, a number of dilatometric samples were extracted from a separate subset of samples with varying build orientation (X-direction, Z-direction, and 45o) and post-processing heat treatments (stress relief, mill annealing, and HIP) for the purpose of determining the effects of these processing parameters on thermal expansion. Anisotropy of various properties arising from LPBF based on build orientation has been reported in separate studies, and is observed again here for the coefficient of thermal expansion (CTE). The heat treatment applied appeared to directly affect the severity of the observed anisotropy and is discussed within.</description><description>La fusion par laser sur lit de poudre (de l'anglais LPBF) de Ti6Al4V est devenue récemment un sujet de grande attention dans une variété de disciplines, notamment dans celles de l'aérospatiale ainsi que de la biomédecine. Pour ces derniers, cet alliage est indispensable due à son faible poids et ses propriétés mécaniques et physiques formidables. Grâce à la LPBF, il est désormais possible de créer des pièces avec une complexité irréalisable par les moyens de fabrications conventionnels, avec très peu de gaspillage. Par contre, pour que la LPBF de cet alliage devienne un processus industriel viable, ses diverses propriétés et son bon fonctionnement doivent être vérifiés. La présente étude explore le comportement thermique de Ti6Al4V durant et suite à la fabrication par LPBF. Il est bien établi que les processus de fabrication par laser, tel la LPBF, représentent une source importante de contraintes thermiques et résiduelles. Les effets de ceux-ci ont été mesurés pour une série d'échantillons ayants de différentes géométries afin de mieux comprendre certaines contraintes de conception. En parallèle, plusieurs échantillons dilatométriques ont été extraits d'une série séparée d'échantillons ayant été construits en différentes orientations (direction X, direction Z, et à 45o) et avec différents traitements thermiques (recuit de détente, recuit à température plus élevée, et HIP) pour pouvoir déterminer les effets de ces paramètres sur l'expansion thermique. L'anisotropie de diverses propriétés suite à la fabrication par LPBF en fonction de l'orientation a été rapportée à plusieurs reprises, et est discutée ici pour le cas du coefficient d'expansion thermique (CTE). Le niveau de traitement thermique semble avoir un lien direct avec la sévérité de l'anisotropie observée et est aussi sujet de discussion dans cette étude.</description><creator>Danovitch, Jason</creator><contributor>Mathieu Brochu (Internal/Supervisor)</contributor><date>2018</date><subject>Mining and Materials</subject><title>Residual stresses and thermal expansion of Ti6Al4V fabricated by laser powder bed fusion</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/fn1071190.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/gh93h181v</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Department of Mining and Materials</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:tx31qm05v</identifier><datestamp>2020-03-21T04:57:06Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les fractures du col du fémur sont des blessures graves caractérisées par un fardeau de maladies important et un taux de mortalité élevé. Le taux de ces blessures est estimé à augmenter et créer un poids considérable pour le secteur de la santé dans les prochaines années. En raison de l'impact de cette blessure sur ceux qui en souffrent ainsi que sur la société, il est nécessaire d'identifier le traitement optimisant la guérison. Pour ce faire, une méta-analyse de réseau a été réalisée selon trois résultats (qualité de vie, mortalité et ostéonécrose avasculaire de la tête du fémur) et les traitements ont été classés en fonction de chaque résultat. De plus, les résultats de l'analyse de la qualité de vie et de la mortalité ont été combinés pour donner un classement sommatif. L'arthroplastie totale de la hanche sans ciment a été classée comme étant le meilleur traitement pour la qualité de vie, tandis que l'hémiarthroplastie unipolaire cimentée était le meilleur en termes de mortalité. Aucun contraste significatif n'a toutefois été trouvé pour cette dernière. La capsulotomie avec réduction ouverte et une greffe osseuse iliaque a été classé la meilleure pour l'ostéonécrose. Les broches étaient significativement supérieures aux vis canulées pour cette complication. Le classement combiné suggère que l'arthroplastie totale avec ou sans ciment ou l'hémiarthroplastie avec ciment devraient être utilisés comme traitement des fractures du col du fémur déplacées chez les personnes âgées. Alors que les deux premiers étaient classés relativement bas (respectivement sixième et troisième) pour la mortalité, ils n'étaient pas significativement pires que les autres traitements. Des recommandations sont présentées pour faire progresser les connaissances sur cette blessure hautement problématique.</description><description>Femoral neck fractures are serious injuries characterised by a significant burden of illness and an elevated mortality rate. The rate of this injury is forecasted to increase and create a substantial burden on the healthcare sector. Due to the impact this injury has on those who suffer them as well as society, there is a need to identify the treatment that optimizes the healing process. To do so, a network meta-analysis was conducted on three outcomes (quality of life, mortality and avascular necrosis) and treatments were ranked according to each outcome. Furthermore, the results of the quality of life analysis and mortality were combined to give a multi-outcome ranking. Uncemented total hip arthroplasty was ranked best for QoL, whereas cemented unipolar hemiarthroplasty was best for mortality. No significant contrasts were found for mortality however. Capsulotomy, with open reduction an iliac graft was found to be ranked highest for avascular necrosis. Pins were significantly superior to cannulated screws for this outcome. Combined rankings suggest that either total hip arthroplasty with or without cement, or hemiarthroplasty with cement should be used as a treatment for displaced femoral neck fractures in the elderly. While the former two were ranked poorly (sixth and third, respectively) for mortality, they were not significantly worse than other treatments. Recommendations are presented to further advance knowledge for this highly problematic injury. </description><creator>Lavigne, Jacob</creator><contributor>John Sotirios Sampalis (Supervisor)</contributor><date>2019</date><subject>Surgery</subject><title>Identifying optimal femoral neck fractures treatments using a network meta-analysis</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/xw42nb03k.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/tx31qm05v</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Surgery</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:w95052654</identifier><datestamp>2020-03-21T04:57:07Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>L'utilisation des technologies de l'information et de la communication (TIC) est un moyen novateur de soutenir l'indépendance des personnes âgées pour qu'elles puissent vieillir chez soi si désiré. Les produits technologiques destinés au maintien de l'indépendance, à la participation sociale, et aux besoins en qualité de vie des personnes âgées, offrent la possibilité d'aider les ergothérapeutes à soutenir les services de soins à domicile. À notre connaissance, aucune étude n'a investigué les connaissances actuelles des ergothérapeutes canadiens sur ces technologies et les facteurs influençant leur utilisation et recommandation en pratique. L'objectif du projet est de décrire l'état des connaissances sur les TIC des ergothérapeutes canadiens et d'identifier les facteurs associés à leur utilisation et recommandation en pratique. Un sondage pancanadien a été déployé en ligne. Celui-ci comprenait des questions démographiques ainsi que sur la pratique clinique et les technologies. Les organisations professionnelles des ergothérapeutes de chacune des provinces et territoires ont été contactées afin d'inviter leurs membres à remplir le sondage. Des statistiques descriptives, des analyses khi-carré et des analyses de régression logistique ont été réalisées. Nous avons reçu 874 réponses au sondage et 681 étaient complètes. Parmi celles-ci, 387 des répondants ont rapporté travailler avec une clientèle gériatrique ou gériatrique et adulte. Parmi eux, 177 (45.7%) ont rapporté être familier avec la technologie, mais seulement 48 (12.4%) ont déclaré l'utiliser en pratique. La majorité des répondants étaient des femmes travaillant dans les provinces du Québec et de la Colombie-Britannique. La majorité des utilisateurs de technologies ont plus de 45 ans et plus de 10 ans d'expérience clinique. Le plus souvent, ils ont rapporté recommander des technologies pour aides à la communication (97.9%), suivie des technologies traitant des incapacités liées à la cognition (79.2%). Parmis celles soutenant la communication, les plus courantes sont les applications de synthèse vocale pour ordinateurs, tablettes ou téléphones intelligents (33%). Les plus courantes pour la cognition sont celles pour la stimulation cognitive sur tablettes ou téléphones intelligents (48%). La régression logistique univariée a montré que les probabilités d'utilisation de technologies en clinique augmentaient si les ergothérapeutes étaient plus âgés (âgé de 35-45 ans (OR: 3.40); âgé de plus de 45 ans (OR: 5.23); par comparaison au groupe d'âge de 24-34 ans), avaient plus de 10 ans d'expérience (OR: 2.65), offraient un service de réadaptation professionnelle (OR: 2.74), traitaient des problèmes de déglutition (OR: 6.25), et travaillaient dans un hôpital/établissement de réadaptation (OR: 2.74). Les probabilités étaient négativement associées si les ergothérapeutes offraient des services hospitaliers d'évaluation (OR: .28), traitaient une clientèle atteinte de démence (et syndromes associés) (OR: .035) et travaillaient dans un hôpital (OR: .34). Dans la régression logistique multivariée, seule le nombre d'années d'expérience clinique restait positivement associé à l'utilisation de la technologie en pratique (OR: 2.43) et le travail dans un hôpital général ainsi que le traitement de la démence (et syndromes associés) restaient négativement associés à l'utilisation de la technologie (OR: .378 et .415 respectivement). Les résultats soulignent que les ergothérapeutes manquent de connaissances sur les TIC pouvant être utilisées dans leur pratique avec les personnes âgées. De plus, une connaissance des TIC ne suffit pas pour en garantir l'utilisation. Les facteurs environnementaux, personnels, et professionnels, doivent être pris en compte lors de la préparation des recommandations pour la mise en pratique de l'utilisation de la technologie. Des recherches supplémentaires sont nécessaires afin d'élucider les facilitateurs et les obstacles à l'adoption de la technologie en pratique.</description><description>The use of information and communication technologies (ICTs) is an innovative way to support independence in later years so that older adults can age in place if they desire. Technological products that cater specifically to the maintenance of independence, social participation, and the quality of life (QoL) needs of seniors, offer the potential to assist occupational therapists (OTs) in supporting home care services. To our knowledge, no study has investigated the current knowledge of such technology by Canadian OTs and which factors influence their use and recommendation of it in practice. The objective of this project is to describe the current state of knowledge on ICTs of Canadian OTs and identify which factors are associated with its use and recommendation in practice. A Canada-wide online survey was deployed. The survey included questions pertaining to demographics, clinical practice characteristics, and technologies used. Provincial and territorial professional OT organizations were contacted to invite their members to complete the survey, available in English and French. Descriptive statistics, chi-square analyses, and logistic regression analyses, were completed to describe clinical practices and identify which factors are associated with the usage of technology. There were 874 respondents to the survey and 681 full completions. Among those, 387 reported working with a geriatric or geriatric and adult clientele. Of those, 177 (45.7%) reported being familiar with technology but only 48 (12.4%) reported using it in practice. The majority of respondents were females working in the provinces of Quebec and British Columbia. The results show that the majority of OTs who are familiar and users of technology in practice are over the age of 45 and have over 10 years of clinical experience. The most reported used and recommended technology in practice addressed disability with communication (97.9%), followed by technologies addressing disabilities related to cognition (79.2%). More specifically, within those to support communication, the most common was text to speech applications (33%) for websites on computers, tablets, or smartphones. Within those for cognition, the most common was applications on tablets or smartphones for cognitive stimulation (48%). Finally, the univariate logistic regression showed that the odds of using technology in clinical practice increased if OTs were older (35-45 age group (OR: 3.40) and over 45 age group (OR: 5.23) as opposed to the 24-34 age group), had over 10 years of clinical experience (OR: 2.65), offered vocational rehabilitation client services (OR: 2.74), treated swallowing client conditions (OR: 6.25) or worked in a rehabilitation hospital or facility (OR: 2.74), as opposed to OTs that did not. On the other hand, the odds were lower for OTs offering assessment or orientation hospital services (OR: .28)), if they addressed dementia and related syndromes client conditions (OR: .035) or if they worked in a general hospital (OR: .34). In the multivariate logistic regression, only years of clinical experience remained positively associated with use of technology in clinical practice (OR: 2.43), and working in a general hospital, as well as treating dementia and related conditions, remained significantly negatively associated with usage of technology (OR: .378 and .415 respectively). The results highlight that OTs lack knowledge on the current ICTs available for use in their practice with older adults. Moreover, familiarity with such technology is not enough to ensure its use. Personal and workplace environmental factors need to be accounted for when preparing recommendations for implementation of technology use in practice. Further research is needed to elucidate the facilitators and barriers faced with adoption of technology in practice.</description><creator>Aboujaoudé, Aline</creator><contributor>Nathalie Bier (Internal/Cosupervisor2)</contributor><contributor>Patricia Da Cunha Belchior (Internal/Supervisor)</contributor><date>2019</date><subject>Physical &amp; Occupational Therapy</subject><title>Use of technology in Canadian occupational therapists' practices with older adults: A nationwide survey</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/4m90dx62z.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/w95052654</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>School of Physical and Occupational Therapy</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:x633f3547</identifier><datestamp>2020-03-21T04:57:08Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Compaction is the first morphogenetic event essential for the formation of the blastocyst during mouse preimplantation development. It is recognized as an increase in cell-cell contact and minimizing the exposed surface area of the embryo. However, the molecular mechanisms governing compaction have not been elucidated. To identify molecular changes before and after compaction, we investigated the distribution of the actomyosin network and the E-cadherin complex, which are major regulators of cell shape. We observed a reduction of both F-actin and phospho-Myosin Light Chain II (pMLCII) at cell-cell contacts, compared to the contact-free surface after compaction, suggesting the generation of two cortical subdomains with distinct biophysical properties within a cell. E-cadherin and β-catenin were evenly distributed across the cell-cell contact and non-contact surfaces before and after compaction. However, we found an increase of α-catenin and a decrease of p120-catenin at cell-cell contacts compared to the contact-free surface after compaction. This suggests that the stoichiometry of the members of the E-cadherin complex appears to be dynamically changing. Homodimer forms of α-catenin have been shown to suppress actin polymerization by blocking ARP2/3 activity at cell-cell contacts and p120-catenin also functions in recruiting ROCK1, a Rho effector which can regulate acto-myosin contractility. We speculate that the change in distribution of α-catenin and p120 catenin would contribute to the reduction of F-actin and pMLCII at cell-cell contacts during compaction. In E-cadherin null embryos, the actomyosin network at cell-cell contacts was not lowered at the 8-cell stage. As expected, cortical localization of p120-catenin and β-catenin, both at cell-cell contacts and contact-free surface, was E-cadherin dependent. Interestingly, while α-catenin localization at the non-contact surface is E-cadherin dependent like other catenins, its localization at cell-cell contacts is E-cadherin independent. These results suggest that E-cadherin regulates the actomyosin network through canonical and non-canonical means at cell-cell contacts and the non-contact surface, respectively. </description><description>Pendant le développement du l'embryon de la souris, le compactage est le premier évènement essential pour the génération du blastocyste. Nous reconnaissons le compactage par le grandissent du contact entre les cellules et la diminution du surface du l'embryon. Toutefois, on ne connaît pas le mécanisme moléculaire qui gouverne le compactage du l'embryon. Pour identifier les changements moléculaires avant et après le compactage, nous avons examiné la distribution des molécules de la groupe actomyosine et le complexe de E-cadherin-catenin, qui sont importante pour régler la forme des cellules.  Nous avons observé une réduction de F-actin et le phospho-Myosin Light Chain II au contact des cellules après le compactage. Ses résultats proposent que la production de deux différents domaines corticaux dans un cellule est nécessaire pour le compactage. Nous avons aussi observé que E-cadherin et β-catenin sont également distribué autour tout le cortex, avant et après le compactage. Toutefois, nous avons aussi observé une augmentation de α-catenin et une diminution de p120-catenin au contact des cellules après le compactage. Ça nous dit que la complexe de E-cadherin-catenin change avant and après le compactage. Le forme homodimère de α-catenin étouffe l'activité de ARP2/3, qui fonctionne à la polymérisation de F-actin.  P120-catenin est aussi trouver de recruté ROCK1, une molécule qui control la fonction de phospho-Myosin Light Chain II. Nous proposons une théorie que la distribution de α-catenin et p120-catenin sont responsables pour la réduction de F-actin et phospho-Myosin Light Chain II au contact entre les cellules. Les embryons mutants qui manquent du E-cadherin, (MZ)Cdh1-/-, ne peuvent pas réduire le F-actin et phospho-Myosin Light Chain II a l'étape de 8-cellules. On a aussi observé que la localisation de β-catenin et p120-catenin sont dépendons à l'expression de E-cadherin. Curieusement, la localisation de α-catenin a la contacte entre les cellules est indépendant de l'expression de E-cadherin. Au total, ses résultats proposent que le E-cadherin fonction a réglé la distribution des protéines corticale pour encourager le compactage.</description><creator>Saini, Deepak</creator><contributor>Yojiro Yamanaka (Internal/Supervisor)</contributor><date>2019</date><subject>Human Genetics</subject><title>Identification of molecular changes during compaction in the preimplantation mouse embryo</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/8623j120r.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/x633f3547</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Human Genetics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:mg74qp35q</identifier><datestamp>2020-03-21T04:57:09Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Lanthipeptides are a family of peptide natural products that contain characteristic thioether rings within their structures. These rings are post-translational modifications installed into the C-terminal region of ribosomally synthesized precursor peptides (LanAs). In class II lanthipeptides, a single enzyme (LanM) constructs these thioether rings in a multistep reaction cascade. Due to their antibiotic properties and the growing crisis of antibacterial resistance, lanthipeptides are important targets of drug development – making an understanding of their biosynthesis essential. Recently, the first crystal structure of a class II lanthipeptide synthetase (CylM) was solved, providing an opportunity to investigate potentially vital structural characteristics of LanMs. One interesting structural feature is an intrinsically disordered loop that appears to be strategically placed between both the dehydratase and cyclase domains of the enzyme. A sequence alignment of hundreds of known LanMs showed that not only does this loop have a conserved length of about 60 residues, but that it also contains a conserved serine/threonine-aspartate motif as well as conserved flanking proline residues. Using a mass spectrometry-based approach, we show here that mutating these residues in the haloduracin β synthetase, HalM2, leads to interesting perturbations in enzymatic activity, implying a functionally critical role for this loop that has been previously overlooked.  Similar results were obtained with a second, distantly-related class II lanthipeptide synthetase (the ProcM enzyme of prochlorosin biosynthesis), suggesting that the disordered loop serves a critical functional role throughout this family of enzymes.  The potential engineering and biotechnological implications of these findings are discussed. </description><description>Les lanthipeptides sont une famille de produits naturels contenant un thioéther cyclique au sein de leur structure peptidique. Ces thioéthers cycliques proviennent de modifications post-traductionnelles ribosomiques et sont installés sur l'extrémité C-terminale des peptides précurseurs (LanAs). Dans le cas des lanthipeptides de classe II, une seule enzyme (LanM) assure la cascade réactionnelle nécessaire à la formation de ces thioéthers cycliques. Dû à leurs propriétés antibiotiques ainsi qu'à la crise croissante de la résistance aux antibiotiques, les lanthipeptides sont d'importantes cibles pour le développement de molécules thérapeutiques. La compréhension de leur biosynthèse est donc essentielle afin de poursuivre cet objectif. Récemment, la révélation de la première structure cristallographique d'une lanthipeptide synthase de classe II (CylM) a nouvellement permis l'investigation d'éléments structurels essentiels à son fonctionnement. Un élément structurel intéressant est un type de coude à la jonction du domaine dehydratase et du domaine cyclase de l'enzyme. Un alignement de séquences de plus d'une centaine de LanMs a montré que ce coude est composé d'environ 60 acides aminés, commençant et terminant par une proline, et possède également un motif conservé de serine/thréonine-aspartate. En utilisant la spectroscopie de masse, nous montrons que la mutation de ces acides aminés perturbe le fonctionnement de l'enzyme haloduracin β synthetase (HalM2) indiquant qu'ils seraient importants à son mécanisme d'action. Des résultats similaires ont été obtenus utilisant une lanthipeptide synthase de classe II distinctement liée (ProcM) suggérant que ce coude liant les deux domaines de l'enzyme pourrait être critique au fonctionnement des enzymes de cette même classe. Les implications biotechnologiques potentielles de ces découvertes sont également explorées. </description><creator>Uggowitzer, Kevin</creator><contributor>Christopher Thibodeaux (Internal/Supervisor)</contributor><date>2019</date><subject>Chemistry</subject><title>A conserved, conformationally dynamic loop defines function in class II lanthipeptide synthetases</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/td96k483x.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/mg74qp35q</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Chemistry</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:m900nw77h</identifier><datestamp>2020-03-21T04:57:09Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Cette thèse utilise des techniques d'identification de systémes pour étudier deux relations entrées-sorties importantes pour la biomécanique de la cheville humaine. En premier lieu, elle étudie la relation entre la surface ElectroMyoGram (EMG) et le moment de torsion et élabore un modéle complet pour les contractions isométriques non-stationnaires. La capacité du modèle de EMG-moment de torsion résultant à prédire le moment de torsion avec précision a de nombreuses applications importantes. Deuxièmement, elle examine Dynamique de rigidité articulaire lors de contractions isométriques variant dans le temps. La dynamique de rigidité articulaire décrit les propriétés neuromécaniques d'une articulation et a deux composants: (a) la rigidité intrinsque qui est due aux propriétés mécaniques de l'articulation ainsi que des muscles et des tissus; et (b) la rigidité réflex générée par réflexe ostéotendineux. Les dynamiques de rigidité sont nonlinéar et changer de manière significative avec position conjointe et niveau d'activation. Cette thése quantifie la dèpendance fonctionnelle de la dynamique de la rigidité articulaire au niveau d'activation lors de contractions isométriques variant dans le temps.La première partie de cette thèse, qui caractérise la relation dynamique entre l'EMG de surface et le moment de torsion, fait quatre contributions importantes : (a) Elle montre que lors des contractions volontaires, l'EMG contient une composante de réaction en moment de torsion, de sorte que des méthodes en boucle fermée doivent être utilisées pour estimer avec précision la relation entre le EMG et le moment de torsion. (b) Elle démontre que les modèles de EMG-moment de torsion linéaires changent avec le niveau moyen du couple volontaire et la vitesse à laquelle il est modulé. (c) Elle développe et valide une nouvelle méthode d'identification non- linéaire en boucle fermée pour les systèmes de Hammerstein. (d) Elle utilise cette méthode pour estimer un système Hammerstein unique qui modélise la dynamique du EMG-moment de torsion sur une large plage de niveaux de contraction.La deuxième partie de la thèse examine les modifications de la rigidité des articulations avec les niveaux de contraction volontaire en utilisant une approche paramètre variable (PV) pour modéliser la dynamique de la rigidité en fonction de moment de torsion. L'approche PV modélise le comportement non linéaire d'un systéme à l'aide d'une structure du modèle dont les paramètres varient avec une ou plusieurs variables de planification (SV). Le modèle PV résultant peut prédire la réponse dynamique de la rigidité à de nouvelles trajectoires de moment de torsion.  De plus, cette approche fournit une représentation cohérente de la biomécanique articulaire où les changements systématiques sont liés à des variables du système neuromusculaire. Cela démontre que la rigidité intrinsèque et réflexe change considérablement avec les niveaux de contraction volontaire. Ainsi, (a) l'élasticité intrinsèque augmente de fa¸con monotone avec le niveau de contraction musculaire; et (b) la contribution relative de la rigidité réflexe est la plus grande aux niveaux de contraction faibles et son role reste modéré aux niveaux de contraction élevés.Pris ensemble, ces résultats améliorent grandement notre capacité de modéliser deux relations biomécaniques importantes. La capacité de prédire avec précision lien entre l'EMG et le moment de torsion a de nombreuses applications dans les études de biomécanique clinique, de rééducation et de contrôle moteur. Deuxièmement, les modèles de rigidité PV permettent de prédire comment la rigidité change tout au long de l'exécution d'une tâche dynamique. Ainsi, ensemble, les méthodes d'identification utilisées dans cette thèse fournissent des outils précieux pour l'évaluation objective et quantitative de la performance neuromusculaire et de la fonction motrice.</description><description>This thesis uses system identification techniques to study two input-output relations important to human ankle biomechanics. First, it investigates the relation between the surface ElectroMyoGram (EMG) and torque and derives a comprehensive model for non-stationary isometric contractions. The ability of the resulting EMG-torque model to predict torque accurately has many important applications. Second, it examines Joint stiffness dynamics during time-varying isometric contractions. Stiffness dynamics describe the neuromechanical properties of a joint and has two components: (a) intrinsic stiffness due to the mechanical properties of the joint, muscles and tissues; and (b) reflex stiffness due to stretch reflex mechanisms. Stiffness dynamics are nonlinear and change significantly with joint position and activation level. This thesis quantifies the functional dependency of joint stiffness dynamics on activation level during isometric, time-varying contractions.The first part of this thesis, which characterizes the dynamic relationship between surface EMG and torque, makes four important contributions: (a) It shows that during voluntary contractions the EMG contains a torque-feedback component, so that closed-loop methods must be used to estimate the EMG-torque relation accurately. (b) It demonstrates that linear EMG-torque models change with the mean level of voluntary torque and the rate at which it is modulated. (c) It develops and validates a novel, closed-loop, nonlinear identification method for Hammerstein systems. (d) It uses this method to estimate a single Hammerstein system that models EMG-torque dynamics over a wide range of contraction levels.The second part of the thesis examines changes in joint stiffness with torque using a Parameter Varying (PV) approach to model the stiffness dynamics as a function of voluntary torque. The PV approach models the nonlinear behaviour of a system using a model structure whose parameters vary with one or more scheduling variables (SVs). The resulting PV model can predict the stiffness dynamics response to novel torque trajectories. Moreover, this approach provides a coherent representation of the joint biomechanics where the systematic changes are related to variables within the neuromuscular system. It demonstrates that both intrinsic and reflex stiffness change greatly with voluntary torque. Thus, (a) the intrinsic elasticity increases monotonically with muscle contraction level; and (b) the relative contribution of reflex stiffness is largest at low contraction levels and its role remains moderate at high contraction levels.Taken together, these findings greatly improve our ability to model two important biomechanical relations. The ability to predict torque accurately from EMG has a wide range of applications in clinical biomechanics, rehabilitation, and motor control studies. Secondly, the PV stiffness models provide the ability to predict how stiffness changes throughout the execution of dynamic task. Thus, together, the identification methods used in this thesis provide valuable tools for the objective and quantitative assessment of neuromuscular performance and motor function.</description><creator>Aliakbar Golkar, Mahsa</creator><contributor>Robert E Kearney (Supervisor)</contributor><date>2019</date><subject>Biomedical Engineering</subject><title>Estimation of EMG-torque dynamics with application to time-varying ankle joint stiffness identification</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/bk128d21h.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/m900nw77h</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Biomedical Engineering</discipline></degree></thesis></metadata></record><resumptionToken completeListSize="47894">oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):3150</resumptionToken></ListRecords></OAI-PMH>