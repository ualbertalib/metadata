<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/assets/blacklight_oai_provider/oai2-b0e501cadd287c203b27cfd4f4e2d266048ec6ca2151d595f4c1495108e36b88.xsl"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd"><responseDate>2020-07-24T23:02:10Z</responseDate><request resumptionToken="oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):3175" verb="ListRecords">https://escholarship.mcgill.ca/catalog/oai</request><ListRecords><record><header><identifier>oai:escholarship.mcgill.ca:jq085n589</identifier><datestamp>2020-03-21T04:57:31Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Mitochondrial fusion occurs in many eukaryotes including animals, plants, and fungi. It is essential for cellular homeostasis, and yet, the underlying mechanisms remain elusive. Fusion in all systems requires core fusion GTPases that reside in the outer mitochondrial membrane, called Fzo1 in yeast or Mfn1 and Mfn2 in mammalian systems. While post-translational ubiquitination of yeast Fzo1 was shown to drive fusion in yeast, a cell-free mitochondrial fusion assay using mitochondria from HeLa cells revealed that this modification is not required for fusion. Comparative analyses and phylogenetic reconstructions revealed further critical distinctions between the fungal Fzo1 and mammalian Mfns. These GTPases are highly diverged from one another, and lack strong sequence similarity. Bioinformatics analysis showed that fungal Fzo1 proteins exhibit two predicted transmembrane domains, whereas metazoan Mitofusins contain only a single transmembrane domain. This prediction contradicts the current models suggesting both animal and fungal proteins share one topology. This newly predicted topology of MFN1 and MFN2 was demonstrated biochemically, confirming that the C-terminal, redox-sensitive cysteine residues reside within the intermembrane space (IMS). Serial truncation mutants revealed that the ~15kDa C-terminus was required for targeting of MFN2. However the heptad repeat 2 (HR2) domains that reside within the intermembrane space of MFN1 and MFN2 were shown to be regulatory, but non-essential for mitochondrial fusion, since MFNs lacking HR2 partially rescued mitochondrial fragmentation morphology in cells lacking these GTPases. Functional experiments further established that redox-mediated disulfide modifications within the IMS domain are key modulators of reversible MFN oligomerization that drives fusion. Together, these results lead to a revised understanding of MFNs as single-spanning outer membrane proteins with an Nout-Cin orientation, providing functional insight into the IMS contribution to redox-regulated fusion events.</description><description>La fusion mitochondriale se produit chez de nombreux eucaryotes, notamment les animaux, les plantes et les champignons. C'est essentiel pour l'homéostasie cellulaire, et pourtant, les mécanismes sous-jacents restent insaisissables. La fusion dans tous les systèmes nécessite des GTPases de fusion de base qui résident dans la membrane mitochondriale externe, appelée Fzo1 dans la levure ou Mfn1 et Mfn2 chez les mammifères. Alors qu'il a été démontré que l'ubiquitination post-traductionnelle de la Fzo1 chez les levures entraînait la fusion dans la levure, un test de fusion mitochondriale sans cellules utilisant des mitochondries de cellules HeLa a révélé que cette modification n'était pas nécessaire pour la fusion. Les analyses comparatives et les reconstitutions phylogénétiques ont révélé d'autres distinctions critiques entre le Fzo1 des levures et les Mfns des mammifères. Ces GTPases sont très différentes les unes des autres et n'ont pas de similarité de séquence. Une analyse bioinformatique a montré que les protéines fongiques Fzo1 présentaient deux domaines transmembranaires prédits, alors que les Mitofusins metazoans ne contiennent qu'un seul domaine transmembranaire. Cette prédiction contredit les modèles actuels suggérant que les protéines animales et fongiques partagent la même topologie. La topologie nouvellement prédite de MFN1 et MFN2 a été démontrée de manière biochimique, confirmant que les résidus de cystéine C-terminal sensibles au redox se trouvent dans l'espace intermembranaire (IMS). Des mutants de troncature en série ont révélé que l'extrémité C-terminale ~15 kDa était nécessaire pour cibler MFN2. Cependant, les domaines heptad repeat 2 (HR2) situés dans l'espace intermembranaire de MFN1 et MFN2 se sont avérés régulateurs, mais non essentiels pour la fusion mitochondriale, car les MFN dépourvues de HR2 ont partiellement sauvé la morphologie de la fragmentation mitochondriale dans les cellules dépourvues de ces GTPases. Des expériences fonctionnelles ont également démontré que les modifications au disulfure induites par l'oxydo-réduction dans le domaine IMS sont des modulateurs essentiels de l'oligomérisation réversible de MFN qui conduit à la fusion. Ensemble, ces résultats ont permis de mieux comprendre les MFNs en tant que protéines membranaires externes à orientation unique orientées vers Nout-Cin, offrant ainsi un aperçu fonctionnel de la contribution du système IMS aux événements de fusion régulés par l'oxydo-réduction.</description><creator>Mattie, Sevan</creator><contributor>Heidi McBride (Supervisor)</contributor><date>2019</date><subject>Neuroscience</subject><title>Ellucidating mechanisms of homotypic mitochondrial fusion</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/2514nn742.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/jq085n589</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Integrated Program in Neuroscience</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:vh53wz03x</identifier><datestamp>2020-03-21T04:57:32Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>L'étude de l'immuno-métabolisme a pris de l'importance ces dernières années avec le développement de nouvelles technologies permettant de mieux comprendre la contribution du métabolisme à la fonction des cellules immunitaires. Le glucose et la glutamine sont des substrats métaboliques clés qui jouent un rôle important dans le soutien bioénergétique, biosynthétique et les fonctions mitochondriales des lymphocytes T, qui soutiennent la croissance, le développement et le maintien de l'homéostasis et les fonctions des cellules immunitaires. À ce jour, la plupart des études métaboliques ont porté sur des lymphocytes T en culture in vitro. Ces études ont été utiles pour identifier les voies métaboliques actives lors de l'activation des cellules T. Cependant, en raison de la nature complexe de l'environnement rencontré in vivo par les cellules immunitaires, notamment la disponibilité des nutriments, la structure tridimensionnelles et les interactions complexes entre cellules, il est difficile de récapituler cet environnement complexe in vitro. Des travaux récents utilisant des études de traceurs d'isotopes stables dans des modèles de cancer in vivo ont établi que le métabolisme des cellules cancéreuses peut varier in vitro et in vivo. Dans cette thèse, j'ai identifié des voies métaboliques alternatives clés, autres que le métabolisme central du carbone, qui jouent un rôle essentiel dans la fonction des cellules T effectrices. Tout d'abord, j'ai identifié la sérine, un acide aminé non essentiel, comme nutriment polyvalent essentiel à la prolifération des lymphocytes T, indépendante du métabolisme central du carbone. J'ai identifié la sérine exogène, un métabolite clé qui alimente le métabolisme à un carbone, comme étant nécessaire pour la prolifération optimale des cellules T par sa contribution à la biosynthèse de novo de nucléotides et ce, indépendamment du métabolisme du glucose ou de la glutamine. Deuxièmement, j'ai développé une méthodologie pour étudier le métabolisme des cellules T effectrices in vivo en utilisant l'analyse du traceur stable isotope 13C-glucose. À travers ces travaux, j'ai découvert que la biosynthèse de novo de la sérine à partir du glucose est une voie métabolique active dans les lymphocytes T en prolifération in vivo. Enfin, j'ai démontré que la biosynthèse de novo de la sérine, régulée via l'enzyme limitante Phgdh, est également nécessaire pour la prolifération optimale des lymphocytes T. Cependant, contrairement au rôle de la sérine extracellulaire, la biosynthèse de la sérine dépendante du glucose semble influencer la prolifération des cellules T et ce, indépendamment de sa contribution au métabolisme du carbone, suggérant ainsi un rôle de Phgdh dans la régulation de la prolifération des cellules T par le biais de voies alternatives parallèles au cycle du folate. Le travail présenté dans cette thèse documente le développement de nouvelles méthodologies pour étudier le métabolisme des cellules T in vivo et souligne comment les voies métaboliques, au-delà du métabolisme du glucose et de la glutamine, peuvent affecter la fonction des cellules T et ainsi influencer les réponses immunitaires.</description><description>The study of immuno-metabolism has gained prominence in recent years with the development of new technologies allowing for insights into the contribution of metabolism to immune cell function. Glucose and glutamine have emerged as key metabolic substrates that play important functions in supporting T cell bioenergetics, biosynthesis and mitochondrial function that support the growth, development and maintenance of immune cell homeostasis and function. Most metabolic studies to date have focused on in vitro cultured T lymphocytes. These studies have been useful in identifying metabolic pathways active during T cell activation. However, due to the complex nature of the environment immune cells encounter in vivo, which includes nutrient availability, 3-D structure, and heterogenous cell-to-cell interactions, it is difficult to mimic this complex environment in vitro. Recent work using stable-isotope tracer studies in cancer models in vivo have established that cancer cell metabolism can vary between in vitro and in vivo settings. This thesis highlights additional key metabolic pathways beyond central carbon metabolism that play essential roles in effector T cell function. Specifically, the non-essential amino acid serine as a versatile and essential nutrient for T lymphocyte proliferation, independent of central carbon metabolism. Exogenous serine, a key metabolite fueling one-carbon metabolism, was identified to support T cell proliferation, through its support of de novo nucleotide biosynthesis. Second, this thesis details the development of methodology for studying effector T cell metabolism in vivo using 13C-glucose stable-isotope tracer analysis. Discovered through in vivo 13C-glucose stable-isotope tracer analysis was the active engagement of de novo serine biosynthesis from glucose in proliferating T cells in vivo. Finally, through shRNA and inhibitor studies, this thesis demonstrated that de novo serine biosynthesis, regulated via the rate limiting enzyme Phgdh, is also required for optimal T cell proliferation. However, unlike the role of extracellular serine, glucose-dependent serine biosynthesis appears to influence T cell proliferation independent of its contribution to one-carbon metabolism, suggesting that Phgdh regulates T cell proliferation through alternate pathways parallel to the folate cycle. The work in this thesis documents the development of new methodologies to study T cell metabolism in vivo, and highlights how metabolic pathways beyond glucose and glutamine metabolism can shape T cell function to influence immune outcomes.</description><creator>Ma, Hsiao En</creator><contributor>Russell Jones (Supervisor)</contributor><date>2019</date><subject>Physiology</subject><title>Metabolic requirements of effector T cells in vitro and in vivo</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/qv33rz720.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/vh53wz03x</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Physiology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:2n49t430q</identifier><datestamp>2020-03-21T04:57:33Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Cette thèse présente une analyse approfondie des écoulements visqueux permanents et oscillatoires autour des profils aérodynamiques et des ailes tridimensionnelles, ainsi que des écoulements confinés tridimensionnels à faible nombre de Reynolds. Ces travaux de recherche ont été réalisés dans plusieurs études: i) les écoulements visqueux confinés permanents et oscillatoires; (ii) les effets de séparation nonstationnaires sur les profils aérodynamiques stationnaires; (iii) l'effet de la proximité du sol sur les écoulements visqueux stationnaires et oscillatoires autour des profils aérodynamiques fixes et oscillants; (iv) les écoulements en trois dimensions autour des ailes à faibles nombres de Reynolds.La première partie présente une méthode numérique efficace pour résoudre les ecoulements permanents et oscillatoires en trois dimensions dans un canal à faibles nombres de Reynolds. Une formulation à différences finies et une compressibilité artificielle ont été utilisées pour la solution des équations de Navier-Stokes, qui est précise au second ordre dans l'espace et dans le temps. Les résultats se sont avérés en bon accord avec les résultats expérimentaux disponibles. Pour la première fois, il a été confirmé que la différence entre les solutions numériques en deux dimensions et les résultats expérimentaux était due à l'effet des parois latérales dans la configuration expérimentale.La seconde partie est l'étude des effets nonstationnaires sur les profils aérodynamiques stationnaires générés par les séparations d'écoulement oscillatoires à faibles nombres de Reynolds. Cette étude a été réalisée avec une méthode numérique efficace dans le temps, utilisant une procédure de relaxation pseudo-temporelle avec compressibilité artificielle et un schéma implicite de la direction alternative (ADI) factorisé pour l'intégration pseudo-temporelle. La méthode est validée avec succès par comparaison avec les résultats expérimentaux obtenus par Suwa et al. pour les profils aérodynamiques triangulaires à faibles nombres de Reynolds. On a constaté que les coefficients aérodynamiques de portance et de traînée présentaient des variations périodiques dans le temps en raison des séparations d'écoulement nonstationnaires se produisant à des nombres de Reynolds faibles sur des profils aérodynamiques fixes à des angles d'attaque relativement faibles.L'analyse des écoulements permanents et oscillatoires sur les profils aérodynamiques à proximité du sol a été étudiée dans la troisième partie. Diverses évolutions de vol des micro-véhicules aériens se produisent à proximité du sol ou d'un plafond, ce qui nécessite des solutions aérodynamiques dans ces conditions à des faibles nombres de Reynolds. Des solutions sont présentées pour les coefficients de portance et de traînée oscillatoires de plusieurs profils aérodynamiques NACA à proximité du sol. Une étude détaillée de l'influence de divers paramètres géométriques et d'écoulement, tels que l'angle d'attaque, l'épaisseur relative du profil, l'amplitude et la fréquence des oscillations et le nombre de Reynolds, a été réalisée dans cette partie. Cette étude a également présenté l'analyse des écoulements oscillatoires autour des profils aérodynamiques stationnaires à proximité du sol, visant à déterminer l'influence de la distance au sol sur ces effets oscillatoires générés par les séparations d'écoulement oscillatoire sur les profils aérodynamiques stationnaires à des faibles nombres de Reynolds. Il a été constaté que ces effets oscillatoires apparaissent à des angles d'attaque plus faibles pour les profils aérodynamiques à proximité du sol qu'en vol libreLa quatrième et dernière étude de cas est l'analyse tridimensionnelle des écoulements visqueux autour des ailes rectangulaires avec diverses sections de profil aérodynamique à faibles nombres de Reynolds. Les solutions sont obtenues en utilisant une méthode numérique efficace pour résoudre les équations de Navier-Stokes pour les écoulements incompressibles</description><description>This thesis presents a deep analysis of the steady and unsteady viscous flows past airfoils and three-dimensional wings, and of three-dimensional confined flows at low Reynolds numbers. This research work was carried out in several cases studies: (i) steady and unsteady confined viscous flows; (ii) unsteady separations effects on the flow past stationary airfoils; (iii) effect of the ground proximity on the steady and unsteady viscous flows past oscillating and fixed airfoils; (iv) three-dimensional steady flows past wings at low Reynolds numbers. The first part presents an efficient numerical method to solve three-dimensional steady and unsteady flows in a three-dimensional downstream-facing step channel at low Reynolds numbers. A finite-difference formulation and artificial compressibility were used on a stretched staggered grid for the solution of the Navier-Stokes equations, which is second-order accurate in space and time. The results were found to be in good agreement with the available experimental results. For the first time it was confirmed that the difference between the two-dimensional numerical solutions and the experimental results was due to the effect of the lateral walls in the experimental configuration.The second part is the study of the unsteady effects on stationary airfoils due to unsteady flow separations at low Reynolds numbers. This study was performed with an efficient time-accurate numerical method using a pseudo-time relaxation procedure with artificial compressibility and a factored Alternate-Direction Implicit (ADI) scheme for the pseudo-time integration. The method is successfully validated by comparison with the experimental results obtained by Suwa et al. for triangular airfoils at low Reynolds numbers. It was found that the aerodynamic coefficients of lift and drag displayed periodic variations in time due to the unsteady flow separations occurring at low Reynolds numbers on stationary airfoils at relatively small angles of attack.Analysis of the steady and unsteady flows over airfoils in the proximity of the ground was studied in the third part. Various flight evolutions of the micro-air-vehicles take place in the proximity of the ground or a ceiling, which require the aerodynamic solutions in these conditions at low Reynolds numbers. Solutions are presented for the unsteady lift and drag coefficients of several NACA airfoils in the proximity of the ground. A detailed study of the influence of various geometric and flow parameters, such as the angle of attack, airfoil relative thickness, amplitude and frequency of oscillations and Reynolds number, on the flow separations in the proximity of the ground were carried out in this part. This study also presented the analysis of the unsteady flows past stationary airfoils in the proximity of the ground, aiming to determine the influence of the distance to the ground on these unsteady effects which are generated by the unsteady flow separations on the stationary airfoils at low Reynolds numbers. It was found that these unsteady effects appear at lower angles of attack for the airfoils in the proximity of the ground than in free flight.The fourth and final case study is the three-dimensional analysis of the steady viscous flows past rectangular wings with various NACA airfoil sections at low Reynolds numbers. The solutions are obtained using an efficient numerical method to solve the Navier-Stokes equations for incompressible flows. The numerical solutions of the aerodynamic lift and drag coefficients obtained by this method are validated with the experimental results obtained by Sunada et al. for rectangular wings. A parametric study of the influence of various geometric and flow parameters, such as wing thickness, wing airfoil camber, angle of attack and Reynolds number is also presented.</description><creator>Panahi, Araz</creator><contributor>Dan Mateescu (Supervisor)</contributor><date>2019</date><subject>Mechanical Engineering</subject><title>Analysis of confined flows, airfoils and wings at low Reynolds numbers</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/nc580p85g.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/2n49t430q</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Mechanical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:gq67jt49p</identifier><datestamp>2020-03-21T04:57:34Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Hydatidiform mole (HM) or molar pregnancy is a rare complication of pregnancy characterized by the excessive proliferation of the trophoblast and abnormal embryonic development. Recurrent hydatidiform moles (RHM) are defined by the occurrence of at least two HMs in the same patient. Though there are two genes, NLRP7 and KHDC3L, whose mutations cause RHM, there exist other patients without mutations in the known genes.Chapter 2 in this thesis describes my MSc project before I fast-tracked to the PhD program. This project focused on the genetic characterization of the conceptions of patients with bi-allelic NLRP7 mutations. Our work showed that NLRP7 acts upstream of p57KIP2 and regulates the balance between trophoblastic proliferation and tissue differentiation in the HM tissues. This work also corroborated previous data that all conceptions from patients with bi-allelic NLRP7 mutations are diploid biparental.Chapters 3 and 4 describe the work of gene identification in patients with RHM. To identify novel genes responsible for this entity, we performed whole exome sequencing on patients with RHM who are negative for mutations in the two known genes, and then targeted sequencing of candidate genes in larger cohorts of patients with milder phenotypes. The main challenge of this work was the high genetic heterogeneity of patients with RHM since we were not able to find any two patients with mutations in the same gene. To overcome this challenge, we retrieved all accessible HM tissues of the patients included in the exome sequencing and comprehensively characterized their genotypes in order to understand the mechanisms underlying them and classify the patients into specific groups (Chapter 3). Our data showed that RHMs from the same patient mostly have the same genotypic type and identified two main mechanisms that recur in patients without mutations in the known genes: diploid androgenetic4(24% of patients) and triploid dispermic (32% of patients), with stronger genetic susceptibility in the former category of patients.Next, we identified bi-allelic deleterious mutations in three genes, MEI1, TOP6BL/C11orf80, and REC114, with roles in meiotic double-strand breaks formation (Chapter 4). Mutations in MEI1 and TOP6BL were found in 2 unrelated patients with recurrent androgenetic HMs and their affected siblings. REC114 is essential in meiotic double-strand breaks formation and its mutation was identified in one patient with androgenetic HM. Our work has revealed that the same genetic defect caused by these three genes can be responsible for both male and female infertility, and uncovered, for the first time in mammals, a mechanism for the genesis of androgenetic zygotes.</description><description>La môle hydatiforme (MH) ou grossesse môlaire est une complication rare de la grossesse humaine. Elle est caractérisée par une prolifération excessive du trophoblaste et un développement embryonnaire anormal. Les môles hydatidiformes récurrentes (MHR) sont définies par la présence d'au moins deux MH chez la même patiente. Bien qu'il existe deux gènes dont les mutations causent des MHR, NLRP7 et KHDC3L, il existe d'autres patientes avec MHR et sans mutations dans ces deux gènes. Le chapitre 2 de cette thèse décrit mon projet de maîtrise en sciences avant que je passe au programme de doctorat. Ce projet était axé sur la caractérisation génétique des conceptions de patientes présentant des mutations bi-alléliques dans NLRP7. Nos travaux ont montré que NLRP7 agissait en amont de p57KIP2 et régulait l'équilibre entre la prolifération trophoblastique et la différenciation tissulaire dans les tissus môlaires. Ce travail a également confirmé des données antérieures selon lesquelles toutes les conceptions de patientes porteuses de mutations bi-alléliques dans NLRP7 sont diploïdes biparentales. Les chapitres 3 et 4 décrivent les travaux d'identification des gènes chez les patientes atteintes de MHR. Pour identifier de nouveaux gènes responsables de cette entité, nous avons effectué un séquençage d'exome complet sur des patientes atteintes de MHR et sans mutations dans les deux gènes connus, puis un séquençage ciblé de gènes candidats dans des cohortes plus importantes de patientes présentant un phénotype moins sévère. Le principal défi de ce travail était la grande hétérogénéité génétique des patientes atteintes de MHR puisque nous n'avons pas été en mesure de trouver deux patientes présentant des mutations dans le même gène. Pour surmonter ce défi, nous avons récupéré les tissus môlaires de ces patientes et nous les avons génotypé afin de comprendre les mécanismes sous-jacents et de classer les patientes dans des groupes spécifiques6(Chapitre 3). Nos données ont montré que les MHR provenant de la même patiente avaient généralement le même type génotypique et avons identifié deux mécanismes récurrents chez les patientes ne présentant pas de mutation dans les gènes connus: diploïde androgénétique (24% des patientes) et triploïde dispermique (32% des patientes), avec une susceptibilité génétique plus forte dans la première catégorie de patientes. Ensuite, nous avons identifié des mutations délétères bi-alléliques dans trois gènes, MEI1, TOP6BL / C11orf80 et REC114. Ces derniers ont des rôles dans la formation de rupture à double brin durant la méiose. Ces mutations ont été trouvées chez cinq patientes non apparentées, atteintes d'HM androgéniques récurrentes, de fausses couches et d'infertilité. Aussi, chez deux soeurs avec plusieurs fausses couches et un frère souffrant d'infertilité (chapitre 4). Nos travaux ont révélé que ce défaut génétique causé par ces trois gènes peut être responsable de l'infertilité masculine et féminine. En outre, nos travaux ont montré pour la premiere fois chez les mammifères, un mécanisme de la genèse des zygotes androgéniques.</description><creator>Nguyen, Ngoc Minh Phuong</creator><contributor>Rima Slim (Supervisor)</contributor><date>2019</date><subject>Human Genetics</subject><title>New genes and mechanisms of recurrent hydatidiform moles</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/dr26z0586.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/gq67jt49p</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Human Genetics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:0p096948p</identifier><datestamp>2020-03-21T04:57:35Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Je propose une analyse contextuelle des relations entre les tribunaux britanniques et la Cour européenne des droits de l'homme par rapport à l'interprétation des droits de la Convention européenne des droits de l'homme. Le cadre de révision de la constitution d'Aileen Kavanagh et le modèle constitutionnel du Commonwealth de Stephen Gardbaum servent de base à mon cadre théorique pour analyser la relation entre le pouvoir judiciaire britannique avec le « Human Rights Act » de 1998 et la Cour européenne des droits de l'homme. Plus précisément, j'évalue les obligations et les pouvoirs de contrôle constitutionnel conférés au pouvoir judiciaire par la « Human Rights Act » de 1998. Je situe mon argument du point de vue des droits contextuels pour évaluer de manière critique l'interdépendance des tribunaux nationaux et de Strasbourg.J'utilise des méthodes doctrinales, empiriques et théoriques pour explorer la relation entre le droit administratif, le droit constitutionnel et le droit de l'immigration, en plus de l'aspect comparatif de la jurisprudence nationale et cela de la Cour européenne des droits de l'homme. À cet effet, j'ai entrepris une enquête quantitative d'environ 50 cas des tribunaux de première et deuxième instance dans lesquels les requérants ont interjeté un appel ou déposé une demande de recours judiciaire pour des motifs médicaux. J'évalue la jurisprudence de la part des cas autoritaires avant et après la récente décision de la Cour européenne des droits de l'homme dans Paposhvili c. Belgique.J'ai proposé d'analyser les appels en matière d'immigration et les droits des migrants dans le contexte domestique à cause du 20e anniversaire de la « Human Rights Act » de 1998 et le débat interne entre les modèles de common law interne et de révision de la constitution européenne.</description><description>I advance a contextual analysis of the relationship between the domestic UK courts and the European Court of Human Rights interpretation of European Convention on Human Rights Convention rights. Aileen Kavanagh's constitution review framework and Stephen Gardbaum's commonwealth model of constitutionalism serve as the basis of my theoretical framework to analyse the relationship between the UK judiciary and the Human Rights Act 1998 and the European Court of Human Rights. Specifically, I assess the intra- and inter-relational component judiciary's obligations and constitutional review powers afforded through the Human Rights Act 1998.  I situate my argument from a contextual rights point of view to critically assess the interrelationship between the domestic and Strasbourg courtsI utilise doctrinal, empirical and theoretical methods to explore the relationship between administrative, constitutional and immigration laws in addition to the comparative aspect of domestic and Strasbourg jurisprudence. For this, I have undertaken a quantitative survey of approximately 50 cases from the First-tier and Upper Tribunals in instances where the appellants have appealed and lodged an application for judicial review on the basis of a medical ground. I assess the survey of case law from the authoritative cases prior to and after the European Court of Human Right's recent decision in Paposhvili v Belgium.  I have proposed to analyse immigration appeals and the rights of migrants from a domestic approach in light of the 20th anniversary of the Human Rights Act 1998 and the internal debate between the domestic common law and European constitutional review models. </description><creator>Yevcak, Ryan</creator><contributor>Nandini Ramanujam (Internal/Supervisor)</contributor><date>2019</date><subject>Law</subject><title>Constitutional rights review and section 2 of the human rights Act 1998: a contextual dialogue of applications for appeals and judicial review on medical grounds in the United Kingdom</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/73666691m.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/0p096948p</identifier><degree><name>Master of Laws</name><grantor>McGill University</grantor><discipline>Faculty of Law</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:cz30pv94h</identifier><datestamp>2020-03-21T04:57:35Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Cette thèse de doctorat décrit le premier emploi combiné d'un modèle de digestion intestinale humaine simulée en association avec des cultures cellulaires intestinales et hépatiques afin d'examiner les profils, les bioactivités et les biodisponibilités des métabolites microbiens générés à partir de polyphénols communément présents dans l'alimentation humaine (l'acide chlorogénique [CGA], l'acide caféique, l'acide férulique et la rutine). L'étude 1 a porté sur la digestion des polyphénols ci-dessus à l'aide d'un modèle continu et dynamique gastro-intestinal (GI) humain contrôlé par ordinateur et à plusieurs réacteurs représentants la digestion dans l'estomac, l'intestin grêle et les trois segments du colon. Les profils des métabolites phénoliques et des acides gras à chaine courte générés par le microbiote ont varié considérablement en fonction du compartiment du colon. Le métabolisme microbien prolongé sur une période de 16 heures a généré une capacité antioxydante similaire à celle produite par les polyphénols parents; ceci diffère des études précédentes de fermentation discontinue à court terme montrant un faible potentiel antioxydant des métabolites. L'étude 2 a utilisé la lignée cellulaire d'adénocarcinome colorectal humain Caco-2 pour étudier les effets de l'acide chlorogénique et de ses principaux métabolites microbiens (les acides caféique, 3-phenylpropionique et benzoïque) sur le cancer du côlon à des concentrations physiologiquement pertinentes d'un mélange équimolaire des composés. La combinaison de CGA et de ses métabolites a amélioré l'efficacité antiproliférative de ces composés, puisque des effets antiprolifératifs, apoptotiques et d'arrêt du cycle cellulaire ont été observés à des concentrations plusieurs fois plus faibles dans le mélange équimolaire que lorsqu'ils étaient administrés séparément. Des altérations de l'ADN mitochondrial n'étaient pas impliquées dans les mécanismes d'action des évènements apoptotiques du CGA et de l'acide caféique, mais une réduction du contenu en ADN mitochondrial était impliquée dans l'apoptose médiée par l'acide 3-phenylpropionique. Dans l'étude 3, les digestats obtenus du système de digestion intestinale humain simulé ont été soumis à une coculture de cellules intestinales humaines Caco-2 et hépatiques HepG2 pour examiner la digestion et l'effet de premier passage d'un extrait de pomme de terre (PRPE) contenant les acides chlorogénique, caféique et férulique et la rutine comme principaux constituants polyphénoliques. La digestion du PRPE par le modèle GI a mené à l'apparition de métabolites générés par les microbes (les acides dihydrocaféique, dihydroférulique, 3-hydroxybenzoïque, 3-hydroxyphénylpropanoïque, coumarique, 3-hydroxyphénylacétique, phénylpropanoïque et cinnamique). Après 2 heures d'incubation du digestat colique avec les cellules Caco-2, l'acide férulique et les acides dihydrocaféique, dihydroférulique, 3-hydroxyphénylpropionique, 3-hydroxybenzoïque et coumarique ont été mal transportés à travers la monocouche de cellules Caco-2 (3 – 15%). Une augmentation de deux à trois fois supérieure des concentrations d'acides férulique, dihydrocaféique, 3-hydroxyphénylpropionique et coumarique après 3 heures d'incubation avec les cellules HepG2 a démontré une contribution majeure du métabolisme hépatique à la génération de ces composés malgré leur faible transport à travers les cellules Caco-2.Globalement, l'approche combinée utilisant les systèmes de digestion intestinale simulée et de culture cellulaire, développée dans le cadre des travaux actuels, offre une plate-forme unique pour l'étude détaillée des mécanismes impliqués dans la biotransformation, la biodisponibilité et la bioactivité des polyphénols et de leurs métabolites, ce qui est par ailleurs difficile à réaliser in vivo.</description><description>This doctoral dissertation describes the first combined use of a human simulated gut digestion model together with intestinal and hepatic cell cultures to examine the profiles, bioactivities and bioavailabilities of microbial metabolites generated from polyphenols commonly present in the human diet (chlorogenic acid, caffeic acid, ferulic acid and rutin). Study 1 involved digestion of the above polyphenols using a continuous multi-reactor Computer Controlled Dynamic Human Gastrointestinal (GI) Model representing digestion in the stomach, the small intestine and the three colonic segments. The profiles of the microbial phenolic metabolites and short chain fatty acids generated by microbiota varied greatly according to the colonic compartment. Prolonged microbial metabolism over a 16 h period generated antioxidant capacity that matched that produced by the parent polyphenols, which differs from previous short-term batch fermentation studies showing low antioxidant potential of the metabolites. Study 2 utilized the human colorectal adenocarcinoma Caco-2 cell line to explore the anti-colon cancer effects of chlorogenic acid and its major microbial metabolites (caffeic, 3-phenylpropionic and benzoic acids) at physiologically relevant concentrations of each compound and an equimolar mixture of the compounds. The combination of chlorogenic acid and its metabolites enhanced the anti-cancer efficacy as anti-proliferative, apoptotic and cell cycle arrest effects were seen at several-fold lower concentrations of those compounds within the equimolar mixture than when they were provided singly. Alterations in mitochondrial DNA were not associated with the apoptotic events for chlorogenic acid and caffeic acid but a reduction of mitochondrial DNA content was involved in 3-phenylpropionic-mediated apoptosis. In Study 3, the digests from the human simulated gut digestion system were coupled with a co-culture of human intestinal Caco-2 and hepatic HepG2 cells to investigate the digestion and first pass metabolism of a polyphenol-rich potato extract (PRPE) containing chlorogenic acid, caffeic acid, ferulic acid and rutin as the major polyphenolic constituents. Digestion of PRPE in the GI model led to generation of the microbial-derived metabolites of the polyphenols (dihydrocaffeic, dihydroferulic, 3-hydroxybenzoic, 3-hydroxyphenylpropionic, coumaric, 3-hydroxyphenylacetic, phenylpropanoic and cinnamic acids). Following a 2 h incubation of the colonic digesta with Caco-2 cells, ferulic acid and dihydrocaffeic, dihydroferulic, 3-hydroxyphenylpropionic, 3-hydroxybenzoic and coumaric acids were noted to be poorly transported (3-15%). A two- to three-fold increase in the concentrations of ferulic, dihydrocaffeic, 3-hydroxyphenylpropionic and coumaric acids after 3 h incubation with HepG2 cells demonstrated a major contribution of hepatic metabolism in the generation of those compounds despite their poor Caco-2 cellular transport.  Overall, the combined approach using simulated gut digestion and cell culture systems applied in the current work provides a unique platform for the detailed study of mechanisms involved in biotransformation, bioavailability and bioactivity of polyphenols and their metabolites, which is otherwise difficult to perform in vivo.</description><creator>Sadeghi Ekbatan, Shima</creator><contributor>Stan Kubow (Supervisor)</contributor><date>2019</date><subject>Human Nutrition</subject><title>Bioavailability and bioactivity of polyphenols and their microbial metabolites following simulated dynamic gastrointestinal digestion</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/5m60qv16q.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/cz30pv94h</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>School of Human Nutrition</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:gf06g485r</identifier><datestamp>2020-03-21T04:57:36Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>This study sought to advance understanding in the academic community about reasons for lower rates of research from scholars on the African continent when compared to their North American and European counterparts. Inquiry addressing this difference often assumes a broad, system-wide approach towards the African continent, nations, and universities. However, this tendency to examine the issue from a macro-level approach excludes voices and experiences of academics living in this context themselves. Drawing on a conceptual framework that blended a socio-rhetorical theory of genre with decolonization methodologies, the following research project invited academics at one university in the southern African country of Botswana to share stories about four aspects of their research-related work: 1) types of work done in their professional positions; 2) social motive(s) for engaging in this work; 3) challenges experienced doing this work; and 4) possible solutions they have devised to overcome these challenges. In total, 13 scholars from various academic ranks and five different faculties of the university participated in interviews between 2010 and 2013. Individual portraits of each academic's story were constructed, supported by extensive member checks with each scholar about their engagement in these four aspects of their research-related work.   Findings illustrated that in terms of research engagement, academics at this post-secondary institution were involved in research-related work; yet, most of their work fell into the categories of research engagement and research dissemination, meaning few scholars in this context did work to sustain their research practice, advance knowledge in their disciplinary fields, or build this institution's next generation of researchers. Although some scholars at this institution did do research to address community development challenges or advance disciplinary knowledge, their most common social motive for engaging in research was to respond to professional and institutional requirements of the university (e.g. to gain promotion). In terms of challenges, and particularly significant to the study of genre, was that despite scholars experiencing highly unique and individual difficulties with their research-related work, their difficulties were also entangled in the complex institutional context in which they were situated, and often resulted in academics' struggles to appropriately use the rhetorical conventions of their disciplines to write about their research work. Thus, contrary to previous research that has assumed a writer's challenges to use a specific genre (e.g. the journal article) to stem from the writer's own individual limitations, this study illustrates that the limitations academics in this context experienced were not only rhetorical and individual, but also highly entangled in the social and institutional contexts in which the scholars were situated. By listening to the stories of how individual researchers engage in their work, the study deduced that greater knowledge of the complexities concerning African research production can be gleaned when scholars consider the ways an array of life experiences, work challenges, and complex institutional factors impact academics' use of their disciplinary rhetorical conventions. Future research might use this study to design projects exploring the research-related work academics do at other African universities on the continent, and to initiate focused investigations of the specific institutional factors emerging from this investigation that impacted academics' abilities to engage in their research activities such as: the institutional performance management tools universities use to evaluate their scholars' annual research performance; the level and types of research mentorship available to doctoral students and early career researchers in these contexts; and the complex relationships imbued in international research partnerships.</description><description>This study sought to advance understanding in the academic community about reasons for lower rates of research from scholars on the African continent when compared to their North American and European counterparts. Inquiry addressing this difference often assumes a broad, system-wide approach towards the African continent, nations, and universities. However, this tendency to examine the issue from a macro-level approach excludes voices and experiences of academics living in this context themselves. Drawing on a conceptual framework that blended a socio-rhetorical theory of genre with decolonization methodologies, the following research project invited academics at one university in the southern African country of Botswana to share stories about four aspects of their research-related work: 1) types of work done in their professional positions; 2) social motive(s) for engaging in this work; 3) challenges experienced doing this work; and 4) possible solutions they have devised to overcome these challenges. In total, 13 scholars from various academic ranks and five different faculties of the university participated in interviews between 2010 and 2013. Individual portraits of each academic's story were constructed, supported by extensive member checks with each scholar about their engagement in these four aspects of their research-related work.   Findings illustrated that in terms of research engagement, academics at this post-secondary institution were involved in research-related work; yet, most of their work fell into the categories of research engagement and research dissemination, meaning few scholars in this context did work to sustain their research practice, advance knowledge in their disciplinary fields, or build this institution's next generation of researchers. Although some scholars at this institution did do research to address community development challenges or advance disciplinary knowledge, their most common social motive for engaging in research was to respond to professional and institutional requirements of the university (e.g. to gain promotion). In terms of challenges, and particularly significant to the study of genre, was that despite scholars experiencing highly unique and individual difficulties with their research-related work, their difficulties were also entangled in the complex institutional context in which they were situated, and often resulted in academics' struggles to appropriately use the rhetorical conventions of their disciplines to write about their research work. Thus, contrary to previous research that has assumed a writer's challenges to use a specific genre (e.g. the journal article) to stem from the writer's own individual limitations, this study illustrates that the limitations academics in this context experienced were not only rhetorical and individual, but also highly entangled in the social and institutional contexts in which the scholars were situated. By listening to the stories of how individual researchers engage in their work, the study deduced that greater knowledge of the complexities concerning African research production can be gleaned when scholars consider the ways an array of life experiences, work challenges, and complex institutional factors impact academics' use of their disciplinary rhetorical conventions. Future research might use this study to design projects exploring the research-related work academics do at other African universities on the continent, and to initiate focused investigations of the specific institutional factors emerging from this investigation that impacted academics' abilities to engage in their research activities such as: the institutional performance management tools universities use to evaluate their scholars' annual research performance; the level and types of research mentorship available to doctoral students and early career researchers in these contexts; and the complex relationships imbued in international research partnerships.</description><creator>Bryant, Katie</creator><contributor>Teresa Strong (Supervisor1)</contributor><contributor>Claudia A Mitchell (Supervisor2)</contributor><date>2019</date><subject>Integrated Studies in Education</subject><title>Storying the rhetorical and institutional: Academics' experiences with research and writing at the University of Botawana</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/z890rw688.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/gf06g485r</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Integrated Studies in Education</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:8k71nk402</identifier><datestamp>2020-03-21T04:57:37Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Recent technological advances in many domains including both genomics and brain imaging have led to an abundance of high-dimensional and correlated data being routinely collected. A widespread analytical goal in these fields is to investigate the relationships between, on the one hand, a group of genomic markers or anatomical brain measurements and, on theother hand, a set of clinical variables or phenotypes. To leverage the correlation within each set of measurements, and to improve the interpretability of a measure of the association, one can use dimension reduction techniques: one, or both, group of variables can be summarised by a small set of latent features that summarise the structure of interest andcapture association through an appropriately chosen statistic. But the high-dimensionality of contemporary datasets brings many computational and theoretical challenges, and most classical multivariate methods cannot be used directly.This thesis is comprised primarily of three manuscripts that investigate the issues related to measuring association in high dimensional datasets. In the first manuscript, I explore the optimality properties of a dimension reduction method known as Principal Component of Explained Variance (PCEV). This method seeks a linear combination of the outcome variablesthat maximises the proportion of variance explained by a set of covariates of interest. I then explain how PCEV can be extended to a computationally simple and efficient estimation strategy for high-dimensional outcomes (p &gt; n) that relies on a "block-independence" assumption. In the second manuscript, I study the problem of inference with high-dimensional datasets: given two datasets Y and X, with one or both being high-dimensional, how can we perform a test of association in a computationally efficient way? Specifically, I look at the set of multivariate methods that can be described as a double Wishart problem; PCEV, Canonical Correlation Analysis (CCA), and Multivariate Analysis of Variance (MANOVA) are all examples of double Wishart problems. I show that valid high-dimensional p-values can be derived using an empirical estimator of the null distribution. This is achieved by performing a small number of permutations, and then fitting a location-scale family of the Tracy-Widom distribution of order 1 to the test statistics computed from the permuted data. Finally, in the third manuscript, I apply the concepts developed in the two other manuscripts to a data analysis of targeted custom capture bisulfite methylation data. I show how PCEV can be used in conjunction with the ideas in the second manuscript to test for a region-level association between the methylation levels of CpG dinucleotides and levels of anti-citrullinated protein antibody (ACPA), an antigen thought to be a predictor of rheumatoid arthritis onset. In this study, the CpG dinucleotides are naturally grouped by design, and several of these groups contain a number of methylation measurements that is larger than the samplesize.</description><description>Les avancées technologiques récentes dans plusieurs domaines, dont la génomique et la neuroimagerie, ont contribué à une abondance de données de grande dimension et corrélées. Un objectif analytique commun à ces domaines est l'étude des relations entre, d'une part, un groupe de marqueurs génomiques ou des mesures anatomiques du cerveau, et d'autre part, un ensemble de variables cliniques ou de phénotypes. Pour mettre à profit la corrélation entre ces ensembles de mesures, et pour améliorer l'interprétabilité des mesures d'association, on peut utiliser des méthodes de réduction dimensionnelle: un groupe de variables (ou les deux) peut être représenté par un petit ensemble de variables latentes qui récapitule la structure d'intérêt et capture l'association via une statistique choisie. Or, la grande dimension des jeux de données contemporains amène de nombreux défis computationnels et théoriques, et la majorité des techniques multivariées classiques ne peuvent être utilisées directement.Cette thèse est composée principalement de trois manuscrits qui étudient les enjeux reliés aux mesures d'association entre jeux de données de grande dimension. Dans le premier manuscrit, j'explore les propriétés optimales d'une méthode de réduction dimensionnelle connue sous le nom de Composante Principale de Variance Expliquée (PCEV). Cette méthode recherche la combinaison linéaire des variables réponses qui maximise la proportion de la variance qui peut être expliquée par les covariables d'intérêt. Ensuite, j'explique comment PCEV peut être généralisé à une stratégie d'estimation efficace et computationellement simple pour les données de grande dimension (p &gt; n). Cette généralisation repose sur une hypothèse d'indépendance "par bloc". Dans le second manuscrit, j'étudie le problème d'inférence pour les jeux de données de grande dimension: étant donné deux jeux de données Y et X potentiellement de grande dimension, comment peut-on obtenir un test d'association de manière computationnellement efficace? Plus précisément, le manuscrit porte sur l'ensemble des méthodes multivariées pouvant être décrites comme un problème Wishart double; PCEV, l'Analyse en Corrélations Canoniques (CCA), et l'Analyse de Variance Multivarié (MANOVA) sont tous des exemples de problèmes Wishart double. Je montre comment des valeurs-p valides et de grande dimension peuvent être obtenues en utilisant un estimateur empirique de la distribution nulle. Cet estimateur peut être construit en commençant par un petit nombre de permutations, et ensuite en calibrant une famille position-échelle de la distribution Tracy-Widom d'ordre 1 en utilisant les statistiques de test calculées sur les données permutées. Finalement, dans le troisième manuscrit, j'utilise les concepts développés dans les deux premiers manuscrits pour analyser des données de méthylation obtenues par séquençage ciblé. Je démontre comment PCEV peut être combiné aux idées développées dans le second manuscrit pour tester l'association entre les niveaux de méthylation de l'ADN et les niveaux de l'anticorps pour les protéines anti-citrullinées (ACPA), un antigène soupçonné d'être un prédicteur de la polyarthrite rhumatoïde, au niveau des régions génomiques. Dans cette étude, les dinucléotides CpG sont naturellement regroupés, et plusieurs de ces groupes comportent plus de mesures de méthylation que d'échantillons.</description><creator>Turgeon, Maxime</creator><contributor>Celia M T Greenwood (Supervisor1)</contributor><contributor>Aurelie Labbe (Supervisor2)</contributor><date>2019</date><subject>Epidemiology and Biostatistics</subject><title>Dimension reduction and high-dimensional data: Estimation and inference with application to genomics and neuroimaging</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/w9505266d.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/8k71nk402</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Epidemiology and Biostatistics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:sf268743b</identifier><datestamp>2020-03-21T04:57:38Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La méthode de tir de relaxation est une mesure de contrôle contre le coup de terrain. Le massif rocheux, lorsque que soumis à des fortes contraintes, est endommagé avec des explosifs afin de réduire sa rigidité et la magnitude des contraintes. Cette méthode est communément pratiquée dans des mines de roche dure profondes dans des galeries susceptibles aux coup de terrains, ainsi que dans des piliers de minerai en diminution. Le tir de relaxation à grande échelle en panneaux est une variante du tir de relaxation - où des panneaux parallèles à l'axe du gisement sont crées avec un patron de forage en éventail à partir de galeries situées dans l'éponte supérieure du gisement.  Malgré de nombreuses années de recherche, la technique de tir de relaxation est toujours appliquée en utilisant une approche essai-erreur qui donne des résultats mitigés. L'effet du tir est souvent évalué selon la réponse sismique du tir. Cette thèse vise donc à quantifier l'effet géomercatique des tirs de relaxation en se basant sur les changements de contraintes mesurés sur le terrain après le tir. Cette méthode a été employée en quatre phases à la Mine Copper Cliff (CCM) pour réduire les contraintes dans l'entièreté d'un pilier en diminution. Dix jauges de contraintes à fil vibrants ont été installées dans le pilier pour mesurer le changement de contrainte suivant le tir. L'effet mécanique du tir de relaxation a été quantifié avec les données d'un modèle numérique des changements de contraintes acquises à la suite du tir. La relaxation du panneau fut simulée avec 2 paramètres : le facteur de fragmentation (α) et le facteur de dissipation de contraintes (β). Pour les tirs de relaxation Phase 1 et Phase 2, une corrélation entre le modèle numérique et les données de changement de contraintes a été obtenue lorsque α = 0.05 et β = 0.95, démontrant que le panneau fut complètement endommagé par le tir. Selon les indices BPI et BSR calculés dans l'ombre du pilier, l'analyse démontre en plus que les contraintes sont suffisamment diminuées dans le pilier pour réduire la propension du chantier aux coups de terrain. Malgré le comportement observé dans les phases 1 et 2, une augmentation des contraintes dans l'ombre d'un panneau fut observée suite au tir de relaxation à la Phase 3. Or, le modèle anisotrope de relaxation a dû être employé.  L'hypothèse de base du modèle anisotrope est que la direction de propagation des fractures attribuables au tir tend vers la direction de la contrainte majeure principale. Le degré de fragmentation et de relaxation de contraintes est donc influencé par l'orientation de la contrainte majeure principale. Le facteur α1, qui représente le facteur de fragmentation dans l'axe de la contrainte majeure principale (σ1), s'avère plus bas que le facteur α2, qui représente le facteur de fragmentation dans le plan normal à σ1. Le même principe s'applique au facteur de relaxation de contraintes β - où il est fort probable que β1 soit plus petit que β2. L'analyse régressive du tir Phase 3 démontre que facteur α1 d'un des panneaux est beaucoup plus haut que le facteur α2 (α1 = 0.5, α2 = 0.05). L'effet géomécanique de la propagation préférentielle des fractures a donc été quantifié. Dans le cas du tir Phase 3, l'effet de fragmentation et de relaxation du tir est presque doublé dans le plan normal à σ1 par rapport à l'effet dans l'axe de σ1.</description><description>Destress blasting is a rockburst control technique where highly stressed rock is blasted to reduce the local stress and stiffness of the rock, thereby reducing its burst proneness. The technique is commonly practiced in deep hard rock mines in burst prone developments, as well as in sill or crown pillars which become burst-prone as the orebody is extracted. Large-scale destressing is a variant of destress blasting where panels are created parallel to the orebody strike with a longhole, fanning blast pattern from cross cut drifts situated in the host rock. The destress blasting practice reviewed in the literature showed varying levels of success, with the main criterion for success being the seismic response. This thesis therefore concentrates on quantifying the geomechanical effect of panel destress blasting based on the stress changes measured in the field after a destress blast.This destressing strategy was implemented at Vale's Copper Cliff Mine (CCM) to create a stress shadow which encompasses the entire 100OB diminishing ore pillar. Destressing was done in 4 Phases, and ten uniaxial vibrating wire stress cells were installed in the diminishing pillar to monitor the stress changes. The geomechanical effect of panel destress blasting is then quantified with a pillar wide numerical model based on the measured stress changes. The destressing mechanism is simulated with a rock fragmentation factor (α) and stress dissipation factor (β). For the Phase 1 and Phase 2 blasts, it is shown that the best correlation between the numerical model and field measurements is obtained when the combination of α and β indicates that the blast causes high fragmentation (α =0.05) and high stress release (β =0.95) in the destress panel. It is also demonstrated that the burst proneness of the ore blocks in the panel stress shadow is reduced in terms of the brittle shear ratio (BSR) and the burst potential index (BPI).For the Phase 3 blast however, a stress increase was detected in the expected panel stress shadow, which cannot be replicated with the previous model. The anisotropic destressing model is therefore explored. With this model, it is proposed that the degree of stiffness reduction and stress dissipation is influenced by the orientation of the in-situ principal stresses, whereby in the direction of major principal stress, σ1, the rock fragmentation factor α1 is likely to be larger than the rock fragmentation factor α2 in the direction of the minor in situ principal stress. Likewise, the stress dissipation factor β1 in the major principal stress direction is likely to be less than β2 in the minor principal stress direction. The back analysis of the Phase 3 blast determined that the crown panel fragmentation factor in the orientation of σ1 was much higher than the rock fragmentation factor in the σ2-σ3 plane, with a value of α1 of 0.5 and a value of α2 of 0.05. Therefore, the anisotropic stress release and fragmentation effect due to preferential fracture propagation was quantified, where the stress release and fragmentation normal to σ1 is almost double the effect in the orientation of σ1.</description><creator>Vennes, Isaac</creator><contributor>Hani Mitri (Supervisor)</contributor><date>2019</date><subject>Mining and Materials</subject><title>Improved ore recovery in burst prone ground using destress blasting</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/70795992n.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/sf268743b</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Mining and Materials</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:9k41zg720</identifier><datestamp>2020-03-21T04:57:39Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>The increase in Earth-orbiting space debris has been the cause of significant debate over the last decade. Large space debris (&gt;10 cm), mostly defunct satellites and upper stages, populate the near-Earth environment and represent a significant risk to current and future space missions. Active Debris Removal (ADR) has been proposed as a solution to this problem, where a removal spacecraft would be launched, would rendezvous with a target, capture and stabilize it, and finally remove it from orbit. However, precise knowledge of the target's rotational parameters ahead of time is key for the stabilization and capture of the debris, especially since current ADR techniques may be dangerous for debris spinning at high angular velocities. Many external torques affect the spin characteristics of uncontrolled debris and the long-term (order of years), cumulative effect of these have only recently started to be studied. A novel comprehensive coupled orbit-attitude propagator, called the Debris Spin/Orbit Simulation Environment (D-SPOSE), for the analysis and prediction of the rotational motion of these large space debris is therefore developed in order to determine, to the highest degree of accuracy possible, the evolution of the rotational parameters of uncontrolled space objects over a time scale of years. This tool, created for space debris remediation purposes, would benefit the space debris community by being able to predict the future attitude state of ADR targets, long before mission launch. The developed propagator includes a widespread list of external gravitational and non-gravitational perturbations. The model is tested and validated against past observations of the evolution of the angular motion of uncontrolled space objects, namely several spherical geodetic satellites, for which an abundant amount of observations exist. Another potentially significant source of disturbances for large space debris is the transfer of momentum from bombardment by small debris (down to the μm scale) and micrometeoroids, the effect of which is a research area still in its infancy. The influence of hypervelocity impacts on the attitude and orbital motion of spacecraft is further investigated and incorporated into D-SPOSE. As collisions are completely random in the space environment, the spacecraft equations of motion will take the form of stochastic differential equations. Correspondingly, a stochastic framework to solve these equations in a Monte Carlo simulation for the distributions of the target's orbital and rotational parameters is outlined, making use of impact fluxes from the European Space Agency's Meteoroid and Space Debris Terrestrial Environment Reference model. D-SPOSE is then applied to two different debris objects. First, the rotational motion of the inoperative European satellite and "most wanted" ADR target Envisat is investigated. Comparisons of simulation results to observations provide insights into the evolution of its complex attitude dynamics and reveal potential difficulties for an upcoming ADR mission. It is shown that as Envisat's rotation slows down, its relative spin stabilization effect will decrease, which will lead the gravity-gradient torque and other environmental torques to drive the satellite toward a larger tumbling motion. Second, the model is applied to another large inoperative satellite, TOPEX/Poseidon, for which a number of model parameters are missing. As well, differently from Envisat, observations of TOPEX/Poseidon have shown it to be rotating with an increasing angular rate. D-SPOSE is employed to investigate the spacecraft's rotational dynamics and in combination with observation results, to obtain estimates of the satellite's parameters, including its moments of inertia and magnetic properties, which are important for future prediction of its rotational motion.</description><description>L'augmentation du nombre de débris spatiaux en orbite autour de la Terre a été à l'origine de nombreux débats au cours des dix dernières années. Les gros débris spatiaux (&gt; 10 cm), principalement des satellites morts et des étages supérieurs, peuplent l'espace autour de la Terre et représentent un risque important pour les missions spatiales actuelles et futures. L'élimination active des débris (ADR) a été proposée comme solution à ce problème, dans le cadre de celle-ci un vaisseau spatial serait lancé, rencontrerait une cible, la capturerait, la stabiliserait, puis la retirerait de son orbite. Cependant, une connaissance précise des paramètres de rotation de la cible est essentielle pour la stabilisation et la capture du débris, d'autant plus que les techniques ADR actuelles peuvent être dangereuses pour des débris tournant à des vitesses angulaires élevées. De nombreux couples externes affectent les caractéristiques de rotation des débris incontrôlés, et leurs effets cumulatifs à long terme (d'un ordre de plusieurs années) n'ont que récemment commencé à être étudiés.Un nouveau propagateur d'orbite et d'attitude, appelé D-SPOSE, dédié à l'analyse et la prévision du mouvement de rotation de ces gros débris spatiaux est donc mis en avant, afin de déterminer, au plus haut degré de précision possible, l'évolution des paramètres de rotation d'objets spatiaux incontrôlés sur une période de plusieurs années. Cet outil, créé à des fins d'assainissement des débris spatiaux et ayant un fonctionnement malléable, serait bénéfique pour la communauté car il permettrait de prédire l'état d'attitude futur des cibles ADR bien avant le lancement de la mission. Le modèle est testé et validé grâce aux observations passées de l'évolution du mouvement angulaire d'objets spatiaux incontrôlés, à savoir plusieurs satellites géodésiques sphériques, pour lesquels il existe une quantité abondante d'observations. Une autre source potentiellement importante de perturbations pour les gros débris spatiaux est le transfert de moment par bombardement de petits débris (allant jusqu'au micromètre) et de micrométéoroïdes. L'analyse de leurs effets est un domaine de recherche encore balbutiant. L'influence des impacts à hypervitesse sur l'attitude et le mouvement orbital des engins spatiaux est ensuite étudiée. Puisque les collisions sont complètement aléatoires dans l'environnement spatial, les équations de mouvement des engins spatiaux prendront la forme d'équations différentielles stochastiques. Parallèlement, un cadre stochastique permettant de résoudre ces équations par simulation Monte Carlo pour la distribution des paramètres orbitaux et de rotation de la cible est décrit, en utilisant les flux d'impact du modèle de l'Agence spatiale européenne MASTER-2009. D-SPOSE est ensuite appliqué à deux débris différents. En premier lieu, le mouvement de rotation du satellite européen et cible ADR "la plus recherchée", Envisat, est étudié. Les comparaisons des résultats de simulations avec les observations fournissent des informations sur l'évolution de sa dynamique d'attitude complexe et révèlent des difficultés potentielles pour une mission ADR future. Deuxièmement, le modèle est appliqué à un autre satellite inopérant, TOPEX/Poseidon, pour lequel un certain nombre de paramètres sont manquants. D-SPOSE est utilisé pour étudier la dynamique de rotation de l'engin spatial et, en combinaison avec les résultats des observations, pour obtenir des estimations des paramètres du satellite, y compris ses moments d'inertie et ses propriétés magnétiques, qui sont importants pour la prévision future de son mouvement de rotation.</description><creator>Sagnières, Luc</creator><contributor>Inna Sharf (Supervisor)</contributor><date>2019</date><subject>Mechanical Engineering</subject><title>Modeling and simulation of long-term rotational dynamics of large space debris</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/nc580p86r.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9k41zg720</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Mechanical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:7m01bn920</identifier><datestamp>2020-03-21T04:57:40Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les données soulignent le rôle vital du soutien social dans les trajectoires de rétablissement personnel mettent en évidence le rôle crucial des membres de la famille et des fournisseurs de services de santé mentale. Les membres de la famille, étant des proches ou encore faisant parti d'un cercle de relations élargi, sont les principales sources de soutien pour les personnes vivant avec une maladie mentale grave. Cependant, les membres de la famille rapportent être exclus et non soutenus par les services de santé mentale, ce qui alourdit leur fardeau de soins et conduit à une dégradation de leur bien-être physique et mental. En réponse, les politiques récentes en santé mentale axées sur le rétablissement visent à placer la voix des membres de la famille au centre de la prestation des services de santé et à créer des services culturellement sensibles aux besoins et valeurs rapportés par des familles diversifiées. De nouvelles approches sont nécessaires, qui non seulement s'appuient sur les forces et les capacités des personnes vivant avec une maladie mentale, mais qui supportent et renforcent également les capacités des membres de la famille, des utilisateurs et fournisseurs de services afin de créer des environnements favorables par le biais de réelles pratique et stratégies. Dans cette étude ethnographique, j'ai suivi pendant neuf mois des personnes ayant une expérience vécue de maladie mentale et des membres de leur famille, conduisant des observations de participants et des entretiens narratifs approfondis autour d'événements signifiants et de leurs expériences. En me basant sur les théories phénoménologiques de Martin Heidegger et Hans-Georg Gadamer et sur un cadre narratif-phénoménologique, développé par Cheryl Mattingly, je présente une description détaillée de trois phénomènes qui ont émergé d'une analyse herméneutique: les excursions, l'ameublement et être prêt. Dans le contexte d'hospitalisation et d'incertitude accrue des participants, je propose une interprétation de ces actions, soutenue à travers les contextes et le temps, comme une pratique de proximité. Je conclue cette dissertation en discutant comment considérer les points de vue des membres de la famille ainsi que des patients ensemble peut mener à une différente manière de voir, pouvant ensuite devenir le fondement d'une autre manière d'agir.</description><description>Evidence underlining the vital role of social support in trajectories of personal recovery highlight the critical role of family members and mental health service providers. Family members are primary sources of support for persons living with severe mental illness, whether they are relatives or chosen from a broader circle of relationships. However, family members report being excluded from and unsupported by mental health services, increasing their burden of care and leading to a decline in their own physical and mental well-being. In response, recent recovery-oriented mental health policies aim to put the voices of family members at the centre of health services delivery and to create services that are culturally sensitive to the self-identified needs and values of diverse families. New approaches are needed that not only build upon the strengths and capacities of individuals living with mental illness, but that also support and build upon the capacities of family members', service users' and service providers' efforts to create supportive environments through actual practices and strategies. In this ethnographic study, I followed persons with lived experience of mental illness and their family members during nine months, conducting participant-observations and in-depth narrative interviews around their significant events and experiences. Drawing upon the phenomenological theories of Martin Heidegger and Hans-Georg Gadamer, and the narrative-phenomenological framework developed by Cheryl Mattingly, I present thick descriptions of three phenomena that have emerged from a hermeneutic analysis: excursions, furnishing, and standing by. Within the study participants' context of hospitalization and heightened uncertainty, I venture an interpretation of these actions, sustained across contexts and time, as practices of being near. I conclude the dissertation by discussing how considering together the perspectives of family members and patients can lead to a different way of seeing, which may then become the grounds for a different way of acting.</description><creator>Xu, Jiameng</creator><contributor>Melissa Park (Supervisor)</contributor><date>2019</date><subject>Physical &amp; Occupational Therapy</subject><title>Practices of being near: an ethnographic study of family members and persons with lived experience of mental illness</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/2514nn75b.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/7m01bn920</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>School of Physical and Occupational Therapy</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:bz60cz84m</identifier><datestamp>2020-03-21T04:57:41Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>In this thesis, I propose that body posture is an important, underappreciated, variable to consider in neuroimaging research. Thousands of brain imaging experiments are published each year, but few consider how the postures that participants assume may influence the data collected. Whereas participants in most behavioural, cognitive, and psychology experiments sit upright, one of the most prominent functional neuroimaging techniques, functional magnetic resonance imaging (fMRI), requires participants to lie supine. Many cognitive processes in our everyday life, moreover, are executed while neither sitting nor lying, but rather when standing, moving, or interacting with other people and the surrounding environment. A growing literature suggests that posture weighs heavily on both cognitive functions and physiological processes that are relevant to brain imaging. This thesis aims to elucidate how body posture shapes neuroimaging data.We directly investigated the effect of posture on spontaneous brain dynamics by recording electrical activity (EEG) in four orthostatic conditions (lying supine, inclined at 45°, sitting upright, and standing erect) and magnetic activity (MEG) in three postures (lying supine, sitting reclined, sitting upright). We found that posture altered electromagnetic brain imaging data. Upright postures (sitting and standing), compared to reclined and supine postures, were associated with widespread increases in high-frequency oscillatory activity regardless of whether participants were involved in a mental task or had their eyes open or closed. Using MEG recordings alongside associated structural MRI scans, we were able to more precisely localize posture-driven changes in brain activity. Sitting upright versus lying supine was associated with greater high-frequency (i.e., beta and gamma) activity in widespread parieto-occipital cortex. Moreover, upright and reclined postures correlated with dampened activity in prefrontal regions, especially across lower frequency bandwidths. Our findings highlight the importance of posture as a determinant in neuroimaging. Generalizing results—from supine neuroimaging measurements to erect positions typical of ecological human behavior—would call for considering the influence that posture wields on brain dynamics. </description><description>Dans cette thèse, je propose la posture corporelle comme une variable importante à prendre en compte dans la recherche en neuroimagerie. Des milliers d'expériences d'imagerie cérébrale sont publiées chaque année, mais peu d'entre elles considèrent comment les postures que les participants adoptent peuvent influencer les données collectées. Alors que les participants à la plupart des expériences comportementales, cognitives, et psychologiques se tiennent debout, l'une des techniques de neuroimagerie fonctionnelle les plus utilisées, l'imagerie par résonance magnétique fonctionnelle (IRMf), exige que les participants soient allongés. De plus, de nombreux processus cognitifs sont exécutés sans n'être ni assis, ni couché, mais plutôt en étant debout, en mouvement ou en interaction avec d'autres personnes et l'environnement immédiat. Une littérature croissante suggère que la posture pèse lourdement sur les fonctions cognitives et les processus physiologiques pertinents pour l'imagerie cérébrale. Cette thèse vise à élucider comment la posture du corps façonne les données de neuroimagerie.Nous avons directement investigué l'effet de la posture sur la dynamique spontanée du cerveau en enregistrant l'activité électrique (EEG) dans quatre conditions orthostatiques (couché sur le dos, incliné à 45°, en position assise, ainsi que debout) et l'activité magnétique (MEG) dans trois postures (couché sur le dos, assis-incliné, assis droit). Nous avons constaté que la posture altérait les données d'imagerie électromagnétique du cerveau. Les postures droites (assis et debout) par rapport aux postures inclinées et en position couchée étaient associées à une augmentation généralisée de l'activité oscillatoire à haute fréquence, peu importe si les participants étaient impliqués dans une tâche mentale ou non et si leurs yeux étaient ouverts ou fermés. En utilisant les enregistrements MEG parallèlement aux examens IRM structurels associés, nous avons trouvé des modifications plus détaillées de l'activité cérébrale liées à la posture. Les postures assises en position verticale ou couchée étaient associées à une plus grande activité à haute fréquence (c.-à-d., bêta et gamma) généralisée dans le cortex pariéto-occipital. De plus, les postures droites et inclinées corrélaient avec une activité atténuée dans les régions préfrontales sur toute pour l'activité à basse fréquence. Nos résultats soulignent l'importance de la posture en tant que déterminant de la neuroimagerie. Ainsi, généraliser ces résultats—des mesures de neuroimagerie en position couchée à des positions droites typiques du comportement humain écologique—nécessiterait de prendre en compte l'influence de la posture sur la dynamique du cerveau. </description><creator>Thibault, Robert</creator><contributor>Amir Raz (Supervisor)</contributor><date>2019</date><subject>Neuroscience</subject><title>Body posture alters brain imaging data</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/2f75r998d.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/bz60cz84m</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Integrated Program in Neuroscience</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:m039k732t</identifier><datestamp>2020-03-21T04:57:41Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Le cancer du sein demeure le cancer le plus souvent diagnostiqué parmi les femmes, affectant une femme canadienne parmi huit. Les lésions mammaires précoces peuvent être détectées en clinique. Cependant, un défi majeur est qu'il n'y a pas de moyen fiable d'identifier les lésions qui sont les plus susceptibles de progresser vers le cancer du sein. Une meilleure compréhension des premiers événements moléculaires qui conduisent la transformation des cellules normales vers le cancer sera essentielle pour permettre la prédiction de la progression et pour le développement de thérapies préventives ciblées pour prévenir le cancer du sein. Un concept émergent est que l'architecture épithéliale normale joue un rôle crucial en tant que barrière physique à la progression du cancer. En utilisant le modèle de souris du cancer du sein « Polyoma virus middle-T antigen » (PyVmT) et l'imagerie en direct, nous avons identifié que les divisions cellulaires asymétriques sont des événements précoces dans la progression du cancer du sein qui donne naissance à une population de cellules dépolarisées. Un défi pour comprendre si l'architecture du tissu agit effectivement pour supprimer la formation de tumeurs est que la plupart des oncogènes perturbent à la fois la prolifération et l'organisation tissulaire. Dans ce projet, j'ai utilisé un modèle modifié de PyVmT où l'hyperprolifération était découplée de la perte d'organisation tissulaire après l'induction d'un oncogène, et les canaux mammaires s'organisent similairement aux tissus normaux en ce qui concerne la polarité apicale-basale et les adhérences cellulaires. De manière remarquable, malgré une prolifération accrue, ces souris ne parviennent pas à former des tumeurs mammaires. Ici, j'investis les mécanismes qui contrôlent l'orientation de la division cellulaire dans ce modèle et si le mécanisme de la résolution de la division cellulaire observée dans les cellules normales est entravé dans la progression tumorale. Je démontre que l'oncogène Src constitutivement actif est suffisant pour induire une stratification tissulaire, et ce, par le biais de la régulation de l'orientation du fuseau mitotique dans le modèle murin PyV mT. Comme il n'est pas encore complètement compris comment les cellules mammaires se transforment d'un phénotype normal à un phénotype malin, ce projet a le potentiel d'identifier une étape importante le long de la voie à travers la régulation de l'orientation de la division cellulaire. En comprenant comment l'organisation tissulaire est perdue pendant la tumorigenèse, j'imagine que ce travail peut être utilisé afin d'aider à identifier les cibles thérapeutiques potentielles qui pourraient être bénéfiques dans la prévention du cancer.</description><description>Breast cancer remains the most frequently diagnosed cancer amongst women, affecting 1 in 8 Canadian women. Precancerous breast lesions can be detected in the clinic; however, a major challenge is that there is no reliable way to identify the lesions that are most likely to progress to breast cancer. A better understanding of the early molecular events that drive transformation of normal tissues towards cancer will be essential to enable the prediction of progression, and for the development of targeted preventative therapies to prevent breast cancer. An emerging concept is that normal epithelial architecture plays a crucial role as physical barrier to cancer progression. Using genetically modified breast cancer mouse models and live-imaging of 3D organoids, I identified that asymmetric cell divisions are an early event in breast cancer progression that give rise to a population of de-polarized cells that proliferate to become the dominant population in tumors through asymmetric cell divisions. A challenge to understanding how tissue architecture functions to suppress tumorigenesis is that most oncogenes disrupt both proliferation/survival and tissue organization. In this project, I made use of a modified PyVmT model whereby hyper-proliferation was uncoupled from loss of tissue organization following oncogene induction and the mammary ducts organize similarly to normal tissue with regards to apical-basal cell polarity and cell adhesions. Remarkably, despite increased proliferation, these mice fail to form mammary tumors. For this thesis, I investigated the mechanisms that control cell division orientation in mouse models of breast cancer in normal cells and in tumor progression. I demonstrate that the constitutively active Src oncogene is sufficient for inducing tissue stratification, and it does so through the regulation of spindle orientation in the PyV mT mouse model. As it is not yet completely understood how mammary cells transform from a normal to malignant phenotype, this project has the potential to identify an important step along the pathway through the regulation of cell division orientation. By understanding how tissue organization is lost during tumorigenesis, I envision this work could be used to help identify potential therapeutic targets that would be beneficial to prevent breast cancer initiation and recurrence. </description><creator>Kalos, Christina</creator><contributor>Luke McCaffrey (Internal/Supervisor)</contributor><date>2019</date><subject>Medicine</subject><title>Investigating the role of src in tissue organization during early breast cancer progression</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/wp988n31m.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/m039k732t</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Medicine</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:pr76f580z</identifier><datestamp>2020-03-21T04:57:42Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Le système INTRABEAM (Carl Zeiss Meditech AG, Jena, Allemagne) est une source miniature de rayons X qui fonctionne à 50 kVp pour utilisation en radiothérapie intra-opératoire (IORT). Dans la source, les électrons sont accélérés vers une cible aurifère hémisphérique produisant ainsi une distribution d'intensité des photons radialement isotrope, incluant des photons Bremsstrahlung et de fluorescence. Le système INTRABEAM est principalement utilisé pour traiter le cancer du sein et il s'est révélé être une option viable par rapport à la radiothérapie par faisceau externe, d'après les résultats de l'essai clinique TARGIT-A. La source de rayons X a été modélisée en utilisant EGSnrc, un code de transport des particules basé sur la méthode Monte Carlo (MC). Les matériaux et les dimensions de la source et de l'applicateur ont été extraits des données publiées et des spécifications fournies par le fabricant. Les résultats du spectre simulé ont été comparés aux résultats de mesures et de simulations précédemment publiés, puis ils ont été validés à l'aide de mesures de la couche de demi-atténuation effectuées dans l'air et de mesures de pourcentage de dose en profondeur dans un fantôme d'eau. L'effet de l'inclusion dans les simulations des transitions atomiques explicites des sous-couches M− et N−par rapport à des coques moyennées a été étudié et a été jugé appréciable. L'efficacité d'utiliser une source "phase-space" de toutes les particules qui quittent la surface de la sonde INTRABEAM, plutôt qu'une source d'électrons frappant la cible en or, a également été étudiée. Un formalisme de dose a été proposé pour calculer la dose absorbée dans l'eau à partir de mesures de source INTRABEAM nue effectuées dans un fantôme d'eau avec une chambre d'ionisation calibrée au kerma dans l'air, en se basant sur les rapports de dose calculés par MC. Il a été constaté que le formalisme calculait systématiquement une dose supérieure (jusqu'à 23% supérieure) à l'équation recommandée par le fabricant. Il a été déterminé que l'incertitude sur la séparation des électrodes de la chambre d'ionisation à plaques parallèles PTW 34013 utilisée avait un effet significatif sur l'incertitude du calcul de la dose. Les formalismes de calcul de dose dérivé de MC (CQ) et recommandé par le fabricant (Zeiss) ont été comparés à celui utilisé dans le protocole TARGIT en fonction de la profondeur dans 'eau.  Des mesures sur film radiochromique de la dose absorbée ont également été effectuées et comparées. La dose déterminée par les méthodes CQ, Zeiss et film concordait généralement, compte tenu des incertitudes de mesure (5-6%).  La dose de TARGIT était considérablement inférieure aux autres méthodes de 14 à 80%, ce qui suggère que la dose de TARGIT sous-estime la dose physique dans l'eau. Les résultats présentés dans ce travail fournissent des preuves solides que les doses délivrées dans les traitements IORT du sein selon le protocole TARGIT étaient significativement supérieures à la dose prescrite et variaient en fonction de la taille de l'applicateur sphérique utilisé.</description><description>The INTRABEAM System (Carl Zeiss Meditech AG, Jena, Germany) is a miniature x-ray source operating at 50 kVp for use in intraoperative radiation therapy (IORT). Electrons are accelerated towards a hemispherical thin gold target to produce a radially isotropic photon intensity distribution, consisting of bremsstrahlung and fluorescence photons. The INTRABEAM source is primarily used to treat breast cancer, and has shown to be a viable option compared to external beam radiation therapy through the results of the TARGIT-A clinical trial. The x-ray source was modeled using EGSnrc, a Monte Carlo (MC) particle transport code. Source and applicator materials and dimensions were taken from published data and specifications provided by the manufacturer. The simulated spectrum results were compared with previously published simulation and measurement results, and validated with measurements of half-value layer performed in-air, and percent depth dose measurements in a water phantom. The effect of including explicit M- and N-subshell atomic transitions versus averaged shells in the source simulations was investigated, and was found to be appreciable. The efficiency of using a phase space source of all particles leaving the surface of the INTRABEAM source probe, rather than an electron source striking the gold target was also investigated.A dose formalism was proposed for calculating the absorbed dose to water from INTRABEAM bare source measurements performed in a water phantom with an air-kerma calibrated ionization chamber, relying on MC-calculated dose ratios. It was found that the formalism systematically calculated a larger dose (up to 23% greater) than the equation recommended by the manufacturer. It was determined that the uncertainty in the electrode separation of the PTW 34013 parallel plate ionization chamber used had a significant effect on the dose calculation uncertainty. The MC-derived formalism (CQ) and manufacturer recommended (Zeiss) dose determinations were compared with the dose calculation used in the TARGIT protocol as a function of depth in water. Radiochromic film measurements of absorbed dose were also performed and compared. The dose determined by the CQ, Zeiss, and film methods generally agreed considering measurement uncertainties (5-6%). The TARGIT dose was considerably less than the other methods by 14% to 80%, suggesting that the TARGIT dose underestimates the physical dose to water. The results presented in this work provide strong evidence that the doses delivered in breast IORT treatments following the TARGIT protocol were significantly greater than the dose prescribed, and varied with the size of spherical applicator used.</description><creator>Watson, Peter</creator><contributor>Jan Peter Frans Seuntjens (Supervisor)</contributor><date>2019</date><subject>Physics</subject><title>Dosimetry of a miniature x-ray source used in intraoperative radiation therapy</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/0v838274j.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/pr76f580z</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Physics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:9880vt085</identifier><datestamp>2020-03-21T04:57:43Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>IntroductionLe taux de survie au cancer a augmenté. Comme les soins en oncologie évoluent, de nouveaux défis apparaissent. De plus en plus de médecins de famille (MF) suivent des survivants du cancer, qui ont souvent des problèmes à long terme en raison du cancer ou de son traitement. Les MF sont enclins à fournir des soins aux survivants du cancer, mais rencontrent plusieurs obstacles. Des lignes directrices sur les soins de survie au cancer existent, mais les MF ne les connaissent pas. Les obstacles liés à l'utilisation des recommandations par les cliniciens ont été étudiés. En revanche, nous avons peu d'information concernant l'utilisation des recommandations sur les soins aux survivants du cancer, en première ligne.ObjectifsLes objectifs spécifiques de mon étude sont (1) de mesurer la fréquence de la non-utilisation des recommandations sur les soins de survie au cancer du sein par les MF utilisant l'application mobile IAM Medical Guidelines et (2) d'identifier les barrières à l'utilisation de ces recommandations du point de vue du MF.Méthodologie et méthodesJ'ai mené une étude convergente à méthodes mixtes. Les participants étaient des MF ayant au moins un patient survivant du cancer du sein. Volet quantitatif : Nous avons regroupé des recommandations provenant de lignes directrices dans une application mobile. Grâce à l'application, nous avons envoyé des notifications hebdomadaires aux utilisateurs de l'application concernant une recommandation. Les MF avaient l'occasion d'évaluer chacune des recommandations en utilisant un questionnaire validé, nommé « Information Assessment Method (IAM) ». J'ai analysé les résultats pour identifier des particularités dans la non-utilisation des recommandations. Volet qualitatif : J'ai réalisé des entrevues avec 16 MF qui ont répondu « non » ou « possiblement » à la question concernant l'utilisation d'une recommandation pour un patient ou plus. J'ai identifié les obstacles liés à l'utilisation de chacune des recommandations. J'ai ensuite créé des thèmes auxquels les obstacles ont été assignés. Intégration : J'ai comparé et combiné les résultats des volets quantitatif et qualitatif.RésultatsPour le volet quantitatif, 22 des 29 (76%) participants ayant évalué des recommandations ont répondu « non » ou « possiblement » à la question concernant l'utilisation d'une recommandation. Les participants ont mentionné être en désaccord avec une information ou avoir trouvé un problème avec la présentation de l'information concernant 8 recommandations : suivi médical, auto-examen des seins, consommation d'alcool, vaccins, douleur, dépistage de détresse, bouffées de chaleur et ostéoporose/ santé osseuse. Des MF ont mentionné qu'ils n'utiliseront pas des recommandations. Cela a été mentionné pour 6 recommandations : suivi médical, dépistage, tests non routiniers, nutrition, dépistage de détresse et bouffées de chaleur. Dans le volet qualitatif, les obstacles liés à l'utilisation des recommandations ont été regroupés sous ces différents thèmes : identité ainsi que rôle professionnel et social du médecin de famille, influences sociales, connaissances, croyances concernant les conséquences, mémoire, contexte environnemental et ressources, buts, renforcement, habiletés, caractéristiques liées à l'information et facteurs liés au patient.Discussion et conclusionCette étude a révélé de nouveaux obstacles qui n'ont pas été identifiés dans la littérature : oubli de la recommandation, manque d'opportunités d'utiliser la recommandation, manque de sensibilisation des patients aux lignes directrices et manque de documents d'information pour les patients. L'identification des obstacles à l'utilisation des recommandations de soins de survie au cancer avec une méthode innovatrice et validée peut contribuer à la mise en place d'interventions pour améliorer les soins cliniques aux niveaux individuel et organisationnel.</description><description>Background The cancer survival rate has increased. As cancer care evolves, new challenges are emerging. A growing number of FPs follow cancer survivors, who often have long-term problems because of their cancer or its treatment. FPs are willing to provide care to cancer survivors but they face obstacles. Survivorship guidelines exist but FPs are not aware of them. While we know about barriers to the implementation of guideline recommendations by clinicians (in general), we know little about survivorship guideline implementation in primary health care.Objectives The specific objectives of my study are (i) to measure the frequency of non-use of breast cancer survivorship guideline recommendations by family physicians (FPs) using the IAM Medical Guidelines mobile application and (ii) to describe key barriers to the implementation of these recommendations from the FP perspective in settings where they practice.Methodology and methodsI conducted a convergent mixed methods study. Participants were FPs providing care to at least one breast cancer survivor. Quantitative component: We integrated 21 key guideline recommendations in a mobile application. Through the app, we delivered a weekly alert to one new key guideline recommendation. FPs could rate each recommendation using the validated Information Assessment Method (IAM) questionnaire. I identified patterns of non-use of recommendations. Qualitative component: I conducted interviews with 16 FPs who answered "no" or "possibly" to the question concerning the use of a recommendation for at least one of their patients. I identified barriers to implementation of each key guideline recommendation and assigned them to a series of themes related to non-use of information. Integration: I compared and combined results of the quantitative and qualitative components.ResultsIn the quantitative component, 22 of 29 (76%) participants who rated recommendations answered "no" or "possibly" to the IAM question about the use of a recommendation. Participants reported disagreeing with the content of the information or found a problem with the presentation of the information for 8 guideline recommendations: follow-up, breast self-exam, alcohol consumption, vaccines, pain, distress screening, hot flushes and osteoporosis/ bone health. Six recommendations were reported as not used: follow-up, screening, non-routine tests, nutrition, distress screening and hot flushes. In the qualitative component, many barriers were identified and grouped into themes. Barriers were related to the FP social and professional role and identity, social influences, knowledge, beliefs about consequences, memory, environmental context and resources, goals, reinforcement, skills, information characteristics and patient related factors. Discussion and conclusionThis study revealed new barriers, not reported in the literature: lack of memory for the guideline recommendation, lack of opportunity to use the guideline recommendation, lack of guideline awareness by patients and lack of information materials for patients. The identification of barriers to implementation of survivorship guideline recommendations through an innovative and validated method may help to develop interventions to improve clinical care at the individual and organizational levels.</description><creator>Asfour, Sara</creator><contributor>Aliki Thomas (Internal/Cosupervisor2)</contributor><contributor>Roland Grad (Internal/Supervisor)</contributor><date>2019</date><subject>Family Medicine</subject><title>In primary health care, what are the key barriers to the implementation of guideline recommendations for breast cancer survivors? a mixed methods study</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/2514nn76m.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9880vt085</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Family Medicine</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:gx41mm16m</identifier><datestamp>2020-03-21T04:57:44Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les microtubules sont formés par un réseau dynamique de polymères présents dans les cellules eucaryotes et formant leur squelette. Ce cytosquelette joue de nombreux rôles notamment dans la migration et la division cellulaire. Pendant la division cellulaire, les microtubules forment un fuseau mitotique qui doit se coordonner correctement avec d'autres composants cellulaires comme l'ADN et l'actine. La formation de nouveaux microtubules et la régulation appropriée des microtubules déjà en extension sont importantes pour un assemblage correct du fuseau mitotique. Les microtubules ont été découverts dans les années 1950, cependant de nombreuses questions sur les microtubules et leur coordination au sein du cytosquelette eucaryote restent sans réponse.Pour répondre à ces questions, j'ai utilisé un système de reconstitution in vitro avec un minimum de composants pour étudier les caractéristiques/paramètres des microtubules et de certaines protéines régulatrices. J'ai développé un nouveau logiciel automatisé de suivi et d'analyse des microtubules pour étudier le processus de nucléation. A l'aide de ce logiciel, j'ai pu estimer que la formation de nouveaux microtubules nécessite l'assemblage de 56 dimères de tubuline sur une amorce de nucléation. J'ai également étudié le complexe de nucléation des microtubules canonique, γ-TuRC. J'ai découvert que γ-TuRC lorsqu'il est reconstitué in vitro lie de manière stable les extrémités moins des microtubules et les protége de l'action de dépolymérases des microtubules. Je présente également des preuves que certains événements de phosphorylation de γ-TuRC, qui contrôlent l'architecture du fuseau mitotique, se produisent probablement pendant la phase S du cycle cellulaire.La régulation de la dynamique des microtubules dépend des protéines associées aux microtubules (MAPs). J'ai développé une méthode pour évaluer si certaines MAPs préfèrent réguler la phase de nucléation ou d'extension des microtubules. Cette approche donne un aperçu des premières structures présentes lors de la formation de microtubules. J'ai également participé à la vérification d'un nouveau mécanisme de régulation de MCAK, par GTSE1, confirmant la régulation complexe de cette protéine lors de l'attachement des microtubules aux kinétochores.Ma thèse a permis de développer des méthodes d'étude de la nucléation et de la régulation des microtubules. Elle établit que la nucléation des microtubules est son propre régime dans le cycle de vie des microtubules tandis que la machinerie cellulaire aide à guider les microtubules nouvellement formés pour l'organisation correcte du cytosquelette microtubulaire.</description><description>The microtubule cytoskeleton is the mechanical support system of eukaryotic cells. It gives them shape, organizes the cytoplasm as well as helps cells migrate and divide. During cell division the microtubules form the mitotic spindle which must correctly interface with other cellular components like DNA and actin. The formation of new microtubules and proper regulation of already growing microtubules is important for proper assembly of the mitotic spindle. Microtubules were first discovered in the 1950s but to this day basic questions about microtubules and how they are coordinated as a part of the eukaryotic cytoskeleton remains unanswered.This thesis takes advantage of a bottom-up approach to answering these questions by investigating different aspects of microtubules and the proteins that regulate them using minimal reconstitution assays. I developed new automated microtubule tracking and analysis software to investigate the microtubule nucleation process. Using this software, I derived an estimate that the formation of new microtubules requires at most 56 tubulin dimers to come together upon a nucleation template. I also investigated the canonical microtubule nucleation complex, the γ-TuRC. I showed that a minimally reconstituted γ-TuRC is competent to stably bind microtubule minus ends and protect them from the action of microtubule depolymerases. I also present evidence that key phosphorylation events of the γ-TuRC that control mitotic spindle architecture likely occur during S-phase. Regulation of microtubule dynamics is dependent on microtubule associated proteins (MAPs). I developed a framework to evaluate whether certain MAPs prefer to regulate the nucleation or growth phase of microtubules which provides insight into the earliest structures of microtubule formation. I also helped to verify a new regulatory mechanism for MCAK, by GTSE1, adding to the complex regulation of this protein during microtubule attachment to kinetochores. Collectively this thesis developed methods to investigate microtubule nucleation and regulation. It establishes that microtubule nucleation is its own regime in the microtubule lifecycle and that the surrounding machinery of the cell helps to guide these new microtubules for proper formation of the microtubule cytoskeleton.</description><creator>Hall, Conrad</creator><contributor>Gary Brouhard (Supervisor)</contributor><date>2019</date><subject>Biology</subject><title>Templated microtubule nucleation and regulation</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/9s161841w.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/gx41mm16m</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Biology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:9p290c81m</identifier><datestamp>2020-03-21T04:57:45Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Peripartum cardiomyopathy (PPCM) is a specific type of cardiomyopathy defined by new-onset heart failure with reduced systolic function during the peripartum period. Preeclampsia, a multisystem disorder affecting pregnant and postpartum women, is strongly associated with PPCM. Since PPCM and preeclampsia are frequently co-incident, and are both independently associated with adverse maternal outcomes, this work sought to further elucidate clinical risk factors and outcomes of their combined occurrence.A cohort was constructed with delivery admissions from 2011 to 2014 using a large US administrative database (Marketscan). All pregnancies complicated by preeclampsia were identified, and clinical risk factors for the development of PPCM were assessed. The risks of Major Adverse Cardiovascular Events (MACE) at 6 months were compared between PPCM with co-incident preeclampsia (pePPCM) and PPCM and no preeclampsia (npePPCM).In total, 1,024,035 pregnancies were included, of which 64,503 (6.3%) were complicated by preeclampsia. There were 283 women with pePPCM and 591 women with npePPCM. Among women with preeclampsia, risk factors for PPCM were chronic kidney disease, multiple pregnancy, chronic hypertension, advanced maternal age, and type 2 diabetes. Women with pePPCM were more likely to experience MACE than women with npePPCM (adjusted RR 1.29, 95% CI [1.06, 1.57]), which was explained by higher rates of acute heart failure, pulmonary edema, and pulmonary embolism in this patient group. There was no difference in mortality between groups.  Close follow-up of preeclamptic women with risk factors for PPCM should be considered. Preeclampsia conferred a greater risk of MACE at 6 months among women with PPCM. Further studies are required to determine whether preeclampsia affects the risk of PPCM recurrence in subsequent pregnancy. </description><description>La cardiomyopathie peripartum (PPCM) se définit par une insuffisance cardiaque avec fonction systolique réduite survenant de novo durant la période peripartum. La prééclampsie, une maladie multisystémique caractérisée par une hypertension artérielle ainsi qu'une atteinte d'organes cibles chez la femme enceinte et postpartum, est fortement associée à la PPCM. Puisque PPCM et prééclampsie sont deux conditions souvent coïncidentes, et toutes deux indépendamment associées à des issues maternelles défavorables, cette étude tenta d'élucider les facteurs de risques et les issues cliniques associés à leur incidence combinée.  Une cohorte fut construite avec l'ensemble des hospitalisations pour accouchement de 2011 à 2014 à l'aide d'une banque de données administrative Américaine (Marketscan). Toutes les grossesses atteintes par la prééclampsie furent identifiées, et les facteurs de risque associés au développement de la PPCM furent examinés. Le risque d'évènements cardiovasculaires majeurs fut comparé entre les femmes avec PPCM et prééclampsie (pePPCM) et celles avec PPCM sans prééclampsie (npePPCM). Un total de 1,024,035 grossesse furent inclues, dont 64,503 (6.3%) furent compliquées par la prééclampsie. Il y eut 282 femmes avec pePPCM et 591 femmes avec npePPCM. Parmi les femmes atteintes de prééclampsie, les facteurs de risques pour la PPCM identifiés furent la maladie rénale chronique, la grossesse multiple, l'hypertension chronique, l'âge maternel avancé, et le diabète de type 2. Par ailleurs, les femmes avec pePPCM étaient à risque plus élevé de développer un évènement cardiovasculaire majeur (RR ajusté 1.29, 95% CI [1.06, 1.57]), ce qui put être expliqué par une plus grande incidence d'insuffisance cardiaque aigüe, d'œdème pulmonaire, et d'embolie pulmonaires dans ce groupe de patientes. Il n'y eut pas de différence dans la mortalité entre les deux groupes. Un suivi rapproché des femmes prééclamptiques avec facteurs de risqué pour la PPCM devrait être considéré. Parmi les femmes atteintes de PPCM, la prééclampsie conférait un risque accru d'évènements cardiovasculaires majeurs à 6 mois d'observation. Des études additionnelles sont requises afin de déterminer si la prééclampsie affecte le risque de récurrence de la PPCM dans les grossesses subséquentes. </description><creator>Malhamé, Isabelle</creator><contributor>Natalie Dayan (Internal/Cosupervisor2)</contributor><contributor>Louise Pilote (Internal/Supervisor)</contributor><date>2019</date><subject>Epidemiology and Biostatistics</subject><title>Risk factors and outcome of peripartum cardiomyopathy with co-incident preeclampsia among commercially insured women in the United States</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/s7526f47p.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/9p290c81m</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Epidemiology and Biostatistics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:j96023207</identifier><datestamp>2020-03-21T04:57:45Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Les microtubules sont de longs polymères de la protéine tubuline que les cellules utilisent pour construire le cytosquelette, le fuseau mitotique, les axonèmes, et les neurites. Ces polymères ne sont pas statiques. Au contraire, ils sont constamment désassemblés et reconstruits au cours de la croissance, la division et la différenciation cellulaire. Ce processus est un mécanisme conservé et fondamental chez les eucaryotes qu'on appelle l'instabilité dynamique des microtubules. Les microtubules de différentes espèces divergent dans leurs vitesses de croissance et dans leurs structures. Ainsi, nous ne savons pas ce qui limite la croissance des microtubules, ce qui détermine leur structure et d'autant moins si les mécanismes de l'instabilité dynamique sont universels. Je me suis donc tourné vers les microtubules du nématode C. elegans, bien uniques pour leur morphologie. Premièrement, ils contiennent 11 protofilaments, contrairement aux microtubules chez la majorité des espèces étudiées, qui en contiennent 13. Deuxièmement, les microtubules de C. elegans croissent beaucoup plus rapidement que ceux d'autres eucaryotes. J'ai donc pensé que l'étude des microtubules de C. elegans rendrait une perspective importante sur les microtubules.Grâce à un système de reconstitution in vitro, j'ai trouvé qu'une croissance rapide est une propriété intrinsèque des microtubules de C. elegans. Pour comprendre comment la particularité de séquence peptidique produit une croissance rapide, je me suis tourné vers la cryo-microscopie électronique. Combinant ceci avec une technique de reconstruction, j'ai réussi à déterminer la structure en 3D des microtubules de C. elegans à 4.8 Å. Ceci a révélé que les résidus divergents se localisent aux contacts inter-tubulines latéraux. Dans ces contacts, une région typiquement désordonnée chez les mammifères est ordonnée chez C. elegans. En effet, une simulation de la dynamique moléculaire de la tubuline par le laboratoire du Dr Sept a démontré que ces résidus sont plus susceptibles de former des structures secondaires stables. En appliquant l'équation d'Arrhenius à la croissance des microtubules, j'ai confirmé que la tubuline de C. elegans a une plus grande énergie libre en solution. Finalement, une analyse de la géométrie de la tubuline a révélé que les microtubules à 11 protofilaments de C. elegans sont surenroulés in vitro. J'ai confirmé cette observation en analysant des tomogrames d'embryons (préparées par le laboratoire du Dr Müller-Reichert). Finalement, cette étude a révélé que (1) la structure secondaire des résidus participant aux contacts inter-tubulines latéraux limite la croissance des microtubules et (2) un métazoaire complexe peut prospérer en ayant des microtubules surenroulés.</description><description>Microtubules are long, slender polymers of the protein tubulin that cells use to construct the cytoskeleton, the mitotic spindle, axonemes, and neuronal processes. These polymers are not static. Rather, they are constantly broken down and rebuilt as cells grow, divide, and differentiate. This process is called the dynamic instability of microtubules, which is a conserved and fundamental mechanism in eukaryotes. However, microtubules from different species diverge in their growth rates and lattice structures. Therefore, we do not know what limits microtubule growth, what determines microtubule structure, or whether the mechanisms of dynamic instability are universal. To approach this challenge, I turned to the nematode C. elegans, which stands out in the microcosm of microtubule morphology. First, its microtubules lack the textbook 13 protofilament architecture found in most species studied to date, including mammals. Instead, its cells harbour smaller microtubules with only 11 protofilaments. Second, its microtubules grow nearly two orders of magnitude faster than those of other eukaryotes. I reasoned that studying the microtubules of C. elegans would yield critical insights into microtubule structure and dynamics.Using a reconstitution approach, I found that C. elegans microtubules were intrinsically fast-growing. To understand how sequence divergence translates to fast growth, I turned to cryo-electron microscopy. In combination with single-particle reconstruction techniques, I was able to solve the 3D structure of C. elegans microtubules to 4.8 Å. This revealed that the divergent residues localize to inter-tubulin lateral contacts. Furthermore, a typically unstructured loop therein was resolved in C. elegans compared to published mammalian microtubule structures. Indeed, a molecular dynamics simulation of tubulin performed by the Sept lab showed that those residues were more likely to form stable secondary structures. By applying the Arrhenius equation to microtubule growth, I confirmed that C. elegans tubulin had a higher free energy in solution. Finally, an analysis of tubulin geometry revealed that the C. elegans 11 protofilament microtubules were supertwisted in vitro. I confirmed this observation in electron tomograms of fixed embryos (prepared by the Müller-Reichert lab) by developing a novel 3D analysis technique. Ultimately, this study revealed that (1) the ordering of lateral contact loops limits microtubule growth, and (2) a complex metazoan can thrive with supertwisted microtubules.</description><creator>Chaaban, Sami</creator><contributor>Gary Brouhard (Supervisor)</contributor><date>2019</date><subject>Biology</subject><title>Microtubule structure &amp;amp; dynamics: insights from C. elegans</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/f4752k086.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/j96023207</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Biology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:7d278w442</identifier><datestamp>2020-03-21T04:57:46Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>L'oreille moyenne joue un rôle crucial dans le transfert du son dans l'oreille interne. Les schémas de vibration du tympan (membrane tympanique, MT) et des osselets ont été étudiés par de nombreux groupes mais, en particulier aux hautes fréquences, ils ne sont toujours pas bien compris. La modélisation numérique du MT et de l'oreille moyenne ouvre la voie à une meilleure compréhension de la fonction mécanique de ces structures, mais le réglage et la validation de tels modèles nécessitent des données expérimentales anatomiques et mécaniques précises. Ces données proviennent généralement des populations d'oreilles et on connaît mal la manière dont les différences individuelles d'anatomie et de propriétés matérielles affectent la fonction du MT et de l'oreille moyenne. Dans cette étude on a créé un modèle numérique par la méthode des éléments finis (EF) et l'a validé contre les mesures de vibration dans la même oreille.Un système de tomographie par cohérence optique (OCT) Doppler sensible à la phase en temps réel a été utilisé dans cette étude pour mesurer les vibrations du MT et des osselets dans un os temporal humain à une fréquence de stimulation de 500 Hz. Le schéma de vibration mesuré du MT à 500 Hz montre un déplacement maximal dans la région postérieur et un plus petit maximum dans la région antérieur. Les données expérimentales montrent également de plus petits déplacements sur les osselets, et le promontoire cochléaire apparaît immobile comme attendu.Un scan 3-D micro-tomodensitométrique (microCT) a été réalisé pour la même oreille. Un modèle EF de l'oreille moyenne a été construit à l'aide d'une combinaison de logiciels développés localement et d'autres logiciels libres et open-source. La géométrie était basée sur une segmentation semi-automatique des images microCT et les propriétés des matériaux étaient basées sur des études précédentes. Une analyse de sensibilité a été réalisée pour analyser l'importance relative des différents paramètres. Les images OCT Doppler, masquées par les images OCT en mode luminosité ('brightness', mode B) pour réduire le bruit, ont également été segmentées et le modèle 3-D résultant a été transformé en coordonnées cartésiennes et aligné avec le modèle à base de microCT.Deux solveurs EF (Code_Aster et SAP IV) ont été utilisés dans cette étude dans le cadre du processus de vérification. Les résultats pour les vibrations simulés des différents solveurs ont été comparés aux données de vélocité mesurées par OCT en mode Doppler et aux données des études précédentes.Les résultats de la simulation correspondent bien à la forme du patron de vibration mesuré du TM à 500 Hz. La mise en correspondence des images OCT et microCT pour les oreilles individuelles est une approche viable pour la construction et la validation des modèles de EF. Si elle était adaptée aux scans CT cliniques, ce processus pourrait conduire à des modèles spécifiques au patient et à un meilleur diagnostic des changements pathologiques dans l'oreille moyenne. Le processus de création de modèles EF pour l'oreille moyenne devrait être simplifié pour les applications cliniques.</description><description>The middle ear plays a critical role in transferring sound into the inner ear. The vibration patterns of the tympanic membrane (TM) and ossicles have been investigated by many groups but, particularly at high frequencies, are still not well understood. Computational modelling of the middle ear offers a pathway toward a better understanding of the mechanical function of these structures. The tuning and validation of such models require accurate anatomical and mechanical experimental data, but such data usually come from populations of ears and little is known about how differences in individual anatomy and material properties affect middle-ear function. In this study we created a finite-element (FE) numerical model of a middle ear and validated it against vibration measurements from the same ear.A real-time phase-sensitive Doppler optical coherence tomography (OCT) system was used to measure the vibrations of both the TM and the ossicles of a human temporal bone at a stimulation frequency of 500 Hz. The measured vibration pattern of the TM showed a maximal displacement in the posterior region and a smaller maximum in the anterior region. The experimental data also showed smaller displacements on the ossicles, while the cochlear promontory appeared immobile as expected.A 3-D X-ray micro-computed tomography (microCT) scan was acquired for the same ear. A FE model of the middle ear was built using a combination of locally developed and other free and open-source software. The geometry was based on semi-automatic segmentation of the microCT images, and material properties were based on previous studies. A sensitivity analysis was performed to analyze the relative importance of the various parameters. The Doppler OCT images, masked by B-mode OCT images to reduce noise, were also segmented and the resulting 3-D model was transformed to Cartesian coordinates and aligned with the microCT-based model.Two FE solvers (Code_Aster and SAP IV) were used as part of the verification process. The simulated vibration patterns from the different solvers were compared with the measured Doppler-mode OCT velocity data and with data from the literature. The simulation results match well with the shape of the measured vibration pattern of the TM at 500 Hz. Co-registration of OCT and microCT for individual ears is a viable approach for building and validating FE models. If extended to clinical CT scans, this process could lead to patient-specific models and improved diagnosis of pathological changes in the middle ear. The process of creating FE models for the middle ear would need to be streamlined for clinical applications.</description><creator>Wang, Xuan</creator><contributor>W Robert J Funnell (Internal/Supervisor)</contributor><date>2019</date><subject>Physics</subject><title>Finite-element modelling of the human middle ear based on X-ray micro-computed tomography and Doppler optical coherence tomography in the same ear</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/08612q86k.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/7d278w442</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Biological and Biomedical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:0c483m36w</identifier><datestamp>2020-03-21T04:57:47Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La radiothérapie à faisceau mixte (MBRT) constitue la création et l'administration de plans de traitement impliquant plusieurs modalités, telles que les multiples énergies de photons et d'électrons produites par un linac. La combinaison d'électrons et de photons dans un seul plan de traitement peut réduire la dose administrée aux tissus normaux pour tous les patients ayant une tumeur superficielle grâce au parcours limité des faisceaux d'électrons dans la matière. Par contre, l'adoption générale de la technique du MBRT n'a pas encore été realisée en clinique et demeure largement un sujet de recherche en raison des collimateurs emcombrants utilisés lors de l'administration de rayonnement à base d'électrons ainsi que d'un manque de sophistication des modèles d'optimisation. Dans ces travaux de thèse, les composantes nécessaires à la création et la validation de plans de traitement à faisceau mixte administrés uniquement avec un collimateur multilame pour photons (pMLC) ont été construites et characterisées.Étant donné que ni la technique MBRT ni l'administration d'électrons à l'aide d'un pMLC ne fait partie de la pratique routinière clinique, un système de planification de traitement (TPS) a dû être créé pour la visualisation de données de patients et de distributions de doses ainsi que pour la coordination du processus de création de mini-faisceaux nécessaires pour l'optimisation de plans de traitement. Un moteur de calcul de dose collapsed cone a été implémenté pour la création de mini-faisceaux de photons. Pour la création de mini-faisceaux d'électrons, un modèle de faisceau Monte Carlo a été couplé au moteur de calcul de dose DOSXYZnrc. Le TPS a été programmé pour communiquer avec ces deux moteurs de calcul de dose pour faciliter le processus de génération de mini-faisceaux.En second lieu, un modèle d'optimisation direct aperture (DAO) basé sur la méthode de génération de colonne a été dérivé pour résoudre le problème de planification de traitement MBRT. En utilisant les mini-faisceaux créés pour chaque modalité, l'algorithme obtient un plan de traitement de façon itérative en proposant des ouvertures de champs pour chaque modalité et en selectionnant les champs les plus suspectibles d'améliorer la fonction de coût pour ajouter au plan de traitement à chaque itération. Une étude du modèle d'optimisation a montré que cette méthode pouvait produire des plans MBRT avec une fonction coût améliorée comparativement aux plans à modalité unique.Ensuite, la robustesse des distributions de doses MBRT aux incertitudes de positionnement des patients a été étudié. Le modèle d'optimisation MBRT a été étendu pour s'assurer que le volume-cible clinique (CTV) demeure couvert de façon adéquate dans une série de scénarios d'erreurs de positionnement. Cette étude a démontré que l'optimisation traditionnelle basé sur un volume-cible de planification (PTV) est inadéquate pour la technique MBRT. Par contre, l'optimisation robuste basé sur le CTV a été en mesure de produire des plans de traitement qui maintiennent une couverture adéquate du CTV pour tous les scénarios d'erreurs considérés.Finalement, deux plans MBRT ont été administrés sur un fantôme à base de Solid Water et un cylindre d'acrylique, respectivement. L'exactitude de l'administration du rayonnement a été évaluée à l'aide de la dosimétrie à base de film ainsi qu'en mesurant la dose sur l'axe centrale du cylindre avec une chambre d'ionisation. La dose mesurée par le film était en accord avec la dose prédite par simulations, avec un taux de passage de 96.4 % pour un critère gamma de 2 %/2 mm. Pour le fantôme cylindrique, la différence entre la dose mesurée par la chambre d'ionisation pour tous les modalités combinées et la dose prédite était de 0.2 %. Lorsque chaque modalité est évaluée individuellement, la différence entre dose mesurée et simulée varie entre -0.8 % et 2.7 %.</description><description>In linac-based radiation therapy, the bulk of recent innovations have involved delivering photon radiation over an ever-growing range of beam delivery angles around the patient, rather than incorporating more particle types into the treatment planning process.Mixed beam radiation therapy (MBRT) is the concept of creating and delivering treatment plans involving multiple modalities, such as multiple photon and electron energies. Combined electron-photon treatment plans can reduce the dose to normal tissue compared to photon-only treatments for patients with a superficial tumour due to the limited range of electrons in matter. However, MBRT has yet to be implemented widely in a clinical environment due to primitive optimisation models and the cumbersome collimation devices typically used in electron delivery. In this work, the components necessary for the creation and validation of mixed electron-photon radiation therapy plans delivered with a photon multi-leaf collimator (pMLC) as the sole collimation device were developed, characterised and validated.As neither MBRT nor pMLC-collimated electron deliveries are part of routine clinical practice, it was necessary to first create an academic treatment planning system (TPS) capable of visualising patient images and dose distributions and coordinating the creation of the beamlet dose distributions necessary for treatment plan optimisation. A collapsed cone convolution superposition dose calculation engine was implemented to generate photon beamlet dose distributions. Electron beamlet dose distributions were created using the DOSXYZnrc Monte Carlo dose calculation engine coupled to a validated electron beam model. The TPS was programmed to interface with the two dose calculation engines in order to facilitate the beamlet generation process.Secondly, a column generation-based (CG) direct aperture optimisation model for MBRT planning was derived and subsequently implemented. Using beamlets created for each modality, the algorithm iteratively creates a treatment plan by producing candidate electron and photon apertures at each iteration, and selecting the apertures most likely to improve the cost function. A study of the algorithm showed that it could successfully produce MBRT plans with a better cost function compared to photon-only and electron-only plans. Next, the robustness of MBRT dose distributions to patient positioning uncertainties was studied. The CG-based MBRT model was extended to explicitly ensure that clinical target volume (CTV) coverage is preserved under a series of setup error scenarios. The study showed that traditional PTV-based optimisation is inadequate for MBRT planning, whereas robust CTV-based optimisation was able to produce plans which maintained adequate coverage under all setup error scenarios considered.Finally, two MBRT plans were delivered on a solid water slab phantom and an acrylic cylinder, respectively. The accuracy of the deliveries was assessed using film dosimetry and by measuring the dose on the central axis of the acrylic cylinder using an ionisation chamber. The solid water slab film agreed with the simulated dose distribution with a 96.4 % pass rate for a 2 %/2 mm gamma criteria. On the cylindrical acrylic phantom, the measured dose for the combined MBRT delivery agreed within 0.2 %. Broken down by modality, the agreement between measured and simulated dose in the ionisation chamber varied between -0.8 % and +2.7 %. We conclude that our beam models can accurately simulate MBRT dose distributions, however, further investigation is needed to confirm that the deliveries are sufficiently robust to positioning uncertainties.This body of work demonstrates that a mixed electron-photon treatment planning algorithm based on the column generation method can produce realistic, deliverable and verifiable treatment plans which offer superior normal tissue sparing compared to current state-of-the-art single-modality photon or electron plans.</description><creator>Renaud, Marc-André</creator><contributor>Jan Peter Frans Seuntjens (Supervisor)</contributor><date>2019</date><subject>Physics</subject><title>Mixed electron-photon radiation therapy treatment planning and delivery</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/vm40xv01m.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/0c483m36w</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Physics</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:47429c52w</identifier><datestamp>2020-03-21T04:57:48Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Objectives: We sought to better understand the predictive effects of autonomous and controlled motivation on treatment outcomes in people with eating disorders. Towards this goal, we first aimed to validate the Autonomous and Controlled Motivation for Treatment Questionnaire (ACMTQ)  an instrument used in previous research to measure motivation for treatment - for use in a population of women with an eating disorder. We then applied the ACMTQ in an investigation of predictive effects of pre-treatment motivation on therapy outcomes in adults who were undergoing treatment for an eating disorder. Finally, we designed a protocol for a meta-analysis on the predictive effects of pre-treatment motivation on post-treatment outcomes in people undergoing therapy for an eating disorder. Methods: We conducted three studies. In the first study, we validated the ACMTQ in a sample of 463 English- or French-speaking women with an eating disorder. We assessed factor structure, internal reliability, test-retest reliability, as well as convergent, divergent and incremental predictive validity. In the second study, we evaluated the prognostic value of the ACMTQ in 770 adults engaged in an outpatient treatment for an eating disorder. The change in the Eating Disorder Examination Questionnaire total score and the rate of dropout throughout treatment served as outcome measures. Relationships were examined with growth curve modelling and logistic regression analyses. In the third study, we developed a protocol for a meta-analysis of longitudinal studies reporting on the effects of pre-treatment motivation on changes in several indices of eating-disorder severity (i.e., measures of overall eating-disorder symptomatology, weight, bingeing frequency, vomiting frequency, anxiety/depression, and treatment completion rates) at the end of treatment or at follow-up timepoints. We planned to run separate meta-analyses for each outcome studied and to combine effect sizes with random-effect models. Results: Data obtained from the first study showed acceptable fit to our predetermined two-factor model (i.e., autonomous and controlled; comparative fit index = 0.92, root mean square error of approximation = 0.09, standardized root mean square residual = 0.09). Both factors showed good internal consistency (alphas 0.80 and 0.85) and convergent/divergent validity as well as acceptable test-retest reliability (intraclass correlation coefficients = 0.73 for both domains). Higher autonomous motivation predicted better end-of-treatment symptomatology whereas controlled motivation did not. In the second study, we found that higher scores of autonomous motivation were associated with lower scores at end of treatment on the Eating Disorder Examination Questionnaire (coeff. = -0.15, p &lt; 0.005) and with a lower likelihood of dropping out of treatment (OR = 0.81; 95% CI: 0.68, 0.96). Again, controlled motivation for treatment was not associated with response to treatment. Given that the third study is still in progress, results for the latter study will not be reported in this thesis. However, we do include our protocol. Discussion: Overall, results suggested that autonomous motivation for eating-disorder treatment has some positive prognostic effects in individuals with eating disorders.</description><description>Objectif : La but de cette maîtrise était de déterminer la valeur pronostique de la motivation autonome et contrôlée pour le traitement chez des participants traités pour un trouble des conduites alimentaires. Pour atteindre ce but, nous avons d'abord validé le Questionnaire de Motivation Autonome et Contrôlée (QMAC) -- un outil utilisé pour mesurer le degré de motivation pour le traitement -- chez des femmes anglophones et francophones atteintes d'un trouble des conduites alimentaires. Par la suite, nous avons évalué, à l'aide du QMAC, la valeur prédictive de la motivation pour le traitement sur la réponse au traitement chez des adultes souffrant d'un trouble des conduites alimentaires. Finalement, nous avons développé un protocole afin de réaliser une méta-analyse visant à déterminer l'effet prédicteur du niveau de motivation en début de traitement sur l'évolution de symptômes cliniques en fin de traitement chez des gens suivant une thérapie pour un trouble des conduites alimentaires. Méthodologie : Trois études furent entreprises. Dans la première étude, le QMAC a été validé chez 463 femmes anglophones ou francophones souffrant d'un trouble des conduites alimentaires. La structure factorielle, les fiabilités interne et test-retest, ainsi que les validités conceptuelle et prédictive ont été examinées. Dans la deuxième étude, la valeur pronostique de la motivation pour le traitement mesurée avec le QMAC a été évaluée chez 770 adultes souffrant d'un trouble des conduites alimentaires. L'évolution du score global de l'"Eating Disorder Examination Questionnaire" ainsi que le taux d'abandon en cours de traitement ont servi de mesures d'intérêt. Dans la troisième étude, nous avons développé le protocole d'une méta-analyse d'études longitudinales s'intéressant à l'effet de la motivation en début de traitement pour un trouble des conduites alimentaires sur l'évolution de plusieurs mesures cliniques (c.-à-d., sévérité globale du trouble des conduites alimentaires, poids, fréquence des orgies alimentaires, fréquence des épisodes de vomissements, sévérité des symptômes anxio-dépressifs et taux de complétion du traitement) en fin de traitement ou lors de suivis subséquents. Nous prévoyons réaliser des méta-analyses différentes pour chacune des mesures d'intérêt étudiées et combiner les tailles d'effet à l'aide d'un modèle à effet aléatoire. Résultats : Les données récoltées au cours de notre première étude ont démontré une correspondance acceptable avec les deux domaines prédéterminés du QMAC (c.-à-d., avec la motivation autonome et contrôlée). Les deux domaines ont par ailleurs démontré une bonne fiabilité interne (alphas 0,80 et 0,85), une bonne validité conceptuelle et une fiabilité test-retest acceptable (coefficient de corrélation interne = 0,73 pour les deux domaines). Par ailleurs, une association a été identifiée entre un score plus élevé sur la sous-échelle mesurant la motivation autonome et une plus grande diminution des symptômes 13 semaines plus tard, indiquant que le QMAC a une valeur prédictive. En contrepartie, aucun lien n'a été trouvé entre les scores de motivation contrôlée et l'évolution des symptômes. Dans la deuxième étude, de plus hauts scores de motivation autonome pour le traitement ont été associés à une plus grande diminution des scores sur l'"Eating Disorder Examination Questionnaire" en cours de traitement (coeff. = -0.15, p &lt; 0.005) et à un risque réduit d'abandon (RC = 0,81; IC 95% : 0,68, 0,96). Comme dans l'étude précédente, aucun lien entre la motivation contrôlée pour le traitement et nos mesures d'intérêt n'a été identifié. Puisque la troisième étude est toujours en cours, les résultats de cette étude ne seront pas présentés dans cette thèse. Le protocole de la méta-analyse sera toutefois inclus. Discussion : Globalement, les résultats obtenus suggèrent que la motivation autonome pour le traitement est un facteur pronostique positif chez les individus atteints de trouble des conduites alimentaires.</description><creator>Sansfaçon, Jeanne</creator><contributor>Howard Steiger (Internal/Supervisor)</contributor><contributor>Mimi Israel (Internal/Cosupervisor2)</contributor><date>2019</date><subject>Psychiatry</subject><title>Applying autonomous and controlled motivation concepts to the study of therapy outcomes in the eating-disorders</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/mp48sf86r.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/47429c52w</identifier><degree><name>Master of Science</name><grantor>McGill University</grantor><discipline>Department of Psychiatry</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:dr26z059g</identifier><datestamp>2020-03-21T04:57:49Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>La culture tissulaire est un puissant outil de conservation, en particulier pour la préservation des espèces soumises à des restrictions permanentes dans la production de semences, ou qui ne peuvent pas être facilement reproduites. Le châtaignier d'Amérique (Castanea dentata (Marsh.) Borkh.) est fonctionnellement éteint dans son aire de répartition naturelle. Certaines sous-populations sont trop isolées pour la production de graines chez cette espèce auto-incompatible, et C. dentata est récalcitrant à la propagation clonale conventionnelle. Des méthodes de conservation à court terme pour C. dentata en culture tissulaire ont été développées et améliorées dans ce travail. Méthodes permettant d'améliorer le taux de multiplication (stade physiologique du matériau source, et la température d'incubation) et la qualité du micro-pied (effet des modifications du milieu exogène sur la 6-benzylaminopurine: BAP, calcium, magnésium, bore, et agent gélifiant (et concentration) sur l'incidence de nécrose au sommet de la tige (STN) ont été étudiés dans la culture axillaire de génotypes de diverses sous-populations de C. dentata. Le stade physiologique de la matière source a entraîné un taux de multiplication, la matière source au stade des semis produisant les cultures les plus vigoureuses. La température d'incubation a eu une incidence sur le taux de multiplication de trois des huit génotypes testés. La BAP la plus concentrée a réduit de manière significative l'incidence de STN. Aucun autre traitement avec un milieu exogène n'a réduit le STN. Un cadre pour l'élaboration d'un plan de conservation utilisant la culture de pousses axillaires avec C. dentata a également été discuté. Un protocole d'embryogenèse somatique utilisant des cultures de pousses axillaires comme micro-coupures a été développé, avec un taux de production d'embryons extrêmement réussi (14 à 19 sur 20 micro-coupes chez des génotypes compétents). En outre, une analyse critique de l'information connue sur la métabolomique de l'interaction hôte-pathogène entre Cryphonectria parasitica et Castanea spp.. Ces outils de conservation des tissus et ces informations métabolomiques permettront une préservation plus efficace de cette espèce pour les générations futures.</description><description>Tissue culture is a powerful conservation tool, particularly in the preservation of species which have ongoing restrictions in seed production or which cannot be otherwise easily propagated. American chestnut (Castanea dentata (Marsh.) Borkh.) is functionally extinct in its native range. Some sub-populations are too isolated for seed production in this self-incompatible species, and C. dentata is recalcitrant to conventional clonal propagation. Short term conservation methods for C. dentata in tissue culture were developed and improved upon in this work. Methods to improve multiplication rate (physiological stage of source material and incubation temperature) and microshoot quality (effect of exogenous medium modifications in 6-benzylaminopurine: BAP, calcium, magnesium, boron, and gelling agent type and concentration on the incidence of shoot top necrosis (STN) were investigated in the axillary shoot culture of genotypes from diverse sub-populations of C. dentata. Physiological stage of source material affected multiplication rate, with seedling-stage source material producing the most vigorous cultures. Incubation temperature affected multiplication rate in three out of eight genotypes tested. The most concentrated BAP significantly reduced the incidence of STN. No other exogenous medium treatments reduced STN. A framework for developing a conservation plan utilizing axillary shoot culture with C. dentata was also discussed. A somatic embryogenesis protocol utilizing axillary shoot cultures as microcuttings was developed, with a highly successful embryogenesis production rate (14-19 out of 20 microcuttings in competent genotypes). As well, a review was conducted critically assessing known information on the metabolomics of the host-pathogen interaction between Cryphonectria parasitica and Castanea spp. These tissue conservation tools and metabolomic insights will allow for the more effective preservation of this species for future generations.</description><creator>Lovat, Christie-Anna</creator><contributor>Danielle J Donnelly (Supervisor)</contributor><date>2019</date><subject>Plant Science</subject><title>Optimizing short term conservation methods for a functionally extinct tree species, American chestnut «Castanea dentata» (Marsh.) Borkh.)</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/5d86p253j.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/dr26z059g</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Plant Science</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:dn39x3618</identifier><datestamp>2020-03-21T04:57:50Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>L'intégrité physique et informationnelle de l'ADN est d'une importance capitale pour la survie, le développement et la reproduction d'organismes vivants. Parmi les diverses formes de dommages pouvant résulter des nombreuses formes intrinsèques et extrinsèques de stress génotoxique, les plus graves sont les cassures à double brin (DSB). Ces lésions sont dangereuses non seulement en raison de leur potentiel mutagène, mais également parce qu'elles perturbent la continuité physique des molécules d'ADN et risquent la perte d'un grand nombre de gènes situés en aval de la rupture. La réparation des DSBs est gérée par plusieurs voies de réparation distinctes, parmi lesquelles la classique jonction d'extrémité non homologue (cNHEJ) est la plus importante dans les tissus somatiques. Le mécanisme de cNHEJ comprend trois étapes: 1) la reconnaissance et liaison rapides de l'extrémité de l'ADN libre par la protéine hétérodimère Ku en forme d'anneau; 2) le traitement des extrémités d'ADN endommagées par un complément de nucléases, kinases, phosphatases et polymérases afin d'obtenir des extrémités compatibles avec la ligature; et 3) la ligature terminale par la ligase IV. Malgré la large conservation des protéines cNHEJ chez les eucaryotes, le nématode Caenorhabditis elegans est unique en ce qu'il ne possède aucun homologue d'enzymes de traitement de la voie cNHEJ ni d'échafaudages structuraux. Cela soulève la question de savoir si un système de cNHEJ de base composé uniquement de l'anneau Ku et de l'orthologue LIG-4 de Ligase IV suffit chez C. elegans ou s'il possède des analogues fonctionnels non conservés d'autres facteurs cNHEJ eucaryotes bien connus.Dans cette thèse, je réponds de manière définitive à cette question en montrant que nhj-1, un gène unique à l'ordre des nématodes Rhabditida et jusque-là non caractérisé, est un facteur cNHEJ indispensable chez C. elegans. Je montre que certaines lignées de la souche de type sauvage de C. elegans la plus couramment utilisée, N2, présentent une sensibilité inattendue à l'exposition aux rayonnements ionisants au premier stade larvaire (L1), qui est spécifique au type de stress et au stage de développement. Je montre que la lignée N2 sensible à l'IR présente une incidence élevée de retard de croissance et de phénotypes morphologiques anormaux, ainsi qu'un nombre considérablement réduit de descendants. Cependant, rien n'indique que l'ADN germinal ait été endommagé, ce qui évoque des mutants cNHEJ connus chez C. elegans. En utilisant le séquençage en profondeur et la mutagenèse CRISPR-Cas9, je révèle l'existence d'une mutation spontanée de nhj-1 dans les lignées sensibles de N2 et montre que cette sensibilité résulte de l'inactivation de ce gène. Je montre également que la sensibilité des mutants nhj-1 est aussi sévère que celle des mutants des anneaux lig-4 ou Ku, et que les doubles mutants ne montrent pas de sensibilité additive à l'IR, démontrant que nhj-1 fait partie de la voie de cNHEJ. Je fournis également la première caractérisation de la localisation subcellulaire de NHJ-1 et LIG-4 dans les larves de C. elegans L1, la lignée germinale adulte et l'intestin adulte, montrant un manque de chevauchement complet des modèles d'expression de NHJ-1 et LIG-4 dans les larves L1. Enfin, j'utilise un contexte génétique dans lequel la voie cNHEJ est activée dans la lignée germinale pour montrer que NHJ-1 agit probablement en aval de la liaison de l'anneau Ku, au moins dans le contexte de la lignée germinale adulte.Mon travail révèle que C. elegans a restructuré l'ancienne voie du cNHEJ pour y inclure un régulateur entièrement nouveau. Cela soulève d'autres questions sur la régulation et le mécanisme de l'activité du cNHEJ dans cet organisme modèle important et ouvre plusieurs pistes permettant de rechercher des réponses à ces questions.</description><description>The physical and informational integrity of DNA is of paramount importance to the survival, development, and reproduction of living organisms. Of the various forms of damage which can arise from the numerous intrinsic and extrinsic forms of genotoxic stress, the most serious are double strand breaks (DSBs). These lesions are dangerous not only because of their mutagenic potential, but because they disrupt the physical continuity of DNA molecules and risk the loss of all genes distal to the break. Repair of DSBs is handled by several distinct pathways, of which the classical non-homologous end joining (cNHEJ) is the most prominent in somatic tissues. The mechanism of cNHEJ involves three steps: 1) the rapid recognition and binding of the free DNA end by the heterodimeric Ku ring protein; 2) the processing of the damaged DNA ends by a complement of nucleases, kinases, phosphatases, and polymerases to yield ligation-compatible ends; and 3) the terminal ligation by Ligase IV. Despite the wide conservation of cNHEJ proteins among eukaryotes, the nematode Caenorhabditis elegans is unique in that it does not possess homologs of known cNHEJ processing enzymes or structural scaffolds. This raises the question of whether a basic cNHEJ system consisting only of the Ku ring and the Ligase IV ortholog LIG-4 suffices in C. elegans or whether it possesses non-conserved functional analogs of other known eukaryotic cNHEJ factors.In this thesis, I provide a definitive answer to this question by showing that nhj-1, a previously uncharacterized gene unique to the nematode order Rhabditida, is an indispensable cNHEJ factor in C. elegans. I show that some lines of the most commonly used C. elegans wild type strain, N2, exhibit unexpected stressor- and developmental stage-specific sensitivity to ionizing radiation exposure at the first larval stage (L1). This sensitivity is characterized by a high incidence of growth delay and abnormal morphological phenotypes, as well as a greatly reduced number of progeny. However, there is no evidence of germline DNA damage, which is evocative of known cNHEJ mutants in C. elegans. Using deep sequencing and CRISPR-Cas9 mutagenesis, I reveal the existence of a spontaneous nhj-1 mutation in the sensitive N2 lines, and show that IR-sensitivity arises because of the resulting nhj-1 loss of function. Furthermore, the IR-sensitivity of nhj-1 mutants is as severe as that of lig-4 or Ku ring mutants, and double mutants do not show additive IR-sensitivity, demonstrating that nhj-1 is part of the cNHEJ pathway. I also provide the first characterization of the subcellular localization of NHJ-1 and LIG-4 in the C. elegans L1 larva, the adult germline, and the adult intestine, showing a lack of complete overlap in the NHJ-1 and LIG-4 expression patterns in the L1 larva. Finally, I employ a germline cNHEJ-enabled genetic background to show that NHJ-1 likely acts downstream of Ku ring binding, at least in the context of the adult germline. My work reveals that C. elegans has restructured the ancient cNHEJ pathway to include an entirely novel regulator. It raises further questions about the regulation and mechanism of cNHEJ activity in this important model organism, and opens several research avenues in which the answers to those questions may be sought. </description><creator>Vujin, Aleksandar</creator><contributor>Monique Zetka (Supervisor)</contributor><date>2019</date><subject>Biology</subject><title>The discovery and characterization of NHJ-1, a novel regulator of canonical non-homologous end joining in the nematode «Caenorhabditis elegans»</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/9306t144r.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/dn39x3618</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Biology</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:4f16c494z</identifier><datestamp>2020-03-21T04:57:50Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Cette thèse décrit la collecte de données dans la littérature publiée au cours des dix dernières années pour mettre à jour la base de Données sur l'Adsorption Biomoléculaire (BAD), ainsi que le traitement et autres calculs sur ces données. Ceci afin de mettre à jour la BAD et lui permettre de fournir une prédiction plus précise de l'adsorption de protéines pour la conception d'applications d'ingénierie. L'adsorption de protéines aux interfaces solide-liquide est cruciale dans de nombreuses applications biomédicales et industrielles. Ces applications comprennent des biomatériaux, des micro-réseaux de protéines, des dispositifs de laboratoire sur puce et des bioréacteurs. (Vasina et al., 2009) Dans le domaine des biomatériaux, après le contact d'un matériau d'implant avec un fluide biologique, la première réponse est l'adsorption de protéines à sa surface. La couche de protéines adsorbées joue un rôle dans la régulation de la réponse biologique à la matière et, par conséquent sa biocompatibilité. C'est à partir de la couche de protéines adsorbée que les cellules du système obtiennent des informations sur la surface étrangère, ce qui détermine le comportement des cellules. Ce comportement cellulaire peut aller de l'adhésion, l'établissement et la prolifération de cellules à proximité du matériau, au rejet et à l'inflammation à l'interface en raison d'une superposition en couches et d'une dénaturation. (Wilson, Clegg, Leavesley, &amp; Pearcy, 2005)Dans le domaine des micro-réseaux de protéines et des micro-/nano- dispositifs, l'adsorption des protéines est intéressante car il est nécessaire de trouver un équilibre optimal pour maximiser la sensibilité et /ou l'activité des fonctions analytiques. Ceci est accompli en préservant les caractéristiques natives des protéines et en minimisant leur dénaturation. (Vasina et al., 2009)Dans le domaine des bioréacteurs, par exemple, l'adsorption des protéines joue un rôle dans l'encrassement de la membrane, ce qui entraîne une augmentation des pressions de fonctionnement et un nettoyage fréquent de l'encrassement biologique. Par conséquent, il est important de choisir des matériaux et des conditions minimisant l'adsorption de protéines et l'encrassement biologique dans les bioréacteurs. (Ognier, Wisniewski, &amp; Grasmick, Influence of macromolecule adsorption during filtration of a membrane bioreactor mixed liquor suspension, 2002)Indépendamment de l'attention et de la recherche considérables des 50 dernières années, la prédiction de l'adsorption de protéines n'avait pas été atteinte avec une précision suffisante pour les applications d'ingénierie. La BAD aborde la prévision de l'adsorption de protéines en archivant les données d'adsorption de protéines et en appliquant une analyse statistique à ces données. Cette approche met en corrélation avec précision les variables d'entrée qui influencent l'adsorption de protéines, telles que la concentration de protéines dans la solution, les caractéristiques des protéines, les conditions environnementales des fluides et les paramètres de surface, avec la variable de sortie : la concentration de protéines à la surface. (Vasina et al., 2009)</description><description>This thesis describes the advancement of the Bio-molecular Adsorption Database (BAD) to more accurately predict protein adsorption. To advance the model of the BAD, data was first: collected from published literature in the last ten years, processed to be added to BAD, and used in calculations to advance the BAD ability to accurately predict protein adsorption.Protein adsorption at solid-liquid interfaces is crucial in many biomedical and industrial applications. These applications include biomaterials, protein microarrays, lab-on-a-chip devices and bioreactors. (Vasina et al., 2009)In the biomaterial area, the first response after contact of an implant material with a biological fluid, is the adsorption of proteins on to the surface. The adsorbed protein layer plays a role in the regulation of the biological response to the material and therefore bio-compatibility. It is from the adsorbed protein layer that the cells in the system obtain information about the foreign surface determining the cell behaviour. This cell behaviour can range from: adhesion establishment and proliferation of cells in the proximity to the material or the rejection and inflammation at the interface due to over layering and denaturation. (Wilson, Clegg, Leavesley, &amp; Pearcy, 2005)In the protein microarrays and micro/nano- devices area, protein adsorption is of interest because of the need finding an optimum balance to maximized sensitivity and/or activity for analytical functions. This is done by preserving the proteins native characteristics and minimizing protein denaturation. (Vasina et al., 2009)In the bioreactors area, protein adsorption plays a role in membrane fouling, leading to increased pressures of operation and frequent biofouling clear out. As such, it is important to choose materials and conditions to minimize protein adsorption and biofouling in bioreactors. (Ognier, Wisniewski, &amp; Grasmick, Influence of macromolecule adsorption during filtration of a membrane bioreactor mixed liquor suspension, 2002)Regardless of the considerable attention and research in the last 50 years, protein adsorption prediction had not been attained with sufficient accuracy for engineering applications. The original work into BAD, addressed protein adsorption prediction by archiving protein adsorption data and applying statistical analysis to the data. (Vasina et al., 2009)This approach correlated accurately the input variables to protein adsorption. Examples include: protein concentration in solution, protein characteristics, fluid environment conditions and surface parameters to the output variable or protein concentration on the surface. (Vasina et al., 2009)</description><creator>Arias Montecillo, Maria Eugenia</creator><contributor>Dan Nicolau (Internal/Supervisor)</contributor><date>2019</date><subject>Anthropology</subject><title>Prediction of protein adsorption on engineered surfaces for biomedical and industrial applications</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/kh04dr810.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/4f16c494z</identifier><degree><name>Master of Engineering</name><grantor>McGill University</grantor><discipline>Biological and Biomedical Engineering</discipline></degree></thesis></metadata></record><record><header><identifier>oai:escholarship.mcgill.ca:4t64gq47m</identifier><datestamp>2020-03-21T04:57:51Z</datestamp></header><metadata><thesis xmlns="http://www.ndltd.org/standards/metadata/etdms/1-0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.ndltd.org/standards/metadata/etdms/1-0/ http://www.ndltd.org/standards/metadata/etdms/1-0/etdms.xsd"><description>Anthropogenic climate change brings into focus the entanglements of humans and nonhumans, a kind of collective world-making that cannot be captured in terms of a divide between separate 'natural' and 'social' orders (Latour 2014; Haraway et al. 2016). Anthropological attunement to these collectives have simultaneously enlarged the field of view and decentered human beings as just one entity among many others (e.g., Kirksey and Helmreich 2010). My dissertation builds on these efforts by conducting an anthropology of sea ice—more specifically, 'sea ice' as constituted by scientific knowledge. It is based on 12 months of fieldwork (2014-2016) among sea ice scientists at the Polar Science Centre and various academic departments at the University of Washington in Seattle, WA. In this dissertation, I seek to shift from sea ice-worlding as 'becomings-with,' in which human-sea ice relationships are basic units of analysis (Haraway 2008), to explore how sea ice itself orders myriad things. My dissertation is self-consciously ice-centric without being post-humanist. This is, perhaps, an effort to explore the possibility of anthropology "after ethnos" from that which exceeds the human (Rees 2018). This dissertation does not seek to make ontological claims about the world as it is in a metaphysical sense, but explores a conceptual provocation—one that enters sea ice-worlding through scientific knowledge as a human practice. As a conceptual departure point, scientific knowledge makes visible 'sea ice' as produced, historically contingent, and open to change. This forms the basis of Chapter One ("Making Sea Ice: A Field Guide") and informs my analysis in Chapter Two ("Rotten Ice"), which followed in real-time the making of 'rotten ice'—a type of heavily melted sea ice that is likely becoming more prevalent in the Arctic. Scientific knowledge is made by human practitioners, but it is not reducible to them. Such knowledge can offer a provisional 'window' onto times and domains beyond the strictly human: What order of things comes into view through scientific knowledge of sea ice? How does sea ice potentially destabilize, inflect, or reconfigure concepts of 'world' and 'time'? Chapter Three ("Non-Predictability") examines how sea ice makes visible a collective temporal reckoning that does not ground in clocks, consciousness, or social relations. Chapter Four ("Salt-Ice Worlds") shows how sea ice gives rise to a non-teleological worlding that is not fully captured by either 'livability' or 'extinction' as the Other to life. The implications of these findings are discussed in conversation with anthropological scholarship on thinking human-nonhuman collectivities in the context of anthropogenic climate change.</description><description>Le changement climatique anthropique met en lumière l'enchevêtrement entre humains et non-humains, une façon collective de produire  le monde qui ne peut être réduite à une séparation entre les domaines du « naturel » et du « social » (Latour 2014; Haraway et al. 2015). L'attention impartie par les anthropologues à ces formes de collectif a simultanément élargi le champ d'horizon et décentré les êtres humains de leur place privilégiée en les situant comme une entité parmi tant d'autres (par exemple Kirksey and Helmreich 2010). Ma thèse s'appuie sur ces efforts pour mener une anthropologie de la glace de mer. Plus spécifiquement, ce travail étudie « la glace de mer » telle que constituée par le savoir scientifique. Cette thèse est fondé sur douze mois de recherche de terrain (2014-2016) parmi les scientifiques étudiant la glace de mer au Polar Science Centre de l'Université de Washington, à Seattle, aux États-Unis. L'objet d'analyse de cette thèse n'est pas tant la relation humain-glace de mer, et comment ceux-ci co-deviennent ou se co-constituent (Haraway 2009). Ce travail cherche plutôt à déplacer l'objet d'étude pour explorer comment la glace de mer elle-même catégorise une multitude de choses. Ce travail est sciemment « glace-centré » sans être pour autant post-humaniste. Ceci pourrait être compris comme un effort d'explorer la possibilité d'une anthropologie « post-ethnos »  par ce qui dépasse le domaine de l'humain (Rees 2018). Cette thèse n'a pas l'ambition d'avancer des conclusions ontologiques à propos du monde et sur ce qu'il est dans un sens métaphysique, mais il examine une provocation d'ordre conceptuel. Cette provocation conceptuelle pénètre dans les mondes engendrés par la glace au travers du savoir scientifique compris comme une pratique humaine. Comme point de départ conceptuel, le savoir scientifique rend visible la « glace de mer » telle que produite, soumis aux contingences historiques, et ouverte au changement. Ceci constitue le cadre pour le Chapitre 1 (« Fabriquer la glace de mer : une guide pratique ») et sous-tend l'analyse du Chapitre 2 (« Rotten Ice »), qui suit en temps réel la fabrication de « rotten ice » — un type de glace en grande partie fondue qui est probablement en passe de devenir plus prévalent dans l'Arctique. Le savoir scientifique est produit par des professionnels humains mais il ne leur est pas réductible. Ce savoir peut offrir une « fenêtre » provisoire sur des temps et des domaines au-delà de ce qui est purement humain. Quel ordre des choses se profile à travers le savoir scientifique à propos de la glace de mer ? Comment est-ce que la glace de mer déstabilise, module, ou reconfigure les concepts de « monde » et de « temps » ? Le Chapitre 3 (« Non-prédictibilité ») examine comment la glace de mer met au jour une façon collective d'appréhender le temps qui n'est pas basée sur les montres, la conscience, ou les relations sociales. Les implications de ces conclusions sont présentées en conversation avec la littérature anthropologique qui a cherché à qualifier les collectivités humain-non-humain dans le contexte du changement climatique anthropique. Le Chapitre 4 (Salt-Ice Worlds) illustre comment la glace de mer donne naissance à une façon non-téléologique d'être au monde  qui ne peut se résumer ni en « habitabilité », ni en  « extinction » comme l'Autre à la vie. </description><creator>Yip, Julianne</creator><contributor>Edward Kohn (Supervisor1)</contributor><contributor>Tobias Rees (Supervisor2)</contributor><date>2019</date><subject>Anthropology</subject><title>Salt-ice worlds: An anthropology of sea ice</title><language>eng</language><publisher>McGill University</publisher><type>Thesis</type><rights>All items in eScholarship@McGill are protected by copyright with all rights reserved unless otherwise indicated.</rights><identifier>https://escholarship.mcgill.ca/downloads/2v23vw28s.pdf</identifier><identifier>https://escholarship.mcgill.ca/concern/theses/4t64gq47m</identifier><degree><name>Doctor of Philosophy</name><grantor>McGill University</grantor><discipline>Department of Anthropology</discipline></degree></thesis></metadata></record><resumptionToken completeListSize="47894">oai_etdms.s(Collection:theses).f(2019-10-16T06:03:34Z).u(2020-07-23T18:55:55Z).t(47894):3200</resumptionToken></ListRecords></OAI-PMH>