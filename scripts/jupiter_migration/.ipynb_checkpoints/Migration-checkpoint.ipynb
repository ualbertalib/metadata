{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from config import sparqlTerms, mig_ns, sparql_mig_test, sparql_mig_simple, sparql_mig_dev\n",
    "from transformation import TransformationFactory\n",
    "from SPARQLWrapper import JSON\n",
    "from utilities import removeNS, PrintException\n",
    "import concurrent.futures\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  MAIN CONTROLLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\tfor ptype in [\"collection\", \"community\", \"generic\", \"thesis\"]:\n",
    "\t\tmig = QueryFactory.getMigrationQuery(ptype)\n",
    "\t\tfor q in mig.queries:\n",
    "\t\t\tDTO = DataFactory.getData(q, mig)\n",
    "\t\t\tDTO.transformData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  TRANSFORMATIONS\n",
    "#### functions for handling data passed over by the data object. Takes a triple, detects what kind of action needs to be taken based on the predicate, sends it to the appropriate function for transformations, then returns it back to the data handler to be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Transformation():\n",
    "\t@staticmethod\n",
    "\tdef rdfsyntaxnstype(triple):\n",
    "\t\t# triple['object']['value'] = \"I did something to this value\"\n",
    "\t\t# triple['object']['type'] = \"string\"\n",
    "\t\t# return [triple] # a list of triples, in case more triples must be added as a result of this operation\n",
    "        pass\n",
    "    \n",
    "\t@staticmethod\n",
    "\tdef language(triple):\n",
    "\t\t# normalize values and convert to \n",
    "\t\treturn[triple]\n",
    "\n",
    "class TransformationFactory():\n",
    "\t@staticmethod\n",
    "\tdef getTransformation(triple):\n",
    "\t\tfunction = re.sub(r'[0-9]+', '', triple['predicate']['value'].split('/')[-1].replace('#', '').replace('-', ''))\n",
    "\t\tif (function == \"rdfsyntaxnstype\"):\n",
    "\t\t\treturn Transformation().rdfsyntaxnstype(triple)\n",
    "\t\telif (function == \"language\"):\n",
    "\t\t\treturn Transformation().language(triple)\n",
    "\t\telse:\n",
    "\t\t\treturn [triple]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  QUERY BUILDER\n",
    "##### Pulls current mappings from triplestore, dynamically builds queries in managable sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Query(object):\n",
    "\t\"\"\" Query objects are dynamically generated, and contain SPARQL CONSTRUCT queries with input from the jupiter application profile \"\"\"\n",
    "\tdef __init__(self, ptype, sparqlTerms=sparqlTerms, sparqlData=sparql_mig_test):\n",
    "\t\tself.mapping = []\n",
    "\t\tself.sparqlTerms = sparqlTerms  # doesn't need to change (the terms store doesn't change)\n",
    "\t\tself.sparqlData = sparqlData  # sets the triple store from which to get data (simple, test, or dev)\n",
    "\t\tself.queries = []\n",
    "\t\tself.prefixes = \"\"\n",
    "\t\tself.filename = \"\"\n",
    "\t\tfor ns in mig_ns:\n",
    "\t\t\tself.prefixes = self.prefixes + \" PREFIX %s: <%s> \" % (ns['prefix'], ns['uri'])\n",
    "\t\tself.getMappings()\n",
    "\t\tself.generateQueries()\n",
    "\n",
    "\n",
    "\tdef getMappings(self):\n",
    "\t\tquery = \"prefix ual: <http://terms.library.ualberta.ca/>SELECT * WHERE {GRAPH ual:%s {?newProperty ual:backwardCompatibleWith ?oldProperty} }\" % (self.ptype)\n",
    "\t\tself.sparqlTerms.setReturnFormat(JSON)\n",
    "\t\tself.sparqlTerms.setQuery(query)\n",
    "\t\tresults = self.sparqlTerms.query().convert()\n",
    "\t\tfor result in results['results']['bindings']:\n",
    "\t\t\tself.mapping.append((result['newProperty']['value'], result['oldProperty']['value']))\n",
    "\n",
    "\tdef generateQueries(self):\n",
    "\t\tpass\n",
    "\n",
    "\n",
    "class Collection(Query):\n",
    "\tdef __init__(self):\n",
    "\t\tself.ptype = 'collection'\n",
    "\t\tself.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; rdf:type pcdm:Collection\"\n",
    "\t\tself.where = [\"WHERE { ?resource info:hasModel 'Collection'^^xsd:string . OPTIONAL { ?resource ualids:is_community 'false'^^xsd:boolean } . OPTIONAL { ?resource ualid:is_community 'false'^^xsd:boolean } . OPTIONAL { ?resource ual:is_community 'false'^^xsd:boolean }\"]\n",
    "\t\tself.select = None\n",
    "\t\tsuper().__init__(self.ptype)\n",
    "\n",
    "\tdef generateQueries(self):\n",
    "\t\tfor where in self.where:\n",
    "\t\t\tconstruct = self.construct\n",
    "\t\t\tfor pair in self.mapping:\n",
    "\t\t\t\tconstruct = \"%s ; <%s> ?%s\" % (construct, pair[0], removeNS(pair[0]))\n",
    "\t\t\t\twhere = \" %s . OPTIONAL { ?resource <%s> ?%s }\" % (where, pair[1], removeNS(pair[0]))\n",
    "\t\t\tself.queries.append( (\"%s %s } %s }\" % (self.prefixes, construct, where), \"\" ) )\n",
    "\n",
    "\n",
    "class Community(Query):\n",
    "\tdef __init__(self):\n",
    "\t\tself.ptype = 'community'\n",
    "\t\tself.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; rdf:type pcdm:Object; rdf:type ual:Community\"\n",
    "\t\tself.where = [\"WHERE { ?resource info:hasModel 'Collection'^^xsd:string ; OPTIONAL { ?resource ualids:is_community 'true'^^xsd:boolean } . OPTIONAL { ?resource ualid:is_community 'true'^^xsd:boolean } . OPTIONAL { ?resource ual:is_community 'true'^^xsd:boolean }\"]\n",
    "\t\tself.select = None\n",
    "\t\tsuper().__init__(self.ptype)\n",
    "\n",
    "\tdef generateQueries(self):\n",
    "\t\tfor where in self.where:\n",
    "\t\t\tconstruct = self.construct\n",
    "\t\t\tfor pair in self.mapping:\n",
    "\t\t\t\tconstruct = \"%s ; <%s> ?%s\" % (construct, pair[0], removeNS(pair[0]))\n",
    "\t\t\t\twhere = \" %s . OPTIONAL { ?resource <%s> ?%s }\" % (where, pair[1], removeNS(pair[0]))\n",
    "\t\t\tself.queries.append( ( \"%s %s } %s }\" % (self.prefixes, construct, where), \"\" ) )\n",
    "\n",
    "\n",
    "class Generic(Query):\n",
    "\tdef __init__(self):\n",
    "\t\tself.ptype = 'generic'\n",
    "\t\tself.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; rdf:type pcdm:Object; rdf:type works:work\"\n",
    "\t\tself.where = []\n",
    "\t\tself.select = \"SELECT distinct ?collection WHERE { ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type ?type . filter(?type != 'Thesis'^^xsd:string) . ?resource ualids:hasCollectionId ?collection }\"\n",
    "\t\tsuper().__init__(self.ptype)\n",
    "\n",
    "\tdef generateQueries(self):\n",
    "\t\tquery = \"%s %s\" % (self.prefixes, self.select)\n",
    "\t\tself.sparqlData.setReturnFormat(JSON)\n",
    "\t\tself.sparqlData.setQuery(query)\n",
    "\t\tresults = self.sparqlData.query().convert()\n",
    "\t\tfor result in results['results']['bindings']:\n",
    "\t\t\twhere = \"WHERE {  ?resource ualids:hasCollectionId '%s'^^xsd:string ; info:hasModel 'GenericFile'^^xsd:string ; dcterm:type ?type . filter(?type != 'Thesis'^^xsd:string)\" % (result['collection']['value'])\n",
    "\t\t\tconstruct = self.construct\n",
    "\t\t\tfor pair in self.mapping:\n",
    "\t\t\t\tconstruct = \"%s ; <%s> ?%s\" % (construct, pair[0], removeNS(pair[0]))\n",
    "\t\t\t\twhere = \" %s . OPTIONAL { ?resource <%s> ?%s }\" % (where, pair[1], removeNS(pair[0]))\n",
    "\t\t\tself.queries.append( ( \"%s %s } %s }\" % (self.prefixes, construct, where), result['collection']['value'] ) )\n",
    "\n",
    "class Thesis(Query):\n",
    "\tdef __init__(self):\n",
    "\t\tself.ptype = 'thesis'\n",
    "\t\tself.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; rdf:type pcdm:Object; rdf:type works:work ; rdf:type bibo:Thesis\"\n",
    "\t\tself.where = []\n",
    "\t\tself.select = \"SELECT distinct ?year_created WHERE { ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type 'Thesis'^^xsd:string ; ualids:year_created ?year_created }\"\n",
    "\t\tsuper().__init__(self.ptype)\n",
    "\n",
    "\tdef generateQueries(self):\n",
    "\t\tquery = \"%s %s\" % (self.prefixes, self.select)\n",
    "\t\tself.sparqlData.setReturnFormat(JSON)\n",
    "\t\tself.sparqlData.setQuery(query)\n",
    "\t\tresults = self.sparqlData.query().convert()\n",
    "\t\tfor result in results['results']['bindings']:\n",
    "\t\t\twhere = \"WHERE { ?resource ualid:year_created '%s'^^xsd:string ; info:hasModel 'GenericFile'^^xsd:string ; dcterm:type 'Thesis'^^xsd:string\" % (result['year_created']['value'])\n",
    "\t\t\tconstruct = self.construct\n",
    "\t\t\tfor pair in self.mapping:\n",
    "\t\t\t\tconstruct = \"%s ; <%s> ?%s\" % (construct, pair[0], removeNS(pair[0]))\n",
    "\t\t\t\twhere = \" %s . OPTIONAL { ?resource <%s> ?%s }\" % (where, pair[1], removeNS(pair[0]))\n",
    "\t\t\tself.queries.append(( \"%s %s } %s }\" % (self.prefixes, construct, where), result['year_created']['value']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  DATA TRANSPORT OBJECTS\n",
    "##### Runs a query, sends data to get transformed, saves data to appropriate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "\tdef __init__(self, q, sparqlData, sparqlTerms):\n",
    "\t\tself.q = q\n",
    "\t\tself.query = q[0]\n",
    "\t\tself.sparqlData = sparqlData\n",
    "\t\tself.sparqlTerms = sparqlTerms\n",
    "\t\tself.filename = \"\"\n",
    "\t\tself.output = []\n",
    "\n",
    "\tdef transformData(self):\n",
    "\t\tself.sparqlData.setMethod(\"GET\")\n",
    "\t\tself.sparqlData.setReturnFormat(JSON)\n",
    "\t\tself.sparqlData.setQuery(self.query)\n",
    "\t\tresults = self.sparqlData.query().convert()['results']['bindings']\n",
    "\t\tfor result in results:\n",
    "\t\t\tresult = TransformationFactory().getTransformation(result)\n",
    "\t\t\tfor triple in result:\n",
    "\t\t\t\ts = \"<%s>\" % (str(triple['subject']['value']))\n",
    "\t\t\t\tp = \"<%s>\" % (str(triple['predicate']['value']))\n",
    "\t\t\t\tif triple['object']['type'] == 'uri':\n",
    "\t\t\t\t\to = \"<%s>\" % (str(triple['object']['value']))\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\to = \"\\\"%s\\\"\" % (str(triple['object']['value']))\n",
    "\t\t\t\tself.output.append(\"%s %s %s . \\n\" % (s, p, o))\n",
    "\t\twith open(self.filename, \"w+\") as f:\n",
    "\t\t\tf.writelines(self.output)\n",
    "\n",
    "\t\t#with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:\n",
    "\t\t#\tfuture_to_result = {executor.submit(self.processResults, results, query): result for result in results}\n",
    "\t\t#\tfor future in concurrent.futures.as_completed(future_to_result):\n",
    "\t\t#\t\tresult = future_to_result[future]\n",
    "\t\t#\t\ttry:\n",
    "\t\t#\t\t\tfuture.result()\n",
    "\t\t#\t\texcept Exception:\n",
    "\t\t#\t\t\tPrintException()\n",
    "\n",
    "class CollectionData(Data):\n",
    "\tdef __init__(self, q, sparqlData, sparqlTerms):\n",
    "\t\tsuper().__init__(q, sparqlData, sparqlTerms)\n",
    "\t\tself.filename = 'results/collection.nt'\n",
    "\n",
    "class CommunityData(Data):\n",
    "\tdef __init__(self, q, sparqlData, sparqlTerms):\n",
    "\t\tsuper().__init__(q, sparqlData, sparqlTerms)\n",
    "\t\tself.filename = 'results/community.nt'\n",
    "\n",
    "\n",
    "class ThesisData(Data):\n",
    "\tdef __init__(self, q, sparqlData, sparqlTerms):\n",
    "\t\tsuper().__init__(q, sparqlData, sparqlTerms)\n",
    "\t\tself.filename = \"results/thesis/%s.nt\" % (self.q[1])\n",
    "\n",
    "\n",
    "class GenericData(Data):\n",
    "\tdef __init__(self, q, sparqlData, sparqlTerms):\n",
    "\t\tsuper().__init__(q, sparqlData, sparqlTerms)\n",
    "\t\tself.filename = \"results/generic/%s.nt\" % (self.q[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QueryFactory():\n",
    "\t@staticmethod\n",
    "\tdef getMigrationQuery(ptype):\n",
    "\t\t\"\"\" returns a specified query object depending on the type passed in\"\"\"\n",
    "\t\tif (ptype == \"collection\"):\n",
    "\t\t\treturn Collection()\n",
    "\t\telif (ptype == \"community\"):\n",
    "\t\t\treturn Community()\n",
    "\t\telif (ptype == \"thesis\"):\n",
    "\t\t\treturn Thesis()\n",
    "\t\telif (ptype == \"generic\"):\n",
    "\t\t\treturn Generic()\n",
    "\t\telse:\n",
    "\t\t\treturn None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataFactory():\n",
    "\t@staticmethod\n",
    "\tdef getData(q, mig):\n",
    "\t\t\"\"\" returns a specified query object depending on the type passed in\"\"\"\n",
    "\t\tif (mig.ptype == \"collection\"):\n",
    "\t\t\treturn CollectionData(q, mig.sparqlData, mig.sparqlTerms)\n",
    "\t\telif (mig.ptype == \"community\"):\n",
    "\t\t\treturn CommunityData(q, mig.sparqlData, mig.sparqlTerms)\n",
    "\t\telif (mig.ptype == \"thesis\"):\n",
    "\t\t\treturn ThesisData(q, mig.sparqlData, mig.sparqlTerms)\n",
    "\t\telif (mig.ptype == \"generic\"):\n",
    "\t\t\treturn GenericData(q, mig.sparqlData, mig.sparqlTerms)\n",
    "\t\telse:\n",
    "\t\t\treturn None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
