{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  MAIN CONTROLLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from config import sparqlTerms, mig_ns, sparql_mig_test, sparql_mig_simple, sparql_mig_dev, vocabs, types\n",
    "from SPARQLWrapper import JSON, SPARQLWrapper\n",
    "from utilities import removeNS, PrintException, cleanOutputs\n",
    "import re, os, concurrent.futures, json, requests\n",
    "from rdflib import URIRef, Literal, Namespace, Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    sparqlData=sparql_mig_simple\n",
    "    #  Iterate over every type of object that needs to be migrated. \n",
    "    #  This is the first splitting of the data for migration.\n",
    "    cleanOutputs(types)\n",
    "    for objectType in types:\n",
    "        # a queryObject knows where it came from.\n",
    "        # a queryObject has been split into multiple groups\n",
    "        # only one group exists for community, and one for collection objects\n",
    "        # approximately a thousand queries each are minted for thesis and for generic objects\n",
    "        # these queries are based on the first folder in the fedora pair tree\n",
    "        queryObject = QueryFactory.getMigrationQuery(objectType, sparqlData)\n",
    "        print('%s queries generated' % (objectType))\n",
    "        print('%i queries of %s objects to be transformed' % (len(queryObject.queries), objectType))\n",
    "        i = 0\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:\n",
    "            \n",
    "            future_to_result = {executor.submit(parellelTransform, queryObject, group): group for group in queryObject.queries.keys()}\n",
    "            for future in concurrent.futures.as_completed(future_to_result):\n",
    "                result = future_to_result[future]\n",
    "                try:\n",
    "                    i = i + 1\n",
    "                    future.result()\n",
    "                    print(\"%i of %i %s queries transformed\" % (i, len(queryObject.queries), objectType) )\n",
    "                except Exception:\n",
    "                    PrintException()\n",
    "        #queryObject.postResults()\n",
    "        print(\"%s objects transformation completed\" % (objectType) )\n",
    "\n",
    "def parellelTransform(queryObject, group):\n",
    "    DTO = Data(queryObject.queries[group], group, queryObject.sparqlData, sparqlTerms, queryObject) # query, group, object\n",
    "    DTO.transformData()\n",
    "    #DTO.resultsToTriplestore(queryObject.sparqlResults)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  TRANSFORMATIONS\n",
    "#### functions for handling data passed over by the data object. Takes a triple, detects what kind of action needs to be taken based on the predicate, sends it to the appropriate function for transformations, then returns it back to the data handler to be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Transformation():\n",
    "    \n",
    "    \"\"\"\n",
    "    the output must be a list of triples matching the same format as the input (as follows):\n",
    "    \n",
    "    {\n",
    "        'subject': {\n",
    "            'value': 'http://gillingham.library.ualberta.ca:8080/fedora/rest/prod/0r/96/76/28/0r967628d', \n",
    "            'type': 'uri'\n",
    "        }, \n",
    "        'predicate': {\n",
    "            'value': 'http://purl.org/dc/elements/1.1/subject', \n",
    "            'type': 'uri'\n",
    "        }, \n",
    "        'object': {\n",
    "            'value': 'Geochemistry', \n",
    "            'type': 'literal'\n",
    "        }\n",
    "    }\n",
    "    output is appended to self.output\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.output = []\n",
    "        \n",
    "\n",
    "\n",
    "       \n",
    "    ############################################################################\n",
    "    ######################## transformation on dcterms:language ################\n",
    "    ############################################################################\n",
    "\n",
    "    def language(self, triple, objectType):\n",
    "        # normalize values and convert to URI (consult the \"vocabs\" variable from the config file (this folder))\n",
    "        for vocab in vocabs[\"language\"]:\n",
    "            # mint a new triple with the mapped type\n",
    "            if triple['object']['value'] in  vocab[\"mapping\"]:\n",
    "                self.output.append(\n",
    "                    {\n",
    "                            'subject': {\n",
    "                                'value': triple['subject']['value'], # the subject of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'predicate': {\n",
    "                                'value': triple['predicate']['value'], # the predicate of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'object': {\n",
    "                                'value': vocab[\"uri\"], # mapped uri\n",
    "                                'type': 'uri'\n",
    "                            }\n",
    "                        } \n",
    "                    ) \n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "\n",
    "\n",
    "    ############################################################################\n",
    "    ######################## transformation on dc:rights #######################\n",
    "    ############################################################################\n",
    "    \n",
    "    \n",
    "    def rights(self, triple, objectType):\n",
    "        #### \n",
    "        # several different license values need to be coerced into one common value, this needs to be confirmed with leah before it is written\n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "\n",
    "    ############################################################################\n",
    "    ######################## transformation on dc:license ######################\n",
    "    ############################################################################\n",
    "    \n",
    "    \n",
    "    def license(self, triple, objectType):\n",
    "        #### \n",
    "        # several different license values need to be coerced into one common value, this needs to be confirmed with leah before it is written\n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "\n",
    "    \n",
    "    ############################################################################\n",
    "    ######################## transformation on ual:institution #################\n",
    "    ############################################################################\n",
    "\n",
    "    def institution(self, triple, objectType):\n",
    "        self.output.append(\n",
    "            {\n",
    "            'subject': {\n",
    "                'value': triple['subject']['value'], \n",
    "                'type': 'uri'\n",
    "            }, \n",
    "            'predicate': {\n",
    "                'value': triple['predicate']['value'], \n",
    "                'type': 'uri'\n",
    "            }, \n",
    "            'object': {\n",
    "                'value': 'http://id.loc.gov/authorities/names/n79058482', \n",
    "                'type': 'uri'\n",
    "            }\n",
    "        }\n",
    "        )\n",
    "        return self.output\n",
    " \n",
    "\n",
    "    ############################################################################\n",
    "    ######################## transformation on dcterms:license #################\n",
    "    ############################################################################\n",
    "\n",
    "    \n",
    "    def license(self, triple, objectType):\n",
    "        #### \n",
    "        # convert licenses from text to URI (use vocabs variable, some coersion will be necessary)\n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "    \n",
    "    \n",
    "    ############################################################################\n",
    "    ######################## transformation on dcterms:type ####################\n",
    "    ############################################################################\n",
    "    \n",
    "    def type(self, triple, objectType):\n",
    "        if objectType == 'generic':\n",
    "            for vocab in vocabs[\"type\"]:\n",
    "                # mint a new triple with the mapped type\n",
    "                if triple['object']['value'] in vocab[\"mapping\"]:\n",
    "                    self.output.append(\n",
    "                        {\n",
    "                            'subject': {\n",
    "                                'value': triple['subject']['value'], # the subject of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'predicate': {\n",
    "                                'value': triple['predicate']['value'], # the predicate of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'object': {\n",
    "                                'value': vocab[\"uri\"], # mapped uri\n",
    "                                'type': 'uri'\n",
    "                            }\n",
    "                        }\n",
    "                    )\n",
    "     \n",
    "            else:\n",
    "                pass\n",
    "        elif (objectType == 'community') or (objectType == 'collection'):\n",
    "            self.output.append(triple)\n",
    "        \n",
    "        return self.output\n",
    "        \n",
    "    def modelsmemberOf(self, triple, objectType):\n",
    "        if \"http\" not in triple['object']['value']:\n",
    "            value = triple['object']['value']\n",
    "            triple['object']['value'] = \"http://gillingham.library.ualberta.ca:8080/fedora/rest/prod/%s/%s/%s/%s/%s\" % (value[0:2], value[2:4], value[4:6], value[6:8], value)\n",
    "            triple['object']['type'] = 'uri'\n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "\n",
    "    def modelshasMember(self, triple, objectType):\n",
    "        if \"http\" not in triple['object']['value']:\n",
    "            value = triple['object']['value']\n",
    "            triple['object']['value'] = \"http://gillingham.library.ualberta.ca:8080/fedora/rest/prod/%s/%s/%s/%s/%s\" % (value[0:2], value[2:4], value[4:6], value[6:8], value)\n",
    "            triple['object']['type'] = 'uri'\n",
    "        self.output.append(triple)\n",
    "        return self.output\n",
    "    \n",
    "    def accessRights(self, triple, objectType):\n",
    "        if \"http://projecthydra.org/ns/auth/group#public\" in triple['object']['value']:\n",
    "            triple['object']['value'] = \"http://terms.library.ualberta.ca/public\"\n",
    "            triple['object']['type'] = 'uri'\n",
    "            self.output.append(triple)\n",
    "            return self.output            \n",
    "        elif (\"http://projecthydra.org/ns/auth/group#university_of_alberta\" in triple['object']['value']) or (\"http://projecthydra.org/ns/auth/group#registered\" in triple['object']['value']):\n",
    "            triple['object']['value'] = \"http://terms.library.ualberta.ca/authenticated\"\n",
    "            triple['object']['type'] = 'uri'\n",
    "            self.output.append(triple)\n",
    "            return self.output \n",
    "        else:\n",
    "            triple['object']['value'] = \"http://terms.library.ualberta.ca/private\"\n",
    "            triple['object']['type'] = 'uri'\n",
    "            self.output.append(triple)\n",
    "            return self.output\n",
    "    \n",
    "    def available(self, triple, objectType):\n",
    "        self.output.append(triple)\n",
    "        self.output.append(\n",
    "                        {\n",
    "                            'subject': {\n",
    "                                'value': triple['subject']['value'], # the subject of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'predicate': {\n",
    "                                'value': \"http://purl.org/dc/terms/accessRights\", # the predicate of the triple\n",
    "                                'type': 'uri'\n",
    "                            }, \n",
    "                            'object': {\n",
    "                                'value':\"http://terms.library.ualberta.ca/public\", # mapped uri\n",
    "                                'type': 'uri'\n",
    "                            }\n",
    "                        }        \n",
    "        )\n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  QUERY BUILDER\n",
    "##### Pulls current mappings from triplestore, dynamically builds queries in managable sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Query(object):\n",
    "    \"\"\" Query objects are dynamically generated, and contain SPARQL CONSTRUCT queries with input from the jupiter application profile \"\"\"\n",
    "    def __init__(self, objectType, sparqlData, sparqlTerms=sparqlTerms):\n",
    "        self.mapping = []\n",
    "        self.sparqlTerms = SPARQLWrapper(sparqlTerms)  # doesn't need to change (the terms store doesn't change)\n",
    "        self.sparqlData = SPARQLWrapper(sparqlData)  # sets the triple store from which to get data (simple, test, or dev)\n",
    "        self.sparqlResults = SPARQLWrapper(\"http://206.167.181.123:9999/blazegraph/namespace/results/sparql\")\n",
    "        self.sparqlTerms.setMethod(\"POST\")\n",
    "        self.sparqlData.setMethod(\"POST\")\n",
    "        self.sparqlResults.setMethod(\"POST\")\n",
    "        self.queries = {}\n",
    "        self.splitBy = {}\n",
    "        self.prefixes = \"\"\n",
    "        self.filename = \"\"\n",
    "        for ns in mig_ns:\n",
    "            self.prefixes = self.prefixes + \" PREFIX %s: <%s> \" % (ns['prefix'], ns['uri'])\n",
    "        self.getMappings()\n",
    "        self.generateQueries()\n",
    "\n",
    "    \n",
    "    def postResults(self):\n",
    "        directory = 'results/%s' % (self.objectType)\n",
    "        for (dirpath, dirnames, filenames) in os.walk(directory):\n",
    "            for filename in filenames:\n",
    "                with open(os.path.join(dirpath, filename), 'rb') as f:\n",
    "                    query = \"INSERT DATA {%s}\" % (f.read())\n",
    "                    self.sparqlResults.setReturnFormat(JSON)\n",
    "                    self.sparqlResults.setQuery(query)\n",
    "                    self.sparqlResults.query()                        \n",
    "                \n",
    "    \n",
    "    def getMappings(self):\n",
    "        if (self.objectType == 'collection') or (self.objectType == 'community') or (self.objectType == 'generic') or (self.objectType ==  'thesis'):\n",
    "            query = \"prefix ual: <http://terms.library.ualberta.ca/>SELECT * WHERE {GRAPH ual:%s {?newProperty ual:backwardCompatibleWith ?oldProperty} }\" % (self.objectType)\n",
    "            self.sparqlTerms.setReturnFormat(JSON)\n",
    "            self.sparqlTerms.setQuery(query)\n",
    "            results = self.sparqlTerms.query().convert()\n",
    "            for result in results['results']['bindings']:\n",
    "                self.mapping.append((result['newProperty']['value'], result['oldProperty']['value']))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def getSplitBy(self):\n",
    "        # base query only needs 3 prefixes appended to the \"select\" statement defined by the object\n",
    "        query = \"prefix dcterm: <http://purl.org/dc/terms/> prefix info: <info:fedora/fedora-system:def/model#> prefix ual: <http://terms.library.ualberta.ca/> %s\" % (self.select)\n",
    "        self.sparqlData.setReturnFormat(JSON)\n",
    "        self.sparqlData.setQuery(query)\n",
    "        results =  self.sparqlData.query().convert()\n",
    "        # iterate over query results\n",
    "        for result in results['results']['bindings']:\n",
    "            # the group is the two folders at the base of the pair tree, concatenated by an underscore\n",
    "            group = result['resource']['value'].split('/')[6]\n",
    "            # assign that parameter by which you want to search to that group\n",
    "            self.splitBy[group] = \"/\".join( result['resource']['value'].split('/')[:7] )# the stem of the resource [0] and the group number by which to save [1] (this is the first digit in the pair tree)\n",
    "            \n",
    "\n",
    "    def generateQueries(self):\n",
    "        pass\n",
    "    \n",
    "    def writeQueries(self):\n",
    "        filename = \"cache/%s.json\" % (self.objectType)\n",
    "        with open(filename, 'w+') as f:\n",
    "            json.dump([self.queries], f)\n",
    "               \n",
    "class Collection(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.objectType = 'collection'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; rdf:type pcdm:Collection\"\n",
    "        self.where = [\"WHERE { ?resource info:hasModel 'Collection'^^xsd:string . OPTIONAL { ?resource ualids:is_community 'false'^^xsd:boolean } . OPTIONAL { ?resource ualid:is_community 'false'^^xsd:boolean } . OPTIONAL { ?resource ual:is_community 'false'^^xsd:boolean }\"]\n",
    "        self.select = None\n",
    "        super().__init__(self.objectType, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        for where in self.where:\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (str(?%s)!='') }\" % (where, pair[1], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')), re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "            self.queries['collection'] = \"%s %s } %s }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries\n",
    "\n",
    "class Community(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.objectType = 'community'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; rdf:type pcdm:Object; rdf:type ual:Community\"\n",
    "        self.where = [\"WHERE { ?resource info:hasModel 'Collection'^^xsd:string ; OPTIONAL { ?resource ualids:is_community 'true'^^xsd:boolean } . OPTIONAL { ?resource ualid:is_community 'true'^^xsd:boolean } . OPTIONAL { ?resource ual:is_community 'true'^^xsd:boolean }\"]\n",
    "        self.select = None\n",
    "        super().__init__(self.objectType, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        for where in self.where:\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (str(?%s)!='') }\" % (where, pair[1], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')), re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "            self.queries['community'] = \"%s %s } %s }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries()\n",
    "\n",
    "class Generic(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.objectType = 'generic'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; dcterm:available ?available ; dcterm:accessRights ?visibility; rdf:type works:Work; rdf:type pcdm:Object ; bibo:owner ?owner ; <http://projecthydra.org/ns/auth/acl#embargoHistory> ?history ; <http://projecthydra.org/ns/auth/acl#visibilityAfterEmbargo> ?visAfter\"\n",
    "        self.where = []\n",
    "        self.select = \"SELECT distinct ?resource WHERE { ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type ?type . filter(str(?type) != 'Thesis'^^xsd:string) }\"\n",
    "        super().__init__(self.objectType, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()\n",
    "        query = \"%s %s\" % (self.prefixes, self.select)\n",
    "        for group in self.splitBy.keys():\n",
    "            where = \"WHERE {  ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type ?type . filter(str(?type) != 'Thesis'^^xsd:string) . FILTER (contains(str(?resource), '%s'))\" % (self.splitBy[group])\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (str(?%s)!='') }\" % (where, pair[1], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')), re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "            self.queries[group] =  \"%s %s } %s . OPTIONAL {?permission <http://www.w3.org/ns/auth/acl#accessTo> ?resource ; <http://www.w3.org/ns/auth/acl#mode> <http://www.w3.org/ns/auth/acl#Read> ; <http://www.w3.org/ns/auth/acl#agent> ?visibility } . OPTIONAL {?permission <http://www.w3.org/ns/auth/acl#accessTo> ?resource ; <http://www.w3.org/ns/auth/acl#mode> <http://www.w3.org/ns/auth/acl#Write> ; <http://www.w3.org/ns/auth/acl#agent> ?owner } . OPTIONAL { ?resource <http://projecthydra.org/ns/auth/acl#hasEmbargo> ?embargo } .OPTIONAL {?embargo <http://projecthydra.org/ns/auth/acl#embargoReleaseDate> ?available } .OPTIONAL {?embargo <http://projecthydra.org/ns/auth/acl#embargoHistory> ?history } .OPTIONAL {?embargo <http://projecthydra.org/ns/auth/acl#visibilityAfterEmbargo> ?visAfter } }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries()\n",
    "\n",
    "\n",
    "class Thesis(Query):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.objectType = 'thesis'\n",
    "        self.construct = \"CONSTRUCT { ?resource info:hasModel 'IRItem'^^xsd:string ; dcterm:available ?available ; dcterm:accessRights ?visibility; rdf:type works:Work ; rdf:type pcdm:Object ; rdf:type bibo:Thesis; bibo:owner ?owner ; <http://projecthydra.org/ns/auth/acl#embargoHistory> ?history ; <http://projecthydra.org/ns/auth/acl#visibilityAfterEmbargo> ?visAfter\"\n",
    "        self.where = []\n",
    "        self.select = \"SELECT distinct ?resource WHERE { ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type 'Thesis'^^xsd:string }\"\n",
    "        super().__init__(self.objectType, sparqlData)\n",
    "\n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()        \n",
    "        query = \"%s %s\" % (self.prefixes, self.select)\n",
    "        for group in self.splitBy.keys():\n",
    "            where = \"WHERE { ?resource info:hasModel 'GenericFile'^^xsd:string ; dcterm:type 'Thesis'^^xsd:string . FILTER (contains(str(?resource), '%s'))\" % (self.splitBy[group])\n",
    "            construct = self.construct\n",
    "            for pair in self.mapping:\n",
    "                construct = \"%s ; <%s> ?%s\" % (construct, pair[0], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "                where = \" %s . OPTIONAL { ?resource <%s> ?%s . FILTER (str(?%s)!='') } \" % (where, pair[1], re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')), re.sub(r'[0-9]+', '', pair[0].split('/')[-1].replace('#', '').replace('-', '')))\n",
    "            self.queries[group] =  \"%s %s } %s . OPTIONAL {?permission <http://www.w3.org/ns/auth/acl#accessTo> ?resource ; <http://www.w3.org/ns/auth/acl#mode> <http://www.w3.org/ns/auth/acl#Read> ; <http://www.w3.org/ns/auth/acl#agent> ?visibility } . OPTIONAL {?permission <http://www.w3.org/ns/auth/acl#accessTo> ?resource ; <http://www.w3.org/ns/auth/acl#mode> <http://www.w3.org/ns/auth/acl#Write> ; <http://www.w3.org/ns/auth/acl#agent> ?owner } . OPTIONAL { ?resource <http://projecthydra.org/ns/auth/acl#hasEmbargo> ?embargo } .OPTIONAL {?embargo <http://projecthydra.org/ns/auth/acl#embargoReleaseDate> ?available } .OPTIONAL {?embargo <http://projecthydra.org/ns/auth/acl#embargoHistory> ?history } .OPTIONAL {?embargo <http://projecthydra.org/ns/auth/acl#visibilityAfterEmbargo> ?visAfter } }\" % (self.prefixes, construct, where)\n",
    "        self.writeQueries()\n",
    "\n",
    "\n",
    "class File(Query):\n",
    "    def __init__(self, sparqlData, objectType, filterType):\n",
    "        self.rdfType = \"<http://www.w3.org/ns/ldp#NonRDFSource>\"\n",
    "        self.pcdmType = \"pcdm:File\"\n",
    "        self.construct = \"CONSTRUCT {?file rdf:type %s; rdf:type %s; pcdm:fileOf ?fileset ; iana:describedby ?fixty ; iana:describedby ?fcr ; fedora:hasParent ?fileset ; ?predicate ?object }\" % (self.rdfType, self.pcdmType)\n",
    "        self.where = \"WHERE { ?resource rdf:type %s . FILTER ( strEnds(str(?resource), '%s') && \" % (self.rdfType, self.filterType)\n",
    "        self.select = \"SELECT distinct ?resource WHERE  {?resource rdf:type %s . FILTER ( strEnds(str(?resource), '%s') ) }\" % (self.rdfType, self.filterType)\n",
    "        super().__init__(self.objectType, self.sparqlData)\n",
    "        \n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()\n",
    "        for group in self.splitBy.keys():\n",
    "            self.queries[group] = \"%s %s %s strStarts(str(?resource), '%s') ) . ?resource ?predicate ?object . FILTER ( !contains(str(?predicate), 'http://www.iana.org/assignments/relation/') && !contains(str(?predicate), 'http://fedora.info/definitions/v4/repository#hasFixityService')  && !contains(str(?predicate), 'http://fedora.info/definitions/v4/repository#hasParent') && str(?object)!='' )  . BIND(URI(CONCAT(str(?resource), '/file')) AS ?file)  . BIND(URI(CONCAT(str(?resource), '/fileset')) AS ?fileset) . BIND(URI(CONCAT(str(?resource), '/file/fcr:fixity')) AS ?fixity)  . BIND(URI(CONCAT(str(?resource), '/file/fcr:metadata')) AS ?fcr)}\" % (self.prefixes, self.construct, self.where, self.splitBy[group])\n",
    "        self.writeQueries()    \n",
    "\n",
    "\n",
    "class Fileset(Query):\n",
    "    def __init__(self, sparqlData, objectType, filterType):\n",
    "        self.pcdmType = \"works:Fileset\"\n",
    "        self.rdfType = \"<http://fedora.info/definitions/v4/repository#NonRdfSourceDescription>\"\n",
    "        self.construct = \"CONSTRUCT { ?parent pcdm:hasRelatedObject ?relatedObject . ?fileset rdf:type fedora:Container ; rdf:type fedora:Resource ; rdf:type pcdm:Object ; rdf:type works:FileSet; rdf:type <http://www.w3.org/ns/ldp#Container> ; rdf:type <http://www.w3.org/ns/ldp#RDFSource> ; pcdm:hasFile ?file ; pcdm:isMemberOf ?relatedObject ; fedora:hasParent ?relatedObject . ?relatedObject pcdm:relatedObjectOf ?parent ; rdf:type ual:%s ; rdf:type fedora:Container ; rdf:type fedora:Resource ; rdf:type pcdm:Object ; rdf:type works:Work ; rdf:type <http://www.w3.org/ns/ldp#Container> ; rdf:type <http://www.w3.org/ns/ldp#RDFSource> ; pcdm:hasMember ?fileset ; fedora:hasParent ?parent ; ?predicate ?object } \" % (self.filterType)\n",
    "        self.where = \"WHERE { ?resource rdf:type %s . FILTER ( strEnds(str(?resource), '%s/fcr:metadata') && \" % (self.rdfType, self.filterType)\n",
    "        self.select = \"SELECT distinct ?resource WHERE  {?resource rdf:type %s . FILTER ( strEnds(str(?resource), '%s/fcr:metadata') ) }\" % (self.rdfType, self.filterType)\n",
    "        super().__init__(self.objectType, self.sparqlData)\n",
    "        \n",
    "    def generateQueries(self):\n",
    "        self.getSplitBy()\n",
    "        for group in self.splitBy.keys():\n",
    "            self.queries[group] = \"%s %s %s strStarts(str(?resource), '%s')) . ?resource ?predicate ?object FILTER ( !contains(str(?predicate), 'http://www.iana.org/assignments/relation/') && !contains(str(?predicate), 'http://fedora.info/definitions/v4/repository#hasFixityService') && !contains(str(?predicate), 'http://fedora.info/definitions/v4/repository#hasParent') && !contains(str(?predicate), 'http://fedora.info/definitions/v4/repository#hasVersions') && str(?object)!='' )  . BIND(URI(REPLACE(STR(?resource), '/%s/fcr:metadata', '/fileset')) AS ?fileset) . BIND(URI(REPLACE(STR(?resource), '/%s/fcr:metadata', '/file')) AS ?file)  . BIND(URI(REPLACE(STR(?resource), '/%s/fcr:metadata', '')) AS ?parent) . BIND(URI(REPLACE(STR(?resource), '/fcr:metadata', '/relatedObject')) AS ?relatedObject) }\" % (self.prefixes, self.construct, self.where, self.splitBy[group], self.filterType, self.filterType, self.filterType)\n",
    "        self.writeQueries()     \n",
    "\n",
    "\n",
    "class era1statsFile(File):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'era1statsFile'        \n",
    "        self.filterType = \"era1stats\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "\n",
    "class era1statsFileset(Fileset):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'era1statsFileset'        \n",
    "        self.filterType = \"era1stats\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "        \n",
    "\n",
    "class fedora3foxmlFile(File):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'fedora3foxmlFile'        \n",
    "        self.filterType = \"fedora3foxml\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "        \n",
    "\n",
    "class fedora3foxmlFileset(Fileset):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'fedora3foxmlFileset'        \n",
    "        self.filterType = \"fedora3foxml\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "        \n",
    "\n",
    "class contentFile(File):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'contentFile'\n",
    "        self.filterType = \"content\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "        self.construct = \"CONSTRUCT { ?file rdf:type ldp:NonRDFSource ; rdf:type fedora:Binary ; rdf:type fedora:Resource ; rdf:type pcdm:File; pcdm:fileOf ?fileset; iana:describedby ?fcr ; ?predicate ?object }\"\n",
    "\n",
    "        \n",
    "class contentFileset(Fileset):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'contentFileset'\n",
    "        self.filterType = \"content\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "        self.construct = \"CONSTRUCT { ?fileset rdf:type fedora:Container ; rdf:type fedora:Resource ; rdf:type pcdm:Object ; rdf:type works:FileSet; rdf:type ldp:Container> ; rdf:type ldp:RDFSource> ; pcdm:hasFile ?file ; pcdm:memberOf ?parent ; ?predicate ?object }\"\n",
    "        \n",
    "        \n",
    "class characterizationFile(File):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'characterizationFile'\n",
    "        self.filterType = \"characterization\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "        self.construct = \"CONSTRUCT { ?file rdf:type ldp:NonRDFSource ; rdf:type fedora:Binary ; rdf:type fedora:Resource ; rdf:type pcdm:File; pcdm:fileOf ?fileset; iana:describedby ?fcr ; ?predicate ?object }\"\n",
    "\n",
    "    \n",
    "class characterizationFileset(Fileset):\n",
    "    def __init__(self, sparqlData):\n",
    "        self.sparqlData = sparqlData\n",
    "        self.objectType = 'characterizationFileset'\n",
    "        self.filterType = \"characterization\"\n",
    "        super().__init__(self.sparqlData, self.objectType, self.filterType)\n",
    "        self.construct = \"CONSTRUCT { ?fileset rdf:type %s; rdf:type %s; rdf:type ual:fits ; pcdm:hasFile ?file ; pcdm:memberOf ?parent ; iana:describes ?file ; ?predicate ?object }\" % (self.rdfType, self.pcdmType)      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  DATA TRANSPORT OBJECTS\n",
    "##### Runs a query, sends data to get transformed, saves data to appropriate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    def __init__(self, query, group, sparqlData, sparqlTerms, queryObject):\n",
    "        self.q = query\n",
    "        self.prefixes = queryObject.prefixes\n",
    "        self.group = group\n",
    "        self.sparqlData = sparqlData\n",
    "        self.sparqlTerms = sparqlTerms\n",
    "        self.output = []\n",
    "        self.graph = Graph()\n",
    "        self.objectType = queryObject.objectType\n",
    "        self.directory = \"results/%s/\" % (self.objectType)\n",
    "        self.filename = \"results/%s/%s.nt\" % (self.objectType, group)\n",
    "        if not os.path.exists(self.directory):\n",
    "            os.makedirs(self.directory)\n",
    "        \n",
    "\n",
    "    def transformData(self):\n",
    "        self.sparqlData.setReturnFormat(JSON)\n",
    "        self.sparqlData.setQuery(self.q)\n",
    "        # queries a batch of resources from this particular \"group\"\n",
    "        results = self.sparqlData.query().convert()['results']['bindings']\n",
    "        # iterates over each resource and performs transformations\n",
    "        for result in results:\n",
    "            result = TransformationFactory().getTransformation(result, self.objectType)\n",
    "            if isinstance(result, list):\n",
    "                for triple in result:\n",
    "                    s = URIRef(triple['subject']['value'])\n",
    "                    p = URIRef(triple['predicate']['value'])\n",
    "                    if triple['object']['type'] == 'uri':\n",
    "                        o = URIRef(triple['object']['value'])\n",
    "                    else:\n",
    "                        o = Literal(triple['object']['value'])\n",
    "                    self.graph.add((s, p, o))\n",
    "        self.graph.serialize(destination=self.filename, format='nt')\n",
    "        \n",
    "    def resultsToTriplestore(self, sparqlResults):\n",
    "        results = SPARQLWrapper(\"http://206.167.181.123:9999/blazegraph/namespace/results/sparql\")\n",
    "        results.setMethod('POST')\n",
    "        for line in self.streamOut:\n",
    "            results.setQuery(\"%s INSERT DATA {%s}\" % (self.prefixes, line))\n",
    "            results.query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QueryFactory():\n",
    "    @staticmethod\n",
    "    def getMigrationQuery(objectType, sparqlData):\n",
    "        \"\"\" returns a specified query object depending on the type passed in\"\"\"\n",
    "        if objectType == \"collection\": return Collection(sparqlData)\n",
    "        elif objectType == \"community\": return Community(sparqlData) \n",
    "        elif objectType == \"thesis\": return Thesis(sparqlData)\n",
    "        elif objectType == \"generic\": return Generic(sparqlData)\n",
    "        elif objectType == \"era1statsFile\": return era1statsFile(sparqlData)\n",
    "        elif objectType == \"era1statsFileset\": return era1statsFileset(sparqlData) \n",
    "        elif objectType == \"fedora3foxmlFile\": return fedora3foxmlFile(sparqlData)\n",
    "        elif objectType == \"fedora3foxmlFileset\": return fedora3foxmlFileset(sparqlData) \n",
    "        elif objectType == \"contentFile\": return contentFile(sparqlData)\n",
    "        elif objectType == \"contentFileset\": return contentFileset(sparqlData) \n",
    "        elif objectType == \"characterizationFile\": return characterizationFile(sparqlData)\n",
    "        elif objectType == \"characterizationFileset\": return characterizationFileset(sparqlData)\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TransformationFactory():\n",
    "    @staticmethod\n",
    "    def getTransformation(triple, objectType):\n",
    "        function = re.sub(r'[0-9]+', '', triple['predicate']['value'].split('/')[-1].replace('#', '').replace('-', ''))      \n",
    "        if function ==  \"accessRights\": return Transformation().accessRights(triple, objectType)\n",
    "        elif function ==  \"modelsmemberOf\": return Transformation().modelsmemberOf(triple, objectType)\n",
    "        elif function ==  \"modelshasMember\": return Transformation().modelshasMember(triple, objectType)\n",
    "        elif function == \"language\": return Transformation().language(triple, objectType)\n",
    "        elif function == \"type\": return Transformation().type(triple, objectType)\n",
    "        elif function ==  \"rights\": return Transformation().rights(triple, objectType)\n",
    "        elif function == \"license\": return Transformation().license(triple, objectType)\n",
    "        elif function == \"ontologyinstitution\": return Transformation().institution(triple, objectType)\n",
    "        elif function == \"available\": return Transformation().avaiable(triple, objectType)\n",
    "        else:\n",
    "            return [triple]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
