07075nam a2200505 i 4500001000800000005001700008008004100025020002500066020002500091035001700116039001200133040005100145050002600196082001600222090003200238100002900270245007900299264010400378300004500482336002600527337002800553338002700581490009200608500007600700504006600776505042000842505084101262505043102103505062402534505019703158505020203355505012003557505005103677520232903728530003206057596000706089650004506096700003806141700002806179830006706207830009206274949001906366926010006385758008406485680568020141120144011.0141120s2015    caua   foab   001 0 eng d  z9781627052627qebook  a9781627052610qprint  aocn981888738  aexclude  aCaBNVSLbengerdacCaBNVSLdCaBNVSLdAEUdAGPC 4aQA76.9.H85bL255 201504a004.019223  aQA 76.9 H85 L255 2015bAGPC1 aLalmas, Mounia,eauthor.10aMeasuring user engagement /cMounia Lalmas, Heather O'Brien, Elad Yom-Tov. 1aSan Rafael, California (1537 Fourth Street, San Rafael, CA  94901 USA) :bMorgan & Claypool,c2015.  axv, 116 pages :billustrations ;c24 cm.  atextbtxt2rdacontent  aunmediatedbn2rdamedia  avolumebnc2rdacarrier1 aSynthesis lectures on information concepts, retrieval, and services,x1947-9468 ;v# 38  aPart of: Synthesis digital library of engineering and computer science.  aIncludes bibliographical references (pages 93-112) and index.0 a1. Introduction and scope -- 1.1 Definitions -- 1.2 User engagement vs. user experience -- 1.3 Characteristics -- 1.3.1 Focused attention -- 1.3.2 Positive affect -- 1.3.3 Aesthetics appeal -- 1.3.4 Endurability -- 1.3.5 Novelty -- 1.3.6 Richness and control -- 1.3.7 Reputation, trust, and expectation -- 1.3.8 User context, motivation, incentives, and benefits -- 1.4 Measurements -- 1.5 Scope -- 1.6 Structure --8 a2. Approaches based on self-report methods -- 2.1 Self-report approaches -- 2.2 Advantages and limitations of self-report methods -- 2.2.1 Communication -- 2.2.2 Methodology bias -- 2.2.3 Reliability and validity -- 2.3 Interviews -- 2.3.1 Types of interviews -- 2.3.2 Applying interviews to measure user engagement -- 2.4 Think aloud and think after protocols -- 2.4.1 Think aloud -- 2.4.2 Think after -- 2.4.3 Relationship to user engagement -- 2.5 Questionnaires -- 2.6 Questionnaires for measuring user engagement -- 2.6.1 Survey to evaluate engagement -- 2.6.2 Engagement and influences on questionnaire -- 2.6.3 User engagement scale -- 2.6.4 eHealth engagement scale -- 2.7 Constructs related to user engagement -- 2.7.1 Mental workload -- 2.7.2 Disorientation -- 2.7.3 Playfulness -- 2.7.4 Cognitive absorption -- 2.8 Summary --8 a3. Approaches based on physiological measurements -- 3.1 Psychophysiological measurements -- 3.2 Facial expressions -- 3.3 Eye tracking -- 3.3.1 Eye tracking and search -- 3.3.2 Eye tracking and reading -- 3.3.3 Eye tracking and selection -- 3.3.4 Summary and limitations -- 3.4 Cursor tracking -- 3.4.1 Aligning eye gaze and mouse movement -- 3.4.2 Mouse movement in search -- 3.4.3 Mouse movement elsewhere -- 3.5 Summary --8 a4. Approaches based on web analytics -- 4.1 Intra-session vs. inter-session engagement -- 4.2 Some dimensions of online measurements -- 4.2.1 Dependence on the type of website -- 4.2.2 Dependence on the type of user -- 4.2.3 Dependence on the task -- 4.3 Large-scale measurements -- 4.4 Intra-session measurements -- 4.4.1 Dwell time and similar measures -- 4.4.2 Revisits to a site -- 4.4.3 Clickthrough rate -- 4.4.4 Number of pages viewed -- 4.4.5 Other measurements -- 4.5 Inter-session measurements -- 4.5.1 Direct value measurement -- 4.5.2 Total use measurement -- 4.5.3 Return-rate measurement -- 4.6 Summary --8 a5. Beyond desktop, single site, and single task -- 5.1 Measuring for online multitasking -- 5.2 Measuring on a network of sites -- 5.3 Measuring in mobile information seeking -- 5.4 Summary --8 a6. Enhancing the rigor of user engagement methods and measures -- 6.1 Scale -- 6.2 Setting -- 6.3 Temporality -- 6.4 Objectivity and subjectivity -- 6.5 Process- and product-based -- 6.6 Summary --8 a7. Conclusions and future research directions -- 7.1 Summary -- 7.2 Future research directions -- 7.3 Take-aways --8 aBibliography -- Authors' biographies -- Index.3 aUser engagement refers to the quality of the user experience that emphasizes the positive aspects of interacting with an online application and, in particular, the desire to use that application longer and repeatedly. User engagement is a key concept in the design of online applications (whether for desktop, tablet or mobile), motivated by the observation that successful applications are not just used, but are engaged with. Users invest time, attention, and emotion in their use of technology, and seek to satisfy pragmatic and hedonic needs. Measurement is critical for evaluating whether online applications are able to successfully engage users, and may inform the design of and use of applications. User engagement is a multifaceted, complex phenomenon; this gives rise to a number of potential measurement approaches. Common ways to evaluate user engagement include using self-report measures, e.g., questionnaires; observational methods, e.g. facial expression analysis, speech analysis; neuro-physiological signal processing methods, e.g., respiratory and cardiovascular accelerations and decelerations, muscle spasms; and web analytics, e.g., number of site visits, click depth. These methods represent various trade-offs in terms of the setting (laboratory versus "in the wild"), object of measurement (user behaviour, affect or cognition) and scale of data collected. For instance, small-scale user studies are deep and rich, but limited in terms of generalizability, whereas large-scale web analytic studies are powerful but negate users' motivation and context. The focus of this book is how user engagement is currently being measured and various considerations for its measurement. Our goal is to leave readers with an appreciation of the various ways in which to measure user engagement, and their associated strengths and weaknesses. We emphasize the multifaceted nature of user engagement and the unique contextual constraints that come to bear upon attempts to measure engagement in different settings, and across different user groups and web domains. At the same time, this book advocates for the development of "good" measures and good measurement practices that will advance the study of user engagement and improve our understanding of this construct, which has become so vital in our wired world.  aAlso issued electronically.  a28 0aHuman-computer interactionxMeasurement.1 aO'Brien, Heather,d1977-eauthor.1 aYom-Tov, Elad,eauthor. 0aSynthesis digital library of engineering and computer science. 0aSynthesis lectures on information concepts, retrieval, and services ;v# 38.x1947-9468  hUAINzSYNTHDIG  aQA 76.9 H85 L255 2015wLCc1i31847001272613lON_SHELFmGPRC_GPp$150.00rYsYtBOOKu2/17/201501ahttp://id.loc.gov/authorities/names/n2004002587bhttp://viaf.org/viaf/317174061