05696nam a2200589 i 4500001000800000005001700008006001900025007001500044008004100059020002500100020002500125024004300150035001700193039001200210040004500222050002400267082001600291090002500307100003700332245012100369246003800490264010400528300005700632336002100689337002600710338003200736490008600768500007600854504005500930505007000985505006101055505029001116505021301406505032501619505025001944505008202194506006002276520215202336588006004488596000704548650004204555650001904597650002104616650002604637700004004663830006704703830008604770856008604856949001904942926011004961758003505071679007920150117143140.0m    eo  d        cr cn |||m|||a150117s2015    caua   foab   000 0 eng d  a9781627055871qebook  z9781627055864qprint7 a10.2200/S00601ED1V01Y201410IVM0172doi  aocn900303151  aexclude  aCaBNVSLbengerdacCaBNVSLdCaBNVSLdAEU 4aTA1637b.M8532 201504a621.367223  aInternet AccessbAEU1 aMukhopadhyay, Sudipta.,eauthor.10aCombating bad weather.nPart II,pFog removal from image and video /cSudipta Mukhopadhyay, Abhishek Kumar Tripathi.30aFog removal from image and video. 1aSan Rafael, California (1537 Fourth Street, San Rafael, CA  94901 USA) :bMorgan & Claypool,c2015.  a1 online resource (xiii, 70 pages) :billustrations.  atext2rdacontent  aelectronic2isbdmedia  aonline resource2rdacarrier1 aSynthesis lectures on image, video, and multimedia processing,x1559-8144 ;v# 17  aPart of: Synthesis digital library of engineering and computer science.  aIncludes bibliographical references (pages 66-69).0 a1. Introduction -- 1.1 Video post-processing -- 1.2 Motivation --8 a2. Analysis of fog -- 2.1 Overview -- 2.1.1 Framework --8 a3. Dataset and performance metrics -- 3.1 Foggy images and videos -- 3.2 Performance metrics -- 3.2.1 Contrast gain (Cgain) -- 3.2.2 Percentage of the number of saturated pixels -- 3.2.3 Computation time -- 3.2.4 Root mean square (RMS) error -- 3.2.5 Perceptual quality metric (PQM) --8 a4. Important fog removal algorithms -- 4.1 Enhancement-based methods -- 4.2 Restoration-based methods -- 4.2.1 Multiple image-based restoration techniques -- 4.2.2 Single image-based restoration techniques --8 a5. Single-image fog removal using an anisotropic diffusion -- 5.1 Introduction -- 5.2 Fog removal algorithm -- 5.2.1 Initialization of airlight map -- 5.2.2 Airlight map refinement -- 5.2.3 Behavior of anisotropic diffusion -- 5.2.4 Restoration -- 5.2.5 Post-processing -- 5.3 Simulation and results -- 5.4 Conclusion --8 a6. Video fog removal framework using an uncalibrated single camera system -- 6.1 Introduction -- 6.2 Challenges of realtime implementation -- 6.3 Video fog removal framework -- 6.3.1 MPEG coding -- 6.4 Simulation and results -- 6.5 Conclusion --8 a7. Conclusions and future directions -- Bibliography -- Authors' biographies.  aAccess restricted to authorized users and institutions.3 aEvery year lives and properties are lost in road accidents. About one-fourth of these accidents are due to low vision in foggy weather. At present, there is no algorithm that is specifically designed for the removal of fog from videos. Application of a single-image fog removal algorithm over each video frame is a time-consuming and costly affair. It is demonstrated that with the intelligent use of temporal redundancy, fog removal algorithms designed for a single image can be extended to the real-time video application. Results confirm that the presented framework used for the extension of the fog removal algorithms for images to videos can reduce the complexity to a great extent with no loss of perceptual quality. This paves the way for the real-life application of the video fog removal algorithm. In order to remove fog, an efficient fog removal algorithm using anisotropic diffusion is developed. The presented fog removal algorithm uses new dark channel assumption and anisotropic diffusion for the initialization and refinement of the airlight map, respectively. Use of anisotropic diffusion helps to estimate the better airlight map estimation. The said fog removal algorithm requires a single image captured by uncalibrated camera system. The anisotropic diffusion-based fog removal algorithm can be applied in both RGB and HSI color space. This book shows that the use of HSI color space reduces the complexity further. The said fog removal algorithm requires pre- and post-processing steps for the better restoration of the foggy image. These pre- and post-processing steps have either data-driven or constant parameters that avoid the user intervention. Presented fog removal algorithm is independent of the intensity of the fog, thus even in the case of the heavy fog presented algorithm performs well. Qualitative and quantitative results confirm that the presented fog removal algorithm outperformed previous algorithms in terms of perceptual quality, color fidelity and execution time. The work presented in this book can find wide application in entertainment industries, transportation, tracking and consumer electronics.  aTitle from PDF title page (viewed on January 17, 2015).  a44 0aImage processingxDigital techniques. 0aDigital video. 0aComputer vision. 0aFogxPictorial works.1 aTripathi, Abhishek Kumar.,eauthor. 0aSynthesis digital library of engineering and computer science. 0aSynthesis lectures on image, video, and multimedia processing ;v# 17.x1559-8144403University of Alberta Accessuhttp://dx.doi.org/10.2200/S00601ED1V01Y201410IVM017  hUAINzSYNTHDIG  aInternet AccesswLCc1i6790079-1001lINTERNETmUAINTERNETrYsYtE-RESOURCEu1/28/2015xE-BOOKzSYNTHDIG01bhttp://viaf.org/viaf/313496974