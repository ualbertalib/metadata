<oai_dc:dc xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd"><dc:title>DNA barcoding media coverage in partner nations 2003-2013</dc:title><dc:identifier>https://doi.org/10.7939/DVN/AGVX6R</dc:identifier><dc:creator>Geary, Janis</dc:creator><dc:publisher>UAL Dataverse</dc:publisher><dc:description>We searched media databases LexisNexis, Factiva, and Canadian Newsstand for English language articles and limited our search to print and online newspaper coverage. We searched publications in iBOL partner nations from January 2003-Dec 2013; 2003 was the publication year of the first paper formally proposing DNA barcoding as a large-scale, standardized system for specimen identification (Hebert et al. 2003). We designed our search algorithms to capture articles with iterations of “Barcode of Life” or “DNA barcoding” found anywhere in the article. We manually excluded duplicated (identical publications obtained from more than one database) but not syndicated articles (similar/identical articles published in more than one newspaper under one management or derived from a paid service subscription, such as a newswire service), and non-print articles (for example, newswires that were not published). We also excluded a small number of articles in which DNA barcoding referred to activities other than the differentiation of species using a standardized short DNA sequence. For example, we excluded articles in which “DNA barcoding” described methods used to track an individual animal from farm to market. We developed a priori codes foR content analysis of each article based on descriptions of the iBOL Project and DNA barcoding from the iBOL website and other publications, including: article characteristics, iBOL missions and working groups, barcoding science, and genetic resource sharing. A single researcher read each article and assigned it codes. We assessed the reliability of this data collection method by having a second researcher code a subset of the articles (n=183) to estimate inter-rater agreement. Our acceptable level of agreement ranged from 70-99% for each category used in our analysis, and the average agreement was 87%.</dc:description><dc:subject>Social Sciences</dc:subject><dc:subject>DNA barcoding</dc:subject><dc:subject>science in the media</dc:subject><dc:subject>public communication of science</dc:subject><dc:language>English</dc:language><dc:contributor>Geary, Janis</dc:contributor></oai_dc:dc>